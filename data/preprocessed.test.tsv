Hierarchical Semantic Classification : Word Sense Disambiguation with World Knowledge .	task-specific and background data ; lexical semantic classification problems ; word sense disambiguation task ; hierarchical learning architecture ; task-specific training data ; background data ; learning architecture	<material> <task> <task> <method> <material> <material> <method>	6 0 1	we present a <method_6> for <task_1> that supplements <material_4> with <material_5> encoding general '' world knowledge '' . the <method_6> compiles knowledge contained in a dictionary-ontology into additional training data , and integrates <material_0> through a novel <method_3> . experiments on a <task_2> provide empirical evidence that this '' <method_3> '' outperforms a state-of-the-art standard '' flat '' one .	6 1 4 5 8 7 -1 0 3 7 -1 2 7 -1
Prior-free and prior-dependent regret bounds for Thompson Sampling .	prior-free and prior-dependent regret bounds ; stochastic multi-armed bandit problem ; distribution-free and distribution-dependent bounds ; non-bayesian stochastic bandit ; thompson sampling ; bayesian regret ; prior distribution ; reward distributions	<otherscientificterm> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 3 ; 7 2 1	we consider the <task_1> with a <otherscientificterm_6> on the <otherscientificterm_7> . we are interested in studying <otherscientificterm_0> , very much in the same spirit than the usual <otherscientificterm_2> for the <material_3> . we first show that <method_4> attains an optimal prior-free bound in the sense that for any <otherscientificterm_6> its <otherscientificterm_5> is bounded from above by 14 √ nk . this result is unimprovable in the sense that there exists a <otherscientificterm_6> such that any algorithm has a <otherscientificterm_5> bounded from below by 1 20 √ nk . we also study the case of <method_4> for the setting of bubeck et al. -lsb- 2013 -rsb- -lrb- where the optimal mean is known as well as a lower bound on the smallest gap -rrb- and we show that in this case the regret of <method_4> is in fact uniformly bounded over time , thus showing that <method_4> can greatly take advantage of the nice properties of these <method_4> .	1 6 7 10 8 -1 0 2 3 9 8 -1 4 5 8 -1 8 -1 8 -1
Speech processing and retrieval in a personal memory aid system for the elderly .	end-to-end spoken information retrieval solution ; ambient assisted living area ; speech processing components ; automatic speech processing ; speech processing flow ; elderly conversational speech ; personal audio archive ; spoken conversations ; speaker tracking ; audio ; transcription	<method> <material> <method> <task> <otherscientificterm> <material> <material> <material> <task> <material> <task>	10 1 8 ; 8 3 4 ; 10 3 4 ; 3 0 1	the paper presents a new application of <task_3> in the <material_1> , developed in the course of a three year research project . recording and automatic processing of <material_7> plays a major role in this solution enabling effective search in a <material_6> and fast browsing of conversations . processing of <material_5> recorded by a distant pda microphone poses a great challenge . the <otherscientificterm_4> includes <task_10> , <task_8> and combined indexing and search of spoken terms and participating speakers identity extracted from the <material_9> . we present the entire application and individual <method_2> as well as evaluation results of the individual components and of the <method_0> .	3 1 15 11 -1 7 6 11 -1 5 11 -1 4 10 8 9 12 13 14 11 -1 2 11 -1
Estimating speech recognition error rate without acoustic test data .	automatic speech recognition system ; word error rate ; probabilistic phoneme sequence conversion rules ; text test corpus ; acoustic test data ; phonemic transcription pairs ; phonemic confusion model ; grammar design ; probability distribution ; word hypotheses ; leave-one-out decoding ; acoustic data ; design cycle ; phonemic level ; confusion model ; dialog strategy	<method> <metric> <otherscientificterm> <material> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <method>	11 5 0 ; 13 2 11 ; 15 1 7 ; 5 0 14 ; 10 0 14 ; 10 0 5 ; 8 2 9 ; 1 0 0 ; 5 0 2 ; 3 5 0 ; 13 2 0	we address the problem of estimating the <metric_1> of an <method_0> without using <material_4> . this is an important problem which is faced by the designers of new applications which use <method_0> . quick estimate of <metric_1> early in the <otherscientificterm_12> can be used to guide the decisions involving <method_15> and <method_7> . our approach involves estimating the <otherscientificterm_8> of the <otherscientificterm_9> produced by the underlying <method_0> given the <material_3> . a critical component of this system is a <method_6> which seeks to capture the errors made by <method_0> on the <material_11> at a <otherscientificterm_13> . we use a <method_14> composed of <otherscientificterm_2> which are learned from <method_5> obtained by <method_10> of the training set . we show reasonably close estimation of <metric_1> when applying the system to test sets from different domains .	1 0 4 24 16 -1 16 -1 12 15 7 19 16 -1 8 9 3 23 26 16 -1 6 11 13 17 18 27 16 -1 14 20 21 22 25 16 -1 2 5 10 16 -1
Product of power spectrum and group delay function for speech recognition .	modified group delay function ; group delay function ; mel-frequency cepstral coefficients ; magnitude spectrum ; cepstral features ; phase spectrum ; speech signal ; speech recognition ; power spectrum ; features	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm>	8 0 4 ; 0 0 4 ; 2 0 0 ; 2 0 7	mel-frequency cepstral coefficients -lrb- <method_2> -rrb- are the most widely used <otherscientificterm_9> for <task_7> . these are derived from the <otherscientificterm_8> of the <material_6> . recently , the <otherscientificterm_4> derived from the <method_0> have been studied by murthy and gadde -lsb- 6 -rsb- for <task_7> . in this paper , we propose to use the product of the <otherscientificterm_8> and the <method_1> , and derive the <method_2> from the product <method_2> . this <method_2> combines the information from the <otherscientificterm_3> as well as the <otherscientificterm_5> . the <method_2> of the <method_0> are also investigated in this paper . results show that the <otherscientificterm_4> derived from the <otherscientificterm_8> perform better than that from the <method_0> , and the product <method_2> based <otherscientificterm_9> provide the best performance .	2 9 7 14 10 -1 8 6 10 -1 4 0 12 10 -1 1 10 -1 3 5 10 -1 13 10 -1 11 10 -1
PODs : Partially Ordered Delivery for 3D Scenes in Resource-Constrained Environments .	three-dimensional graphic scenes ; streaming 3d scenes ; 100-kb bit rate ; network bandwidth ; sender-driven mechanism ; decoding independencies ; resource-constrained environment ; heuristic	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method>	4 0 1 ; 3 0 0	three-dimensional -lrb- 3d -rrb- graphic scenes require considerable <otherscientificterm_3> to be transmitted and computing power to be rendered on users ' terminals . toward high-quality display in real time , we propose a <method_4> for <task_1> in a <otherscientificterm_6> . by pre-processing the database , objects in the scene are properly weighted upon their rendering importance , and their resolutions are selected accordingly to reduce the bit rate . partially ordered delivery is then performed using <method_5> between the objects . simulation results show the efficacy of the proposed <method_4> . for a test benchmark , for example , the proposed algorithm outperforms the comparing <method_7> by 4 db under a <otherscientificterm_2> .	3 10 8 -1 4 1 6 9 8 -1 8 -1 5 8 -1 8 -1 8 -1
Modeling Geometric Structure and Illumination Variation of a Scene from Real Images .	3d geometric information of the scene structure ; structure-from-motion and correlation-based stereo techniques ; low-dimensional linear space ; illumination conditions ; product advertisement ; basis images ; virtual reality ; real images ; geometric structure ; 3d space ; scene model ; object recognition ; photometric information ; position ; images	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <material> <material> <material> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material>	11 1 6 ; 3 3 14 ; 6 1 4 ; 3 2 10 ; 12 2 10 ; 0 0 10 ; 14 0 8	we present in this paper a system which automatically builds , from <material_7> , a <method_10> containing both <otherscientificterm_0> and its <otherscientificterm_12> under various <otherscientificterm_3> . the <otherscientificterm_8> is recovered from <material_14> taken from distinct viewpoints . <method_1> are used to match pix-els between <material_14> of different viewpoints and to reconstruct the scene in <otherscientificterm_9> . the <otherscientificterm_8> is extracted from <material_14> taken under different <otherscientificterm_3> -lrb- orientation , <otherscientificterm_13> and intensity of the light sources -rrb- . this is achieved by computing a <otherscientificterm_2> of the spatio-illumination volume , and is represented by a set of <material_5> . the model that has been built can be used to create realistic renderings from different viewpoints and <otherscientificterm_3> . applications include <task_11> , <material_6> and <material_4> .	7 10 0 12 3 19 20 21 15 -1 8 14 1 22 15 -1 9 15 -1 13 17 15 -1 2 5 15 -1 15 -1 16 18 15 -1
Contextual Models for Object Detection Using Boosted Random Fields .	conditional random field ; boosted random fields ; local image data ; graph structure ; dense graphs ; dense models ; contextual information ; additive model ; computational cascade ; graph fragments ; boosting ; detection ; accuracy ; speed	<otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <task> <metric> <metric>	10 0 1 ; 2 0 6 ; 6 0 11 ; 12 1 13 ; 9 3 7 ; 2 0 1 ; 1 0 3 ; 9 0 3	we seek to both detect and segment objects in images . to exploit both <material_2> as well as <otherscientificterm_6> , we introduce <method_1> , which uses <method_10> to learn the <otherscientificterm_3> and local evidence of a <otherscientificterm_0> . the <otherscientificterm_3> is learned by assembling <otherscientificterm_9> in an <method_7> . the connections between individual pixels are not very informative , but by using <otherscientificterm_4> , we can pool information from large regions of the image ; <method_5> also support efficient inference . we show how <otherscientificterm_6> from other objects can improve <task_11> performance , both in terms of <metric_12> and <metric_13> , by using a <method_8> . we apply our system to detect stuff and things in office and street scenes . 1 .	14 -1 2 6 1 10 3 0 15 16 20 21 14 -1 9 7 19 22 14 -1 4 5 14 -1 11 12 13 17 18 14 -1 8 14 -1 14 -1
The computational complexity of dominance and consistency in CP-nets .	cyclic dependency graphs ; strips planning ; general cp-nets ; computational complexity ; restricted classes ; dependency graph ; cp-nets ; dominance ; consistency ; pspace-complete	<otherscientificterm> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <material>	3 2 6	we investigate the <metric_3> of testing <otherscientificterm_7> and <metric_8> in <otherscientificterm_6> . up until now , the complexity of <otherscientificterm_7> has been determined only for <otherscientificterm_4> in which the <otherscientificterm_5> of the <otherscientificterm_6> is acyclic . however , there are preferences of interest that define <otherscientificterm_0> ; <otherscientificterm_0> are modeled with <material_2> . we show here that both <otherscientificterm_7> and <metric_8> testing for <material_2> are <material_9> . the reductions used in the proofs are from <method_1> , and thus establish strong connections between both areas .	3 7 8 6 11 10 -1 4 5 10 -1 0 2 10 -1 9 10 -1 1 10 -1
Automatic classification of oral/nasal snoring sounds based on the acoustic properties .	acoustic properties of snoring sounds ; k-nearest neighbor classifier ; cross validation evaluations ; sleep apnea syndrome ; sleep disordered breathing ; heavy snoring ; oral breathing ; benign snorers ; medical treatment ; oral snoring ; snoring sounds ; snoring	<material> <method> <metric> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <task> <material> <material> <otherscientificterm>	3 6 4 ; 9 0 8	snoring was once regarded as an indication of good sleep . but recently it has been known to be one of the symptoms which indicate <task_4> such as <otherscientificterm_3> . moreover , <otherscientificterm_5> caused by <material_6> sometimes leads <otherscientificterm_7> to be apneics . thus , it is important to detect <material_9> for <task_8> in the earlier stage , but we can not know our own snoring . this paper describes a method to detect <material_9> by extracting the <material_0> and using the <method_1> . as a result , over 92 % of <material_10> are successfully classified under the various <metric_2> .	12 -1 4 3 13 12 -1 5 6 7 12 -1 9 8 14 12 -1 0 1 12 -1 10 2 12 -1
Extracting Resource Terms for Sentiment Analysis .	positive or negative opinions ; real-life sentiment corpora ; iterative algorithm ; sentiment words ; sentiment analysis ; bipartite graph ; resource words ; gas ; documents ; sentiments ; water ; electricity	<otherscientificterm> <material> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 4 ; 11 1 7 ; 10 1 11	existing research on <task_4> mainly uses <otherscientificterm_3> and phrases to determine <otherscientificterm_9> expressed in <material_8> and sentences . techniques have also been developed to find such words and phrases using dictionaries and domain corpora . however , there are still other types of words and phrases that do not bear <otherscientificterm_9> on their own , but when they appear in some particular contexts , they imply <otherscientificterm_0> . one class of such words or phrases is those that express resources such as <otherscientificterm_10> , <otherscientificterm_11> , <otherscientificterm_7> , etc. . for example , '' this washer uses a lot of <otherscientificterm_11> '' is negative but '' this washer uses little <otherscientificterm_10> '' is positive . extracting such <otherscientificterm_6> and phrases are important for <task_4> . this paper formulates the problem based on a <method_5> and proposes a novel <method_2> to solve the problem . experimental results using diverse <material_1> show good results .	4 3 9 8 13 12 -1 12 -1 0 12 -1 10 11 7 14 15 12 -1 12 -1 12 -1 6 12 -1 5 2 12 -1
Regularized Laplacian Estimation and Fast Eigenvector Approximation .	regularized semi-definite programs ; 2-regularized or 1-regularized 2-regression ; data graph laplacian ; approximate eigenvector computation ; regularized estimation problem ; diffusion-based pagerank procedure ; mahoney-orecchia regularized sdp ; laplace prior ; lasso regression ; ridge regression ; coefficient vector ; regression problem ; nontrivial eigenvector ; diffusion-based procedures ; regularized estimates ; statistical regularization ; gaussian prior ; approximation procedure	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method>	10 0 11 ; 10 2 7 ; 9 1 8 ; 3 0 15	recently , mahoney and orecchia demonstrated that popular <method_13> to compute a quick approximation to the first <otherscientificterm_12> of a <otherscientificterm_2> exactly solve certain <otherscientificterm_0> . in this paper , we extend that result by providing a statistical interpretation of their <method_17> . our interpretation will be analogous to the manner in which <otherscientificterm_1> -lrb- often called <method_9> and <method_8> , respectively -rrb- can be interpreted in terms of a <otherscientificterm_16> or a <otherscientificterm_7> , respectively , on the <otherscientificterm_10> of the <task_11> . our framework will imply that the solutions to the <task_6> can be interpreted as <method_14> of the pseu-doinverse of the <otherscientificterm_2> . conversely , it will imply that the solution to this <task_4> can be computed very quickly by running , e.g. , the fast <method_5> for computing an approximation to the first <otherscientificterm_12> of the <otherscientificterm_2> . empirical results are also provided to illustrate the manner in which <method_3> implicitly performs <method_15> , relative to running the corresponding exact algorithm .	13 12 2 0 18 -1 17 18 -1 1 9 8 16 7 10 11 19 20 21 18 -1 6 14 18 -1 18 -1 4 5 22 18 -1
Human-Guided Machine Learning for Fast and Accurate Network Alarm Triage .	interactive machine learning systems ; triaging decisions of operators ; low-level device health information ; network alarm triage ; interactive machine learning ; rule-based tools ; alarm triage ; cuet ; grouping ; accuracy	<method> <method> <otherscientificterm> <task> <method> <method> <task> <method> <method> <metric>	7 0 6 ; 4 0 7	network <task_6> refers to <method_8> and prioritizing a stream of <otherscientificterm_2> to help operators find and fix problems . today , this process tends to be largely manual because existing <method_5> can not easily evolve with the network . we present <method_7> , a <method_7> that uses <method_4> to constantly learn from the <method_1> . <method_7> then uses that learning in novel visualizations to help them quickly and accurately triage alarms . unlike prior <method_0> , <method_7> handles a highly dynamic environment where the groups of interest are not known a priori and evolve constantly . our evaluations with real operators and data from a large network show that <method_7> significantly improves the speed and <metric_9> of <task_6> .	6 8 2 10 -1 5 10 -1 7 4 1 12 10 -1 10 -1 0 10 -1 11 10 -1
A New GPCA Algorithm for Clustering Subspaces by Fitting , Differentiating and Dividing Polynomials .	linear and polynomial algebra ; computer vision problems ; news video segmentation ; vanishing point detection ; clustering data ; iterative techniques ; subspace clustering ; distance function ; algebraic algorithms ; face clustering ; gpca algorithm ; polynomial factorization ; em ; polynomials ; subspace ; initialization ; subspaces ; k-subspace ; pca	<otherscientificterm> <task> <task> <task> <task> <method> <method> <otherscientificterm> <method> <task> <method> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <material> <method>	12 6 5 ; 17 6 5 ; 11 0 8 ; 18 0 1 ; 3 1 9 ; 3 6 1 ; 9 1 2 ; 10 4 8 ; 0 0 10 ; 2 6 1 ; 11 0 10 ; 17 1 12 ; 9 6 1 ; 10 0 6 ; 15 5 10	we consider the problem of <task_4> lying on multiple <otherscientificterm_16> of unknown and possibly different dimensions . we show that one can represent the <otherscientificterm_16> with a set of <method_13> whose derivatives at a data point give normal vectors to the <otherscientificterm_14> associated with the data point . since the <method_13> can be estimated linearly from data , <method_6> is reduced to classifying one point per <otherscientificterm_14> . we do so by choosing points in the data set that minimize a <otherscientificterm_7> . a basis for the complement of each <otherscientificterm_14> is then recovered by applying standard <method_18> to the set of derivatives -lrb- normal vectors -rrb- at those points . the final result is a new <method_10> for <method_6> based on simple <otherscientificterm_0> . our experiments show that our <method_10> outperforms existing <method_8> based on <method_11> and provides a good <method_15> to <method_5> such as <material_17> and <material_12> . we also present applications of <method_18> on <task_1> such as <task_3> , <task_9> , and <task_2> .	4 16 19 -1 13 14 19 -1 6 19 -1 7 19 -1 18 19 -1 28 33 19 -1 10 0 20 21 22 27 30 31 34 19 -1 8 11 15 5 17 12 23 24 25 26 29 32 19 -1
Estimation of semantic case of Japanese dialogue by use of distance derived from statistics of dependency .	statistics of dependent noun-particle-verb triples ; atr dialogue corpus ; measure of distance ; semantic cases ; noun-particle-verb triples ; consistency rates ; single-case clusters ; clustering analysis ; correlation analysis ; estimation accuracies ; accuracy	<material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <method> <otherscientificterm> <metric>	0 0 2 ; 4 3 1 ; 3 3 1 ; 10 5 8	in an attempt to estimate the <otherscientificterm_3> for <otherscientificterm_4> in the <material_1> , the authors propose a <otherscientificterm_2> based on <material_0> . a <method_7> of all the triples in the corpus was conducted using the <otherscientificterm_2> . competence of the proposed <otherscientificterm_2> is verified by examination of the distribution of the <otherscientificterm_6> . by use of the score derived from the <otherscientificterm_2> of the training corpus , the authors conducted the estimation of the correct semantic case for a given <otherscientificterm_4> in the test corpus . the result remarkably differentiates the particles with respect to the <otherscientificterm_9> . for instance , particle ` wo ' has accuracies over 80 % , while ` de ' has accuracies less than 40 % . the <method_8> between the <metric_10> and the <metric_5> indicates that the particles of higher consistency have also tendencies to higher accuracies .	3 4 1 2 0 12 13 14 11 -1 7 11 -1 6 11 -1 11 -1 9 11 -1 11 -1 15 11 -1
Moving shape dynamics : A signal processing perspective .	characterization and recognition of human motion sequences ; discrete wavelet transform ; discrete fourier transform ; general discrete time signals ; sophisticated signal processing techniques ; signal processing community ; human motion analysis ; signal transform methods ; data sets ; motion dynamics ; discriminating features ; articulated motion	<task> <method> <method> <otherscientificterm> <method> <method> <task> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 9 ; 2 6 7 ; 2 1 1 ; 1 0 0 ; 1 6 7 ; 10 0 9	this paper provides a new perspective on <task_6> , namely regarding human motions in video as <otherscientificterm_3> . while this seems an intuitive idea , research on <task_6> has attracted little attention from the <method_5> . <method_4> create important opportunities for new solutions to the problem of <task_6> . this paper investigates how the deformations of human silhouettes -lrb- or shapes -rrb- during <otherscientificterm_11> can be used as <otherscientificterm_10> to implicitly capture <otherscientificterm_9> . in particular , we demonstrate the applicability of two widely used <method_7> , namely the <method_2> and <method_1> , for <task_0> . experimental results show the effectiveness of the proposed method on two state-of-the-art <material_8> .	6 3 12 -1 5 4 12 -1 12 -1 11 10 9 13 18 12 -1 7 2 1 0 14 15 16 17 12 -1 12 -1
Improving channel selection of sound coding algorithms in cochlear implants .	resource-limited and time critical devices ; spectral maxima sound coding algorithms ; commercial cochlear implant processors ; commercial cochlear implant devices ; formant location of speech ; channel selection criterion ; sound coding framework ; cochlear implant users ; low signal-to-noise ratio ; n-of-m strategies ; time-frequency unit ; perception quality ; noise-dominant channels ; instantaneous signal ; speech intelligibility ; noise scenarios ; stimulation ; noise	<otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <otherscientificterm>	4 1 13 ; 1 0 14 ; 12 0 16 ; 7 5 1 ; 6 0 2 ; 14 5 1 ; 1 0 0 ; 9 0 3	spectral maxima sound coding algorithms , for example <method_9> , used in <method_3> rely on selecting channels with the highest energy in each frequency band . this <method_1> works well in quiet , but is inherently problematic in noisy conditions when <otherscientificterm_17> dominates the target , and <otherscientificterm_12> are mistakenly selected for <task_16> . a new <method_5> is proposed to addresses this shortcoming which adaptively assigns weights to each <otherscientificterm_10> based on the <otherscientificterm_4> and <otherscientificterm_13> to <otherscientificterm_17> ratio . the performance of the proposed <method_1> is evaluated acutely with three <otherscientificterm_7> in different <otherscientificterm_15> . results indicate that the proposed <method_1> improves <metric_14> and <metric_11> , particularly at <otherscientificterm_8> . significance of the proposed <method_1> lies in its ability to be integrated with the existing <method_6> employed within <method_2> , making <method_1> easier to adapt for <otherscientificterm_0> .	9 3 26 18 -1 1 17 12 16 21 18 -1 5 10 4 13 19 18 -1 7 15 22 18 -1 20 24 18 -1 14 11 8 23 25 18 -1
Joint disparity and optical flow by correspondence growing .	inherent search space reduction ; temporally coherent stereo disparity ; optical flow maps ; 3d velocity vector ; seed growing algorithm ; reconstructed 3d point ; binocular stereo setup ; disparity map ; scene flow ; stereo images ; optical flow ; images ; calibration	<task> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <task>	7 0 2 ; 4 0 6 ; 9 1 2	the <otherscientificterm_8> in <otherscientificterm_6> is estimated using a <method_4> . a pair of calibrated and synchronized cameras observe a scene and output a sequence of <material_11> . the algorithm jointly computes a <otherscientificterm_7> between the <material_9> and <material_2> between consecutive frames . having the <task_12> , this is a representation of the <otherscientificterm_8> , i.e. a <otherscientificterm_3> is associated with each <otherscientificterm_5> . the proposed algorithm starts from correspondence seeds and propagates the correspondences to the neighborhood . it is accurate for complex scenes with large motion and produces <otherscientificterm_1> and <otherscientificterm_10> results . the algorithm is fast due to <task_0> .	8 6 4 15 13 -1 11 13 -1 7 9 2 14 16 13 -1 12 3 5 13 -1 13 -1 1 10 13 -1 13 -1
In-service adaptation of multilingual hidden-Markov-models .	multilingual romanic/germanic seed model ; unsupervised online task adaptation ; automatic speech recognition system ; task independent seed model ; slovene digits multilingual modeling ; incremental online task adaptation ; task dependent models ; language dependent models ; slavic target task ; acoustic data ; hmm parameters ; recognition accuracy ; recognition	<method> <method> <task> <method> <task> <task> <method> <method> <task> <material> <otherscientificterm> <metric> <task>	12 0 5 ; 1 0 12 ; 11 5 4 ; 12 0 3 ; 0 0 8 ; 4 5 7 ; 11 5 7	in this paper we report on advances regarding our approach to porting an <task_2> to a new target task . in case there is not enough <material_9> available to allow for thorough estimation of <otherscientificterm_10> it is impossible to train an appropriate model . the basic idea to overcome this problem is to create a <method_3> that can cope with all tasks equally well . however , the performance of such generalist model is of course lower than the performance of <method_6> -lrb- if these were available -rrb- . so , the <method_3> is gradually enhanced by using its own <task_12> results for <task_5> . here , we use a <method_0> for a <task_8> . in tests on <task_4> yields the best <metric_11> compared to other <method_7> . applying <method_1> we observe a remarkable boost of <task_12> performance .	2 13 -1 9 10 13 -1 3 13 -1 6 13 -1 14 17 13 -1 12 5 18 13 -1 0 8 16 19 20 13 -1 4 11 7 15 13 -1
Lexicalized Phonotactic Word Segmentation .	dis-criminative model of boundary marking ; morphologically complex words ; inferring word boundaries ; transcribed adult conversations ; child language acquisition ; phone ngrams ; miniature datasets ; speech understanding ; phonetic transcriptions ; unsupervised algorithm ; arabic ; wordends ; english	<method> <otherscientificterm> <task> <material> <task> <material> <material> <task> <material> <method> <material> <method> <material>	12 1 10 ; 9 0 2 ; 11 0 4 ; 5 0 0	this paper presents a new <method_9> -lrb- <method_11> -rrb- for <task_2> from <material_3> . <material_5> before and after observed pauses are used to bootstrap a simple <method_0> . this fast algorithm delivers high performance even on <otherscientificterm_1> in <material_12> and <material_10> , and promising results on accurate <material_8> with extensive pronunciation variation . expanding training data beyond the traditional <material_6> pushes performance numbers well above those previously reported . this suggests that <method_11> is a viable model of <task_4> and might be useful in <task_7> .	9 11 2 3 5 15 13 -1 0 17 13 -1 1 12 10 8 14 13 -1 6 13 -1 4 7 16 13 -1
Perception of non-native phonemes in noise .	vowel and consonant identification ; native phoneme inventory ; american english phonemes ; multispeaker babble ; signal-to-noise ratios ; syllable position ; dutch listeners ; native listeners ; signal-to-noise ratio ; vowel ; consonant ; english	<task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <metric> <otherscientificterm> <otherscientificterm> <material>	10 1 9	we report an investigation of the perception of <material_2> by <material_6> proficient in <material_11> . listeners identified either the <otherscientificterm_10> or the <otherscientificterm_9> in most possible <material_11> cv and vc syllables . the syllables were embedded in <otherscientificterm_3> at three <otherscientificterm_4> -lrb- 16 db , 8 db , and 0 db -rrb- . effects of <metric_8> on <task_0> are discussed as a function of <otherscientificterm_5> and of relationship to the <otherscientificterm_1> . comparison of the results with previously reported data from <material_7> reveals that noise affected the responding of native and non-native listeners similarly .	2 6 11 12 -1 10 9 13 12 -1 3 4 12 -1 8 0 5 1 12 -1 7 12 -1
Track and Transfer : Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection .	pascal 2007 and 2010 datasets ; manually annotated bounding boxes ; pseudo ground-truth boxes ; tracked object boxes ; status quo approach ; bounding box annotations ; hough transform algorithm ; weakly-labeled image collection ; posi-tive/negative images ; discriminative regions ; weakly-labeled videos ; object detectors ; object detector ; weakly-labeled images ; pseudo gt	<material> <material> <otherscientificterm> <material> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <material> <task> <method> <material> <otherscientificterm>	6 0 14 ; 0 5 9 ; 6 0 12 ; 9 0 7	the <method_4> to training <task_11> requires expensive <otherscientificterm_5> . our <method_4> takes a markedly different direction : we transfer <material_3> from <material_10> to <material_13> to automatically generate <otherscientificterm_2> , which replace <material_1> . we first mine <otherscientificterm_9> in the <otherscientificterm_7> that frequently/rarely appear in the <material_8> . we then match those regions to videos and retrieve the corresponding <material_3> . finally , we design a <method_6> to vote for the best box to serve as the <otherscientificterm_14> for each image , and use <method_6> to train an <method_12> . together , <otherscientificterm_9> lead to state-of-the-art weakly-supervised detection results on the <material_0> .	4 11 5 15 -1 3 10 13 2 1 15 -1 9 7 8 19 15 -1 15 -1 6 14 12 16 18 15 -1 17 15 -1
Audiovisual emotional speech of game playing children : effects of age and culture .	cross-cultural perception studies ; classification accuracy ; pakistani children ; audiovisual speech ; pakistani	<task> <metric> <material> <material> <material>	1 5 2	in this paper we study how children of different age groups -lrb- 8 and 12 years old -rrb- and with different cultural backgrounds -lrb- dutch and <material_4> -rrb- signal positive and negative emotions in <material_3> . data was collected in an ethical way using a simple but surprisingly effective game in which pairs of participants have to guess whether an upcoming card will contain a higher or lower number than a reference card . the data thus collected was used in a series of <task_0> , in which dutch and <material_4> observers classified emotional expressions of dutch and <material_4> speakers . results show that <metric_1> is uniformly high for <material_2> , but drops for older and for winning dutch children 1 .	4 3 5 -1 5 -1 0 5 -1 6 5 -1
A comparison of EM and GMVQ in estimating Gauss mixtures : application to probabilistic image retrieval .	gauss mixture vector quantization ; gauss mixture ; expectation-maximization ; asymptotic likelihood approximation ; gm parameter values ; image retrieval ; convergence speed ; lloyd algorithm ; similarity criterion ; computational complexity ; em ; classification ; compression	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <task> <task>	9 2 10 ; 7 0 0	the <method_2> is the dominant algorithm for estimating the parameters of a <method_1> . recently , <method_0> based on the <method_7> has been applied successfully as an alternative for both <task_12> and <task_11> . we investigate the performance of the two algorithms for gm 's in <task_5> . the <otherscientificterm_3> is used as a <otherscientificterm_8> to compare gm 's directly . the two algorithms result in very close retrieval performance . we demonstrate that the closeness comes from the close mutual approximation of the estimated <otherscientificterm_4> and that the two algorithms have similar <otherscientificterm_6> . our analysis shows that <method_0> has roughly half the <metric_9> of <method_10> .	2 1 13 -1 0 7 12 11 15 13 -1 5 13 -1 3 8 13 -1 13 -1 4 6 13 -1 14 13 -1
Guiding Semi-Supervision with Constraint-Driven Learning .	semi-supervised learning algorithms ; natural language processing ; structured learning tasks ; information extraction domain ; labeled data ; machine learning ; domain knowledge ; classifiers	<method> <task> <task> <task> <material> <task> <otherscientificterm> <method>	0 0 7 ; 6 3 0 ; 0 0 4 ; 0 0 5 ; 0 0 1	over the last few years , two of the main research directions in <task_5> of <task_1> have been the study of <method_0> as a way to train <method_7> when the <material_4> is scarce , and the study of ways to exploit knowledge and global information in <task_2> . in this paper , we suggest a method for incorporating <otherscientificterm_6> in <method_0> . our novel framework unifies and can exploit several kinds of task specific constraints . the experimental results presented in the <task_3> demonstrate that applying constraints helps the model to generate better feedback during learning , and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks .	5 1 0 7 4 2 9 11 12 13 8 -1 6 10 8 -1 8 -1 3 8 -1
Kernel-Based Reinforcement Learning in Average-Cost Problems : An Application to Optimal Portfolio Choice .	parametric function approximators ; portfolio choice problem ; markov decision process ; learning algorithms ; reinforcement learning ; kernel-based approach ; neural networks ; temporal-diierence learning ; average-cost framework	<method> <task> <method> <method> <task> <method> <method> <method> <method>	5 0 4 ; 6 1 7 ; 3 4 5 ; 6 1 0	many approaches to <task_4> combine <method_6> or other <method_0> with a form of <method_7> to estimate the value function of a <method_2> . a signiicant disadvantage of those procedures is that the resulting <method_3> are frequently unstable . in this work , we present a new , <method_5> to <task_4> which overcomes this diiculty and provably converges to a unique solution . by contrast to existing <method_3> , our <method_5> can also be shown to be consistent in the sense that its costs converge to the optimal costs asymptotically . our focus is on learning in an <method_8> and on a practical application to the optimal <task_1> .	4 6 0 7 2 11 13 9 -1 3 9 -1 5 10 9 -1 12 9 -1 8 9 -1
A block-iterative quadratic signal recovery algorithm .	block-iterative parallel decomposition method ; quadratic signal recovery problems ; quadratic minimizations ; convex constraints ; block-parallel structure ; constraint enforcement ; approximate enforcement ; multi-constraint problem ; linearization ; deconvolution	<method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm>	0 0 7 ; 8 0 6 ; 3 0 0 ; 0 0 1	we propose a <method_0> to solve <task_1> under <otherscientificterm_3> . the idea of the <method_0> is to disintegrate the original <task_7> into a sequence of simple <otherscientificterm_2> over the intersection of two half-spaces constructed by linearizing blocks of constraints . the implementation of the <method_0> is quite exible thanks to its <otherscientificterm_4> . in addition a wide range of complex constraints can be incorporated since the <method_0> does not require exact <method_5> at each step but merely <method_6> via <otherscientificterm_8> . an application to <otherscientificterm_9> is demonstrated .	0 1 3 13 14 10 -1 7 2 11 10 -1 4 10 -1 5 6 8 12 10 -1 9 10 -1
An Optimization Method of Layered Neural Networks based on the Modified Information Criterion .	layered neural networks ; optimization method ; information criterion	<method> <method> <otherscientificterm>	1 0 0	this paper proposes a practical <method_1> for <method_0> , by which the optimal model and parameter can be found simultaneously . ` i \ te modify the conventional <otherscientificterm_2> into a differentiable function of parameters , and then , minimize <otherscientificterm_2> , while controlling <otherscientificterm_2> back to the ordinary form . effectiveness of this <method_1> is discussed theoretically and experimentally .	1 0 4 3 -1 2 3 -1 3 -1
Speech to speech translation system for monologues-data driven approach .	japanese-to-english speech-to-speech translation system ; realization of simultaneity ; tv news ; speaking styles ; commentary programs ; absolute size ; translation rules ; parallel corpus ; data-driven approach	<method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method>	4 6 0 ; 2 1 4	this paper describes ongoing research on a <method_0> for '' controlled monologue '' , such as <material_2> and <method_4> in which the <otherscientificterm_3> are controlled as a monologue . we have adopted the <method_8> since the tv programs in question cover a wide range of topics , and because it seems much too labor intensive to handcraft <otherscientificterm_6> . the <method_8> therefore requires a gigantic <material_7> for the target domain , although the <otherscientificterm_5> needed is not so easy to obtain . there are also difficulties inherent in monologue such as the need to handle long sentences , averaging over 25 words , and the <otherscientificterm_1> . these problems are presented in the light of our available corpora and we go on to present the kinds of problems we have to solve . finally , we present our prospective system architecture and introduce the present status of the work .	0 2 4 3 10 11 9 -1 8 6 9 -1 7 5 9 -1 9 -1 1 9 -1 9 -1
An efficient approach for designing nearly perfect-reconstruction cosine-modulated and modified DFT filter banks .	cosine-modulated and modified dft filter banks ; aliasing and amplitude errors ; maximum allowable aliasing ; perfect-reconstruction filter bank ; efficient two-step algorithms ; filter orders ; prototype filter ; nonlinear optimization ; stopband response ; filter lengths ; aliasing errors ; start-up solution ; minimax	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	7 0 11 ; 6 4 3 ; 6 0 0 ; 4 0 8	efficient two-step algorithms are described for optimizing the <otherscientificterm_8> of the <method_6> for <otherscientificterm_0> either in the <otherscientificterm_12> or in the least-mean-square sense subject to the maximum allowable <otherscientificterm_1> . the first step involves finding a good <method_11> using a simple technique . this <method_11> is improved in the second step by using <method_7> . several examples are included illustrating the flexibility of the proposed <method_11> for making compromises between the required <otherscientificterm_9> and the <otherscientificterm_1> . these examples show that by allowing very small amplitude and <otherscientificterm_10> , the stopband performance of the resulting <method_6> is significantly improved compared to the corresponding <material_3> . alternatively , the <otherscientificterm_5> and , consequently , the overall delay can be significantly reduced to achieve practically the same performance .	8 6 0 12 1 16 17 13 -1 11 13 -1 7 14 13 -1 9 13 -1 10 15 13 -1 3 13 -1
Improved speaker diarization of meeting speech with recurrent selection of representative speech segments and participant interaction pattern modeling .	analysis of meeting speech ; participant interaction pattern modeling ; robust cluster modeling perspective ; meeting speech corpora ; speaker diarization system ; di-arization error rate ; representative speech segments ; speech segments ; conversation patterns ; priori information ; speaker clustering ; clustering procedures	<task> <method> <otherscientificterm> <material> <method> <metric> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method>	6 0 10 ; 2 0 10 ; 4 0 0	in this work we describe two distinct novel improvements to our <method_4> , previously proposed for <task_0> . the first approach focuses on recurrent selection of <material_6> for <task_10> while the other is based on <method_1> . the former selects <otherscientificterm_7> with high relevance to <task_10> , especially from a <otherscientificterm_2> , and keeps updating them throughout <method_11> . the latter statistically models <otherscientificterm_8> between meeting participants and applies it as a <otherscientificterm_9> when refining diarization results . experimental results reveal that the two proposed approaches provide performance enhancement by 29.82 % -lrb- relative -rrb- in terms of <metric_5> in tests on 13 meeting excerpts from various <material_3> .	4 0 15 12 -1 6 10 1 13 12 -1 7 2 11 14 12 -1 8 9 12 -1 5 12 -1
Modeling Complex Cells in an Awake Macaque during Natural Image Viewing .	classical energy mechanism ; nonclassical gain control ; suppressive surround effects ; delayed suppressive surround ; visual area vi ; natural vision ; natural images ; energy mechanism ; stimulus sequence	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <method> <material>	1 0 0	we model the responses of cells in <otherscientificterm_4> during <task_5> . our model consists of a <method_0> whose output is divided by <otherscientificterm_1> and texture contrast mechanisms . we apply this model to review movies , a <material_8> that replicates the stimulation a cell receives during free viewing of <material_6> . data were collected from three cells using five different review movies , and the model was fit separately to the data from each movie . for the <method_7> alone we find modest but significant correlations -lrb- re = 0.41 , 0.43 , 0.59 , 0.35 -rrb- between model and data . these correlations are improved somewhat when we allow for <otherscientificterm_2> -lrb- re + g = 0.42 , 0.56 , 0.60 , 0.37 -rrb- . in one case the inclusion of a <otherscientificterm_3> dramatically improves the fit to the data by modifying the time course of the model 's response .	4 5 9 -1 0 1 10 9 -1 8 6 9 -1 9 -1 7 9 -1 9 -1 2 9 -1
Speech analysis with the short-time chirp transform .	blurry harmonic representation ; pitch tendency segment-by-segment ; time-frequency analysis tool ; short-time fourier transform ; time-frequency techniques ; analysis tool ; filtering purposes ; inconsistent bins ; time-frequency localization ; fourier analysis ; spectral representation ; quadratic chirps ; voiced speech	<method> <otherscientificterm> <method> <method> <method> <method> <task> <otherscientificterm> <task> <method> <method> <otherscientificterm> <material>	3 6 2 ; 11 3 3 ; 3 6 5 ; 12 0 0 ; 5 0 6	the most popular <method_2> , the <method_3> , suffers from <method_0> when <material_12> undergoes changes in pitch . these relatively fast variations lead to <otherscientificterm_7> in frequency domain and can not be accurately described by the <method_9> with high resolution both in time and frequency . in this paper a new <method_5> , called <method_3> is presented , offering more precise time-frequency representation of speech signals . the base of this <method_3> is composed of <otherscientificterm_11> that follow the <otherscientificterm_1> . comparative results between the proposed <method_3> and popular <method_4> reveal an improvement in <task_8> and finer <method_10> . since the signal can be resynthesized from its <method_3> , the proposed <method_5> is also suitable for <task_6> .	2 3 0 12 14 17 13 -1 7 9 13 -1 5 16 13 -1 11 1 15 13 -1 4 8 10 13 -1 18 13 -1
A one-microphone algorithm for reverberant speech enhancement .	estimating reverberation time ; reverberant speech enhancement method ; pitch-based reverberation measure ; reverberant speech enhancement ; relative time lags ; reverberation effects ; harmonic structure ; pitch strength ; echo components ; reverberation	<task> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm>	2 0 0	we present an algorithm for <task_3> using one microphone . we first propose a novel <method_2> for <task_0> based on the distribution of <otherscientificterm_4> . this measure of <metric_7> correlates with <otherscientificterm_9> and decreases systematically as detrimental effects of <otherscientificterm_9> on <otherscientificterm_6> increase . then a <method_1> is developed to estimate and subtract later <method_8> . the results show that our approach appreciably reduces <otherscientificterm_5> .	3 10 -1 2 0 4 11 10 -1 7 9 6 10 -1 1 8 10 -1 5 10 -1
Fundamental properties of non-negative impulse response filters - Theoretical bounds I.	non-negative impulse response filter ; geometrically spaced frequency regions ; maximally allowable power attenua-tion ; continuous and discrete-time domains ; power spectral attenuation ; power spectral gain ; frequency-domain bounds ; upper-bounds	<method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 0	this paper presents several fundamental <otherscientificterm_6> for a <method_0> . <otherscientificterm_7> on <otherscientificterm_4> and <otherscientificterm_5> in <otherscientificterm_1> are derived , when <otherscientificterm_4> near frequency zero is limited . by analyzing the tightnesses of these bounds , the relationship between the <otherscientificterm_2> and gain is also treated . all results hold for both <material_3> .	6 0 7 9 8 -1 4 5 1 8 -1 2 8 -1 3 8 -1
Language Splitting and Relevance-Based Belief Change in Horn Logic .	relevance-based partial meet horn contraction operator ; parikh 's relevance criterion ; partial meet horn contraction ; parikh 's relevance postulate ; classical propositional logic ; propositional horn logic ; parallel interpolation theorem ; horn formulae ; horn logic ; representation theorem	<method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method>	1 0 0 ; 6 0 8	this paper presents a framework for relevance-based belief change in <otherscientificterm_5> . we firstly establish a <method_6> for <method_8> and show that parikh 's finest splitting theorem holds with <method_7> . by reformulating <otherscientificterm_1> in the setting of horn belief change , we construct a <method_0> and provide a <method_9> for the operator . interestingly , we find that this <method_0> can be fully characterised by delgrande and wassermann 's postulates for <task_2> as well as <otherscientificterm_3> without requiring any change on the postulates , which is qualitatively different from the case in <otherscientificterm_4> .	5 10 -1 6 8 7 12 10 -1 1 0 9 11 10 -1 2 3 4 10 -1
Study on prosodic boundary location in Chinaese mandarin .	large speech corpus ; serial acoustic parameter ; prosodic boundary type ; prosodic boundary location ; acoustic parameter ; prosodic boundary ; syllable duration ; speech recognition ; acoustic feature ; statistical model ; boundary efficiency ; intensity ; mandarin ; parameter ; cart	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <method> <metric> <otherscientificterm> <material> <otherscientificterm> <method>	14 0 2 ; 1 0 14 ; 6 1 11 ; 9 0 7	in this paper , based on <material_0> with prosodic structure label -lrb- asccd -rrb- , we present some statistic result on <otherscientificterm_4> at <material_5> . we study the <otherscientificterm_6> , <otherscientificterm_11> and pitch at the boundary and select a <otherscientificterm_1> to train a <method_14> . then the <method_14> was employed to classify the <otherscientificterm_2> . the result shows that the <otherscientificterm_13> characterize <otherscientificterm_8> of the <material_5> and the trained <method_14> can classify different <metric_10> . so it is possible to train <method_9> for <otherscientificterm_3> in <material_12> , this is very important both for <task_7> and synthesis .	0 4 5 15 -1 6 11 1 14 17 18 15 -1 2 16 15 -1 13 8 10 15 -1 9 3 12 7 19 15 -1
Super-resolving Noisy Images .	noise-free , high resolution image ; noisy and the denoised images ; super-resolution algorithm ; part-recovery and part-synthesis of textures ; patch-similarity based sr algorithm ; missing textural details ; denoising step ; hr domain ; numerical metrics ; noisy image ; processing pipeline ; denoising algorithm ; lost signal ; convex combination ; denoising algorithms ; hr versions ; sr step ; textural details ; textural signal ; hr image ; image ; noise	<material> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <metric> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 20 ; 5 3 7 ; 14 0 5	our goal is to obtain a <material_0> , from an observed , noisy , low resolution -lrb- lr -rrb- <otherscientificterm_20> . the conventional approach of preprocessing the <otherscientificterm_20> with a <method_11> , followed by applying a <method_2> , has an important limitation : along with <otherscientificterm_21> , some high frequency content of the <otherscientificterm_20> -lrb- particularly textural detail -rrb- is invariably lost during the <otherscientificterm_6> . this ` denoising loss ' restricts the performance of the subsequent <otherscientificterm_16> , wherein the challenge is to synthesize such <otherscientificterm_17> . in this paper , we show that high frequency content in the <material_9> -lrb- which is ordinarily removed by <method_14> -rrb- can be effectively used to obtain the <otherscientificterm_5> in the <material_7> . to do so , we first obtain <method_15> of both the <material_1> , using a <method_4> . we then show that by taking a <otherscientificterm_13> of orientation and frequency selective bands of the noisy and the denoised <otherscientificterm_19> , we can obtain a desired <otherscientificterm_19> where -lrb- i -rrb- some of the <otherscientificterm_18> lost in the <otherscientificterm_6> is effectively recovered in the <material_7> , and -lrb- ii -rrb- additional textures can be easily synthesized by appropriately constraining the parameters of the <otherscientificterm_13> . we show that this <otherscientificterm_3> through our algorithm yields <otherscientificterm_19> that are visually more pleasing than those obtained using the conventional <method_10> . furthermore , our results show a consistent improvement in <metric_8> , further corroborating the ability of our algorithm to recover <otherscientificterm_12> .	0 20 22 -1 11 2 21 6 23 22 -1 16 17 22 -1 24 25 22 -1 9 14 5 7 22 -1 15 1 4 22 -1 13 19 18 22 -1 22 -1
Why Most Decisions Are Easy in Tetris - And Perhaps in Other Sequential Decision Problems , As Well .	sequential decision problems ; learning algorithms ; evaluation function ; cumulative dominance ; decision problems ; domain knowledge ; dominance ; tetris ; noncompensation	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	6 1 3 ; 3 1 8 ; 5 3 1	we examined the sequence of <task_4> that are encountered in the game of <method_7> and found that most of the problems are easy in the following sense : one can choose well among the available actions without knowing an <otherscientificterm_2> that scores well in the game . this is a consequence of three conditions that are prevalent in the game : simple <otherscientificterm_6> , <otherscientificterm_3> , and <otherscientificterm_8> . these conditions can be exploited to develop faster and more effective <method_1> . in addition , they allow certain types of <otherscientificterm_5> to be incorporated with ease into a <method_1> . among the <otherscientificterm_0> we encounter , it is unlikely that <method_7> is unique or rare in having these properties .	4 7 2 9 -1 6 3 8 10 11 9 -1 1 9 -1 5 12 9 -1 9 -1
Raw-to-Raw : Mapping between Image Sensor Color Responses .	global and illumination-specific manner ; minimally processed sensor responses ; images of arbitrary scenes ; linear and non-linear transformations ; computer vision tasks ; illumination-independent mapping approach ; sensors spectral sensitivities ; camera images ; raw-rgb values ; camera manufacturers ; illumination-specific mappings ; consumer cameras ; raw format ; raw values ; mapping strategies ; raw images ; raw image ; white-balancing ; illuminations ; mapping	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <method> <otherscientificterm> <material> <otherscientificterm> <material> <method> <material> <material> <material> <method> <material> <material> <method> <otherscientificterm> <task>	7 0 4 ; 3 6 14 ; 11 5 5 ; 2 5 5 ; 2 1 18 ; 11 1 2 ; 12 0 4 ; 17 0 5 ; 3 1 0	camera images saved in <material_12> are being adopted in <task_4> since <material_13> represent <otherscientificterm_1> . <material_9> , however , have yet to adopt a standard for <material_15> and current <otherscientificterm_8> are device specific due to different <otherscientificterm_6> . this results in significantly different <material_15> for the same scene captured with different cameras . this paper focuses on estimating a <task_19> that can convert a <material_16> of an arbitrary scene and illumination from one camera 's raw space to another . to this end , we examine various <method_14> including <otherscientificterm_3> applied both in a <otherscientificterm_0> . we show that <method_10> give the best result , however , at the expense of requiring a large number of transformations . to address this issue , we introduce an <method_5> that uses <method_17> to assist in reducing the number of required transformations . we show that this <method_5> achieves state-of-the-art results on a range of <material_11> and <material_2> and <otherscientificterm_18> .	12 4 13 1 9 21 27 20 -1 15 8 6 20 -1 20 -1 19 16 20 -1 14 3 0 22 29 20 -1 10 20 -1 28 20 -1 5 17 23 24 25 26 20 -1
Terminological Logics with Modal Operators .	representation of multi-agent environments ; terminological knowledge representation formalisms ; terminological knowledge representation languages ; modal logics ; modal operators ; domain assumption ; concept expressions ; application domain ; belief ; intentions ; syntax ; notions	<task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 1 9 ; 8 6 11 ; 4 3 2 ; 9 6 11	terminological knowledge representation formalisms can be used to represent objective , time-independent facts about an <material_7> . <otherscientificterm_11> like <otherscientificterm_8> , <otherscientificterm_9> , and time which are essential for the <task_0> can only be expressed in a very limited way . for such notions , <otherscientificterm_3> with possible worlds semantics provides a formally well-founded and well-investigated basis . this paper presents a framework for integrating <method_4> into <method_2> . these <method_4> can be used both inside of <otherscientificterm_6> and in front of termino-logical and assertional axioms . we introduce <otherscientificterm_10> and semantics of the extended language , and show that satisfiability of finite sets of formulas is decidable , provided that all <method_4> are interpreted in the basic logic k , and that the increasing <otherscientificterm_5> is used .	7 11 12 -1 8 9 0 13 14 16 12 -1 3 12 -1 4 2 15 12 -1 6 12 -1 10 12 -1
Selection of Effective Contextual Information for Automatic Synonym Acquisition .	contextual clues of words ; contextual information selection ; automatic synonym acquisition ; modification categories ; contextual information ; lexical knowledge ; sentence co-occurrence ; word relationships ; dependency relations ; subject-object combination ; contex-tual information ; proximity ; synonyms	<otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 1 11 ; 11 6 7 ; 7 0 1 ; 6 6 7	various methods have been proposed for <task_2> , as <otherscientificterm_12> are one of the most fundamental <otherscientificterm_5> . whereas many methods are based on <otherscientificterm_0> , little attention has been paid to what kind of categories of <otherscientificterm_10> are useful for the purpose . this study has experimentally investigated the impact of <task_1> , by extracting three kinds of <otherscientificterm_7> from corpora : dependency , <otherscientificterm_6> , and <otherscientificterm_11> . the evaluation result shows that while dependency and <otherscientificterm_11> perform relatively well by themselves , combination of two or more kinds of <otherscientificterm_4> gives more stable performance . we 've further investigated useful selection of <otherscientificterm_8> and <otherscientificterm_3> , and it is found that modification has the greatest contribution , even greater than the widely adopted <otherscientificterm_9> .	2 12 5 13 -1 0 10 13 -1 1 7 6 11 14 15 16 17 13 -1 4 13 -1 13 -1
Transition Constraints for Parallel Planning .	domain transition graphs ; parallel planning ; planner named transition constraints ; minion the constraint solver ; cell values ; wild cards ; constraint model ; table constraints ; constraint-based planners ; parallel plan ; tcpp	<otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method>	7 0 10 ; 7 0 6 ; 3 0 6 ; 3 0 10 ; 6 4 8 ; 10 0 6 ; 0 0 6	we present a <method_2> for <task_1> . <method_10> constructs a new <method_6> from <otherscientificterm_0> of a given planning problem . <method_10> encodes the <method_6> by using <otherscientificterm_7> that allow do n't cares or <otherscientificterm_5> as <otherscientificterm_4> . <method_10> uses <method_3> to solve the <method_6> and returns the <otherscientificterm_9> . empirical results exhibit the efficiency of our <method_6> over state-of-the-art <method_8> .	2 1 10 11 -1 6 0 18 11 -1 7 5 4 12 13 11 -1 3 9 14 15 17 11 -1 8 16 11 -1
Unsupervised Discovery of Action Classes .	linear programming relaxation technique ; clustering and image labeling ; unsupervised learning approach ; human figures ; coarse shape ; pruning method ; action classes ; spectral clustering ; training images ; images	<method> <task> <method> <material> <otherscientificterm> <method> <otherscientificterm> <method> <material> <material>	9 0 5	in this paper we consider the problem of describing the action being performed by <material_3> in still <material_9> . we will attack this problem using an <method_2> , attempting to discover the set of <otherscientificterm_6> present in a large collection of <material_8> . these <otherscientificterm_6> will then be used to label test <material_9> . our <method_2> uses the <otherscientificterm_4> of the <material_3> to match pairs of <material_9> . the distance between a pair of <material_9> is computed using a <method_0> . this is a computationally expensive process , and we employ a fast <method_5> to enable its use on a large collection of <material_9> . <method_7> is then performed using the resulting distances . we present <task_1> results on a variety of datasets .	3 9 10 -1 2 6 8 10 -1 10 -1 4 10 -1 0 10 -1 5 11 10 -1 7 10 -1 10 -1
Self-Training for Enhancement and Domain Adaptation of Statistical Parsers Trained on Small Datasets .	seed and test data ; manually annotated seed data ; statistical pcfg parsers ; domain adaptation case ; out-of-domain adaptation scenario ; in-domain case ; annotation cost ; annotated data ; self-training ; parsers ; parser	<material> <material> <method> <task> <task> <material> <metric> <material> <method> <method> <method>	7 0 2 ; 6 5 5 ; 8 0 10 ; 0 1 4	creating large amounts of <material_7> to train <method_2> is expensive , and the performance of such <method_9> declines when training and test data are taken from different domains . in this paper we use <method_8> in order to improve the quality of a <method_10> and to adapt <method_10> to a different domain , using only small amounts of <material_1> . we report significant improvement both when the <material_0> are in the same domain and in the <task_4> . in particular , we achieve 50 % reduction in <metric_6> for the <material_5> , yielding an improvement of 66 % over previous work , and a 20-33 % reduction for the <task_3> . this is the first time that <method_8> with small labeled datasets is applied successfully to these tasks . we were also able to formulate a characterization of when <method_8> is valuable .	7 2 9 12 11 -1 8 10 1 14 11 -1 0 4 15 11 -1 6 5 13 11 -1 3 11 -1 11 -1
Mechanical vocal-tract models for speech dynamics .	sliding three-tube model ; umeda & teranishi model ; s3t and flexible-tongue models ; human vocal tract ; physical models ; dynamic models ; flexible-tongue model ; sliding tongue ; head-shaped model ; computer-controlled version	<method> <method> <method> <material> <method> <method> <method> <otherscientificterm> <method> <method>	6 6 5 ; 0 6 5 ; 0 1 6 ; 7 0 8	arai has developed several <method_4> of the <material_3> for education and has reported that <method_4> are intuitive and helpful for students of acoustics and speech science . we first reviewed <method_5> , including the <method_0> and the <method_6> . we then developed a <method_8> with a <otherscientificterm_7> , which has the advantages of both the <method_2> . we also developed a <method_9> of the <method_1> , as the original <method_8> was hard to manipulate precisely by hand . these <method_8> are useful when teaching the dynamic aspects of speech .	4 3 10 -1 5 0 6 11 12 13 10 -1 8 7 2 14 10 -1 9 1 10 -1 10 -1
Linear Classification and Selective Sampling Under Low Noise Conditions .	low noise condition ; selective sampling versions ; margin-based algorithm ; convergence rate ; selective sampling ; bayes risk ; selective sampler ; classification problems ; textual data ; logarithmic factors ; instance distribution ; classifier	<otherscientificterm> <method> <method> <metric> <task> <metric> <method> <task> <material> <otherscientificterm> <task> <method>	3 5 5 ; 9 0 6 ; 2 0 7 ; 2 0 4 ; 8 5 6 ; 6 4 5	we provide a new analysis of an efficient <method_2> for <task_4> in <task_7> . using the so-called tsybakov <otherscientificterm_0> to parametrize the <task_10> , we show bounds on the <metric_3> to the <metric_5> of both the fully supervised and the <method_1> of the basic algorithm . our analysis reveals that , excluding <otherscientificterm_9> , the average risk of the <method_6> converges to the <metric_5> at rate n − -lrb- 1 + α -rrb- -lrb- 2 + α -rrb- / 2 -lrb- 3 + α -rrb- where n denotes the number of queried labels , and α > 0 is the exponent in the <otherscientificterm_0> . for all α > √ 3 − 1 ≈ 0.73 this <metric_3> is asymptotically faster than the rate n − -lrb- 1 + α -rrb- / -lrb- 2 + α -rrb- achieved by the fully supervised version of the same <method_11> , which queries all labels , and for α → ∞ the two rates exhibit an exponential gap . experiments on <material_8> reveal that simple variants of the proposed <method_6> perform much better than popular and similarly efficient competitors .	2 4 7 15 16 12 -1 0 10 3 5 1 13 12 -1 9 6 14 18 12 -1 12 -1 11 17 12 -1
Phone set construction based on context-sensitive articulatory attributes for code-switching speech recognition .	hierarchical phone unit clustering algorithm ; cross-lingual context-sensitive articulatory features ; phone set construction methods ; large-scale code-switching speech database ; code-switching speech recognition ; phone set construction ; data sparseness problem ; model training ; model construction ; acoustic features ; bilingual speakers ; distance measure ; data-driven approach ; bilinguals ; kl-divergence	<method> <otherscientificterm> <method> <material> <task> <task> <task> <task> <task> <otherscientificterm> <material> <metric> <method> <otherscientificterm> <method>	12 0 5 ; 1 0 12 ; 12 4 2 ; 9 3 11 ; 9 0 12 ; 3 0 7 ; 9 1 1	bilingual speakers are known for their ability to code-switch or mix their languages during communication . this phenomenon occurs when <otherscientificterm_13> substitute a word or phrase from one language with a phrase or word from another language . for <task_4> , it is essential to collect a <material_3> for <task_7> . in order to ease the negative effect caused by the <task_6> in training code-switching speech recognizers , this study proposes a <method_12> to <task_5> by integrating <otherscientificterm_9> and <otherscientificterm_1> into <metric_11> between phone units . <method_14> and a <method_0> are used in this study to cluster similar phone units to reduce the need of the training data for <task_8> . the experimental results show that the proposed <method_12> outperforms other traditional <method_2> .	15 -1 13 15 -1 4 3 7 21 15 -1 6 12 5 9 1 11 14 16 17 19 20 22 15 -1 0 15 -1 8 18 15 -1
Discourse Generation Using Utility-Trained Coherence Models .	stochastic models of discourse coherence ; utility-trained log-linear coherence models ; coherence models	<method> <method> <method>	1 4 2	we describe a generic framework for integrating various <method_0> in a manner that takes advantage of their individual strengths . an integral part of this framework are algorithms for searching and training these <method_0> . we evaluate the performance of our models and algorithms and show empirically that <method_1> out-perform each of the individual <method_2> considered .	0 3 -1 3 -1 1 2 4 3 -1
Collaborative prediction using ensembles of Maximum Margin Matrix Factorizations .	maximum margin matrix factorization ; fast gradient-based methods ; collaborative prediction benchmarks ; total training time ; evaluation metrics ; mmmf model ; ensemble approach	<method> <method> <method> <metric> <metric> <method> <method>	1 0 0 ; 4 5 5	fast gradient-based methods for <method_0> were recently shown to have great promise -lrb- rennie & srebro , 2005 -rrb- , including significantly outperforming the previous state-of-the-art methods on some standard <method_2> -lrb- including movielens -rrb- . in this paper , we investigate ways to further improve the performance of <method_0> , by casting <method_0> within an <method_6> . we explore and evaluate a variety of alternative ways to define such ensembles . we show that our resulting ensembles can perform significantly better than a single <method_5> , along multiple <metric_4> . in fact , we find that ensembles of partially trained <method_5> can sometimes even give better predictions in <metric_3> comparable to a single <method_5> .	0 2 8 7 -1 6 7 -1 7 -1 5 4 9 7 -1 7 -1
Jaw Movement in Vowels and Liquids Forming the Syllable Nucleus .	phonemic length effects ; phonemic length distinction ; rising-falling sonority profile ; syllable nucleus position ; main lingual articulation ; syllabic liquids ; nucleus type ; jaw movements ; jaw opening ; jaw activity ; vowels ; jaw	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 10 ; 6 1 0	this paper investigates <otherscientificterm_7> in the production of slovak syllables with and without <otherscientificterm_10> . we test the hypothesis that / l , r / in the <otherscientificterm_3> show a degree of <otherscientificterm_8> comparable to <otherscientificterm_10> , therefore providing a <otherscientificterm_2> even in syllables lacking <otherscientificterm_10> . we also investigate whether the <otherscientificterm_1> occurring for both <otherscientificterm_10> and syllabic consonants is implemented in a similar fashion for the different nucleus types . our articulatory data show that the <otherscientificterm_9> during <material_5> is indeed comparable to that of <otherscientificterm_10> , and that the <otherscientificterm_11> is recruited to help maintain the <otherscientificterm_4> . this became evident in particular in an interaction between <otherscientificterm_6> and <otherscientificterm_0> .	7 10 12 -1 3 8 2 12 -1 1 13 12 -1 9 5 11 4 12 -1 14 12 -1
Wavelet systems with zero moments .	zero scaling function ; coifman wavelets ; wavelet moments ; daubechies wavelets ; nonunique solutions	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	0 1 2 ; 4 4 3	the <otherscientificterm_1> created by daubechies have more zero moments than imposed by specifications . this results in systems with approximately equal numbers of <otherscientificterm_0> and <otherscientificterm_2> and gives a partitioning of the systems into three well defined classes . the <method_4> are more complex than for <otherscientificterm_3> .	1 5 -1 0 2 6 5 -1 4 3 7 5 -1
Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model .	topical or semantic content of documents ; dimension-reduction of sparse count data ; lower-dimensional latent variable representation ; probabilistic topic models ; probabilistic model ; mixture distribution ; word level ; background distribution ; topic models ; latent-sematic indexing ; latent-semantic indexing ; common words ; information retrieval ; distribution ; abstraction	<material> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	8 1 9 ; 3 1 10 ; 4 0 4 ; 7 1 5 ; 4 0 12	techniques such as <method_3> and <method_10> have been shown to be broadly useful at automatically extracting the <material_0> , or more generally for <material_1> . these types of models and algorithms can be viewed as generating an <otherscientificterm_14> from the words in a document to a <method_2> that captures what the document is generally about beyond the specific words it contains . in this paper we propose a new <method_4> that tempers this <method_4> by representing each document as a combination of -lrb- a -rrb- a <otherscientificterm_7> over <otherscientificterm_11> , -lrb- b -rrb- a <method_5> over general topics , and -lrb- c -rrb- a <otherscientificterm_13> over words that are treated as being specific to that document . we illustrate how this <method_4> can be used for <task_12> by matching documents both at a general topic level and at a specific <otherscientificterm_6> , providing an advantage over techniques that only match documents at a general level -lrb- such as <method_8> or <method_9> -rrb- or that only match documents at the specific <otherscientificterm_6> -lrb- such as tf-idf -rrb- .	3 10 0 1 17 15 -1 14 2 15 -1 4 7 11 5 18 19 15 -1 13 16 20 15 -1
Planning in Dynamic Environments : Extending HTNs with Nonlinear Continuous Effects .	hierarchical task network planners ; linear continuous effects planner ; discrete effects htn planner ; state projection algorithm ; nonlinear continuous effects ; navy training simulation ; dynamic continuous environments ; benchmark domain ; planning domain ; htn planner ; wait action ; domain knowledge ; continuous effects ; planning	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <material> <material> <method> <method> <otherscientificterm> <otherscientificterm> <task>	1 1 2 ; 3 0 9 ; 4 2 9	planning in <otherscientificterm_6> requires reasoning about <otherscientificterm_4> , which previous <method_0> do not support . in this paper , we extend an existing <method_9> with a new <method_3> . to our knowledge , this is the first <method_9> that can reason about <otherscientificterm_4> . we use a <method_10> to instruct this <method_9> to consider <otherscientificterm_12> in a given state . we also introduce a new <material_8> to demonstrate the benefits of planning with <otherscientificterm_4> . we compare our approach with a <method_1> and a <method_2> on a <material_7> , which reveals that its additional costs are largely mitigated by <otherscientificterm_11> . finally , we present an initial application of this algorithm in a practical domain , a <method_5> , illustrating the utility of this approach for planning in <otherscientificterm_6> .	6 4 0 14 -1 9 3 16 14 -1 17 14 -1 10 12 14 -1 8 14 -1 1 2 7 11 15 14 -1 14 -1
Word-level F0 range in Mandarin Chinese and its application to inserting words into a sentence .	automatic voice response application ; wf 0 rs ; f 0 context ; f 0 contour ; tone combination ; inserted word ; word utterance	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 2 5 ; 2 2 5	this paper considers an <task_0> in which a <otherscientificterm_6> is inserted into a fixed carrier sentence . an important task here is to adjust the <otherscientificterm_3> of the <otherscientificterm_5> according to the <otherscientificterm_2> of the carrier sentence . instead of generating the <otherscientificterm_3> on syllable basis , we employ an approach to adjust the <otherscientificterm_3> of the whole word . in this approach , two questions arise : -lrb- a -rrb- how to evaluate the <otherscientificterm_2> and -lrb- b -rrb- how to adjust the <otherscientificterm_3> suitably for the context . we have found that the <otherscientificterm_3> of a word can be appropriately regulated in a tone-independent word-level f 0 range -lrb- wf 0 r -rrb- . after estimating the <otherscientificterm_1> of the preceding and succeeding words , the wf 0 r of the <otherscientificterm_5> is set at the mean of these <otherscientificterm_1> . the <otherscientificterm_3> of the <otherscientificterm_5> is then mapped to the wf 0 r taking into account the <otherscientificterm_4> of the word . a perceptual evaluation experiment showed that the adjusted f 0 was coordinated well with the context .	0 6 7 -1 3 5 2 9 7 -1 7 -1 7 -1 7 -1 7 -1 1 8 7 -1 4 7 -1
Integration of Speech to Computer-Assisted Translation Using Finite-State Automata .	automatic speech recognition models ; statistical machine translation models ; human translator types ; n-best rescoring approach ; statistical prediction engine ; asr word graphs ; computer-assisted translation engines ; human speech ; n-best rescor-ing ; search method ; asr models ; finite-state automata	<method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <material> <method> <method> <method> <method>	4 0 6 ; 9 0 6	state-of-the-art <method_6> are based on a <method_4> , which interactively provides completions to what a <otherscientificterm_2> . the integration of <material_7> into a <method_6> is also a challenging area and is the aim of this paper . so far , only a few methods for integrating <method_1> with <method_0> have been studied . they were mainly based on <method_3> . <method_8> is not an appropriate <method_9> for building a <method_6> . in this paper , we study the incorporation of <method_0> and <method_10> using <method_11> . we also propose some transducers based on <method_0> for rescoring the <otherscientificterm_5> .	6 4 2 13 12 -1 7 12 -1 1 0 12 -1 3 8 12 -1 9 14 12 -1 10 11 12 -1 5 12 -1
An analysis of a modulated orthogonal sequence .	autocorrelation and cram correlation characteristics ; information construction methods ; modulated orthogonal sequence ; symbol error probability ; modular techniques ; integer sums ; dummy symbol ; generation ; cross-correlation	<metric> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	5 1 4 ; 1 0 2	one <otherscientificterm_6> has to be included for the sequence in this paper , a new <task_7> and an <method_1> for a <otherscientificterm_2> are suggested the sequence is generated by only <otherscientificterm_5> and <method_4> . the <metric_0> of the sequence are investigated via a new procedure . a modified sequence also having the orthogonality and satisfying the mathematical lower bound of the <otherscientificterm_8> is proposed , and the <otherscientificterm_3> of the sequence is investigated .	6 7 1 2 5 4 10 11 9 -1 0 9 -1 8 3 9 -1
Passive ranging capability of a multi-module array in underwater acoustic environments .	cramer-rao lower bound ; array 's source localization capability ; acoustic-field 's spatial coherence ; towed multi-module array ; underwater acoustic environments ; passive source localization ; passive ranging ; towed array ; spatial coherence ; array modules ; two-stage approach ; environmental uncertainties	<method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	3 0 5 ; 11 2 1 ; 2 6 11 ; 10 0 6 ; 9 1 2 ; 0 0 1 ; 9 6 11	this work presents our research results on the capability of <task_5> using a <otherscientificterm_3> in <otherscientificterm_4> . we developed new <method_0> results for assessing the <metric_1> under <otherscientificterm_11> , such as <otherscientificterm_9> ' positions and <otherscientificterm_2> . we also developed a <method_10> and provide details for <task_6> by utilizing data either non-coherently or coherently , depending on the availability of <otherscientificterm_8> in the received data from multiple modules of <otherscientificterm_7> .	5 3 4 13 12 -1 0 1 11 9 2 14 15 17 18 19 12 -1 10 6 8 7 16 12 -1
Multi-scale and Snakes for Automatic Road Extraction .	geometric constrained snake-based edge extraction ; scale-space behavior of roads ; automatic road extraction ; bridging of shadows ; aerial imagery	<task> <otherscientificterm> <task> <task> <task>	4 0 2	this paper proposes an approach for <task_2> in <task_4> which exploits the <otherscientificterm_1> in combination with <task_0> . the approach not only has few parameters to be adjusted , but for the first time allows for a <task_3> and partially occluded areas using the heavily disturbed evidence in the image . the road network is constructed after extracting crossings of various shape and topology . reasonable results are obtained which are evaluated based on ground truth .	2 4 1 0 6 5 -1 3 5 -1 5 -1 5 -1
Using residual vector quantization for image content classification .	multistage residual vector quantizers ; markov random field ; maximum a-posteriori sense ; natural and man-made structure recognition ; direct sum decoder codebooks ; class conditional pattern recognition ; fine-grained feature attribution ; voronoi cell partitions ; stage-wise codebooks ; bayesian framework ; data compression ; multistage rvq ; image understanding ; input space ; optimized classification ; multistage structure ; image-content classification	<method> <method> <method> <task> <method> <task> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <task> <otherscientificterm> <method>	8 0 11 ; 11 0 6 ; 6 0 3 ; 4 0 0 ; 6 0 12 ; 0 0 5 ; 1 0 9 ; 11 0 12	multistage residual vector quantizers -lrb- <method_0> -rrb- with optimal <method_4> have been successfully designed and implemented for <task_10> . due to its <otherscientificterm_15> , <method_0> has the ability to densely populate the <otherscientificterm_13> with <otherscientificterm_7> . the same design concept has yielded good results in the application of <method_16> -lsb- 1 -rsb- . furthermore , the <method_11> , with <otherscientificterm_8> , provides an opportunity to perform <task_6> for <task_12> , in general , and feature foundation data generation for <task_3> , in specific . in -lsb- 1 -rsb- , the information at the stages of <method_0> is heuristically integrated to perform <task_5> ; hence the process is not robust . <method_1> provides a suitable <method_9> to integrate the information available at the various stages of <method_0> to achieve <task_14> in the <method_2> .	0 4 10 21 17 -1 15 13 7 17 -1 16 17 -1 11 8 6 12 3 18 19 20 22 25 17 -1 23 17 -1 5 1 24 17 -1
Direction matters : Depth estimation with a surface normal classifier .	state of the art benchmark datasets ; surface normal direction estimation ; single view depth estimation ; global stereo matching approaches ; road scene imagery ; data driven classification ; binocular stereo matching ; real-world datasets ; classifier responses ; surface orientations ; scene geometry ; indoor environments ; surface orientation ; images ; classifier	<material> <task> <task> <method> <material> <task> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method>	6 1 2 ; 14 0 3 ; 4 0 6 ; 13 0 2 ; 7 5 14 ; 5 0 6	in this work we make use of recent advances in <task_5> to improve standard approaches for <task_6> and <task_2> . <task_1> has become feasible and shown to work reliably on <material_0> . information about the <otherscientificterm_12> contributes crucial information about the <otherscientificterm_10> in cases where standard approaches struggle . we describe , how the responses of such a <method_14> can be included in <method_3> . one of the strengths of our <method_14> is , that we can use the <otherscientificterm_8> for a whole set of directions and let the final optimization decide about the <otherscientificterm_12> . this is important in cases where based on the <method_14> , multiple different <otherscientificterm_9> seem likely . we evaluate our <method_14> on two challenging <material_7> for the two proposed applications . for the <task_6> we use <material_4> taken from a car and for the <task_2> we use <material_13> taken in <otherscientificterm_11> .	5 6 2 1 16 21 15 -1 0 15 -1 12 10 15 -1 14 3 17 15 -1 8 15 -1 15 -1 9 20 15 -1 7 18 19 15 -1
Entity-Based Local Coherence Modelling Using Topological Fields .	natural language generation system ; topologi-cal field information ; high-level clausal structure ; entity grid model ; natural language generation ; clausal order information ; constituent orders ; coherence component ; manual annotations ; grammatical role ; topological fields ; coherent text ; local coherence ; topolog-ical fields ; german text ; logical order ; german	<method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material>	13 0 0 ; 10 0 2 ; 9 1 5 ; 0 0 14 ; 4 0 11 ; 1 0 3 ; 0 0 6	one goal of <task_4> is to produce <material_11> that presents information in a <otherscientificterm_15> . in this paper , we show that <otherscientificterm_10> , which model <otherscientificterm_2> , are an important component of <otherscientificterm_12> in <material_16> . first , we show in a sentence ordering experiment that <otherscientificterm_1> improves the <method_3> of barzilay and lapata -lrb- 2008 -rrb- more than <otherscientificterm_9> and simple <otherscientificterm_5> do , particularly when <material_8> of this information are not available . then , we incorporate the model enhanced with <otherscientificterm_13> into a <method_0> that generates <otherscientificterm_6> for <material_14> , and show that the added <method_7> improves performance slightly , though not statistically significantly .	4 11 15 22 17 -1 10 2 12 16 19 17 -1 1 3 9 5 8 20 23 17 -1 13 0 6 14 7 18 21 24 17 -1
Graceful degradation of speech recognition performance over lossy packet networks .	client-server automatic speech recognition systems ; forward error correction system ; low and medium loss channel conditions ; packet loss rates ; packet loss recovery ; data acquisition delay ; channel loss models ; simulated packet loss	<task> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <method> <task>	0 0 0 ; 4 0 0	this paper explores <task_4> in <task_0> . a <method_1> is designed and tested over several <method_6> , at variable amounts of <otherscientificterm_5> . in experiments with <task_7> , the <task_0> provides robust asr performance which degrades gracefully as <metric_3> increase . comparing this <task_0> to several alternatives under <otherscientificterm_2> , we found one approach -lrb- multiple transmission plus interpolation -rrb- that yielded similar performance , but the <task_0> should scale better to lower bit rate conditions .	4 0 10 8 -1 1 6 5 8 -1 7 3 9 8 -1 2 8 -1
Deep belief nets for natural language call-routing .	support vector machines ; image , audio and speech classification ; deep belief nets ; maximum entropy ; natural language call routing ; feed-forward neural network ; dbn-initialized neural network ; text classification algorithms ; multi-layer generative model ; learning technique ; unlabeled data ; features ; backpropagation ; boosting	<method> <task> <method> <method> <task> <method> <method> <method> <method> <method> <material> <otherscientificterm> <method> <method>	12 0 5 ; 13 1 3 ; 0 6 7 ; 0 1 13 ; 2 0 4 ; 10 0 8 ; 0 6 6 ; 2 0 8	this paper considers application of <method_2> to <task_4> . <method_2> have been successfully applied to a number of tasks , including <task_1> , thanks to the recent discovery of an efficient <method_9> . <method_2> learn a <method_8> from <material_10> and the <otherscientificterm_11> discovered by this <method_8> are then used to initialize a <method_5> which is fine-tuned with <method_12> . we compare a <method_6> to three widely used <method_7> ; <method_0> , <method_13> and <method_3> . the <method_8> gives a call -- routing classification accuracy that is equal to the best of the other models even though <method_8> currently uses an impoverished representation of the input .	2 4 19 14 -1 1 9 14 -1 8 10 11 5 12 15 20 22 14 -1 6 7 0 13 3 16 17 18 21 14 -1 14 -1
On the role of localization cues in binaural segregation of reverberant speech .	localization of groups of time-frequency units ; binaural and stereo speech segregation ; sequential grouping of time-frequency objects ; object localization ; room reverberation ; time-frequency grouping ; localization information	<task> <task> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 3 ; 6 0 2	approaches to <task_1> have often assumed that <otherscientificterm_6> can be used as a primary cue to achieve segregation of a target signal . results produced by these systems degrade significantly in the presence of <otherscientificterm_4> . in this work , we present an alternative framework to achieve <task_0> . we show that grouping across time and frequency allows the use of <otherscientificterm_6> as an important cue for <task_2> . we analyze the level of <otherscientificterm_5> needed to achieve accurate <task_3> and show preliminary binaural segregation results using the proposed framework . results indicate that both <otherscientificterm_6> and segregation performance can be improved by grouping across time and frequency .	1 6 7 -1 4 7 -1 0 7 -1 2 9 7 -1 5 3 8 7 -1 7 -1
A Unification-Based Semantic Interpretation for Coordinate Constructs .	montagovian semantics of coordination ; first-order unification-based semantic interpretation ; lambda reduction steps ; partial execution ; semantic interpretation ; lambda expressions	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	2 0 4	this paper shows that a <method_1> for various coordinate constructs is possible without an explicit use of <otherscientificterm_5> if we slightly modify the standard <otherscientificterm_0> . this modification , along with <otherscientificterm_3> , completely eliminates the <otherscientificterm_2> during <task_4> .	1 5 0 6 -1 3 2 4 7 6 -1
Evaluation of Scan-Line Optimization for 3D Medical Image Registration .	semi-global cost integration strategy ; 3d ct scan pairs ; 3d medical image registration ; computer vision applications ; pulmonary motion analysis ; copdgene study archive ; high dimensional data ; consecutive pyramid levels ; search space dimension ; registration errors ; cost accumulation ; scan-line optimization ; clinical applications ; coarse-to-fine strategy ; optimization technique ; stereo estimation ; sgm-3d ; sgm	<method> <material> <task> <task> <task> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <method> <method> <task> <method> <method>	10 0 11 ; 11 0 3 ; 17 6 0 ; 5 0 1 ; 11 0 15 ; 8 0 7	scan-line optimization via <otherscientificterm_10> has become very popular for <task_15> in <task_3> and is often combined with a <method_0> , known as <method_17> . this paper introduces this combination as a general and effective <method_14> . it is the first time that this concept is applied to <task_2> . the presented algorithm , <method_16> , employs a <method_13> and reduces the <otherscientificterm_8> for <otherscientificterm_7> by a fixed linear rate . this allows it to handle large displacements to an extent that is required for <task_12> in <material_6> . <method_16> is evaluated in context of <task_4> on the recently extended dir-lab benchmark that provides ten 4d computed tomography -lrb- ct -rrb- image data sets , as well as ten challenging <material_1> from the <material_5> . results show that both <otherscientificterm_9> as well as run-time performance are very competitive with current state-of-the-art methods .	10 15 3 0 17 19 20 21 23 18 -1 14 18 -1 2 18 -1 16 13 8 7 24 18 -1 12 6 18 -1 4 22 18 -1 1 5 18 -1
Multi-view Domain Generalization for Visual Recognition .	multi-view domain generalization approach ; unlabeled target domain samples ; inherent cluster structures ; domain generalization capability ; unseen target domain ; alternating optimization algorithm ; multi-view features ; domain generalization ; weight matrix ; cluster structure ; visual recognition ; weight matrices ; latent domains ; svm classifiers ; weight vectors ; low-rank representation ; exemplar svms ; robust classifiers ; features	<method> <material> <otherscientificterm> <method> <material> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm>	0 0 7 ; 13 0 3 ; 0 0 10 ; 7 1 10 ; 16 0 13	in this paper , we propose a new <method_0> for <task_10> , in which we aim to use the source domain samples with multiple types of <otherscientificterm_18> -lrb- i.e. , <otherscientificterm_6> -rrb- to learn <method_17> that can generalize well to any <material_4> . considering the recent works show the <method_3> can be enhanced by fusing multiple <method_13> , we build upon <method_16> to learn a set of <method_13> by using one positive sample and all negative samples in the source domain each time . when the source domain samples come from multiple <otherscientificterm_12> , we expect the <otherscientificterm_14> of exemplar svm clas-sifiers can be organized into multiple hidden clusters . to exploit such <otherscientificterm_9> , we organize the <otherscientificterm_14> learnt on each view as a <otherscientificterm_8> and seek the <method_15> by reconstructing this <otherscientificterm_8> using itself as the dictionary . to enforce the consistency of <otherscientificterm_2> discovered from the <otherscientificterm_11> learnt on different views , we introduce a new <method_0> to minimize the mismatch between any two representation matrices on different views . we also develop an efficient <method_5> and further extend our <method_0> for <task_10> by exploiting the manifold structure of <material_1> . comprehensive experiments for <task_10> clearly demonstrate the effectiveness of our <method_0> for <task_7> and <task_10> .	0 10 18 6 17 4 19 -1 3 13 16 21 24 19 -1 12 14 19 -1 19 -1 9 8 15 19 -1 2 11 19 -1 5 1 20 22 23 19 -1
Cost-sensitive stacking for audio tag annotation and retrieval .	cost-sensitive multi-label learning problem ; mirex 2009 winning method ; audio tagging problem ; automatic audio tagging ; cost-sensitive classification problem ; audio tag annotation ; music clip ; musical knowledge ; tag correlation ; noisy information ; audio tags ; social tags ; tag count ; mood ; tag ; keywords ; tags	<task> <method> <task> <task> <task> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 0 11 ; 13 6 6 ; 0 0 2 ; 4 0 2 ; 8 0 3 ; 10 0 6 ; 15 0 6	audio <otherscientificterm_16> correspond to <otherscientificterm_15> that people use to describe different aspects of a <material_6> , such as the genre , <otherscientificterm_13> , and instrumentation . since <otherscientificterm_11> are usually assigned by people with different levels of <otherscientificterm_7> , they inevitably contain <otherscientificterm_9> . by treating the <otherscientificterm_14> counts as costs , we can model the <task_2> as a <task_4> . in addition , <otherscientificterm_8> is another useful information for <task_3> since some <otherscientificterm_16> often co-occur . by considering the co-occurrences of <otherscientificterm_16> , we can model the <task_2> as a <task_4> . to exploit the <otherscientificterm_12> and correlation information jointly , we formulate the <task_2> as a novel <task_0> . the results of <task_5> and retrieval experiments demonstrate that the new approach outperforms our <method_1> .	16 15 6 13 19 23 24 17 -1 11 7 9 18 17 -1 14 2 4 17 -1 8 3 22 17 -1 21 17 -1 12 20 17 -1 0 17 -1
Supervised Bipartite Graph Inference .	network topology of the bipartite graph ; compound-protein interaction network reconstruction ; reproducing kernel hilbert space ; distance metric learning ; unified euclidean space ; supervised learning problem ; bipartite graph inference ; chemical structure data ; genomic sequence data ; optimization problem ; graph	<method> <task> <otherscientificterm> <method> <otherscientificterm> <task> <task> <material> <material> <task> <otherscientificterm>	7 1 8 ; 7 0 1 ; 2 2 9 ; 8 0 1 ; 5 0 6	we formulate the problem of <task_6> as a <task_5> , and propose a new method to solve it from the viewpoint of <method_3> . the method involves the learning of two mappings of the heterogeneous objects to a <otherscientificterm_4> representing the <method_0> , where the <otherscientificterm_10> is easy to infer . the algorithm can be formulated as an <task_9> in a <otherscientificterm_2> . we report encouraging results on the problem of <task_1> from <material_7> and <material_8> .	6 5 3 16 11 -1 4 0 10 11 -1 9 2 14 11 -1 1 7 8 12 13 15 11 -1
Sampling and reconstructing spatial fields using mobile sensors .	sampling time-invariant spatial fields ; wide spatial area ; time-domain anti-aliasing filter ; temperature measurement problem ; field values ; mobile sensors ; moving sensor ; out-of-band noise ; static sensors ; reconstruction accuracy ; time-domain signal ; spatial field ; static sensing ; sampling ; filtering	<task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method>	5 1 14 ; 6 0 11 ; 2 0 5	the classical approach to <task_0> uses <otherscientificterm_8> distributed over space . we study a new approach involving <otherscientificterm_5> that move through space measuring the <otherscientificterm_4> along their paths . a single <otherscientificterm_6> can take measurements over a <otherscientificterm_1> thus acting as a substitute for a potentially large number of <otherscientificterm_8> . a <otherscientificterm_6> encounters the <otherscientificterm_11> in its path in the form of a <otherscientificterm_10> . hence a <method_2> can be employed at the <otherscientificterm_5> to limit the amount of <otherscientificterm_7> prior to <task_13> . we analytically quantify the advantage of <otherscientificterm_5> over <otherscientificterm_12> in rejecting <otherscientificterm_7> . we also demonstrate via simulations the improvement in <metric_9> that can be obtained using <otherscientificterm_5> and <method_14> in a <task_3> .	0 8 15 -1 5 4 15 -1 6 1 15 -1 11 10 17 15 -1 2 7 13 18 15 -1 12 15 -1 16 15 -1
Exploring Compositional High Order Pattern Potentials for Structured Output Learning .	compositional high order pattern potentials ; restricted boltzmann machines ; linear deviation pattern potentials ; pattern-like high order potential ; loss-sensitive joint learning procedure ; image-dependent high order potentials ; complex high level structure ; quantitative variability measure ; high variability datasets ; internal pattern parameters ; convolutional patterns ; tractable models ; image-dependent mapping ; image seg-mentations ; image features ; joint learning ; mod-eling structure ; prediction	<method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	2 3 0 ; 14 0 12 ; 0 6 3 ; 11 0 6 ; 4 0 0	when modeling structured outputs such as <otherscientificterm_13> , <task_17> can be improved by accurately <otherscientificterm_16> present in the labels . a key challenge is developing <method_11> that are able to capture <otherscientificterm_6> like shape . in this work , we study the learning of a general class of <otherscientificterm_3> , which we call <method_0> . we show that <method_0> include the <otherscientificterm_2> of rother et al. -lsb- 26 -rsb- and also <method_1> ; we also establish the near equivalence of these two models . experimentally , we show that performance is affected significantly by the degree of variability present in the datasets , and we define a <metric_7> to aid in studying this . we then improve <method_0> performance in <otherscientificterm_8> with two primary contributions : -lrb- a -rrb- developing a <method_4> , so that <otherscientificterm_9> can be learned in conjunction with other model potentials to minimize expected loss ; and -lrb- b -rrb- learning an <method_12> that encourages or inhibits patterns depending on <otherscientificterm_14> . we also explore varying how multiple patterns are composed , and learning <otherscientificterm_10> . quantitative results on challenging highly variable datasets show that the <method_15> and <otherscientificterm_5> can improve performance .	13 17 16 18 -1 11 6 22 18 -1 3 0 21 18 -1 2 1 19 18 -1 18 -1 7 20 23 18 -1 8 4 9 12 14 18 -1 10 18 -1
Corpus-Based Induction of Syntactic Structure : Models of Dependency and Constituency .	unsupervised learning of dependency structures ; model of linear constituency ; unsupervised constituency parsing ; un-supervised dependency parsing ; evaluation metrics ; distributional regularities ; generative model	<task> <method> <task> <task> <metric> <otherscientificterm> <method>	3 1 2 ; 4 5 6 ; 6 0 3 ; 6 0 0	we present a <method_6> for the <task_0> . we also describe the multiplicative combination of this <method_6> with a <method_1> . the <method_6> outperforms both components on their respective <metric_4> , giving the best published figures for <task_3> and <task_2> . we also demonstrate that the combined <method_6> works and is robust cross-linguistically , being able to exploit either attachment or <otherscientificterm_5> that are salient in the data .	6 0 11 7 -1 1 7 -1 4 3 2 8 9 10 7 -1 5 7 -1
Additive character sequences with small alphabets for compressed sensing matrices .	k × n measurement matrix ; additive character sequences ; incoherent tight frame ; asymptotically optimal coherence ; deterministic sensing matrix ; l 1-minimization method ; compressed sensing ; weil bound ; noiseless measurements ; sparse signals ; compressed sensing ; undersampled measurements	<method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm>	5 0 4 ; 5 0 8 ; 0 0 10	compressed sensing is a novel technique where one can recover <otherscientificterm_9> from the <otherscientificterm_11> . in this paper , a <method_0> for <task_10> is deterministically constructed via <material_1> . the <otherscientificterm_7> is then used to show that the <otherscientificterm_4> has <otherscientificterm_3> for n = k 2 , and that it is a tight frame . a sparse recovery guarantee for the <otherscientificterm_2> is also discussed . numerical results show that the <otherscientificterm_4> guarantees empirically reliable recovery performance via an <method_5> for <material_8> .	9 11 12 -1 0 10 1 15 12 -1 7 4 3 12 -1 2 12 -1 5 8 6 13 14 12 -1
Nonparametric internet tomography .	nonparametric , wavelet-based density estimation method ; inferring queuing delay distributions ; network level ns simulations ; host-based , end-to-end measurements ; fast fourier transform implementation ; global internet monitoring ; expectation-maximization optimization algorithm ; internal delay distributions ; spatially localized information ; priori limit ; unknown parameters ; delay distributions ; estimation procedure ; accuracy	<method> <task> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric>	4 0 6 ; 13 5 12 ; 5 0 8 ; 2 5 12	the substantial overhead of performing <task_5> motivates techniques for inferring <otherscientificterm_8> about performance using only <otherscientificterm_3> . in this paper , we present a novel methodology for <task_1> across internal links in the network based solely on unicast , end-to-end measurements . a key feature of our new approach is that it is nonparametric , meaning that no a <otherscientificterm_9> is placed on the number of <otherscientificterm_10> used to model the <otherscientificterm_11> . the nonparametric approach is required in order to accurately estimate the wide variety of <otherscientificterm_7> . the methodology is formulated according to a recently proposed <method_0> in combination with an <method_6> that employs a novel <method_4> . we perform <method_2> to verify the <metric_13> of the <method_12> .	5 8 3 17 14 -1 1 14 -1 9 10 11 14 -1 7 14 -1 0 15 14 -1 6 4 16 18 14 -1
Probabilistic Inference Based Message-Passing for Resource Constrained DCOPs .	distributed constraint optimization ; expectation-maximization and convex optimization machinery ; coordinated multiagent decision making ; convergent message-passing algorithm ; probabilistic inference ; near-optimal solutions ; dcop algorithms ; inference techniques ; coordination problem ; centralized solver ; failure rate	<method> <method> <task> <method> <task> <method> <method> <method> <task> <method> <metric>	0 0 2 ; 7 0 3 ; 10 5 6 ; 1 6 7 ; 3 0 0	distributed constraint optimization -lrb- <method_0> -rrb- is an important framework for <task_2> . we address a practically useful variant of <method_0> , called <method_0> , which takes into account agents ' consumption of shared limited resources . we present a promising new class of algorithm for <method_0> by translating the underlying <task_8> to <task_4> . using <method_7> such as <method_1> , we develop a novel <method_3> for <method_0> . experiments on standard benchmarks show that our approach provides better quality than previous best <method_6> and has much lower <metric_10> . comparisons against an efficient <method_9> show that our approach provides <method_5> , and is significantly faster on larger instances .	0 2 12 11 -1 11 -1 8 4 11 -1 7 1 3 13 15 16 11 -1 6 10 14 11 -1 9 11 -1
Training Conditional Random Fields with Multivariate Evaluation Measures .	conditional random fields ; sequential segmentation tasks ; error minimization approach ; multivariate evaluation measures ; target evaluation measure ; named entity recognition ; non-linear measures ; crf training ; loss function ; evaluation measure ; segmentation f-score ; text chunking ; f-score	<method> <task> <method> <metric> <metric> <task> <method> <method> <otherscientificterm> <metric> <method> <task> <method>	11 1 5 ; 5 6 1 ; 10 6 1 ; 12 6 6 ; 0 0 3 ; 8 0 1 ; 11 6 1	this paper proposes a framework for training <method_0> to optimize <metric_3> , including <method_6> such as <method_12> . our proposed framework is derived from an <method_2> that provides a simple solution for directly optimizing any <metric_9> . specifically focusing on <task_1> , i.e. <task_11> and <task_5> , we introduce a <otherscientificterm_8> that closely reflects the <metric_4> for these <task_1> , namely , <method_10> . our experiments show that our method performs better than standard <method_7> .	0 3 6 12 17 18 13 -1 2 9 13 -1 1 11 5 8 4 10 14 15 16 19 20 13 -1 7 13 -1
Elimination Ordering in Lifted First-Order Probabilistic Inference .	lifted probabilistic inference ; non-relational probabilistic inference ; generated relational graphs ; parameterized random variables ; rela-tional models ; logical variables ; inference methods ; relational models ; population sizes ; np-complete	<method> <task> <material> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method>	6 0 1 ; 6 0 0	various representations and <method_6> have been proposed for <method_0> in <method_4> . many of these <method_6> choose an order to eliminate -lrb- or branch on -rrb- the <otherscientificterm_3> . similar to such <method_6> for <task_1> , the order of elimination has a significant role in the performance of the <method_6> . since finding the best order is <method_9> even for <method_7> , heuristics have been proposed to find good orderings in the <method_7> . in this paper , we show that these heuristics are inefficient for <method_7> , because they fail to consider the <otherscientificterm_8> associated with <otherscientificterm_5> . we extend existing heuristics for <method_7> and propose new heuristics for <method_7> . we evaluate the existing and new heuristics on a range of <material_2> .	6 0 4 12 10 -1 3 10 -1 1 11 10 -1 9 7 10 -1 8 5 10 -1 10 -1 10 -1
Solving Risk-Sensitive POMDPs With and Without Cost Observations .	partially observable markov decision processes ; risk-sensitive pomdps ; user-defined cost threshold ; real-world data ; taxi domain ; synthetic domains ; cumulative cost ; search-based algorithm ; cost observations ; policy	<method> <task> <otherscientificterm> <material> <material> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	7 4 4 ; 5 1 4 ; 7 0 1 ; 3 0 4	partially observable markov decision processes -lrb- pomdps -rrb- are often used to model planning problems under uncertainty . the goal in <task_1> is to find a <otherscientificterm_9> that maximizes the probability that the <otherscientificterm_6> is within some <otherscientificterm_2> . in this paper , unlike existing <task_1> , we distinguish between the two cases of whether costs can or can not be observed and show the empirical impact of <otherscientificterm_8> . we also introduce a new <method_7> to solve <task_1> and show that <method_7> is faster and more scalable than existing approaches in two <material_5> and a <material_4> generated with <material_3> .	10 -1 1 9 6 2 10 -1 8 10 -1 7 5 4 3 11 12 13 14 10 -1
Frank-Wolfe works for non-Lipschitz continuous gradient objectives : Scalable poisson phase retrieval .	poisson phase retrieval problem ; nuclear norm constraints ; nuclear norm constraint ; poisson noise model ; global convergence rate ; lipschitz continuous gradient ; phase retrieval problem ; maximum-likelihood estimator ; convex program ; iteration counter ; phaselift approach ; objective function ; frank-wolfe algorithm ; convergence guarantees ; lanczos method	<task> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method>	12 0 1 ; 12 4 14 ; 2 2 8 ; 14 0 1 ; 12 0 0 ; 8 0 7	we study a <task_6> in the <method_3> . motivated by the <method_10> , we approximate the <method_7> by solving a <method_8> with a <otherscientificterm_2> . while the <method_12> , together with the <method_14> , can efficiently deal with <otherscientificterm_1> , our <otherscientificterm_11> does not have a <otherscientificterm_5> , and hence existing <otherscientificterm_13> for the <method_12> do not apply . in this paper , we show that the <method_12> works for the <task_0> , and has a <metric_4> of o -lrb- 1/t -rrb- , where t is the <otherscientificterm_9> . we provide rigorous theoretical guarantee and illustrating numerical results .	6 3 15 -1 10 7 8 2 18 21 15 -1 12 14 1 11 5 13 16 17 19 15 -1 0 4 9 20 15 -1 15 -1
Analysis of speaking styles by two-dimensional visualization of aggregate of acoustic models .	gaussian distributions of multidimensional vectors ; human visual perception ; acoustic model library ; multidimensional scaling technique ; two-dimensional visual map ; speech recognition system ; hmm acoustic models ; speaking styles ; cosmos map ; marginal region ; recognition	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <task>	3 0 6 ; 0 0 6	to ensure high enough <task_10> performance from the outset of usage of the <method_5> , prior development of highly precise <method_2> is necessary . the analysis of <method_6> expressed with <otherscientificterm_0> is typically a difficult task . the cosmos -lrb- acoustic space map of sound -rrb- method featuring the visualization of distributions of the <method_6> in a two dimensional space by utilizing <method_3> is proposed in order to support the analysis through capability of <otherscientificterm_1> . the effectiveness of the proposed technique is reviewed based on an analysis on <material_7> . the <otherscientificterm_9> within the <otherscientificterm_4> -lrb- called <otherscientificterm_8> -rrb- obtained by the proposed method the contains <method_6> with lower <task_10> performance . it is possible to improve <task_10> performance by dividing the <otherscientificterm_9> into several smaller zones in which separate <method_6> is trained and provided to the speakers belonging to the same zone .	10 5 2 11 -1 6 0 13 11 -1 3 1 12 11 -1 7 11 -1 9 4 8 11 -1 11 -1
Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich Linguistic Features .	expectation-maximization clustering algorithm ; electronic chinese semantic dictionaries ; chinese verb sense discrimination ; rich linguistic features ; predicate-argument structure information ; fine-grained semantic categories ; normalized mutual information ; chinese verbs ; lexical sets ; semantic features ; semantic taxonomy ; chinese nouns	<method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <otherscientificterm>	10 0 11 ; 1 0 10 ; 5 0 0 ; 0 0 2 ; 8 6 5 ; 9 0 0 ; 8 0 0 ; 3 0 0	this paper discusses the application of the <method_0> to the task of <task_2> . the <method_0> utilized <otherscientificterm_3> that capture <otherscientificterm_4> of the target verbs . a <method_10> for <otherscientificterm_11> , which was built semi-automatically based on two <material_1> , was used to provide <otherscientificterm_9> for the <method_0> . purity and <otherscientificterm_6> were used to evaluate the clustering performance on 12 <material_7> . the experimental results show that the <method_0> can learn sense or sense group distinctions for most of the verbs successfully . we further enhanced the <method_0> with certain <otherscientificterm_5> called <method_8> . our results indicate that these <method_8> improve the <method_0> 's performance for the three most challenging verbs chosen from the first set of experiments .	0 2 16 12 -1 3 4 20 12 -1 10 11 1 9 13 14 18 12 -1 6 7 12 -1 12 -1 5 8 15 17 12 -1 19 12 -1
On the generation of synthetic disfluent speech : local prosodic modifications caused by the insertion of editing terms .	disfluent speech synthesis ; automatic film dubbing ; synthetic disfluent speech ; segmental units ; disfluency elements ; spoken translation ; local modifications ; prosody	<task> <task> <material> <otherscientificterm> <otherscientificterm> <task> <method> <method>	6 0 3 ; 1 1 5	disfluent speech synthesis is necessary in some applications such as <task_1> or <task_5> . this paper presents a model for the generation of <material_2> based on inserting each element of a disfluency in a context where they can be considered fluent . <method_7> obtained by the application of standard techniques on these new sentences is used for the synthesis of the disfluent sentence . in addition , <method_6> are applied to <otherscientificterm_3> adjacent to <otherscientificterm_4> . experiments evidence that duration follows this behavior , what supports the feasibility of the model .	1 5 10 8 -1 2 7 8 -1 8 -1 6 3 4 9 8 -1 0 8 -1
Simultaneous Object Pose and Velocity Computation Using a Single View from a Rolling Shutter Camera .	closed-form linear solution ; 2d-3d point correspondences ; cmos image sensors ; rolling shutter phenomenon ; full 3d velocity ; rolling shutter deformations ; 3d pose ; planar objects ; bundle adjustment ; velocity sensor ; image deformations ; rolling shutter ; image formation ; non-linear optimization ; accuracy	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric>	11 0 2 ; 0 0 7 ; 11 0 10 ; 13 1 8	an original concept for computing instantaneous <otherscientificterm_6> and 3d velocity of fast moving objects using a single view is proposed , implemented and validated . it takes advantage of the <otherscientificterm_10> induced by <otherscientificterm_11> in <otherscientificterm_2> . first of all , after analysing the <otherscientificterm_3> , we introduce an original model of the <otherscientificterm_12> when using such a camera , based on a general model of moving rigid sets of 3d points . using <method_1> , we derive two complementary methods , compensating for the <otherscientificterm_5> to deliver an accurate <otherscientificterm_6> and exploiting them to also estimate the <otherscientificterm_4> . the first solution is a general one based on <method_13> and <otherscientificterm_8> , usable for any object , while the second one is a <method_0> valid for <otherscientificterm_7> . the resulting <method_0> enable us to transform a cmos low cost and low power camera into an innovative and powerful <method_9> . finally , experimental results with real data confirm the relevance and <metric_14> of the <method_0> .	6 15 -1 10 11 2 16 18 15 -1 3 12 15 -1 1 5 4 15 -1 17 19 15 -1 13 8 0 7 15 -1 9 15 -1
Two dimensional Maximum Margin Criterion .	two dimensional maximum margin criterion ; benchmark face recognition data sets ; low dimensional matrix subspace ; matrix representation data ; maximum margin criterion ; orthogonal projection matrices ; feature extraction ; dimensionality reduction ; theoretical analysis ; 2dmmc ; images	<method> <material> <otherscientificterm> <material> <method> <method> <task> <task> <method> <method> <material>	4 0 6 ; 9 0 5	maximum margin criterion is a well-known method for <task_6> and <task_7> . in this paper , we propose a novel <task_6> method , namely <method_0> , specifically for <material_3> , e.g. <material_10> . <method_9> aims to find two <method_5> to project the original matrices to a <otherscientificterm_2> , in which a sample is close to those in the same class but far from those in different classes . both <method_8> and experiments on <material_1> illustrate that the proposed method is very effective and efficient .	6 7 12 11 -1 0 3 10 9 11 -1 5 2 13 11 -1 8 1 4 11 -1
Acoustic investigation of / th / lenition in brunei Mandarin .	conversational speech of brunei mandarin ; acoustic characteristics ; perceptual judgments ; spectral properties ; spectrographic inspection ; sound change ; perceptual judgments ; female speakers ; spectrographic analysis ; mandarin chinese ; chinese bruneians ; correct classification ; features ; closure ; identification ; frication ; burst	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <material> <task> <material> <material> <metric> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	12 2 5 ; 1 0 12 ; 1 3 0 ; 8 1 1 ; 6 1 8	this study investigates the <otherscientificterm_1> of / t h / lenition in <material_0> , a variety of <material_9> . based on data from 20 <material_10> , / t h / lenition was found in the third-person pronoun tā / t h a / , which is frequently pronounced as hā -lsb- ha -rsb- . <otherscientificterm_6> , <task_8> and <otherscientificterm_1> were conducted to examine the <otherscientificterm_12> of this <otherscientificterm_5> . in comparison with the <otherscientificterm_2> , it was found that the <metric_4> yielded 83.6 % <metric_11> of -lsb- t h -rsb- and -lsb- h -rsb- for <material_7> and 77.2 % for male speakers , indicating there is reasonably high reliability in <task_14> in terms of <otherscientificterm_3> . results of the <otherscientificterm_1> showed that there is an increase in high frequency intensity after the release of the <otherscientificterm_13> for -lsb- t h -rsb- while there is little change in intensity during the <otherscientificterm_15> for -lsb- h -rsb- . the results showed that the lack of <otherscientificterm_16> and little increase in intensity are reasonably reliable cues for stop lenition .	1 0 9 20 17 -1 10 6 17 -1 8 12 5 18 19 21 22 17 -1 2 4 11 7 17 -1 14 3 17 -1 13 15 17 -1
Comparative News Summarization Using Linear Programming .	semantic-related cross-topic concept pairs ; comparative news summaries ; linear programming model ; optimization problem ; topic-related concepts ; news topics	<otherscientificterm> <material> <method> <task> <otherscientificterm> <material>	2 0 3	comparative news summarization aims to highlight the commonalities and differences between two comparable <material_5> . in this study , we propose a novel approach to generating <material_1> . we formulate the task as an <task_3> of selecting proper sentences to maximize the comparativeness within the summary and the representativeness to both <material_5> . we consider <otherscientificterm_0> as comparative evidences , and consider <otherscientificterm_4> as representative evidences . the <task_3> is addressed by using a <method_2> . the experimental results demonstrate the effectiveness of our proposed model .	5 6 -1 1 6 -1 3 6 -1 0 4 6 -1 2 7 6 -1 6 -1
Stochastic optimization based on the Laplace transform order with applications to precoder designs .	maximum ergodic or effective capacity ; nonnegative random variables ; laplace transform order ; stochastic power allocation ; multi-antenna fading channel ; stochastic optimization problems ; multi-antenna channels ; objective function ; nonconvex structure ; relaying ; precoding	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <method> <method>	10 0 3 ; 10 3 4 ; 4 0 3 ; 1 0 2	stochastic optimization arising from <method_10> in a <otherscientificterm_4> with channel mean feedback to maximize data rates is important but challenging . the use of <method_9> further complicates the situation , as it may induce a <otherscientificterm_8> in the <otherscientificterm_7> , thereby excluding the use of existing approaches which require convexity or concavity . to deal with challenges as such , this paper presents a new framework for solving a class of <task_5> . the analysis here involves the comparison of two <otherscientificterm_1> in the <otherscientificterm_2> . our framework is particularized to optimal <method_10> for <otherscientificterm_0> in <material_6> with or without <method_9> assuming channel mean feedback , where the objectives may or may not have convexity or concavity . the application to <task_3> is also discussed .	10 4 12 13 14 11 -1 9 8 7 11 -1 5 11 -1 1 2 15 11 -1 0 6 11 -1 11 -1
SFBC design tradeoffs for mobile SC-FDMA with application to LTE-advanced .	open-loop space-frequency block coding scheme ; orthogonal frequency-division multiple access ; single-carrier frequency-division multiple-access ; peak-to-average-power ratio ; lte-advanced standardization ; uplink transmit diversity schemes ; practical decoding complexity ; full spatial diversity ; performance degradation ; lte standard ; design tradeoffs ; sfbc codeword ; sc-fdma uplink ; mobile sc-fdma ; doppler ; robustness ; uplink	<method> <method> <method> <metric> <task> <method> <metric> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <metric> <task>	2 0 9 ; 0 0 12 ; 2 0 13	single-carrier frequency-division multiple-access -lrb- sc-fdma -rrb- has been adopted in the <task_16> of the <method_9> due to its lower <metric_3> compared to <method_1> . recent activities in the <task_4> have focused on effective <method_5> with low papr -lsb- 1 -rsb- but without considering the <metric_8> due to <method_14> despite the fact that <method_1> is required to support high mobility . in this paper , we present an <method_0> for the <method_12> and demonstrate its <metric_15> to high <method_14> and large multipath delay spread while enjoying <otherscientificterm_7> , low papr and <metric_6> by a suitable design of the frequency span of each <otherscientificterm_11> . in this paper , we study the <otherscientificterm_10> involved in <method_2> for <task_13> .	16 9 3 1 18 17 -1 4 5 8 14 17 -1 0 12 15 7 6 19 17 -1 11 20 17 -1
Liptracking and Mpeg4 Animation With Feedback Control .	global real-time face tracking application ; two step approach ; real-time facial segmentation ; real time application ; active contour models ; global analysis/synthesis chain ; face model synthesis ; 3d-face model ; feedback control ; face tracking ; facial segmentation ; augmented reality ; image analysis ; 3d synthesis ; liptracking	<task> <method> <method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <task> <otherscientificterm> <task> <method> <task>	8 1 14 ; 10 1 14 ; 4 1 2 ; 10 1 8 ; 9 1 11	this article deals with <task_10> and <task_14> with <otherscientificterm_8> by <method_6> . on this topic , the search community is divided into two parts : analysis and synthesis . we want to use all the knowledge to create a <otherscientificterm_5> where the <task_12> needs the <method_13> and conversely . as it happens , applications like <task_9> or <otherscientificterm_11> need a rapid , robust and descriptive-enough solution . our solution is based on a <method_1> : the first step is a <method_2> with <method_4> and the second step recovers a <method_7> in order to extract more precise parameters to adjust the first step . the contribution of this paper is to couple two research fields for creating a <task_3> . the results obtained show rapid and robust performances which could be exploited in a more <task_0> .	10 14 8 6 16 17 19 15 -1 15 -1 5 12 13 15 -1 9 11 20 15 -1 1 2 4 7 18 15 -1 15 -1 3 15 -1
SenseRelate : : TargetWord-A Generalized Framework for Word Sense Disambiguation .	wordnet-based measures of semantic relatedness ; similarity perl modules ; word sense disambiguation ; word senses ; context words ; perl package ; targetword ; senserelate	<method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method>	1 3 7 ; 6 6 5 ; 7 6 5 ; 6 6 7	we have previously introduced a method of <task_2> that computes the intended sense of a target word , using <method_0> -lrb- patwardhan et al. , 2003 -rrb- . <method_7> : : <method_6> is a <method_5> that implements this algorithm . the <task_2> is carried out by selecting that sense of the target word which is most related to the <otherscientificterm_4> . relatedness between <otherscientificterm_3> is measured using the <method_7> : : <method_1> .	2 0 7 8 -1 6 5 10 11 12 8 -1 4 8 -1 3 1 9 8 -1
Multichannel speech enhancement using convolutive transfer function approximation in reverberant environments .	transfer-function generalized sidelobe canceler beamformer ; suppression of reverberations ; relative transfer functions ; speech signal reflections ; noise reduction ; tf-gsc beamformer ; delay-and-sum beamformer ; tf-gsc structure ; reverberant environments ; tf-gsc	<method> <task> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <method>	8 2 3 ; 0 4 9 ; 0 0 4 ; 7 0 3 ; 1 1 4 ; 0 0 1	recently , we have presented a <method_0> in the short time fourier transform domain , which relies on a convolutive transfer function approximation of <otherscientificterm_2> between distinct sensors . in this paper , we combine a <method_6> with the <otherscientificterm_7> in order to suppress the <otherscientificterm_3> captured at the sensors in <otherscientificterm_8> . we demonstrate the performance of the proposed <method_0> and compare <method_0> with the <method_9> . we show that the proposed <method_0> enables <task_1> and further <metric_4> compared with the <method_5> .	0 2 10 -1 6 7 3 8 11 14 10 -1 9 12 10 -1 1 4 5 13 15 16 10 -1
A Representation Theory for Ranking Functions .	bayes optimal ranking functions ; exchangeable listwise ranking functions ; natural symmetricity assumption ; listwise ranking functions ; de finetti theorems ; listwise loss functions ; point-wise ranking functions ; list-wise ranking functions ; representation theory ; rank tasks ; loss function ; supervised learning ; reranking method ; functional analysis ; permutation-valued functions ; tensor analysis	<method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method>	11 0 9 ; 8 0 12 ; 15 1 13 ; 8 0 14 ; 13 1 4	this paper presents a <method_8> for <otherscientificterm_14> , which in their general form can also be called <method_3> . <otherscientificterm_6> assign a score to each object independently , without taking into account the other objects under consideration ; whereas <otherscientificterm_5> evaluate the set of scores assigned to all objects as a whole . in many <task_11> to <task_9> , it might be of interest to use <method_3> instead ; in particular , the <method_0> might themselves be listwise , especially if the <otherscientificterm_10> is listwise . a key caveat to using <otherscientificterm_7> has been the lack of an appropriate <method_8> for such functions . we show that a <otherscientificterm_2> that we call exchangeability allows us to explicitly characterize the set of such <otherscientificterm_1> . our analysis draws from the theories of <method_15> , <method_13> and <method_4> . we also present experiments using a novel <method_12> motivated by our <method_8> .	8 14 3 6 20 16 -1 5 16 -1 11 9 0 10 17 16 -1 7 16 -1 16 -1 2 1 19 21 16 -1 15 13 4 18 16 -1
Improved speech understanding using dialogue expectation in sentence parsing .	speech recognition errors ; higher level information ; flight reservation task ; dialogue manager ; dialogue expectation ; dialogue state ; dialogue systems ; dialogue efficiency ; concept recognition ; recognition process ; discourse knowledge ; history ; decoder ; expectation ; recognition ; pragmatics ; expectation	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	3 0 5 ; 11 1 16 ; 4 0 14 ; 16 1 10 ; 10 1 15	in <method_6> , <otherscientificterm_0> force the user to repeat information resulting in more turns , lower <metric_7> and maybe complete failure . <otherscientificterm_1> such as <otherscientificterm_11> , <otherscientificterm_16> , <otherscientificterm_10> and <otherscientificterm_15> can improve performance but are hard to quantify and effectively include in the <method_9> . in this paper , <otherscientificterm_4> is used to improve <task_14> . by permitting the <method_3> to guide the interaction it is possible to track the <otherscientificterm_5> and thus estimate the expected semantic content of the user 's response . the <method_3> is allowed to process a large number of sentences provided by the <method_12> . <otherscientificterm_13> is used as an effective criterion for selecting among competing hypotheses . this approach was tested with a simple <task_2> and results show improvement in <task_8> without adding significant computation .	6 0 7 1 17 -1 11 16 10 15 9 19 21 22 17 -1 4 14 20 17 -1 3 5 18 17 -1 17 -1 12 13 17 -1 17 -1
Non-rigid point set registration : A bidirectional approach .	robust gaussian mixture model ; point set registration algorithm ; bidirectional em process ; medical images ; point sets ; noise component ; synthetic data ; registration techniques ; outliers ; accuracy ; robustness	<method> <method> <method> <material> <otherscientificterm> <method> <material> <method> <otherscientificterm> <metric> <metric>	10 5 1 ; 3 0 4 ; 6 1 4 ; 9 5 1 ; 4 5 1 ; 6 5 1 ; 2 0 4 ; 1 4 7 ; 0 0 1 ; 5 3 0	in this paper we present a novel <method_1> based on the <method_0> . we take advantage of a robust estimation to weigh the <method_5> in <method_0> . moreover , a <method_2> is introduced to model <otherscientificterm_8> in both <otherscientificterm_4> in contrast to traditional methods . the performance of the <method_1> is demonstrated and validated in carefully designed <material_6> and <otherscientificterm_4> extracted from <material_3> . results show that the proposed <method_1> can improve the <metric_10> and <metric_9> as compared to the traditional <method_7> .	1 0 20 11 -1 5 21 11 -1 2 8 4 18 11 -1 6 3 13 14 16 17 11 -1 10 9 7 12 15 19 11 -1
Latent Pyramidal Regions for Recognizing Scenes .	latent support vector machine ; latent pyramidal regions ; discriminative characteristic of the scenes ; indoor and outdoor scene classification ; global and local scene characteristics ; latent svm training procedure ; non-linear locality constraint coding ; scene representation model ; nonlinear feature coding ; spatial pyramid representation ; scene classification problem ; spatial pyramid ; image representation ; uiuc-sports	<method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <method> <method> <task> <method> <method> <method>	0 0 9 ; 1 0 2 ; 0 0 1 ; 12 0 10 ; 6 0 11 ; 12 0 3 ; 12 0 4 ; 8 1 0 ; 8 0 9	in this paper we propose a simple but efficient <method_12> for solving the <task_10> . our new <method_12> combines the benefits of <method_9> using <method_8> and <method_0> to train a set of <method_1> . each of our <method_1> captures a <otherscientificterm_2> and is trained by searching over all possible sub-windows of the images in a <method_5> . each <method_1> is represented in a <method_11> and uses <method_6> for learning both shape and texture patterns of the scene . the final response of the <method_1> form a single feature vector which we call the <method_12> and can be used for the <task_10> . we tested our proposed <method_7> in three datasets which contain a variety of scene categories -lrb- 15-scenes , <method_13> and mit-indoor -rrb- . our <method_12> obtains state-of-the-art results on all these datasets which shows that <method_12> can simultaneously model the <otherscientificterm_4> in a single framework and is general enough to be used for both <task_3> .	12 10 18 14 -1 9 8 0 1 15 17 22 23 14 -1 2 5 16 14 -1 11 6 19 14 -1 14 -1 14 -1 7 13 20 21 14 -1
Tangent Prop - A Formalism for Specifying Selected Invariances in an Adaptive Network .	machine learning applications ; scale changes ; distortion operators ; character recognizer ; priori knowledge ; learning time ; rotations	<task> <otherscientificterm> <method> <method> <otherscientificterm> <metric> <otherscientificterm>	6 1 1	in many <task_0> , one has access , not only to training data , but also to some high-level a <otherscientificterm_4> about the desired behavior of the system . for example , it is known in advance that the output of a <method_3> should be invariant with respect to small spatial distortions of the input images -lrb- translations , <otherscientificterm_6> , <otherscientificterm_1> , etcetera -rrb- . we have implemented a scheme that allows a network to learn the derivative of its outputs with respect to <method_2> of our choosing . this not only reduces the <metric_5> and the amount of training data , but also provides a powerful language for specifying what generalizations we wish the network to perform .	0 4 7 -1 3 6 1 8 7 -1 2 7 -1 5 7 -1
On scalar ambiguity in blind channel estimation for OFDM systems .	information of source constellation ; scalar ambiguity problem ; blind channel estimation ; blind identification ; ofdm systems ; ambiguous scalar ; constellation type ; pilot overhead ; integer part ; annoying ambiguity ; scalar ambiguity ; fractional part ; multiple-constellation scheme ; semi-blind identification	<otherscientificterm> <task> <task> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	11 1 8 ; 12 0 9	blind channel estimation is a promising technique to reduce the <otherscientificterm_7> . unfortunately , most existing algorithms suffer from the <task_1> , and hence only achieve <task_13> . in this paper , we show that with the <otherscientificterm_0> , the phase of the <otherscientificterm_5> can be divided into a <otherscientificterm_11> and an <otherscientificterm_8> . then we propose a <method_12> enabling totally <task_3> regardless of <otherscientificterm_6> for <task_4> . the necessary and sufficient condition for eliminating the <otherscientificterm_10> is given . an application example shows that our <method_12> can help other algorithms circumvent the <otherscientificterm_9> .	7 14 -1 1 13 14 -1 0 5 11 8 15 14 -1 12 3 6 4 14 -1 10 14 -1 9 2 16 14 -1
Belief Change Based on Global Minimisation .	set-theoretic notion of minimisation ; semantic and syntactic characterisations ; cardinality-based and priority-based minimisation ; minimisation-based belief change ; belief revision ; spatial locations ; minimisation-based approaches ; belief merging ; undirected graph ; vertices ; graph	<task> <otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 4 ; 6 0 7 ; 9 2 10 ; 7 1 4 ; 1 0 9	a general framework for <task_3> is presented . a problem instance is made up of an <otherscientificterm_8> , where a formula is associated with each vertex . for example , <otherscientificterm_9> may represent <otherscientificterm_5> , points in time , or some other notion of locality . information is shared between <otherscientificterm_9> via a process of <otherscientificterm_9> over the <otherscientificterm_10> . we give equivalent <otherscientificterm_1> of this <otherscientificterm_9> . we also show that this approach is general enough to capture existing <method_6> to <task_7> , <task_4> , and -lrb- temporal -rrb- extrap-olation operators . while we focus on a <task_0> , we also consider other approaches , such as <method_2> .	3 11 -1 8 11 -1 9 5 11 -1 10 14 11 -1 1 16 11 -1 6 7 4 12 13 15 11 -1 0 11 -1
Fast Image Super-Resolution Based on In-Place Example Regression .	benchmark and real-world images ; low-to high-resolution image patches ; single image super-resolution ; fast regression model ; upper scale image ; nonlinear mapping function ; diverse textures ; origin location ; super-resolution approaches ; in-place self-similarity ; local self-similarity ; visual artifacts ; external database ; input images ; robust estimation ; first-order approximation ; in-place examples ; patch ; noise	<material> <material> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <material> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 0 3 ; 1 0 5 ; 1 0 15 ; 17 0 4 ; 3 0 2 ; 15 0 5 ; 8 0 3 ; 3 0 18 ; 0 5 3	we propose a <method_3> for practical <task_2> based on <otherscientificterm_16> , by leveraging two fundamental <method_8> -- learning from an <material_12> and learning from self-examples . our <otherscientificterm_9> refines the recently proposed <otherscientificterm_10> by proving that a <otherscientificterm_17> in the <otherscientificterm_4> have good matches around its <otherscientificterm_7> in the lower scale image . based on the <otherscientificterm_16> , a <method_15> of the <method_5> from <material_1> is learned . extensive experiments on <material_0> demonstrate that our <method_3> can produce natural-looking results with sharp edges and preserved fine details , while the current state-of-the-art algorithms are prone to <material_11> . furthermore , our <method_3> can easily extend to deal with <otherscientificterm_18> by combining the regression results on multiple <otherscientificterm_16> for <task_14> . the <method_3> runs fast and is particularly useful for practical applications , where the <material_13> typically contain <otherscientificterm_6> and they are potentially contaminated by <otherscientificterm_18> or compression artifacts .	3 2 16 8 12 20 24 26 19 -1 9 10 17 4 7 23 19 -1 15 5 1 21 22 25 19 -1 0 11 28 19 -1 27 19 -1 18 14 19 -1
The Design of ESSENCE : A Constraint Language for Specifying Combinatorial Problems .	complex combinatorial object ; natural rigorous specifications ; decision variable ; formal language ; discrete mathematics ; combina-torial objects ; combinatorial object ; decision variables ; arbitrary depth ; natural language ; combinatorial problems ; multisets ; partitions ; essence ; tuples ; abstraction ; relations	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 1 4 ; 12 6 5 ; 11 1 12 ; 11 6 5 ; 14 6 5 ; 11 1 16 ; 14 1 11 ; 14 1 16 ; 16 1 12 ; 16 6 5	essence is a new <otherscientificterm_3> for specifying <task_10> in a manner similar to <otherscientificterm_1> that use a mixture of <material_9> and <method_4> . <method_13> provides a high level of <otherscientificterm_15> , much of which is the consequence of the provision of <otherscientificterm_7> whose values can be <otherscientificterm_5> , such as <otherscientificterm_14> , sets , <otherscientificterm_11> , <otherscientificterm_16> , <otherscientificterm_12> and functions . <method_13> also allows these <task_10> to be nested to <otherscientificterm_8> , thus providing , for example , sets of <otherscientificterm_12> , sets of sets of <otherscientificterm_12> , and so forth . therefore , a problem that requires finding a <otherscientificterm_0> can be directly specified by using a <otherscientificterm_2> whose type is precisely that <otherscientificterm_6> .	3 10 1 9 4 13 18 17 -1 15 7 5 14 11 16 12 19 20 21 22 23 24 25 26 27 17 -1 8 17 -1 17 -1
Unsupervised Learning by Program Synthesis .	unsupervised learning of symbolic composi-tional structures ; visual learning domain ; unsupervised learning algorithm ; english inflectional morphology ; language learning problem ; program synthesis tools ; probabilistic modeling ; noisy data ; visual concepts ; solver-based techniques ; program synthesis	<task> <task> <method> <otherscientificterm> <task> <method> <method> <material> <otherscientificterm> <method> <task>	1 1 4 ; 9 0 2 ; 7 0 5 ; 6 0 2 ; 6 1 9 ; 2 0 3 ; 5 0 7 ; 2 0 10 ; 9 0 10 ; 2 0 8	we introduce an <method_2> that combines <method_6> with <method_9> for <task_10> . we apply our techniques to both a <task_1> and a <task_4> , showing that our <method_2> can learn many <otherscientificterm_8> from only a few examples and that <method_2> can recover some <otherscientificterm_3> . taken together , these results give both a new approach to <task_0> , and a technique for applying <method_5> to <material_7> .	2 6 9 10 13 15 16 19 20 11 -1 1 4 8 3 12 17 21 11 -1 0 5 7 14 18 11 -1
Robust Optimal Pose Estimation .	image of a known scene ; branch and bound setting ; l ∞ norm ; l ∞ optimality ; camera pose estimation ; real data ; calibrated camera ; classical geometry ; image features ; optimal algorithms ; position ; outliers ; ransac	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	3 0 11	we study the problem of estimating the <otherscientificterm_10> and orientation of a <otherscientificterm_6> from an <material_0> . a common problem in <task_4> is the existence of false correspondences between <otherscientificterm_8> and modeled 3d points . existing techniques such as <method_12> to handle <otherscientificterm_11> have no guarantee of opti-mality . in contrast , we work with a natural extension of the <otherscientificterm_2> to the outlier case . using a simple result from <material_7> , we derive necessary conditions for <otherscientificterm_3> and show how to use <otherscientificterm_3> in a <otherscientificterm_1> to find the optimum and to detect <otherscientificterm_11> . the algorithm has been evaluated on synthetic as well as <material_5> showing good empirical performance . in addition , for cases with no <otherscientificterm_11> , we demonstrate shorter execution times than existing <method_9> .	10 6 0 13 -1 4 8 13 -1 12 11 13 -1 2 13 -1 7 3 1 14 13 -1 13 -1 5 13 -1
Controlled Query Evaluation for Datalog and OWL 2 Profile Ontologies .	controlled query evaluation framework ; owl 2 profiles ; ontology languages ; confidentiality enforcement ; censors	<method> <material> <material> <task> <method>	0 0 3	we study <task_3> in ontologies under the <method_0> , where a policy specifies the sensitive information and a censor ensures that query answers that may compromise the policy are not returned . we focus on <method_4> that ensure confidentiality while max-imising information access , and consider both dat-alog and the <material_1> as <material_2> .	3 0 6 5 -1 4 1 2 5 -1
Privacy preserving crowd monitoring : Counting people without people models or tracking .	dynamic textures motion model ; gaussian process regression ; crowd segmentation algorithm ; explicit object segmentation ; large pedestrian dataset ; crowd counting system ; privacy-preserving system ; segmented region ; homogeneous motion ; holistic features ; inhomogeneous crowds ; features ; crowd ; tracking	<method> <method> <method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	2 1 5 ; 7 0 9	we present a <method_6> for estimating the size of <otherscientificterm_10> , composed of pedestrians that travel in different directions , without using <method_3> or <task_13> . first , the <otherscientificterm_12> is segmented into components of <otherscientificterm_8> , using the mixture of <method_0> . second , a set of simple <otherscientificterm_9> is extracted from each <otherscientificterm_7> , and the correspondence between <otherscientificterm_11> and the number of people per segment is learned with <method_1> . we validate both the <method_2> , and the <method_5> , on a <material_4> -lrb- 2000 frames of video , containing 49,885 total pedestrian instances -rrb- . finally , we present results of the <method_6> running on a full hour of video .	6 10 3 13 14 -1 12 8 0 14 -1 9 7 11 1 16 14 -1 2 5 4 15 14 -1 14 -1
Replicated Softmax : an Undirected Topic Model .	two-layer undirected graphical model ; unstructured collection of documents ; low-dimensional latent semantic representations ; learning and inference algorithms ; latent dirichlet allocation ; held-out documents ; retrieval accuracy	<method> <material> <otherscientificterm> <method> <task> <material> <metric>	0 4 4 ; 6 5 0 ; 0 0 2 ; 0 6 0 ; 3 0 0	we introduce a <method_0> , called a '' replicated soft-max '' , that can be used to <method_0> and automatically extract <otherscientificterm_2> from a large <material_1> . we present efficient <method_3> for this <method_0> , and show how a <method_0> , <method_0> , can be used to produce an accurate estimate of the log-probability the <method_0> assigns to test data . this allows us to demonstrate that the proposed <method_0> is able to generalize much better compared to <task_4> in terms of both the log-probability of <material_5> and the <metric_6> .	0 2 1 10 7 -1 3 11 12 7 -1 4 5 6 8 9 7 -1
An Analysis of Forward Pruning .	minimax values of sibling nodes ; game-playing computer programs ; game playing ; decision-making technique ; chess-playing programs ; game tree ; game trees ; forward pruning	<otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method>	7 0 2	several early <method_1> used <method_7> -lrb- i.e. , the practice of deliberately ignoring nodes that are believed unlikely to affect a <otherscientificterm_5> 's minimax value -rrb- , but this technique did not seem to result in good decision-making . the poor performance of <method_7> presents a major puzzle for ai research on <task_2> , because some version of <method_7> seems to be '' what people do , '' and the best <method_4> still do not play as well as the best humans . as a step toward deeper understanding of <method_7> , we have set up models of <method_7> on two different kinds of <otherscientificterm_6> , and used these models to investigate how <method_7> affects the probability of choosing the correct move . in our studies , <method_7> did better than minimaxing when there was a high correlation among the <otherscientificterm_0> in a <otherscientificterm_5> . this result suggests that <method_7> may possibly be a useful <method_3> in certain kinds of games . in particular , we believe that bridge may be such a game .	1 7 5 8 -1 2 4 9 8 -1 8 -1 6 8 -1 0 8 -1 3 8 -1
Efficient Dimensionality Reduction for High-Dimensional Network Estimation .	high-dimensional gaussian graphical model ; module graphical lasso ; predicting survival time of patients ; module assignment of variables ; functionally coherent gene sets ; gene expression data ; network estimation technique ; graph structure ; cancer biology ; graphical lasso ; real-world networks ; latent variables ; clustering algorithms ; ovarian cancer ; ggm ; ro-bustness ; module ; variables ; scalability	<method> <method> <task> <otherscientificterm> <material> <material> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <material> <method> <metric> <otherscientificterm> <otherscientificterm> <metric>	18 5 1 ; 13 0 5 ; 11 3 14 ; 1 0 2 ; 1 4 9 ; 4 1 2 ; 1 4 12 ; 12 0 2 ; 1 0 4 ; 12 0 4 ; 1 0 3 ; 6 0 0	we propose <method_1> , an aggressive dimensionality reduction and <method_6> for a <method_0> . <method_1> achieves <metric_18> , interpretability and <metric_15> by exploiting the modularity property of many <method_10> . <otherscientificterm_17> are organized into tightly coupled modules and a <otherscientificterm_7> is estimated to determine the conditional independencies among modules . <method_1> iteratively learns the <otherscientificterm_3> , the <otherscientificterm_11> , each corresponding to a <otherscientificterm_16> , and the parameters of the <method_14> of the <otherscientificterm_11> . in synthetic data experiments , <method_1> outperforms the standard <method_9> and three other methods that incorporate <otherscientificterm_11> into <method_14> . when applied to <material_5> from <material_13> , <method_1> out-performs standard <method_12> in identifying <material_4> and <task_2> . the learned modules and their dependencies provide novel insights into <task_8> as well as identifying possible novel drug targets .	1 6 0 31 19 -1 18 15 10 17 20 19 -1 7 19 -1 3 11 16 14 30 19 -1 9 22 24 19 -1 5 21 23 25 26 27 28 29 19 -1 13 12 4 2 19 -1
Approximate earth mover 's distance in linear time .	earth mover 's distance ; linear time algorithm ; weighted wavelet transform ; wavelet emd metric ; kantorovich-rubinstein transshipment problem ; weighted wavelet coefficients ; normal euclidean distance ; low dimensional his-tograms ; hölder continuity constraint ; difference histogram ; optimization problem ; dual form ; wavelet domain ; emd computation ; computational complexity ; histogram bins ; histograms	<method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <material> <task> <metric> <otherscientificterm> <method>	13 6 4 ; 1 0 7 ; 14 5 0 ; 0 2 10 ; 12 2 10 ; 1 0 0 ; 11 2 8 ; 3 0 0	the <method_0> -lsb- 19 -rsb- is an important perceptually meaningful metric for comparing <method_16> , but <method_0> suffers from high -lrb- o -lrb- n 3 log n -rrb- -rrb- <metric_14> . we present a novel <method_1> for approximating the <method_0> for <otherscientificterm_7> using the sum of absolute values of the <otherscientificterm_5> of the <method_9> . <task_13> is a special case of the <task_4> , and we exploit the <otherscientificterm_8> in its <otherscientificterm_11> to convert <method_0> into a simple <task_10> with an explicit solution in the <material_12> . we prove that the resulting <method_3> is equivalent to <method_0> , i.e. the ratio of the two is bounded . we also provide estimates for the bounds . the <otherscientificterm_2> can be computed in time linear in the number of <otherscientificterm_15> , while the comparison is about as fast as for <otherscientificterm_6> or χ 2 statistic . we experimentally show that <method_3> is a good approximation to <method_0> , has similar performance , but requires much less computation .	0 16 14 20 17 -1 1 7 5 9 13 19 23 17 -1 4 8 11 10 12 18 21 22 24 17 -1 3 17 -1 17 -1 17 -1 2 15 6 25 17 -1
Blind equalization of MIMO channels using deterministic precoding .	unknown instantaneous-mixture channel ; unknown mimo channel ; iterative demodulation algorithm ; parallel transmission ; signal demodulation ; data signals ; transmission	<otherscientificterm> <otherscientificterm> <method> <material> <task> <material> <task>	2 0 6 ; 0 0 6	we present a novel precoding or modulation scheme -lrb- matrix modulation -rrb- that allows <material_3> of several <material_5> over an unknown multiple-input multiple-output -lrb- mimo -rrb- channel . we first present a theorem on unique <task_4> and an efficient <method_2> for <task_6> over an <otherscientificterm_0> . we then generalize our results to an <otherscientificterm_1> with memory .	3 5 7 -1 4 2 6 0 8 9 7 -1 1 7 -1
MMSE based noise PSD tracking with low complexity .	noise power spectral density ; minimum statistics based noise tracking ; minimum mean-squared error estima-tor ; noise magnitude-squared dft coefficients ; non-stationary noise sources ; speech enhancement algorithms ; noise psd estimation ; low complexity method ; noise tracking ; noisy data ; segmental snr ; computational complexity ; pesq	<method> <method> <method> <otherscientificterm> <material> <method> <task> <method> <task> <material> <method> <metric> <method>	7 0 6 ; 2 0 7 ; 10 0 4 ; 12 0 4 ; 0 0 5 ; 10 1 12	most <method_5> heavily depend on the <method_0> . because this quantity is unknown in practice , estimation from the <material_9> is necessary . we present a <method_7> for <task_6> . the <method_7> is based on a <method_2> of the <otherscientificterm_3> . compared to <method_1> , <method_10> and <method_12> are improved for <material_4> with 1 db and 0.25 mos points , respectively . compared to recently published algorithms , similar good <task_8> performance is obtained , but at a <metric_11> that is in the order of a factor 40 lower .	5 0 18 13 -1 9 13 -1 7 6 14 13 -1 2 3 15 13 -1 1 10 12 4 16 17 19 13 -1 8 11 13 -1
Wavelet-based perceptual speech enhancement using adaptive threshold estimation .	time-frequency adaptive wavelet soft thresholding ; stationary and non-stationary noise cases ; modified weiner filtering technique ; adaptive noise level-tracking algorithm ; bark-scaled wavelet packet decomposition ; wiener filtering process ; speech enhancement technique ; speech enhancement system ; bark-scaled wavelet packet ; magnitude decision-directed approach ; threshold estimation method ; noise suppression ; computed threshold ; wavelet band ; speech signal ; threshold estimation	<method> <material> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	0 0 7 ; 12 0 5 ; 9 0 7 ; 7 0 11 ; 3 0 13 ; 10 0 2 ; 4 0 7 ; 1 0 6 ; 9 0 4 ; 4 0 2 ; 15 0 13 ; 9 0 10 ; 10 0 7	a new <method_7> , which is based on a <method_0> , is presented in this paper . the <method_7> utilises a <method_4> integrated into a <method_2> using a novel <method_10> based on a <method_9> . first , a <otherscientificterm_8> transform is used to decompose the <otherscientificterm_14> into critical bands . <method_15> is then performed for each <otherscientificterm_13> according to an <method_3> . finally , the speech is estimated by incorporating the <otherscientificterm_12> into a <method_5> , using the <method_9> . the proposed <method_6> has been tested with various <material_1> . reported results show that the <method_7> is capable of a high-level of <task_11> while preserving the intelligibility and naturalness of the speech .	7 0 17 16 -1 4 2 10 9 19 22 23 25 26 28 29 16 -1 8 14 15 16 -1 13 3 21 27 16 -1 12 5 18 16 -1 6 1 24 16 -1 20 16 -1
Robust collaborative state estimation for smart grid monitoring .	gossip-based gauss-newton algorithm ; smart grid wide-area monitoring ; decentralized state estimation scheme ; power flow equations ; global state estimate ; distributed control areas ; bad data ; noise variances ; state estimation ; ieee-118 system ; network gossiping ; network reconfigurations ; random failures ; distributed techniques ; gossiping	<method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <task> <method> <method> <task> <otherscientificterm> <method> <method>	13 4 2 ; 5 0 4 ; 12 1 6 ; 10 0 2 ; 2 0 4 ; 3 0 0	this paper proposes a <method_2> via <method_10> with applications in <task_1> . the proposed <method_2> allows <otherscientificterm_5> to solve for an accurate <task_4> collaboratively using the proposed <method_0> . furthermore , the proposed <method_2> mitigates the influence of <material_6> by adap-tively updating the <otherscientificterm_7> and re-weighting the contributions of the most recent measurements for <task_8> . compared with other <method_13> , our <method_2> via <method_14> is more flexible and resilient in case of <task_11> and failures . we further prove that the <otherscientificterm_3> satisfy the sufficient condition for the <method_0> to converge to the desired solution . simulations of the <method_9> show that the proposed <method_2> estimates and tracks the global state robustly , and degrades gracefully when there are <otherscientificterm_12> and <material_6> .	2 10 1 19 15 -1 5 4 0 17 20 15 -1 6 7 8 15 -1 13 14 11 16 15 -1 3 21 15 -1 18 15 -1
Taming the Curse of Dimensionality : Discrete Integration by Hashing and Optimization .	randomly generated parity constraints ; discrete combinatorial optimization problem ; discrete graphical models ; hash function ; model selection ; marginal computation ; map queries ; randomized algorithm ; partition function ; integration	<otherscientificterm> <task> <method> <otherscientificterm> <task> <task> <otherscientificterm> <method> <otherscientificterm> <task>	0 2 1 ; 5 1 4 ; 0 0 3	integration is affected by the curse of dimen-sionality and quickly becomes intractable as the dimensionality of the problem grows . we propose a <method_7> that , with high probability , gives a constant-factor approximation of a general discrete integral defined over an exponentially large set . this <method_7> relies on solving only a small number of instances of a <task_1> subject to <otherscientificterm_0> used as a <otherscientificterm_3> . as an <task_1> , we demonstrate that with a small number of <otherscientificterm_6> we can efficiently approximate the <otherscientificterm_8> of <method_2> , which can in turn be used , for instance , for <task_5> or <task_4> .	10 -1 7 10 -1 1 0 3 11 13 10 -1 6 8 2 12 10 -1
Spectral Estimation of Voiced Speech using a Family of MVDR Estimates .	mvdr estimates -lrb- mvdr estimates ; spectral estimation of sinusoids ; sinusoidal and noise power ; ſxed order mvdr-mfcc ; least squares approach ; estimated mvdr spectra ; ſxed model order ; modeling voiced speech ; synthetic vowels ; sinusoidal signal ; mvdr estimate ; voiced speech ; sinusoidal frequency ; linear manner ; timit database ; model order ; coefſcients ; recognition	<material> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task>	10 0 0 ; 16 2 13 ; 0 2 14 ; 4 0 0 ; 0 1 3	we present a robust approach to modeling <material_11> using a family of minimum variance distortionless response -lrb- mvdr -rrb- spectral estimates . the method exploits the fact that for a <otherscientificterm_6> , for a <otherscientificterm_9> in noise , the <method_10> at the <otherscientificterm_12> is approximately related to the <otherscientificterm_2> in a simple <otherscientificterm_13> with the <otherscientificterm_16> being dependent on the <otherscientificterm_15> . <task_7> as a sum of harmonic signals , we then use the aforementioned relationship along with a <method_4> to combine a family of <material_0> of different orders -rrb- and develop a robust approach for modeling <material_11> . experimental results of <task_1> , <material_8> , and actual speech signals at <material_0> of 0 db and 5 db using this approach indicate an increased resolution in the <otherscientificterm_5> . the <material_0> computed from the <method_10> using this approach are also used for speaker identiſcation experiments on the <material_14> at various <material_0> . the results indicate a reasonable improvement in <task_17> performance when compared to the <material_0> and the <material_3> .	11 18 -1 6 9 10 12 2 13 16 15 7 20 18 -1 4 0 22 18 -1 18 -1 1 8 5 19 21 18 -1 14 23 18 -1
Consistent iterative hard thresholding for signal declipping .	subjective user listening evaluations ; high-dimensional audio data processing ; iterative hard thresholding ; signal restoration problem ; clipped observations ; audio signals ; declipping algorithms ; reconstructed signal ; signal processing ; snr ; saturation	<task> <task> <method> <task> <otherscientificterm> <material> <method> <otherscientificterm> <task> <task> <otherscientificterm>	5 1 8	clipping or <otherscientificterm_10> in <material_5> is a very common problem in <task_8> , for which , in the severe case , there is still no satisfactory solution . in such case , there is a tremendous loss of information , and traditional methods fail to appropriately recover the signal . we propose a novel approach for this <task_3> based on the framework of <method_2> . this approach , which enforces the consistency of the <otherscientificterm_7> with the <otherscientificterm_4> , shows superior performance in comparison to the state-of-the-art <method_6> . this is confirmed on synthetic and on actual <task_1> , both on <task_9> and on <task_0> .	10 5 8 12 11 -1 11 -1 3 2 11 -1 7 4 6 11 -1 1 11 -1
Optimal joint base station assignment and downlink beamforming for heterogeneous networks .	joint base station assignment ; α-fairness utility functions ; linear beam-former design ; sum rate maximization ; mimo heterogeneous network ; linear transmit beamformers ; system wide utility ; optimization problem ; sum rate	<task> <otherscientificterm> <task> <task> <method> <otherscientificterm> <method> <task> <metric>	0 1 2 ; 7 0 1	consider a <method_4> with multiple transmitters -lrb- including macro , pico and femto base stations -rrb- and many receivers -lrb- mobile users -rrb- . the users are to be assigned to the base stations which then optimize their <otherscientificterm_5> accordingly . in this work , we consider the problem of <task_0> and <task_2> to maximize a <method_6> . we first establish the np-hardness of the resulting <task_7> for a large family of <otherscientificterm_1> . then , we propose an efficient algorithm to approximately solve this problem for the special case of <task_3> . the simulation results show that the algorithm improves the <metric_8> .	4 9 -1 5 9 -1 0 2 6 10 9 -1 7 1 11 9 -1 3 9 -1 9 -1
New Algorithms for Blind Block Synchronization in Zero-Padding Systems .	linear redundant filterbank precoders ; zero-padding precoder ; block synchronization error rate ; blind block synchronization problem ; blind block synchronization algorithm ; blind channel identification ; generalized versions ; repetition index ; block synchronization ; parameter	<method> <method> <metric> <task> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm>	2 5 4 ; 0 0 5 ; 1 0 3	blind channel identification using <method_0> has been studied extensively in the literature . most methods are proposed based on the assumption that <method_8> is perfect . in practice , a <method_4> must be used to justify this assumption . this paper studies the <task_3> in systems using a <method_1> . a previously reported method is reviewed and a new approach for the <task_3> is proposed . <method_6> of both approaches are then developed using a <otherscientificterm_9> called <otherscientificterm_7> . simulation results show that when the <otherscientificterm_7> is chosen to be greater than unity , the <metric_2> performance of the proposed <method_4> has a significant improvement over the previously reported method . '	0 12 10 -1 8 10 -1 4 10 -1 3 1 13 10 -1 6 10 -1 9 7 10 -1 2 11 10 -1
Grammars for Local and Long Dependencies .	polarized dependency -lrb- pd - -rrb- grammars ; negative and positive va-lencies of words ; discontinuous constructions ; bounded pd-grammars ; derived structures ; unbounded raising ; non-saturated valencies ; rules ; ex-traposition ; dependencies ; extraction ; cf-grammar ; local	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	12 6 9 ; 10 1 8 ; 5 1 10	polarized dependency -lrb- pd - -rrb- grammars are proposed as a means of efficient treatment of <otherscientificterm_2> . pd-grammars describe two kinds of <otherscientificterm_9> : <otherscientificterm_12> , explicitly derived by the <otherscientificterm_7> , and long , implicitly specified by <otherscientificterm_1> . if in a pd-grammar the number of <otherscientificterm_6> in <otherscientificterm_4> is bounded by a constant , then it is weakly equivalent to a <method_11> and has a cents ¡ $ # ¦ ¥ ¨ § - time parsing algorithm . it happens that such <method_3> are strong enough to express such phenomena as <otherscientificterm_5> , <task_10> and <otherscientificterm_8> .	2 13 -1 9 12 7 1 14 13 -1 6 4 11 13 -1 3 5 10 8 15 16 13 -1
Handwritten Digit Recognition with a Novel Vision Model that Extracts Linearly Separable Features .	handwritten digit recognition ; biological vision ; vision model ; linear classifier ; features	<task> <otherscientificterm> <method> <method> <otherscientificterm>	3 0 4 ; 2 0 0 ; 1 0 2	we use well-established results in <otherscientificterm_1> to construct a novel <method_2> for <task_0> . we show empirically that the <otherscientificterm_4> extracted by our <method_2> are linearly separable over a large training set -lrb- mnist -rrb- . using only a <method_3> on these <otherscientificterm_4> , our <method_2> is relatively simple yet outperforms other models on the same data set .	1 2 0 7 8 5 -1 4 5 -1 3 6 5 -1
Fast modelling of pinna spectral notches from HRTFs using linear prediction residual cepstrum .	linear prediction residual cepstrum ; virtualization of sound ; batteaus reflection model ; spectral notches ; pinna images ; hrtf ; accuracy	<method> <task> <method> <otherscientificterm> <material> <method> <metric>	0 0 3 ; 2 0 3	developing individualized head related transfer functions -lrb- <method_5> -rrb- is an essential requirement for accurate <task_1> . however it is time consuming and complicated for both the subject and the developer . obtaining the <otherscientificterm_3> which are the most prominent features of <method_5> is very important to reconstruct the head related impulse response -lrb- <method_5> -rrb- accurately . in this paper , a method suitable for fast computation of the frequencies of <otherscientificterm_3> is proposed . the <method_0> is used to compute the <otherscientificterm_3> with a high degree of <metric_6> in this work . subsequent use of <method_2> to overlay the <otherscientificterm_3> on the <material_4> indicate that the proposed method is able to provide finer contours . experiments on reconstruction of the <method_5> indicates that the method performs better than other methods .	5 1 7 -1 7 -1 3 7 -1 7 -1 0 6 8 7 -1 2 9 7 -1 4 7 -1
Partial Matchmaking using Approximate Subsumption .	sound and complete algorithm ; web ontology language owl ; computing approximate subsumption ; approximate logical reasoning ; matching tasks ; description logics ; information integration ; partial matches ; subsumption relation ; service discovery ; matching criterion ; structured objects ; mismatch ; subsumption	<method> <material> <task> <method> <task> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	6 1 9 ; 0 0 2	description logics , and in particular the <material_1> has been proposed as an appropriate basis for computing matches between <material_11> for the sake of <task_6> and <task_9> . a drawback of the direct use of <otherscientificterm_13> as a <otherscientificterm_10> is the inability to compute <otherscientificterm_7> and qualify the degree of <otherscientificterm_12> . in this paper , we describe a method for overcoming these problems that is based on <method_3> . in particular , we approximate the <otherscientificterm_8> by defining the notion of <otherscientificterm_13> with respect to a certain subset of the concept and relation names . we present the formal semantics of this relation , describe a <method_0> for <task_2> and discuss its application to <task_4> .	1 11 6 9 15 14 -1 13 10 7 12 14 -1 3 14 -1 8 14 -1 16 14 -1
Weber 's law-based side-informed data hiding .	perceptually-shaped side-informed data hiding scheme ; logarithmic quantization algorithm ; generalized version ; embedding power	<method> <method> <method> <task>	0 6 1	in this work weber 's law is followed for designing a <method_0> . the resulting <method_0> is a <method_2> of a <method_1> previously proposed by the authors . closed formulas for analyzing the <task_3> and decoding error probability of this new <method_0> are provided , and experimental results showing its good behavior against severe attacks are reported .	0 4 -1 2 1 5 4 -1 3 4 -1
Multiscale manifold representation and modeling .	real world data sets ; noisy point cloud samples ; unknown smooth manifold ; wavelet thresholding ideas ; lower-dimensional manifold structure ; higher-dimensional space ; multiscale representation ; point clouds ; point cloud ; manifold approximations ; lifting	<material> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 7 ; 10 0 6 ; 5 2 0	many <material_0> can be viewed as points in a <otherscientificterm_5> that lie concentrated around a <otherscientificterm_4> . we propose a new <method_6> for such <otherscientificterm_7> based on <method_10> and perfect matching . the result is an adaptive wavelet transform that decomposes a <otherscientificterm_8> into <otherscientificterm_9> and details at multiple scales . we illustrate with several examples that the transform can extract an <otherscientificterm_2> from <material_1> using simple <method_3> .	0 5 4 14 11 -1 6 7 10 12 13 11 -1 8 9 11 -1 2 1 3 11 -1
Improved Bit Allocation in an Error-Resilient Scheme Based on Distributed Source Coding .	distributed source coding principles ; dsc based auxiliary stream ; bit allocation problem ; main stream ; auxiliary stream ; video stream ; decoder side ; channel loss ; error-resilient scheme ; encoder ; decoder ; robustness	<method> <method> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <method> <method> <metric>	1 0 2	in this work we propose an <method_8> that allows enhancing the <metric_11> of a <material_5> . based on <method_0> , an <method_4> is sent in parallel to the <otherscientificterm_3> as a redundant representation of the sequence that is used to correct errors at the <method_10> , thus reducing the impact of drift . in order to perform an optimal bit allocation in the <method_4> , the <method_9> needs to compute a reliable estimate of the expected video distortion observed at the <otherscientificterm_6> due to <otherscientificterm_7> . this paper proposes an algorithm to calculate the expected distortion of decoded dct-coefficients -lrb- dubbed eddd -rrb- and its application to the <task_2> in a <method_1> .	8 11 5 12 -1 0 4 3 10 12 -1 9 6 7 12 -1 13 12 -1
A comparative study of evidence combination strategies .	content based image retrieval ; bordafuse combination strategies ; support vector machines ; feature combinations strategies ; corel images ; combmin	<task> <method> <method> <method> <material> <method>	3 0 0	this paper reports on experimental results obtained from a performance comparison of <method_3> in <task_0> . the use of <method_2> is compared to <method_5> , combmax , combsum and <method_1> , all of which are evaluated on a carefully compiled set of <material_4> and the trecvid 2003 search task collection .	3 0 7 6 -1 2 5 1 4 6 -1
Time domain acoustic contrast control implementation of sound zones for low-frequency input signals .	acoustic contrast control ; average squared sound pressure ; flat frequency response ; sound field control ; sound zoning method ; bandlimited low-frequency scenario ; acousti-cally damped room ; loudspeaker layout ; anechoic environments ; reverberant environment ; personal audio ; bacc method ; sound zones ; controlled zones ; listening space	<method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 6 4 ; 4 0 2	sound zones are two or more regions within a <otherscientificterm_14> where listeners are provided with <otherscientificterm_10> . <method_0> is a <method_4> that maximizes the <otherscientificterm_1> in one zone constrained to constant pressure in other zones . state-of-the-art time domain broadband acoustic contrast control -lrb- bacc -rrb- <method_4> are designed for <otherscientificterm_8> . these <method_4> are not able to realize a <otherscientificterm_2> in a limited frequency range within a <otherscientificterm_9> . <method_3> in a limited frequency range is a requirement to accommodate the effective working range of the loudspeakers . in this paper , a new <method_11> is proposed which results in an implementation realizing a <otherscientificterm_2> in the target zone . this <method_11> is applied in a <otherscientificterm_5> where the <otherscientificterm_7> surrounds two <otherscientificterm_13> . the performance is verified with experimental results in an <otherscientificterm_6> .	14 10 0 15 -1 4 1 16 15 -1 8 15 -1 2 9 3 17 15 -1 15 -1 11 15 -1 15 -1 5 7 13 15 -1
Structure in Dichotomous Preferences .	computationally hard approval-based multi-winner rules ; hard computational social choice problems ; single-peaked and single-crossing preferences ; single-peaked or single-crossing preferences ; dichotomous profiles ; restricted domains ; restricted domain	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	5 0 0	many <task_1> are known to become tractable when voters ' preferences belong to a <material_6> , such as those of <otherscientificterm_3> . however , to date , all algorithmic results of this type have been obtained for the setting where each voter 's preference list is a total order of candidates . the goal of this paper is to extend this line of research to the setting where voters ' preferences are dichotomous , i.e. , each voter approves a subset of candidates and disapproves the remaining candidates . we propose several analogues of the notions of <otherscientificterm_2> for <otherscientificterm_4> and investigate the relationships among them . we then demonstrate that for some of these notions the respective <otherscientificterm_5> admit efficient algorithms for <otherscientificterm_0> .	1 6 3 7 -1 7 -1 7 -1 2 4 7 -1 8 7 -1
Stereoscopic inpainting : Joint color and depth completion from stereo images .	simultaneous color and depth inpainting ; depth-assisted texture synthesis technique ; data sets ; stereo images ; segmentation-based approach ; missing color ; occlusion regions ; 3d warping ; object removal ; occlusions	<task> <method> <material> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 6 ; 9 1 8	we present a novel algorithm for <task_0> . the algorithm takes <material_3> and estimated disparity maps as input and fills in <otherscientificterm_5> and depth information introduced by <otherscientificterm_9> or <otherscientificterm_8> . we first complete the disparities for the <otherscientificterm_6> using a <method_4> . the completed disparities can be used to facilitate the user in labeling objects to be removed . since part of the removed regions in one image is visible in the other , we mutually complete the two images through <otherscientificterm_7> . finally , we complete the remaining unknown regions using a <method_1> , which simultaneously fills in both color and depth . we demonstrate the effectiveness of the proposed algorithm on several challenging <material_2> .	0 10 -1 3 5 9 8 12 10 -1 6 4 11 10 -1 10 -1 7 10 -1 1 10 -1 10 -1
Elastic Fragments for Dense Scene Reconstruction .	reconstruction of detailed scene geometry ; locally smooth scene fragments ; commodity handheld cameras ; complex scene geometry ; high-frequency errors ; range data ; low-frequency distortion ; optimization	<task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task>	2 2 3 ; 6 2 2 ; 4 1 6 ; 4 2 2 ; 2 0 5	we present an approach to <task_0> from range video . <material_5> produced by <method_2> suffers from <otherscientificterm_4> and <otherscientificterm_6> . our approach deals with both sources of error by reconstructing <otherscientificterm_1> and letting these fragments deform in order to align to each other . we develop a volumetric registration formulation that leverages the smoothness of the deformation to make <task_7> practical for large scenes . experimental results demonstrate that our approach substantially increases the fidelity of <otherscientificterm_3> reconstructed with <method_2> .	0 5 8 -1 2 4 6 10 11 12 13 8 -1 1 8 -1 7 8 -1 3 9 8 -1
Unlevel-Sets : Geometry and Prior-Based Segmentation .	zero-crossing of the evolving level set function ; recovered transformation parameters ; chan-vese energy functional ; top-down image segmentation ; point correspondences ; ground truth ; generalized cone ; variational approach ; reference object ; unlevel sections ; visible contour ; shape term ; transformation parameters ; perspective distortion ; contour ; scaling	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 2 ; 13 2 10 ; 7 0 3 ; 13 1 15	we present a novel <method_7> to <task_3> , which accounts for significant projective transformations between a single prior image and the image to be segmented . the proposed <method_7> is coupled with reliable estimation of the <otherscientificterm_12> , without using <otherscientificterm_4> . the prior shape is represented by a <otherscientificterm_6> that is based on the <otherscientificterm_14> of the <otherscientificterm_8> . its <otherscientificterm_9> correspond to possible instances of the <otherscientificterm_10> under <otherscientificterm_13> and <otherscientificterm_15> . we extend the <otherscientificterm_2> by adding a <otherscientificterm_11> . this term measures the distance between the currently estimated section of the <otherscientificterm_6> and the region bounded by the <otherscientificterm_0> . promising segmentation results are obtained for images of rotated , translated , corrupted and partly occluded objects . the <otherscientificterm_1> are compatible with the <otherscientificterm_5> .	7 3 19 16 -1 12 4 16 -1 6 14 8 16 -1 9 10 13 15 18 20 16 -1 2 11 17 16 -1 16 -1 0 16 -1 16 -1
Co-Regression for Cross-Language Review Rating Prediction .	cross-language review rating prediction ; review rating prediction ; unlabeled reviews ; co-regression algorithm ; human ratings ; regression algorithms ; german	<task> <task> <otherscientificterm> <method> <otherscientificterm> <method> <material>	5 0 1 ; 2 0 3	the task of <task_1> can be well addressed by using <method_5> if there is a reliable training set of reviews with <otherscientificterm_4> . in this paper , we aim to investigate a more challenging task of <task_0> , which makes use of only rated reviews in a source language -lrb- e.g. english -rrb- to predict the rating scores of unrated reviews in a target language -lrb- e.g. <material_6> -rrb- . we propose a new <method_3> to address this task by leveraging <otherscientificterm_2> . evaluation results on several datasets show that our proposed <method_3> can consistently improve the prediction results .	1 5 4 8 7 -1 0 6 7 -1 3 2 9 7 -1 7 -1
Sparse probabilistic state mapping and its application to speech bandwidth expansion .	artificial bandwidth expansion ; nar-rowband speech signal ; missing frequency components ; entropic priors ; probabilistic algorithm ; sparsity constraints ; state map ; subspace ; mapping	<task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	4 0 0 ; 4 0 8	in this paper we present a <method_4> that extracts a <task_8> between two subspaces by representing each <otherscientificterm_7> as a collection of states . an arbitrary increase in number of states results in over-fitting the training data without exploring the underlying structure of the map . this paper suggests a method to impose <otherscientificterm_5> on the <otherscientificterm_6> by using <otherscientificterm_3> . this <method_4> is applied to the problem of <task_0> that involves estimating the <method_2> -lrb- 3.7 -- 8 khz and 0 -- 0.3 khz -rrb- of speech given the <otherscientificterm_1> -lrb- 0.3 -- 3.7 khz -rrb- .	4 8 7 11 9 -1 9 -1 5 6 3 9 -1 0 2 1 10 9 -1
Corrected Laplacians : Closer Cuts and Segmentation with Shape Priors .	average case normalized cut ; corrected laplacians ; parameterized family of shapes ; mri medical images ; statistical shape models ; image segmentation applications ; spectral relaxation approaches ; combinatorial solution ; prior information ; cut cost ; weighted graph ; cl optimization ; spectral relaxation ; quantitative comparison ; graph partitioning ; optimization procedure ; matrix sparsity ; ground truth ; edge-relaxation sdps ; foreground regions ; perceptual relevance ; segmentation method	<metric> <otherscientificterm> <otherscientificterm> <material> <method> <task> <method> <method> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <method>	11 0 7 ; 7 4 12 ; 8 0 4 ; 6 0 14 ; 21 0 19 ; 15 0 4 ; 10 0 1 ; 0 5 14	we optimize over the set of <otherscientificterm_1> associated with a <method_10> to improve the <metric_0> of a <otherscientificterm_14> . unlike <method_18> , optimizing over the set cl naturally exploits the <otherscientificterm_16> by operating solely on the diagonal . this structure is critical to <task_5> because the number of vertices is generally proportional to the number of pixels in the image . <method_11> provides a guiding principle for improving the <method_7> over the <otherscientificterm_12> , which is important because small improvements in the <metric_9> often result in significant improvements in the <metric_20> of the segmenta-tion . we develop an <method_15> to accommodate <otherscientificterm_8> in the form of <method_4> , resulting in a <method_21> that produces <otherscientificterm_19> which are consistent with a <otherscientificterm_2> . we validate our <method_15> with <otherscientificterm_17> on <material_3> , providing a <otherscientificterm_13> against results produced by current <method_6> to <otherscientificterm_14> .	1 10 0 14 29 30 22 -1 18 16 22 -1 5 11 22 -1 7 12 9 20 23 24 22 -1 15 25 27 28 22 -1 8 4 21 19 2 26 22 -1
Expensive Function Optimization with Stochastic Binary Outcomes .	stochastic binary optimization problem ; bayesian optimization framework ; real world systems ; bayesian optimization methods ; experiment selection metric ; stochastic binary outcome ; offline training phase ; bayesian optimization ; synthetic problems ; physical system ; bandit problems ; gaussian processes ; parameterized controllers	<task> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <method> <task> <method> <method>	11 0 0 ; 3 0 2 ; 12 0 2 ; 1 0 0 ; 5 0 7	real world systems often have <method_12> which can be tuned to improve performance . <method_3> provide for efficient optimization of these <method_2> , so as to reduce the number of required experiments on the expensive <method_9> . in this paper we address <task_7> in the setting where performance is only observed through a <otherscientificterm_5> -- success or failure of the experiment . unlike <task_10> , the goal is to maximize the <method_2> performance after this <otherscientificterm_6> rather than minimize regret during training . in this work we define the <task_0> and propose an approach using an adaptation of <method_11> for <task_0> that presents a <method_1> for this <task_0> . we propose an <method_4> for this setting based on expected improvement . we demonstrate the algorithm 's performance on <task_8> and on a real snake robot learning to move over an obstacle .	12 3 16 13 -1 2 9 15 13 -1 7 5 18 13 -1 10 6 13 -1 0 11 14 17 13 -1 1 13 -1 4 13 -1
Solving MAP Exactly by Searching on Compiled Arithmetic Circuits .	constrained treewidth of the network ; compilation of bayesian networks ; posteriori hypothesis -rrb- problem ; structure-based inference methods ; compiled arithmetic circuit ; branch-and-bound search ; treewidth-imposed limits ; join-tree algorithms ; arithmetic circuits ; local structure ; constrained treewidth ; bayesian networks ; variable elimination ; linear-time operations ; treewidth ; bounds ; map	<otherscientificterm> <method> <task> <method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	3 0 16 ; 1 0 8 ; 12 1 7 ; 11 0 8	the <method_16> -lrb- maximum a <task_2> in <method_11> is to find the most likely states of a set of variables given partial evidence on the complement of that set . standard <method_3> for finding exact solutions to <method_16> , such as <method_12> and <method_7> , have complexities that are exponential in the <otherscientificterm_0> . a more recent algorithm , proposed by park and darwiche , is exponential only in the <otherscientificterm_14> and has been shown to handle networks whose <otherscientificterm_10> is quite high . in this paper we present a new algorithm for exact <method_16> that is not necessarily limited in scalability even by the <otherscientificterm_14> . this is achieved by leverag-ing recent advances in <method_1> into <method_8> , which can circumvent <otherscientificterm_6> by exploiting the <otherscientificterm_9> present in the <method_11> . specifically , we implement a <method_5> where the <otherscientificterm_15> are computed using <otherscientificterm_13> on the <method_4> . on networks with <otherscientificterm_9> , we observe orders-of-magnitude improvements over the algorithm of park and darwiche . in particular , we are able to efficiently solve many problems where the latter algorithm runs out of memory because of high <otherscientificterm_14> .	16 2 11 17 -1 3 12 7 0 18 20 17 -1 14 10 17 -1 17 -1 19 21 17 -1 1 8 6 9 17 -1 5 15 13 4 17 -1 17 -1
Non-parametric Bayesian Segmentation of Japanese Noun Phrases .	non-parametric bayesian language models ; japanese noun phrase segmentation ; hybrid type-based sampling ; external lexical resources ; block sampling procedure ; word segmenta-tion ; morphological dictionary ; morphological ana-lyzer ; segmentation criteria ; global optimum ; lexical resource ; high-coverage dictionary ; local optimum ; japanese ; inference	<method> <task> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <material> <material> <otherscientificterm> <material> <task>	7 0 4	a key factor of high quality <task_5> for <material_13> is a <material_11> , but it is costly to manually build such a <material_10> . although <material_3> for human readers are potentially good knowledge sources , <material_3> have not been utilized due to differences in <metric_8> . to supplement a <otherscientificterm_6> with these resources , we propose a new task of <task_1> . we apply <method_0> to segment each noun phrase in these resources according to the statistical behavior of its supposed constituents in text . for <task_14> , we propose a novel <method_4> named <method_2> , which has the ability to directly escape a <otherscientificterm_12> that is not too distant from the <otherscientificterm_9> . experiments show that the proposed <method_4> efficiently corrects the initial segmentation given by a <otherscientificterm_7> .	5 13 11 10 15 -1 3 8 15 -1 6 1 15 -1 0 15 -1 14 4 2 15 -1 12 9 16 15 -1
Delaying Commitment in Plan Recognition Using Combinatory Categorial Grammars .	combinatory categorial grammar ; lexicalized intent recognition -rrb- ; plan goals ; grammatical formalism ; plan recognition	<method> <task> <otherscientificterm> <method> <task>	0 6 3	this paper presents a new algorithm for <task_4> called elexir -lrb- engine for <task_1> . elexir represents the plans to be recognized with a <method_3> called <method_0> . we show that representing plans with <method_0> can allow us to prevent early commitment to <otherscientificterm_2> and thereby reduce runtime .	4 1 5 -1 3 0 6 5 -1 2 5 -1
Entity-Centric Coreference Resolution with Model Stacking .	conll shared task dataset ; mention pair scores ; entity-centric coreference system ; mention pair models ; entity-level information ; coref-erence resolution ; loss function ; english portion ; entity-level features ; search space ; coreference chains ; features ; policy	<material> <metric> <method> <method> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 0 10 ; 1 3 2 ; 2 0 12 ; 11 0 2 ; 1 0 9 ; 3 0 8	mention pair <method_3> that predict whether or not two mentions are coreferent have historically been very effective for <task_5> , but do not make use of <otherscientificterm_4> . however , we show that the scores produced by such <method_3> can be aggregated to define powerful <otherscientificterm_8> between clusters of mentions . using these <otherscientificterm_11> , we train an <method_2> that learns an effective <otherscientificterm_12> for building up <otherscientificterm_10> incrementally . the <metric_1> are also used to prune the <otherscientificterm_9> the <method_2> works in , allowing for efficient training with an exact <otherscientificterm_6> . we evaluate our <method_2> on the <material_7> of the 2012 <material_0> and show that <method_2> improves over the current state of the art .	3 5 4 13 -1 8 19 13 -1 11 2 12 10 14 16 17 13 -1 1 9 6 15 18 13 -1 7 13 -1
Do discourse cues facilitate recall in information presentation messages ? .	information presentation ; discourse cues ; item recall	<task> <otherscientificterm> <task>	0 0 2	this paper describes an experiment comparing the effect of two different approaches to <task_0> on <task_2> . the results show that using <otherscientificterm_1> facilitates recalling the presented information .	0 2 4 3 -1 1 3 -1
RANSAC versus CS-RANSAC .	constraint satisfaction problems ; computer vision field ; model estimation step ; stereo images ; degenerate features ; feature points ; homography matrix ; sampling problem ; correspondence problem ; ransac algorithm ; execution time ; features ; ransac ; grid ; image ; two-layers	<method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <task> <task> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	6 3 2 ; 6 0 1 ; 9 0 15 ; 0 0 4 ; 9 4 12 ; 1 0 8 ; 9 0 6 ; 6 0 8 ; 3 0 8	a <method_6> is used in <task_1> to solve the <task_8> between a pair of <material_3> . <method_9> is often used to calculate the <method_6> by randomly selecting a set of <otherscientificterm_11> iteratively . <method_9> in this paper converts <method_9> into <method_15> . the first layer is addressing <task_7> which we can describe our knowledge about <otherscientificterm_4> by mean of <method_0> . by dividing the input <otherscientificterm_14> into a <otherscientificterm_13> and making <otherscientificterm_5> into discrete domains , we can model the <otherscientificterm_14> into the <method_0> to efficiently filter out <otherscientificterm_4> . by expressing the knowledge about degenerate feature samples using <method_0> in the first layer , so that computer has knowledge about how to skip computing the <method_6> in the <otherscientificterm_2> for the second layer . the experimental results show that the proposed <method_9> can outperform the most of variants of <method_12> without sacrificing its <metric_10> .	6 1 8 3 9 18 22 24 25 16 -1 11 23 16 -1 15 19 16 -1 7 4 0 16 -1 14 13 5 20 16 -1 17 16 -1 2 21 16 -1
Study of Dynamical Processes with Tensor-Based Spatiotemporal Image Processing Techniques .	ocean surface microturbulence in ir image sequences ; exchange , growth , and transport processes ; first-order derivatives of the motion field ; dynamical changes of the moving objects ; optimization of low-level motion estimators ; estimation of the motion field ; image sequence processing techniques ; analysis of plant growth ; calibrated image sequence ; two-point calibration ; dynamical processes ; spatial nonuni-formity ; derivative filters ; motion estimation ; environmental physics ; tensor method ; real-world images ; sediment transport ; computer-generated sequences ; ccd sensors ; responsivity ; pixels/frame ; accuracy ; biology	<task> <task> <otherscientificterm> <otherscientificterm> <task> <task> <method> <task> <material> <method> <method> <otherscientificterm> <method> <task> <material> <method> <material> <task> <material> <otherscientificterm> <otherscientificterm> <metric> <metric> <material>	2 1 3 ; 6 0 1 ; 19 0 13 ; 11 2 20 ; 6 0 0 ; 18 5 15 ; 18 1 8 ; 14 1 23 ; 16 0 21 ; 6 0 7 ; 0 1 17 ; 6 0 17 ; 8 5 15 ; 22 5 15 ; 12 0 15 ; 22 5 13 ; 22 5 5 ; 20 2 19 ; 7 1 0	image sequence processing <method_6> are used to study <task_1> and to tackle key questions in <material_14> and <material_23> . these applications require high <metric_22> for the <task_5> since the most interesting parameters of the <method_10> studied are contained in <otherscientificterm_2> or in <otherscientificterm_3> . therefore the performance and <task_4> is discussed . a <method_15> tuned with carefully optimized <method_12> yields reliable and dense displacement vector fields -lrb- dvf -rrb- with an <metric_22> of up to a few hundredth <metric_21> for <material_16> . the <metric_22> of the <method_15> is verified with <material_18> and a <material_8> . with the improvements in <metric_22> the <task_13> is now rather limited by imperfections in the <otherscientificterm_19> , especially the <otherscientificterm_11> in the <otherscientificterm_20> . with a simple <method_9> , these effects can efficiently be suppressed . the application of the <method_6> to the <task_7> , to <task_0> , and to <task_17> is demonstrated .	6 1 14 23 26 32 24 -1 22 5 10 2 3 25 41 24 -1 4 24 -1 15 12 21 16 33 39 24 -1 18 8 30 31 37 38 24 -1 27 28 40 42 24 -1 13 19 11 20 24 -1 9 29 34 35 36 43 24 -1
Bilinear signal synthesis in array processing .	time-frequency domain ; smearing of the signal terms ; blind source separation methods ; spatial signatures of sources ; multiple source signals ; source separation techniques ; spatial time-frequency distributions ; quadratic t-f distributions ; time-frequency synthesis techniques ; source positions ; angular separations ; communication channel ; noise levels ; non-integer values ; weighing function ; time-frequency distributions ; antenna array ; veraging ; crossterms ; whitening	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	9 1 10 ; 8 0 4 ; 13 0 14 ; 14 0 0 ; 7 0 5 ; 6 0 2 ; 8 0 16	| <otherscientificterm_4> impinging on an <otherscientificterm_16> can be separated by <method_8> . averaging of the <otherscientificterm_15> of the data across the array permits the <otherscientificterm_3> to play a fundamental role in improving the synthesis performance . array a <method_17> introduces a <otherscientificterm_14> in the <otherscientificterm_0> that decreases the <otherscientificterm_12> , reduces the interactions of the source signals , and mitigates the <otherscientificterm_18> . this is achieved independent of the temporal characteristics of the source signals and without causing any <otherscientificterm_1> . the <otherscientificterm_14> may take <otherscientificterm_13> , which are determined by the <otherscientificterm_11> , the <otherscientificterm_9> and their <otherscientificterm_10> . unlike the recently devised <method_2> using <otherscientificterm_6> , the proposed method does not require <otherscientificterm_19> or retrieval of the source directional matrix . the paper evaluates the proposed method in terms of performance and computations relative t o the existing <method_5> based on <otherscientificterm_7> .	4 16 8 22 27 20 -1 15 3 20 -1 17 14 0 12 18 24 20 -1 1 20 -1 13 11 9 10 21 23 20 -1 26 20 -1 2 6 19 25 20 -1
Probabilistic latent variable models for distinguishing between cause and effect .	probabilistic latent variable models ; hypothetical cause variable ; bayesian model selection ; hypothetical effect variable ; real-world data ; causal direction ; unobserved noise ; synthetic data ; model class	<method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	2 0 5	we propose a novel method for inferring whether x causes y or vice versa from joint observations of x and y . the basic idea is to model the observed data using <method_0> , which incorporate the effects of <otherscientificterm_6> . to this end , we consider the <otherscientificterm_3> to be a function of the <otherscientificterm_1> and an independent noise term -lrb- not necessarily additive -rrb- . an important novel aspect of our work is that we do not restrict the <otherscientificterm_8> , but instead put general non-parametric priors on this function and on the distribution of the cause . the <otherscientificterm_5> can then be inferred by using standard <method_2> . we evaluate our approach on <material_7> and <material_4> and report encouraging results .	9 -1 0 6 9 -1 3 1 9 -1 8 9 -1 10 9 -1 5 2 9 -1
Automatic recognition of speech without any audio information .	hidden markov models ; electromagnetic articulogra-phy device ; automatic recognition of speech ; automatic speech recognition ; audio information ; lip parameters ; tongue parameters ; phonetic features ; features ; acoustics ; articulation ; accuracy	<otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric>	1 0 0 ; 6 4 5 ; 11 5 6	this article introduces <task_2> without any <otherscientificterm_4> . movements of the tongue , lips , and jaw are tracked by an <method_1> and are used as <otherscientificterm_8> to create <otherscientificterm_0> and conduct <task_3> in a conventional way . the results obtained are promising , which confirm that <otherscientificterm_7> characterizing <task_10> are as discriminating as those characterizing <otherscientificterm_9> -lrb- except for voicing -rrb- . the results also show that using <otherscientificterm_6> result in a higher <metric_11> compared with the <otherscientificterm_5> .	2 4 12 -1 1 8 0 3 13 12 -1 7 10 9 12 -1 6 11 5 14 15 12 -1
PR : More than Meets the Eye .	statistical descriptors of lsb occurrences ; progressive randomiza-tion ; broad image categorization ; training examples ; image descriptor ; image databases ; images ; perturbations ; accuracy	<method> <method> <task> <material> <method> <material> <material> <otherscientificterm> <metric>	5 0 4 ; 0 0 4 ; 4 0 2	in this paper , we introduce a new <method_4> for <task_2> , the <method_1> , that uses <otherscientificterm_7> on the values of the least significant bits -lrb- lsb -rrb- of <material_6> . we show that different classes of <material_6> have a distinct behavior under our <method_4> , and that using <method_0> and enough <material_3> , the <method_4> already performs as well or better than comparable existing techniques in the literature . with few <material_3> , pr still has good separability , and its <metric_8> increases with the size of the training set . we validate our <method_4> using four <material_5> with different categories .	4 2 1 7 6 12 9 -1 0 3 11 9 -1 8 9 -1 5 10 9 -1
A Tuned Eigenspace Technique for Articulated Motion Recognition .	real-world and synthetic pose recognition ; human motion recognition ; tuned eigenspace technique ; background subtraction method ; clothing texture ; real-world data ; sequential postures ; tuned eigenspaces ; human motions ; sequential eigenspaces ; outdoor environment ; recognition task ; human poses ; synthetic imagery ; articulated motion ; human motion	<task> <task> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <material> <otherscientificterm> <otherscientificterm>	2 0 1 ; 2 0 10 ; 2 0 15 ; 2 0 0	in this paper , we introduce a <method_2> so as to classify <otherscientificterm_15> . the <method_2> presented here overcomes those problems related to <otherscientificterm_14> and dress texture effects by learning various <otherscientificterm_8> in terms of their <otherscientificterm_6> in an eigenspace . in order to cope with the variability inherent to <otherscientificterm_14> , we propose a <method_2> to tune the set of <otherscientificterm_9> . once the learnt <otherscientificterm_7> are at hand , the <task_11> then becomes a nearest-neighbor search over the eigenspaces . we show how our <method_2> can be used for purposes of <task_0> . we also discuss and overcome the problem related to <otherscientificterm_4> that occurs in <material_5> , and propose a <method_3> to employ the <method_2> in <otherscientificterm_10> . we provide results on <material_13> for a number of <material_12> and illustrate the utility of the <method_2> for the purposes of <task_1> .	2 15 19 16 -1 14 8 6 16 -1 9 16 -1 7 11 16 -1 0 20 16 -1 18 16 -1 4 5 3 10 17 16 -1
Interactive Tracking of 2D Generic Objects with Spacetime Optimization .	interactive tracking of 2d generic objects ; simultaneous tracking of multiple objects ; sudden movement of objects ; continuous optimization framework ; spacetime optimization framework ; visual measurements ; tracking ambiguity ; illumination changes ; user constraints ; scale	<task> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 1 1 ; 3 0 0 ; 3 0 6	we present a <method_3> for <task_0> in a single video stream . the user begins with specifying the locations of a target object in a small set of keyframes ; the <method_3> then automatically tracks locations of the objects by combining <otherscientificterm_8> with <otherscientificterm_5> across the entire sequence . we formulate the problem in a <method_4> that optimizes over the whole sequence simultaneously . the resulting <method_3> is consistent with <otherscientificterm_5> across the entire sequence while satisfying <otherscientificterm_8> . we also introduce prior terms to reduce <task_6> . we demonstrate the power of our <method_3> on <task_6> with significant occlusions , <otherscientificterm_9> and orientation changes , <otherscientificterm_7> , <otherscientificterm_2> , and also <task_1> . we compare the performance of our <method_3> with alternative methods .	3 0 12 10 -1 8 5 10 -1 4 10 -1 10 -1 6 10 -1 11 13 10 -1 9 7 2 1 10 -1
Parameter estimation using sparse reconstruction with dynamic dictionaries .	dynamic dictionary subset selection approach ; fixed dictionary approaches ; parameterized functions ; dictionary quantization ; parameter estimation ; parameter bias ; dictionary elements	<method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	0 0 4 ; 1 0 5	we consider the problem of <task_4> for signals characterized by sums of <otherscientificterm_2> . we present a <method_0> to <task_4> where we iteratively select a small number of <otherscientificterm_6> and then alter the parameters of these <otherscientificterm_6> to achieve better signal model fit . the proposed <method_0> avoids the use of highly oversampled -lrb- and highly correlated -rrb- <otherscientificterm_6> , which are needed in <method_1> to reduce <otherscientificterm_5> associated with <otherscientificterm_3> . we demonstrate estimation performance on a sinusoidal signal estimation example .	4 2 7 -1 0 6 8 7 -1 1 5 3 9 7 -1 7 -1
Cluster identification for speaker-environment tracking .	cluster-labelling scheme selection ; cluster identification ; broadcast news ; speaker-environment tracking ; bbn metrics	<task> <method> <material> <task> <metric>	4 0 3	cluster identification is introduced as the process of jointly evaluating clustering and labelling schemes for <task_0> . normalized rand and <metric_4> for comparing clustering performances across varied clustering and labelling schemes are presented . the merits of the <metric_4> are evaluated and applied for <task_3> in <material_2> .	0 5 -1 4 5 -1 3 2 1 6 5 -1
Acoustic feature analysis in speech emotion primitives estimation .	robust linear and nonlin-ear estimation techniques ; mean absolute error ; local and global speech duration ; emotion estimation context ; average fusion ; acoustic features ; feature selection ; estimator fusion ; emotion primitives ; relative importance ; valence ; features ; dominance ; energy ; activation ; mfcc ; speech	<method> <metric> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material>	2 1 13 ; 14 1 12 ; 5 3 3 ; 14 6 8 ; 10 1 14 ; 10 6 8 ; 0 0 8 ; 12 6 8	we recently proposed a family of <method_0> for recognizing the three <otherscientificterm_8> -- <otherscientificterm_10> , <otherscientificterm_14> , and <otherscientificterm_12> -- from <material_16> . these were based on both <otherscientificterm_2> , <otherscientificterm_13> , <method_15> and pitch <otherscientificterm_11> . this paper aims to study the <otherscientificterm_9> of these four categories of <otherscientificterm_5> in this <otherscientificterm_3> . three measures are considered : the number of <otherscientificterm_11> from each category when all <otherscientificterm_11> are used in selection , the <metric_1> when each category is used separately , and the <metric_1> when a category is excluded from <otherscientificterm_6> . we find that the <otherscientificterm_9> is in the order of <method_15> > energy ≈ pitch > duration . additionally , <method_7> almost always improves performance , and locally weighted fusion always outperforms <metric_4> regardless of the number of <otherscientificterm_11> used .	0 8 10 14 12 16 19 21 22 23 24 25 17 -1 2 13 15 11 18 17 -1 9 5 3 20 17 -1 1 6 17 -1 17 -1 17 -1
FBEM : A filter bank EM algorithm for the joint optimization of features and acoustic model parameters in bird call classification .	expectation-maximization algorithm ; optimal acoustic model parameters ; classification error rate ; bird call classification ; cepstral feature extraction ; gradient ascent method ; mel-scaled filter bank ; filter bank ; antbird calls ; features	<method> <otherscientificterm> <metric> <task> <task> <method> <material> <method> <material> <otherscientificterm>	2 5 9 ; 6 0 9 ; 4 0 3 ; 0 0 1	this paper extends the <method_0> to estimate not only <otherscientificterm_1> , but also optimal center frequencies and bandwidths of the <method_7> used in <task_4> for <task_3> . the search is done using the <method_5> . filter bank and model parameters are optimized iteratively . experiments are conducted on a large noisy corpus containing <material_8> from 5 species . it is shown that <otherscientificterm_9> extracted using the optimized <method_7> result in a lower <metric_2> than those extracted using a <material_6> .	0 1 7 4 3 13 14 10 -1 5 10 -1 10 -1 8 10 -1 9 2 6 11 12 10 -1
Instance-Based Utile Distinctions for Reinforcement Learning with Hidden State .	reinforcement learning algorithm ; utile suffix memory ; state aliasing ; short-term memory ; hidden state ; tree-structured representation ; statistical tests	<method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method>	3 0 2 ; 0 0 2 ; 5 0 1 ; 1 6 0 ; 3 0 0	we present <method_1> , a <method_0> that uses <otherscientificterm_3> to overcome the <method_2> that results from <otherscientificterm_4> . by combining the advantages of previous work in instance-based -lrb- or '' memory-based '' -rrb- learning and previous work with <method_6> for separating noise from task structure , the <method_0> learns quickly , creates only as much memory as needed for the task at hand , and handles noise well . <method_1> uses a <method_5> , and is related to work on predic	1 0 3 2 4 8 9 11 12 7 -1 6 7 -1 5 10 7 -1
Data driven example based continuous speech recognition .	pure example based recognition ; large vocabulary speech recognition ; dominant acoustic modeling methodology ; hidden markov models ; data driven approach ; speaker and environment ; speaker information ; time dependencies ; speech examples ; dtw algorithm ; search space ; dtw-alignment ; hmm ; adaptation	<task> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <task>	7 1 6 ; 4 0 8	the <method_2> based on <method_3> is known to have certain weaknesses . partial solutions to these flaws have been presented , but the fundamental problem remains : compression of the data to a compact <method_12> discards useful information such as <otherscientificterm_7> and <otherscientificterm_6> . in this paper , we look at <task_0> as a solution to this problem . by replacing the <method_12> with the underlying examples , all information in the training data is retained . we show how information about <otherscientificterm_5> can be used , introducing a new interpretation of <task_13> . the basis for the <task_0> is the well-known <method_9> , which has often been used for small tasks . however , <task_1> introduces new demands , resulting in an explosion of the <otherscientificterm_10> . we show how this problem can be tackled using a <method_4> which selects appropriate <material_8> as candidates for <method_11> .	2 3 14 -1 12 7 6 15 14 -1 0 14 -1 14 -1 5 13 14 -1 14 -1 9 14 -1 1 10 16 14 -1
Rate-optimal MIMO transmission with mean and covariance feedback at low SNR .	multiple-input multiple-output wireless communication scenario ; spatially-correlated complex gaussian distribution ; ergodic rate perspective ; ergodic achievable rate ; non-zero mean ; low snrs ; beamforming strategy	<method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method>	4 2 1	we consider a <method_0> in which the channel follows a general <method_1> with <otherscientificterm_4> . we derive an explicit characterization of the optimal input covariance from an <otherscientificterm_2> for systems that operate at <otherscientificterm_5> . this characterization is in terms of the eigen decomposition of a matrix that depends on the mean and the covariance of the channel , and typically results in a <method_6> along the principal eigenvector of that matrix . simulation results show the potential impact of -lrb- jointly -rrb- exploiting the mean and the covariance of the channel on the <metric_3> at both low and moderate-to-high snrs .	0 1 4 8 7 -1 2 5 7 -1 6 7 -1 3 7 -1
Two-Phase Kernel Estimation for Robust Motion Deblurring .	iterative support detection kernel refinement ; tv-1 deconvolution model ; gradient selection process ; profit kernel estimation ; motion deblurring problems ; variable substitution scheme ; image edges ; non-blind deconvolution ; motion deblurring ; spatial prior ; hard threshold ; kernel estimation ; edges ; noise ; sparsity	<method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 1 2 ; 11 1 7 ; 5 0 1 ; 5 0 13 ; 6 0 8 ; 9 0 0 ; 8 1 2	we discuss a few new <task_4> that are significant to <task_11> and <otherscientificterm_7> . we found that strong <otherscientificterm_12> do not always <otherscientificterm_3> , but instead under certain circumstance degrade it . this finding leads to a new metric to measure the usefulness of <otherscientificterm_6> in <task_8> and a <method_2> to mitigate their possible adverse effect . we also propose an efficient and high-quality <task_11> method based on using the <otherscientificterm_9> and the <method_0> , which avoids <otherscientificterm_10> of the kernel elements to enforce <otherscientificterm_14> . we employ the <method_1> , solved with a new <method_5> to robustly suppress <otherscientificterm_13> .	4 11 7 17 15 -1 12 3 15 -1 6 8 2 16 20 22 15 -1 9 0 10 14 21 15 -1 1 5 13 18 19 15 -1
What do color changes reveal about an outdoor scene ? .	spectral composition of daylight ; radiometric and geometric information ; analysis of outdoor scenes ; temporal color changes ; time-lapse video data ; ambient skylight ; direct sunlight ; visual tasks ; scene reconstruction ; shadow detection ; image sequence ; camera geo-location ; background subtraction	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <task> <task> <otherscientificterm> <task> <task>	8 6 7 ; 11 6 7 ; 9 1 8 ; 12 6 7 ; 8 1 11 ; 4 0 2 ; 12 1 8 ; 9 6 7 ; 12 1 9 ; 9 1 11	in an extended <otherscientificterm_10> of an outdoor scene , one observes changes in color induced by variations in the <otherscientificterm_0> . this paper proposes a model for these <otherscientificterm_3> and explores its use for the <task_2> from <material_4> . we show that the time-varying changes in <otherscientificterm_6> and <otherscientificterm_5> can be recovered with this model , and that an <otherscientificterm_10> can be decomposed into two corresponding components . the decomposition provides access to both <otherscientificterm_1> about a scene , and we demonstrate how this can be exploited for a variety of <task_7> , including color-constancy , <task_12> , <task_9> , <task_8> , and <task_11> .	10 0 13 -1 3 2 4 19 13 -1 6 5 13 -1 1 7 12 9 14 15 16 17 18 20 21 22 23 13 -1
Aligning Clattses in Parallel Texts .	automatic alignment of parallel texts ; small eng ~ lish-greek corpus ; parallel bilingual corpus ; dynamic progranuning framework ; shallow linguistic processing ; simulated annealing system ; sentence size ; part-of-speech categories ; software systems ; parallel texts ; probabilistic model ; parallel text ; word occurrence ; character lengths ; clause alignments ; regular grammars ; clause level ; statistical techniques ; 1he method ; co-occurrence probabilities	<task> <material> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm>	1 5 18 ; 17 1 4 ; 12 1 13 ; 16 2 0 ; 19 1 13 ; 12 1 19	this paper describes a method for the <task_0> at <otherscientificterm_16> . the method features <method_17> coupled with <method_4> . it presupposes a <material_2> and identifies alignments between the clauses of the source and target language sides of the corpus . <material_9> are first statistically aligned at sentence level and then tagged with their <otherscientificterm_7> . <method_15> functioning on tags , recognize clauses on both sides of the <material_11> . a <method_10> is applied next , operating on the basis of <otherscientificterm_12> and <otherscientificterm_19> and <otherscientificterm_13> . depending on <otherscientificterm_6> , possible alignments arc fed into a <method_3> or a <method_5> in order to find or approxim ~ te the best alignment . <method_18> has been tested on a <material_1> consisting of texts relevant to <method_8> and has produced promising results in terms of correctly identified <otherscientificterm_14> .	0 16 24 20 -1 17 4 22 20 -1 2 9 20 -1 7 15 20 -1 11 20 -1 10 12 19 13 23 25 26 20 -1 6 3 5 20 -1 18 21 20 -1
Learning to Take Concurrent Actions .	semi-markov decision process framework ; concurrent temporally extended actions ; concurrent decision making ; parallel termination schemes	<method> <otherscientificterm> <task> <method>	0 0 2	we investigate a general <method_0> for modeling <task_2> , where agents learn optimal plans over <otherscientificterm_1> . we introduce three types of <method_3> -- all , any and continue -- and theoretically and experimentally compare them .	0 2 1 5 4 -1 3 4 -1
On Maximizing the Within-Cluster Homogeneity of Speaker Voice Characteristics For Speech Utterance Clustering .	unknown speech utterances ; divergence-based model similarity ; within-cluster homogeneity ; within-cluster utterances ; computational efficiency ; likelihood probability ; cluster model ; genetic algorithm ; clusters ; cluster	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	1 2 5	this paper investigates the problem of how to partition <otherscientificterm_0> into <otherscientificterm_8> , such that the overall <otherscientificterm_2> of speakers ' voice characteristics can be maximized . the <otherscientificterm_2> is characterized by the <otherscientificterm_5> that a <method_6> , trained using all the utterances within a <otherscientificterm_9> , matches each of the <otherscientificterm_3> . such probability is then maximized by using a <method_7> , which determines the best <otherscientificterm_9> where each utterance should be located . for greater <metric_4> , also proposed is an alternative solution that approximates the <otherscientificterm_5> with a <otherscientificterm_1> . the method is further designed to estimate the optimal number of <otherscientificterm_8> automatically .	0 8 2 10 -1 5 6 9 3 10 -1 7 10 -1 4 1 11 10 -1 10 -1
A Multibaseline Stereo System with Active Illumination and Real-Time Image Acquisition .	dense stereo depth data ; parallel depth recovery scheme ; camera view areas ; four-camera multibaseline stereo ; stereo depth data ; video rate ; conver-gent configuration ; image capture ; three-dimensional tracking ; local discriminability	<material> <method> <otherscientificterm> <method> <material> <material> <otherscientificterm> <task> <method> <otherscientificterm>	1 0 7 ; 1 0 3 ; 7 5 1 ; 6 2 3	we describe our implementation of a <method_1> for a <method_3> in a <otherscientificterm_6> . our <method_1> is capable of <task_7> at <material_5> . this is critical in applications that require <method_8> . we obtain <material_0> by projecting a light pattern of frequency modulated sinusoidally varying intensity onto the scene , thus increasing the <otherscientificterm_9> at each pixel and facilitating matches . in addition , we make most of the <otherscientificterm_2> by converging them at a volume of interest . results show that we are able to extract <material_4> that are , on the average , less than 1 mm in error at distances between 1.5 to 3.5 m away from the cameras .	1 3 6 12 14 10 -1 7 5 11 13 10 -1 8 10 -1 0 9 10 -1 2 10 -1 4 10 -1
Source coding with intermittent and degraded side information at the decoder .	gaussian-erasure models ; lower and upper bounds ; non-standard correlation models ; ge correlation model ; distributed video coding ; practical schemes ; rate-distortion functions ; correlation models ; impulse noise ; rate-distortion function ; gaussian correlation ; gaussian sources ; side information ; erasures ; decoder ; non-stationarities	<method> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	5 0 4 ; 9 0 10 ; 12 0 5 ; 7 0 11	practical schemes for <task_4> with <otherscientificterm_12> at the <method_14> need to consider <method_2> in order to take <otherscientificterm_15> into account . in this paper we introduce two <method_7> for <material_11> , the gaussian-bernoulli-gaussian -lrb- gbg -rrb- and the <method_0> , and evaluate <otherscientificterm_1> on their <otherscientificterm_6> . provided that the probability of <otherscientificterm_8> or of <otherscientificterm_13> remains small , these bounds remain close to the <otherscientificterm_9> for <otherscientificterm_10> . two practical schemes for the <method_3> are also presented , with performance about 1.5 db away from the upper bound .	4 12 14 2 15 17 19 16 -1 7 11 0 1 6 20 16 -1 8 13 9 10 18 16 -1 3 5 16 -1
A Characterization of n-Player Strongly Monotone Scheduling Mechanisms .	additive combinatorial auctions ; affine min-imizers ; additive valuations ; player-grouping minimizer ; task-independent	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	4 1 3	our work deals with the important problem of globally characterizing truthful mechanisms where players have multi-parameter , <otherscientificterm_2> , like scheduling unrelated machines or <otherscientificterm_0> . very few mechanisms are known for these settings and the question is : can we prove that no other truthful mechanisms exist ? we characterize truthful mechanisms for n players and 2 tasks or items , as either <otherscientificterm_4> , or a <method_3> , a new class of mechanisms we discover , which generalizes <method_1> . we assume decisiveness , strong mono-tonicity and that the truthful payments 1 are continuous functions of players ' bids .	2 0 5 -1 4 3 1 5 -1 6 5 -1 5 -1
Random time-frequency subdictionary design for sparse representations with greedy algorithms .	low bit rate compression of audio signals ; low bit-rate coding schemes ; sparse signal approximation ; greedy decomposition process ; controlled computational complexity ; probabilistic fashion ; parameter estimation ; dictionary space ; decomposition algorithms ; sparse decompositions ; sparsity	<otherscientificterm> <method> <method> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	2 0 1 ; 2 0 8	sparse signal approximation can be used to design efficient <method_1> . <method_2> heavily relies on the ability to design appropriate dictionaries and corresponding <method_8> . the size of the dictionary , and therefore its resolution , is a key parameter that handles the tradeoff between <otherscientificterm_10> and tractability . this work proposes the use of a non adaptive random sequence of subdictionaries in a <method_3> , thus browsing a larger <otherscientificterm_7> in a <otherscientificterm_5> with no additional projection cost nor <method_6> . this <method_2> leads to very <otherscientificterm_9> , at a <metric_4> . experimental evaluation is provided as proof of concept for <otherscientificterm_0> .	1 2 12 11 -1 8 13 11 -1 10 11 -1 3 7 5 6 11 -1 9 4 11 -1 11 -1
Amplitude modulation features for emotion recognition from speech .	smoothed nonlinear energy operator ; energy separation algorithm ; speech emotion recognition ; discrete cosine transform ; root compressed am power spectrum ; fau aibo spontaneous emotion corpus ; amplitude and frequency components ; c-channel gammatone filterbank ; am power spectrum ; amcc features ; recognizing emotions ; speech features ; emotion recognition ; speech signals ; am-fm signal ; speech signal ; features ; recognition ; mfcc	<method> <method> <task> <method> <otherscientificterm> <material> <method> <method> <method> <method> <task> <otherscientificterm> <task> <material> <material> <material> <otherscientificterm> <task> <method>	15 0 9 ; 7 0 9 ; 13 0 10 ; 0 0 14 ; 5 5 12 ; 7 0 15	the goal of <task_2> is to identify the emotional or physical state of a human being from his or her voice . one of the most important things in a <task_2> is to extract and select relevant <otherscientificterm_11> with which most emotions could be recognized . in this paper , we present a <method_0> - based amplitude modulation cepstral coefficients -lrb- amcc -rrb- feature for <task_10> from <material_13> . <method_0> estimates the energy required to produce the <material_14> , and then the estimated energy is separated into its <method_6> using an <method_1> . <method_9> are obtained by first decomposing a <material_15> using a <method_7> , computing the <method_8> , and taking a <method_3> of the <otherscientificterm_4> . conventional <method_18> -lrb- mel-frequency cepstral coefficients -rrb- and mel-warped dft -lrb- discrete fourier transform -rrb- spectrum based cepstral coefficients -lrb- mwdcc -rrb- <otherscientificterm_16> are used for comparing the <task_17> performances of the proposed <otherscientificterm_16> . <task_12> experiments are conducted on the <material_5> . it is observed from the experimental results that the <method_9> provide a relative improvement of approximately 3.5 % over the baseline <method_18> .	2 19 -1 11 19 -1 0 10 13 22 19 -1 14 6 1 9 23 19 -1 20 21 25 19 -1 15 7 8 3 4 19 -1 18 16 17 12 24 19 -1 5 19 -1
Robust HMM training for unified dutch and German speech recognition .	unified dutch and german speech recognition system ; dutch and german subword recognition tasks ; overall string error rate reduction ; language dependent phoneme models ; mce-trained multilingual system ; mce-based training algorithm ; common phonemes ; acoustic component ; speechdat domain	<method> <material> <metric> <method> <method> <method> <otherscientificterm> <method> <material>	1 5 4 ; 8 2 0 ; 7 3 0 ; 2 5 0 ; 1 5 0 ; 2 5 4 ; 0 4 4	this paper describes our recent work in developing an <method_0> in the <material_8> . the <method_7> of the <method_0> is accomplished through sharing <otherscientificterm_6> without preserving any information about the languages . we propose a more robust <method_5> , where only the <method_3> are allowed to be adjusted , according to the type of training data . experimental results on <material_1> clearly show an <metric_2> of about 7 % and 13 % obtained by the newly trained <method_0> in comparison with the conventional <method_4> .	0 8 11 9 -1 7 6 12 9 -1 5 3 9 -1 1 2 4 10 13 14 15 16 9 -1
Compressive spectral embedding : sidestepping the SVD .	singular value decomposition ; low-complexity compressive spectral embedding algorithm ; m × n matrix ; finite order polynomial expansions ; general svd-based embeddings ; partial svd computation ; dominant singular vectors ; pairwise similarity metrics ; downstream inference tasks ; predefined function ; problem size ; svd-based embedding ; time complexity ; singular vectors ; di-mensionality reduction ; coordinate axes ; t non-zeros ; random projections ; embedding dimension ; network datasets ; problem structure ; spectral embedding ; learning tasks ; arbitrary vectors ; matrix ; embedding ; clustering	<method> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <task>	21 0 22 ; 17 0 1 ; 13 0 4 ; 26 6 8 ; 1 0 8 ; 19 5 1 ; 12 1 18 ; 0 0 21 ; 17 1 3	spectral <method_25> based on the <method_0> is a widely used '' preprocessing '' step in many <task_22> , typically leading to <task_14> by projecting onto a number of <otherscientificterm_6> and rescaling the <otherscientificterm_15> -lrb- by a <otherscientificterm_9> of the singular value -rrb- . however , the number of such vectors required to capture <otherscientificterm_20> grows with <otherscientificterm_10> , and even <method_5> becomes a bottleneck . in this paper , we propose a <method_1> , which employs <otherscientificterm_17> and <method_3> to compute approximations to <task_11> . for an <otherscientificterm_2> with <otherscientificterm_16> , its <metric_12> is o -lrb- -lrb- t + m + n -rrb- log -lrb- m + n -rrb- -rrb- , and the <otherscientificterm_18> is o -lrb- log -lrb- m + n -rrb- -rrb- , both of which are independent of the number of <otherscientificterm_13> whose effect we wish to capture . to the best of our knowledge , this is the first work to circumvent this dependence on the number of <otherscientificterm_13> for <task_4> . the key to sidestepping the <method_0> is the observation that , for <task_8> such as <task_26> and classification , we are only interested in using the resulting <method_25> to evaluate <metric_7> derived from the ℓ 2-norm , rather than capturing the effect of the underlying <otherscientificterm_24> on <otherscientificterm_23> as a partial <method_0> tries to do . our numerical results on <material_19> demonstrate the efficacy of the proposed <method_1> , and motivate further exploration of its application to <task_8> .	25 0 22 14 6 15 9 28 35 27 -1 20 10 5 27 -1 1 17 3 11 29 36 27 -1 2 16 12 34 27 -1 18 13 30 27 -1 4 31 27 -1 8 26 7 32 33 27 -1
Optimizing acoustic models for commercial speech recognition using foreground scores and data weighting .	frame-averaged foreground log-likelihoods -lrb- foreground scores ; live evaluation set ; speech recognition systems ; poorly modeled data ; commercial applications ; score-based optimization ; semantic errors ; data weighting ; recognition errors ; data-driven technique ; acoustic models ; priors	<otherscientificterm> <material> <method> <material> <task> <method> <otherscientificterm> <task> <task> <method> <method> <otherscientificterm>	7 0 10 ; 9 0 2 ; 10 0 2 ; 10 0 4 ; 1 5 5 ; 5 0 10 ; 9 0 10	this paper describes a <method_9> for optimizing the <method_10> for <method_2> that target <task_4> over telephones . <otherscientificterm_0> -rrb- correlate to <task_8> . these scores are used together with gender to optimize <task_7> for the <method_10> . this process is interpreted as increasing the <otherscientificterm_11> and associated parameters for <material_3> . the <method_5> leads to about 7 % fewer <otherscientificterm_6> on a <material_1> collected after the last data used to estimate the <method_10> .	9 10 2 4 0 14 15 16 19 12 -1 8 12 -1 7 13 12 -1 11 3 12 -1 5 6 1 17 18 12 -1
Integration of speaker and pitch adaptive training for HMM-based singing voice synthesis .	hidden markov models ; hmm-based singing voice synthesis systems ; singer adaptive training '' ; data sparse-ness problem ; synthesized singing voices ; statistical parametric approach ; singing voice data ; singing voice synthesis ; contextual factors ; context-dependent hmms ; vibrato ; hmms	<method> <method> <method> <task> <material> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 0 7 ; 5 0 4 ; 0 0 5	a <method_5> to <task_7> based on <method_0> has been growing in popularity over the last few years . the spectrum , exci-tation , <otherscientificterm_10> , and duration of the singing voice in this <method_5> are simultaneously modeled with <otherscientificterm_9> and waveforms are generated from the <method_11> themselves . since <method_1> are '' corpus-based , '' the <method_11> corresponding to <otherscientificterm_8> that rarely appear in the training data can not be well-trained . however , it may be difficult to prepare a large enough quantity of <material_6> sung by one singer . furthermore , the pitch included in each song is imbalanced , and there is the vocal range of the singer . in this paper , we propose '' <method_2> which can solve the <task_3> . experimental results demonstrated that the proposed <method_5> improved the quality of the <material_4> .	5 7 0 13 15 12 -1 10 9 11 12 -1 1 8 12 -1 6 12 -1 12 -1 12 -1 2 3 14 12 -1
Inducing Deterministic Prolog Parsers from Treebanks : A Machine Learning Approach .	corpora of parsed sentences ; inductive logic programming ; machine learning methods ; de-terministic prolog parsers ; prolog rules ; atis corpus ; statistical methods ; parsers	<material> <method> <method> <method> <otherscientificterm> <material> <method> <method>	2 0 4	this paper presents a method for constructing <method_3> from <material_0> . our approach uses recent <method_2> for inducing <otherscientificterm_4> from examples -lrb- <method_1> -rrb- . we discuss several advantages of this method compared to recent <method_6> and present results on learning complete <method_7> from portions of the <material_5> .	3 0 8 -1 2 4 1 9 8 -1 6 7 5 8 -1
Inferring Unseen Views of People .	probabilistic tensor completion problem ; synthetic views of people ; unseen view synthesis ; 3d appearance tensor ; low-dimensional latent factors ; camera viewpoint ; estimating viewpoint ; image positions ; rough viewpoint ; inferred views ; virtual views ; unseen views ; viewpoints ; robustness	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	0 0 2 ; 12 1 7	we pose <otherscientificterm_2> as a <task_0> . given images of people organized by their <otherscientificterm_8> , we form a <otherscientificterm_3> indexed by images -lrb- pose examples -rrb- , <otherscientificterm_12> , and <otherscientificterm_7> . after discovering the <otherscientificterm_4> that approximate that tensor , we can impute its missing entries . in this way , we generate novel <otherscientificterm_1> -- even when they are observed from just one <otherscientificterm_5> . we show that the <otherscientificterm_9> are both visually and quantitatively accurate . furthermore , we demonstrate their value for recognizing actions in <otherscientificterm_11> and <task_6> in novel images . while existing methods are often forced to choose between data that is either realistic or multi-view , our <otherscientificterm_10> offer both , thereby allowing greater <metric_13> to viewpoint in novel images .	2 0 15 14 -1 8 3 12 7 16 14 -1 4 14 -1 1 5 14 -1 9 14 -1 11 6 14 -1 14 -1
Classification of tensors and fiber tracts using Mercer-kernels encoding soft probabilistic spatial and diffusion information .	nonlinear kernel support vector machines ; atlas-based registration of diffusion-free images ; healthy and diseased subjects ; clustering of diffusion tensors ; spatial and diffusion information ; classification of fibers ; soft fiber representation ; diffusion tensors ; kernel-based approach ; mercer kernel ; tensor segmentation ; landmark-isomap embedding ; fiber tracts ; tensor space ; multi-instance kernel ; tensor kernel ; k-means clustering ; kernel-pca	<method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method>	9 4 13 ; 14 0 15 ; 14 0 12 ; 11 1 16 ; 1 0 8 ; 11 0 10 ; 8 0 3 ; 16 0 10 ; 0 0 8 ; 0 0 5 ; 17 0 10 ; 15 0 12	in this paper , we present a <method_8> to the <task_3> and <otherscientificterm_12> . we propose to use a <method_9> over the <otherscientificterm_13> where both <otherscientificterm_4> are taken into account . this <method_9> highlights implicitly the connectivity along <otherscientificterm_12> . <method_10> is performed using <method_17> compounded with a <method_11> and <method_16> . based on a <method_6> , we extend the <method_15> to deal with <otherscientificterm_12> using the <method_14> that reflects not only interactions between points along <otherscientificterm_12> , but also the interactions between <otherscientificterm_7> . this <method_8> is further extended by way of an <task_1> , followed by a <otherscientificterm_5> based on <method_0> . promising experimental results of tensor and fiber classification of the human skeletal muscle over a significant set of <otherscientificterm_2> demonstrate the potential of our <method_8> .	8 3 12 25 18 -1 9 13 4 19 18 -1 10 18 -1 17 11 16 22 24 26 29 18 -1 6 15 14 7 20 21 30 18 -1 1 5 23 27 28 18 -1 0 18 -1
Exploring Distributional Similarity Based Models for Query Spelling Correction .	web query spelling correction task ; query spelling correction models ; distributional similarity based models ; web search relevance ; query logs ; dis-tributional similarity ; distributional similarity ; query speller ; search engine ; correction	<task> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <method> <task> <otherscientificterm>	4 0 6 ; 7 0 3 ; 6 0 1 ; 7 0 8	a <method_7> is crucial to <task_8> in improving <otherscientificterm_3> . this paper describes novel methods for use of <task_6> estimated from <material_4> in learning improved <method_1> . the key to our methods is the property of <otherscientificterm_5> between two terms : it is high between a frequently occurring misspelling and its <otherscientificterm_9> , and low between two irrelevant terms only with similar spellings . we present two models that are able to take advantage of this property . experimental results demonstrate that the <method_2> can significantly outper-form their baseline systems in the <task_0> .	7 8 3 12 14 10 -1 6 4 1 11 13 10 -1 5 9 10 -1 10 -1 2 0 10 -1
A Fast Accurate Two-stage Training Algorithm for L1-regularized CRFs with Heuristic Line Search Strategy .	stochastic gradient descent method ; conditional random fields ; learning rate parameter settings ; name entity recognition tasks ; heuris-tic line search strategy ; two-stage training algorithm ; batch training algorithm ; sparse learning framework ; l1 regularization method ; nature language processing ; chinese word segmentation ; l1 regularization ; training time ; l1-regularized crfs ; quasi-newton method ; convergence ; generalizability	<method> <method> <task> <task> <method> <method> <method> <method> <method> <task> <task> <task> <metric> <method> <method> <otherscientificterm> <otherscientificterm>	3 5 5 ; 7 0 9 ; 14 6 6 ; 10 1 3 ; 4 0 0 ; 0 0 2 ; 0 0 13	sparse learning framework , which is very popular in the field of <task_9> recently due to the advantages of efficiency and <otherscientificterm_16> , can be applied to <method_1> with <method_8> . <method_0> has been used in training <method_13> , because <method_0> often requires much less <metric_12> than the <method_6> like <method_14> in practice . nevertheless , <method_0> sometimes fails to converge to the optimum , and <method_0> can be very sensitive to the <task_2> . we present a <method_5> which guarantees the <otherscientificterm_15> , and use <method_4> to make the first stage of <method_0> more robust and stable . experimental evaluations on <task_10> and <task_3> demonstrate that our <method_5> can produce more accurate and compact model with less <metric_12> for <task_11> .	9 16 1 8 0 19 17 -1 13 12 6 14 20 24 17 -1 2 23 17 -1 5 15 4 22 17 -1 18 21 17 -1
Channel Tracking using Pruning for MIMO-OFDM Systems over Gauss-Markov Channels .	zero-forcing soft detector ; reduced spectral ef ¿ ciency ; kalman ¿ lter mismodeling ; error propagation effect ; time domain tracking ; bit error probability ; channel matrix taps ; kalman ¿ lter ; error propagation ; soft detector ; mimo-ofdm systems ; channel tracking ; gauss-markov model ; communication systems ; detected symbols ; mis-detected symbols ; symbols detection ; detection ; mis-detections	<method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <task>	0 0 16 ; 11 0 10	in this paper we investigate the problem of <task_11> and <task_17> for <method_10> over fast varying channels obeying a <method_12> . we consider <method_4> of the <otherscientificterm_6> with kalman ¿ l-ter , whereas <task_16> is carried out by a <method_0> . a key assumption of the theory of <method_7> is that the <method_12> is perfectly known , while <method_13> make use of the <otherscientificterm_14> as an input to the <method_7> in order to form a suitable <method_12> . this gives rise to <task_8> due to <otherscientificterm_15> -lrb- model mismatch -rrb- and is usually solved by using frequently inserted pilot symbols , resulting in a <otherscientificterm_1> . to overcome this problem , we suggest a novel approach to mitigate the <task_8> due to <task_18> without using frequent pilot symbols . in particular , we consider the reliability of the detections based on the <method_9> and use only those outputs that have robust reliability to track the <otherscientificterm_6> , minimizing the effect of <method_2> . this method can signi ¿ cantly reduce the <metric_3> , leading to an improved <otherscientificterm_5> .	11 17 10 12 21 19 -1 4 6 16 0 20 19 -1 7 13 14 19 -1 8 15 19 -1 1 19 -1 18 19 -1 9 2 19 -1
Scale-Invariant Shape Features for Recognition of Object Categories .	convex local arrangements of contours ; class of distinguished regions ; spurious edge detections ; local interest points ; tangential-gradient energy term ; scale changes ; shape matching ; local convexity ; local support ; cost functions ; entropy term ; angular positions ; gray-level images ; tangential edges ; detected regions ; distinguished regions ; occlusions ; rotations ; clutter	<otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 1 2 ; 9 3 1 ; 4 6 9 ; 5 1 17 ; 18 1 16 ; 15 0 3	we introduce a new <metric_1> based on detecting the most salient <otherscientificterm_0> in the image . the regions are used in a similar way to the <otherscientificterm_3> extracted from <material_12> , but they capture shape rather than texture . <otherscientificterm_7> is characterized by measuring the extent to which the detected image contours support circle or arc-like local structures at each position and scale in the image . our <metric_1> combines two <otherscientificterm_9> defined on the <otherscientificterm_13> near the circle : a <otherscientificterm_4> , and an <otherscientificterm_10> that ensures <otherscientificterm_8> from a wide range of <otherscientificterm_11> around the circle . the <otherscientificterm_14> are invariant to <otherscientificterm_5> and <otherscientificterm_17> , and robust against <otherscientificterm_18> , <otherscientificterm_16> and <otherscientificterm_2> . experimental results show very good performance for both <task_6> and recognition of object categories .	1 0 19 -1 3 12 7 25 19 -1 19 -1 9 13 4 10 8 11 21 22 19 -1 20 23 24 19 -1 14 5 17 18 16 2 19 -1
Feature Clustering for Accelerating Parallel Coordinate Descent .	large-scale 1-regularized loss minimization problems ; maximum inner product ; theoretical convergence analysis ; unified convergence analysis ; large-scale 1-regularization problems ; high-dimensional supervised learning ; coordinate descent algorithms ; block-greedy coordinate descent ; high-performance algorithms ; block-greedy algorithms ; real-world applications ; regression problems ; high-dimensional applications ; greedy cd ; 1-regularized problems ; convergence analysis ; compressed sensing ; thread-greedy ; scd ; parallelism ; features ; shotgun ; classification	<task> <otherscientificterm> <method> <method> <task> <task> <method> <method> <method> <method> <task> <task> <task> <material> <task> <method> <task> <material> <material> <otherscientificterm> <otherscientificterm> <material> <task>	5 6 12 ; 16 6 12 ; 22 6 12 ; 16 1 22 ; 22 1 5 ; 18 1 13 ; 3 0 9 ; 21 1 17 ; 16 1 5 ; 6 0 14 ; 22 1 11 ; 13 1 21	large-scale 1-regularized loss minimization problems arise in <task_12> such as <task_16> and <task_5> , including <task_22> and <task_11> . <method_8> and implementations are critical to efficiently solving these problems . building upon previous work on <method_6> for <task_14> , we introduce a novel family of algorithms called <method_7> that includes , as special cases , several existing algorithms such as <material_18> , <material_13> , <material_21> , and <material_17> . we give a <method_3> for the family of <method_9> . the analysis suggests that <method_7> can better exploit <otherscientificterm_19> if <otherscientificterm_20> are clustered so that the <otherscientificterm_1> between <otherscientificterm_20> in different blocks is small . our <method_2> is supported with experimental results using data from diverse <task_10> . we hope that algorithmic approaches and <method_15> we provide will not only advance the field , but will also encourage researchers to systematically explore the design space of algorithms for solving <task_4> .	12 16 5 22 11 8 24 25 26 27 28 32 34 23 -1 23 -1 6 14 7 18 13 21 17 29 31 33 35 23 -1 3 9 30 23 -1 19 20 1 23 -1 23 -1 2 10 23 -1
On the acoustics of overlapping laughter in conversational speech .	acoustics of overlapping laughs ; contagious nature of laughter ; joint vocal action ; spoken dialogue systems ; overlapping laughter ; non-overlapping laughs ; maximum intensity ; laughter event ; non-overlapping ones ; group size ; entrainment	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 0	the social nature of laughter invites people to laugh together . this <otherscientificterm_2> often results in <otherscientificterm_4> . in this paper , we show that the <otherscientificterm_0> are different from <otherscientificterm_5> . we found that overlapping laughs are stronger prosodically marked than <otherscientificterm_8> , in terms of higher values for duration , mean f0 , mean and <metric_6> , and the amount of voicing . this effect is intensified by the number of people joining in the <otherscientificterm_7> , which suggests that <otherscientificterm_10> is at work . we also found that <otherscientificterm_9> affects the number of overlapping laughs which illustrates the <otherscientificterm_1> . finally , people appear to join laughter simultaneously at a delay of approximately 500 ms ; a delay that must be considered when developing <method_3> that are able to respond to users ' laughs .	11 -1 2 4 11 -1 0 5 12 11 -1 8 6 11 -1 7 10 11 -1 9 11 -1 1 11 -1
Filter-and-forward distributed beamforming for relay networks in frequency selective fading channels .	finite impulse response filters ; amplify-and-forward distributed beamforming techniques ; destination quality-of-service constraint ; filter-and-forward strategy ; frequency selective fading channels ; half-duplex distributed beamforming technique ; transmitter-to-relay and relay-to-destination channels ; destination qos constraint ; relay transmitted power ; distributed beamforming problem ; transmit relay power ; network relays ; closed-form solution ; relay networks ; receiver	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <metric> <task> <method> <method> <method> <method> <material>	4 0 5 ; 3 0 11 ; 5 0 13 ; 3 0 6	a <method_5> for <method_13> with <otherscientificterm_4> is developed . the <method_11> use the <method_3> to compensate for the <material_6> using <method_0> . with the channel state information -lrb- csi -rrb- being available at the <material_14> , the <method_10> is minimized subject to the <otherscientificterm_2> . this <task_9> is shown to have a <method_12> . simulation results demonstrate substantial improvements in terms of the <metric_8> and feasibility of the <otherscientificterm_7> as compared to <method_1> .	5 13 4 16 18 15 -1 11 3 6 0 17 19 15 -1 14 10 2 15 -1 9 12 15 -1 8 7 1 15 -1
Getting the last laugh : automatic laughter segmentation in meetings .	frame level detection of laughter ; icsi meeting recorder corpus ; high-level and long-term features ; hybrid mlp/hmm system ; equal-prior test set ; recall rate ; precision rate ; median filtering ; viterbi decoding ; short-term features ; laughter segments ; speaker recognition ; laughter detection ; long-term features ; mlps ; mfccs ; eer	<task> <material> <otherscientificterm> <method> <material> <metric> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <method> <method> <metric>	9 0 14 ; 8 3 3 ; 14 0 0 ; 2 1 7 ; 6 1 5 ; 13 1 7 ; 15 6 9 ; 1 5 12	our goal in this work was to develop an accurate method to identify <otherscientificterm_10> , ultimately for the purpose of <task_11> . our previous work used <method_14> to perform <task_0> using <otherscientificterm_9> , including <method_15> and pitch , and achieved a 7.9 % <metric_16> on our test set . we improved upon our previous results by including <otherscientificterm_2> , <method_7> , and performing segmentation via a <method_3> with <method_8> . upon including the <otherscientificterm_13> and <method_7> , our results improved to 5.4 % <metric_16> on our test set and 2.7 % <metric_16> on an <material_4> used by others . after attaining segmentation results by incorporating the <method_3> and <method_8> , we had a 78.5 % <metric_6> and 85.3 % <metric_5> on our test set . to our knowledge these are the best known <task_12> results on the <material_1> to date .	10 11 17 -1 14 0 9 15 16 18 20 24 17 -1 2 7 3 8 19 21 17 -1 13 4 23 17 -1 22 17 -1 6 5 25 17 -1
A Decomposable Attention Model for Natural Language Inference .	stanford natural language inference dataset ; natural language inference ; word-order information ; neural architecture ; intra-sentence attention	<material> <task> <otherscientificterm> <method> <otherscientificterm>	3 0 1	we propose a simple <method_3> for <task_1> . our <method_3> uses attention to decompose the problem into subprob-lems that can be solved separately , thus making it trivially parallelizable . on the <material_0> , we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any <otherscientificterm_2> . adding <otherscientificterm_4> that takes a minimum amount of order into account yields further improvements .	3 1 6 5 -1 5 -1 0 2 5 -1 4 5 -1
Accidental pinhole and pinspeck cameras : Revealing the scene outside the picture .	accidental pin-hole camera image ; accidental '' images ; natural light ; accidental cameras ; reference image ; indoor scene ; lighting conditions ; video sequence ; aperture ; shadows	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	0 0 9	we identify and study two types of '' <material_1> that can be formed in scenes . the first is an <otherscientificterm_0> . these images are often mistaken for <otherscientificterm_9> , but can reveal structures outside a room , or the unseen shape of the light <otherscientificterm_8> into the room . the second class of <material_1> are '' inverse '' pinhole camera images , formed by subtracting an image with a small occluder present from a <material_4> without the oc-cluder . the <material_4> can be an earlier frame of a <material_7> . both types of <material_1> happen in a variety of different situations -lrb- an <otherscientificterm_5> illuminated by <otherscientificterm_2> , a street with a person walking under the shadow of a building , etc. -rrb- . <otherscientificterm_3> can reveal information about the scene outside the image , the <otherscientificterm_6> , or the <otherscientificterm_8> by which light enters the scene .	1 10 -1 0 10 -1 9 8 11 10 -1 4 10 -1 7 10 -1 10 -1 5 2 3 10 -1
A Flow-Based Approach to Vehicle Detection and Background Mosaicking in Airborne Video .	mosaic of the background layer ; stabilization of the frames ; gross affine background motion ; em-based motion segmentation ; dense residual flow ; optical flow algorithm ; airborne video sequences ; detection of vehicles ; background appearance model ; moving airborne platform ; ground vehicles ; stabilized frames ; video stream	<otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <material> <task> <method> <method> <method> <otherscientificterm> <material>	6 0 10 ; 9 0 12 ; 1 0 2 ; 9 0 7	we address the <task_7> in a <material_12> obtained from a <method_9> . our approach is based on robust <method_5> applied on <otherscientificterm_11> . <task_1> compensates for <otherscientificterm_2> prior to running robust optical flow to compute <otherscientificterm_4> . based on the flow and the previous <method_8> , the new frame is separated into background and foreground oc-clusion layers using an <method_3> . the proposed framework shows that <method_10> can be detected and segmented from <material_6> while building a <otherscientificterm_0> .	7 12 9 15 17 13 -1 5 11 1 13 -1 2 4 16 13 -1 8 3 13 -1 10 6 0 14 13 -1
Improving the performance of model-order selection criteria by partial-model selection search .	nested full-parameters-set searching procedure ; partial-model selection searching method ; low signal-to-noise ratios ; full-model order selection ; model-order selection criteria ; model-order selection ; linear regression ; bootstrap-based criterion ; model-selection searches ; accuracies	<method> <method> <otherscientificterm> <method> <metric> <task> <task> <otherscientificterm> <task> <metric>	1 0 7 ; 9 5 1 ; 1 0 5	the traditional <method_1> for <task_5> in <task_6> is a <method_0> over the desired orders , which we call <method_3> . on the other hand , a method for <task_8> for the best sub-model within each order . in this paper , we propose using the <method_1> for <task_5> , which we call <method_3> . we show by simulations that the proposed <method_1> gives better <metric_9> than the traditional one , especially for <otherscientificterm_2> over a wide range of <metric_4> -lrb- both information theoretic-based and bootstrap-based -rrb- . also , we show that for some models the performance of the <otherscientificterm_7> improves significantly by using the proposed <method_1> .	1 5 6 0 3 10 -1 8 10 -1 13 10 -1 9 2 4 12 10 -1 7 11 10 -1
Symbolic Dynamic Programming for Continuous State and Action MDPs .	continuous state and action spaces ; symbolic dynamic programming solution ; mul-tivariate continuous state and actions ; restricted piecewise quadratic -rrb- reward ; didactic nonlinear planning example ; real-world decision-theoretic planning problems ; continuous action maximization step ; unknown state parameters ; automated exact solution ; symbolic constrained optimization ; closed-form value function ; piecewise linear dynamics ; dynamic programming backup ; discrete noise ; csa-mdps ; sdp ; policy	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method>	2 1 13 ; 16 0 14 ; 13 1 11 ; 11 1 3 ; 2 1 11 ; 6 0 12 ; 0 0 5 ; 1 0 16	many <task_5> are naturally modeled using both <otherscientificterm_0> , yet little work has provided exact solutions for the case of continuous actions . in this work , we propose a <method_1> to obtain the optimal <otherscientificterm_10> and <method_16> for <method_14> with <otherscientificterm_2> , <otherscientificterm_13> , <otherscientificterm_11> , and piecewise linear -lrb- or <otherscientificterm_3> . our key contribution over previous <method_15> work is to show how the <method_6> in the <method_12> can be evaluated optimally and symbolically -- a task which amounts to <method_9> subject to <otherscientificterm_7> ; we further integrate this technique to work with an efficient and compact data structure for <method_15> -- the extended algebraic decision diagram -lrb- xadd -rrb- . we demonstrate empirical results on a <material_4> and two domains from operations research to show the first <task_8> to these problems .	5 0 24 17 -1 1 10 16 14 2 13 11 3 18 19 20 21 22 25 17 -1 15 6 12 9 7 23 17 -1 17 -1
Commonsense Knowledge Base Completion .	knowledge base completion ; neural network models ; true held-out tuples ; bilinear model ; common-sense knowledge ; additive architecture ; medium-confidence tuples ; knowledge bases ; freebase ; tu-ples ; conceptnet	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <material> <otherscientificterm> <material>	5 0 3 ; 8 6 7 ; 3 0 9	we enrich a curated resource of <otherscientificterm_4> by formulating the problem as one of <method_0> . most work in <method_0> focuses on <material_7> like <material_8> that relate entities drawn from a fixed set . however , the tuples in <material_10> -lrb- speer and havasi , 2012 -rrb- define relations between an unbounded set of phrases . we develop <method_1> for scoring tuples on arbitrary phrases and evaluate <method_1> by their ability to distinguish <otherscientificterm_2> from false ones . we find strong performance from a <method_3> using a simple <method_5> to <method_3> phrases . we manually evaluate our trained <method_3> 's ability to assign quality scores to novel tuples , finding that <method_3> can propose <otherscientificterm_9> at the same quality level as <otherscientificterm_6> from <material_10> .	4 0 11 -1 7 8 13 11 -1 10 11 -1 1 2 11 -1 3 5 12 11 -1 14 11 -1
Imaging concert hall acoustics using visual and audio cameras .	panoramic mosaiced visual image of the space ; visual and the audio camera images ; acoustics of rooms and halls ; spherical microphone array beamformer ; real time audio camera ; audio and video images ; acoustic intensity images ; computer vision techniques ; acoustical features ; central projection ; registration	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <method> <otherscientificterm> <otherscientificterm> <task>	4 0 6 ; 3 0 9 ; 4 0 9	using a recently developed <otherscientificterm_4> , that uses the output of a <otherscientificterm_3> steered in all directions to create <otherscientificterm_9> to create <material_6> , we present a technique to measure the <otherscientificterm_2> . a <otherscientificterm_0> is also create . since both the <material_1> are <otherscientificterm_9> , <task_10> of the acquired <material_5> can be performed using standard <method_7> . we describe the technique , and apply it to the examine the relation between <otherscientificterm_8> and architectural details of the dekelbaum concert hall at the clarice smith performing arts center in college park , md. .	4 3 9 6 2 12 13 14 11 -1 0 11 -1 1 10 5 7 11 -1 8 11 -1
Non-minimum phase inverse filter methods for immersive audio rendering .	augmented and virtual reality ; synthetic head-related transfer functions ; signal processing considerations ; manufacturing and entertainment ; spatial sound rendering ; virtual sound sources ; air traffic control ; immersive audio systems ; spectral characteristics ; real source ; guidance systems ; sound fields ; distance learning ; pilot warning ; teleconferencing ; displays	<task> <otherscientificterm> <task> <task> <task> <material> <task> <method> <otherscientificterm> <material> <task> <otherscientificterm> <task> <task> <task> <material>	8 2 1 ; 13 1 15 ; 13 1 10 ; 7 0 11 ; 6 1 12 ; 3 1 12 ; 3 1 13 ; 14 1 6 ; 7 0 3 ; 14 1 13 ; 6 1 13 ; 6 1 10 ; 14 1 0 ; 0 0 3 ; 12 1 15	immersive audio <method_7> are being envisioned for applications that include <task_14> and telepresence ; <task_0> for <task_3> ; <task_6> , <task_13> , and <task_10> ; <material_15> for the visually-impaired ; <task_12> ; and professional sound and picture editing for television and film . the principal function of such <method_7> is to synthesize , manipulate and render <otherscientificterm_11> in real time . in this paper we examine several <task_2> in <task_4> over loudspeakers . we propose two methods that can be used to implement the necessary filters for generating <material_5> based on <otherscientificterm_1> with the same <otherscientificterm_8> as those of the <material_9> .	7 14 0 3 6 13 10 15 12 18 19 21 22 23 24 25 26 27 28 29 30 31 16 -1 11 20 16 -1 2 4 16 -1 5 1 8 17 16 -1
Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction .	computing word semantics ; iterative reinforcement approach ; summary and keywords ; single document ; knowledge-based approach ; document summarization ; keyword extraction ; keywords	<task> <method> <otherscientificterm> <material> <method> <task> <task> <otherscientificterm>	5 1 6 ; 1 0 2 ; 4 0 0 ; 1 4 4	though both <task_5> and <task_6> aim to extract concise representations from documents , these two tasks have usually been investigated independently . this paper proposes a novel <method_1> to simultaneously extracting <otherscientificterm_2> from <material_3> under the assumption that the <otherscientificterm_2> of a document can be mutually boosted . the <method_1> can naturally make full use of the reinforcement between sentences and <otherscientificterm_7> by fusing three kinds of relationships between sentences and words , either homogeneous or heterogeneous . experimental results show the effectiveness of the proposed <method_1> for both tasks . the <method_1> is validated to work almost as well as the <method_4> for <task_0> .	5 6 9 8 -1 1 2 3 10 8 -1 7 8 -1 8 -1 11 12 8 -1
Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing .	brain-computer interfaces ; motor imagery ; eeg connectivity patterns ; eeg connectivity measures ; connectivity based bcis ; high frequency bands ; connectivity features ; bandpower features ; feature space ; cognitive demands ; transfer entropy ; beamforming ; modulation ; γ-band	<task> <task> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	11 1 10 ; 1 6 13 ; 10 1 11 ; 7 0 1 ; 3 0 1 ; 2 0 0 ; 6 2 0	eeg connectivity measures could provide a new type of <otherscientificterm_8> for inferring a subject 's intention in <task_0> . however , very little is known on <otherscientificterm_2> for <task_0> . in this study , <metric_3> during <task_1> of the left and right is investigated in a broad frequency range across the whole scalp by combining <method_11> with <method_10> and taking into account possible volume conduction effects . observed connec-tivity patterns indicate that <otherscientificterm_12> intentionally induced by <task_1> is strongest in the <otherscientificterm_13> , i.e. , above 35 hz . furthermore , <otherscientificterm_12> between <task_1> and rest is found to be more pronounced than between <task_1> of different hands . this is in contrast to results on <task_1> obtained with <otherscientificterm_7> , and might provide an explanation for the so far only moderate success of <otherscientificterm_6> in <task_0> . it is concluded that future studies on <task_4> should focus on <otherscientificterm_5> and consider experimental paradigms that maximally vary <otherscientificterm_9> between conditions .	8 0 14 -1 2 20 14 -1 3 1 11 10 15 17 19 14 -1 12 13 16 14 -1 14 -1 18 21 14 -1 7 6 14 -1
Abstraction Heuristics for Symbolic Bidirectional Search .	abstract state spaces and/or ; partial and perimeter abstractions ; symbolic bidirectional uniform-cost search ; symbolic bidirectional search ; abstraction heuristics ; heuristic functions ; bidi-rectional search ; bidirectional search ; cost-optimal planning ; symba ⇤ ; search ; heuristics ; ipc ; perimeter	<otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <task> <task> <task> <method> <method> <method> <method> <otherscientificterm>	11 0 6 ; 1 0 7 ; 4 0 3	symbolic bidirectional uniform-cost <method_10> is a prominent technique for <task_8> . thus , the question whether it can be further improved by making use of <otherscientificterm_5> raises naturally . however , the use of <method_11> in <task_6> does not always improve its performance . we propose a novel way to use <method_4> in <task_3> in which the <method_10> only resorts to <method_11> when it becomes unfeasible . we adapt the definition of <otherscientificterm_1> to <task_7> , where a ⇤ is used to traverse the <otherscientificterm_0> generate the <otherscientificterm_13> . the results show that <method_4> can further improve <task_3> in some domains . in fact , the resulting planner , <method_9> , was the winner of the optimal-track of the last <method_12> .	10 8 14 -1 5 14 -1 11 6 15 14 -1 4 3 14 -1 1 7 0 13 16 14 -1 17 14 -1 14 -1
A computational model for unsupervised word discovery .	acoustic phone models ; mainstream asr approaches ; acoustic pattern discovery ; upfront defined lexicon ; temporal sequence learning ; computational model ; word-like fragments ; modelling constraints ; language acquisition ; acoustic similarity ; speech signal ; speech recognition ; raw input ; unsupervised algorithm ; asr ; clustering	<method> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <task> <otherscientificterm> <method> <task> <method>	13 0 5 ; 2 0 13 ; 4 0 13 ; 13 0 9 ; 13 0 11 ; 2 1 15 ; 15 1 4 ; 15 0 13 ; 3 1 0	we present an <method_13> for the discovery of words and <otherscientificterm_6> from the <material_10> , without using an <otherscientificterm_3> or <method_0> . the <method_13> is based on a combination of <task_2> , <method_15> , and <method_4> . <method_13> exploits the <otherscientificterm_9> between multiple acoustic tokens of the same words or <otherscientificterm_6> . in its current form , the <method_13> is able to discover words in speech with low per-plexity -lrb- connected digits -rrb- . although its performance still falls off compared to <method_1> , the value of the <method_13> is its potential to serve as a <method_5> in two research directions . first , the <method_13> may lead to an approach for <task_11> that is fundamentally liberated from the <otherscientificterm_7> in conventional <task_14> . second , the proposed <method_13> can be interpreted as a <method_5> of <task_8> that takes actual speech as input and is able to find words as 'em ergent ' properties from <otherscientificterm_12> .	13 6 10 3 0 25 16 -1 2 15 4 18 19 22 23 24 16 -1 9 20 16 -1 16 -1 1 5 17 16 -1 21 16 -1 11 7 14 16 -1
Reordering Grammar Induction .	predicting target order ; phrase-based machine translation ; non-itg reordering patterns ; word-aligned parallel corpora ; transduction function ; linguistic annotation ; translation quality ; latent variable ; hierarchical structure ; reordering rules ; phrase reordering ; permutation trees ; reordering grammar ; preordering baselines ; preordering ; bracketing ; labeling ; english-japanese ; accuracy	<task> <task> <otherscientificterm> <material> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <task> <method> <otherscientificterm> <material> <metric>	13 0 17 ; 8 1 4	we present a novel approach for unsu-pervised induction of a <method_12> using a modified form of <method_11> -lrb- zhang and gildea , 2007 -rrb- , which we apply to <task_14> in <task_1> . unlike previous approaches , we induce in one step both the <otherscientificterm_8> and the <otherscientificterm_4> over it from <material_3> . furthermore , our model -lrb- 1 -rrb- handles <otherscientificterm_2> -lrb- up to 5-ary branching -rrb- , -lrb- 2 -rrb- is learned from all derivations by treating not only <otherscientificterm_16> but also <method_15> as <otherscientificterm_7> , -lrb- 3 -rrb- is entirely unlexicalized at the level of <otherscientificterm_9> , and -lrb- 4 -rrb- requires no <method_5> . our model is evaluated both for <metric_18> in <task_0> , and for its impact on <metric_6> . we report significant performance gains over <task_10> , and over two known <method_13> for <material_17> .	12 11 14 1 19 -1 8 4 3 21 19 -1 2 16 15 7 9 19 -1 5 19 -1 18 0 6 20 19 -1
Speech recognition of Japanese news commentary .	speech recognition of broadcast news commentary ; linguistic features of news commentaries ; linguistic and acoustic features ; crossword triphone models ; language model adaptation ; news commentary speech ; word error rate ; word recognition accuracy ; news commentary ; acoustic models ; read speech ; word sequences ; speech rate ; news programs ; rules ; japanese ; decoder	<task> <otherscientificterm> <otherscientificterm> <method> <task> <material> <metric> <metric> <material> <method> <material> <otherscientificterm> <metric> <material> <otherscientificterm> <material> <method>	11 0 4 ; 12 4 10 ; 16 0 3 ; 8 4 10	this paper describes some improvements in <task_0> in <material_15> . since <material_5> has different <otherscientificterm_2> from <material_10> , it gives lower <metric_7> . in this paper we apply to news manuscripts some <otherscientificterm_14> which represent the <otherscientificterm_1> , and generate <otherscientificterm_11> for <task_4> . we also use a large volume of transcriptions of <material_13> as training texts . <method_9> are speaker-adapted and their structures are changed so as to recognize relatively short phonemes , because we found the <metric_12> of <material_8> is sometimes much faster than that of <material_10> . furthermore , by using a <method_16> that can handle <method_3> , we reduced the <metric_6> by 32 % .	0 15 17 -1 5 2 10 7 17 -1 14 1 11 4 18 17 -1 13 9 17 -1 12 8 19 21 17 -1 16 3 20 17 -1
Estimation of speech lip features from discrete cosinus transform .	automatic extraction of speech lip features ; 2-d discrete cosine transform ; geometric lip features ; principal component analysis ; visual speech processing ; dct coefficients ; natural lips ; lip aperture ; features ; accuracy ; pca	<task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric> <method>	3 0 1	this study is a contribution to the field of <task_4> . it focuses on the <task_0> from <material_6> . the method is based on the direct prediction of these <otherscientificterm_8> from predictors derived from an adequate transformation of the pixels of the lip region of interest . the transformation is made of a <method_1> combined with a <method_3> applied to a subset of the <otherscientificterm_5> corresponding to about 1 % of the total dcts . the results show the possibility to estimate the <otherscientificterm_2> with a good <metric_9> -lrb- a root mean square of 1 to 1.4 mm for the <otherscientificterm_7> and the lip width -rrb- using a reduce set of predictors derived from the <method_10> .	4 11 -1 0 6 11 -1 8 11 -1 1 3 5 12 11 -1 2 9 11 -1
Supervised descriptor learning for multi-output regression .	supervised descriptor learning algorithm ; supervised manifold regularization ; generalized low-rank approximations of matrices ; discriminative and compact feature representation ; benchmark pointing '04 dataset ; representative multi-output regression task ; supervision of multivariate targets ; head pose estimation ; multi-output regression tasks ; descriptor learning framework ; multivariate estimation ; descriptor learning ; low-dimensional space ; estimation accuracy ; error reduction ; computer vision ; multi-output regression ; raw features ; ambiguity ; regression ; classification	<method> <method> <method> <method> <material> <task> <otherscientificterm> <task> <task> <method> <task> <method> <otherscientificterm> <metric> <metric> <task> <task> <otherscientificterm> <metric> <task> <task>	13 5 0 ; 0 0 9 ; 14 5 0 ; 1 0 2 ; 0 0 16 ; 3 0 16 ; 4 0 0 ; 4 0 7 ; 9 0 16 ; 0 0 3 ; 11 0 15	descriptor learning has recently drawn increasing attention in <task_15> , existing algorithms are mainly developed for <task_20> rather than for <task_19> which however has recently emerged as a powerful tool to solve a broad range of problems , e.g. , <task_7> . in this paper , we propose a novel <method_0> to establish a <method_3> for <task_16> . by formulating as <method_2> with a <method_1> , the <method_0> removes irrelevant and redundant information from <otherscientificterm_17> by transforming into a <otherscientificterm_12> under the <otherscientificterm_6> . the obtained discriminative while compact descriptor largely reduces the variability and <metric_18> in <task_16> , and therefore enables more accurate and efficient <task_10> . we demonstrate the effectiveness of the proposed <method_0> on a <task_5> : <task_7> using the <material_4> . experimental results show that the <method_0> can achieve high pose <metric_13> and significantly outperforms state-of-the-art algorithms by an <metric_14> up to 27.5 % . the proposed <method_0> provides a general <method_9> in a supervised way for <task_16> which can largely boost the performance of existing <task_8> .	15 20 19 7 32 21 -1 0 3 16 27 31 21 -1 2 1 17 12 6 25 21 -1 18 21 -1 10 28 29 21 -1 5 4 22 24 21 -1 13 14 23 26 30 21 -1
Improved multiple birdsong tracking with distribution derivative method and Markov renewal process clustering .	markov renewal process model ; rapid pitch modulations ; simultaneous bird sounds ; distribution derivative method ; segregation algorithm ; spec-trogram representation ; automatic recognition ; vocalisation patterns ; birdsong	<method> <otherscientificterm> <material> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm>	0 0 4 ; 3 0 5 ; 4 0 7	segregating an audio mixture containing multiple <material_2> is a challenging task . however , <otherscientificterm_8> often contains <otherscientificterm_1> , and these <otherscientificterm_1> carry information which may be of use in <task_6> . in this paper we demonstrate that an improved <method_5> , based on the <method_3> , leads to improved performance of a <method_4> which uses a <method_0> to track <otherscientificterm_7> consisting of singing and silences .	2 9 -1 8 1 6 9 -1 5 3 4 0 7 10 11 12 9 -1
Spectral-envelope and group-delay models for transient signals - Applications to castanets and stop consonants .	spectral-domain amplitude-modulated/frequency-modulated functions ; group delay function ; additive noise ; coherent demodulator ; fourier spectrum ; spectral fm ; spectral envelope ; group delay ; spectral am ; modulation structure ; spectral zero-crossings ; envelope ; transients	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 1 4 ; 10 1 6 ; 5 6 1 ; 8 1 5 ; 10 0 7 ; 3 0 6	we present a novel approach to represent <otherscientificterm_12> using <otherscientificterm_0> . the model is applied to the real and imaginary parts of the fourier transform -lrb- ft -rrb- of the transient . the suitability of the model lies in the observation that since <otherscientificterm_12> are well-localized in time , the real and imaginary parts of the <otherscientificterm_4> have a <otherscientificterm_9> . the <method_8> is the <otherscientificterm_11> and the <otherscientificterm_5> is the <otherscientificterm_1> . the <otherscientificterm_7> is estimated using <otherscientificterm_10> and the <otherscientificterm_6> is estimated using a <method_3> . we show that the proposed technique is robust to <otherscientificterm_2> . we present applications of the proposed technique to castanets and stop-consonants in speech .	12 0 13 -1 13 -1 4 9 14 13 -1 8 11 5 1 16 17 13 -1 7 10 6 3 15 18 19 13 -1 2 13 -1 13 -1
GiSS : Combining Gibbs Sampling and SampleSearch for Inference in Mixed Probabilistic and Deterministic Graphical Models .	mixed probabilistic and deterministic graphical models ; importance sampling technique ; approximate weighting schemes ; hard deterministic spaces ; unweighted samples ; sat/csp solvers ; mcmc technique ; belief propagation ; gibbs sampling ; real-world applications ; mc-sat ; samplesearch ; inference ; accuracy ; determinism	<method> <method> <method> <otherscientificterm> <material> <method> <method> <task> <method> <task> <method> <method> <task> <metric> <otherscientificterm>	11 1 10 ; 8 0 4 ; 11 6 1 ; 13 5 11 ; 10 1 7	mixed probabilistic and deterministic graphical models are ubiquitous in <task_9> . unfortunately , <method_8> , a popular <method_6> , does not converge to the correct answers in presence of <otherscientificterm_14> and therefore can not be used for <task_12> in such models . in this paper , we propose to remedy this problem by combining <method_8> with <method_11> , an advanced <method_1> which leverages complete <method_5> to generate high quality samples from <otherscientificterm_3> . we call the resulting algorithm , <method_11> . unlike <method_8> which yields <material_4> , <method_11> yields weighted samples . computing these weights exactly can be computationally expensive and therefore we propose several approximations . we show that our <method_2> yield consistent estimates and demonstrate experimentally that <method_11> is competitive in terms of <metric_13> with state-of-the-art algorithms such as <method_11> , <method_10> and <task_7> .	9 15 -1 8 6 14 12 15 -1 11 1 5 3 18 15 -1 15 -1 4 17 15 -1 15 -1 16 19 20 15 -1
Shape Recipes : Scene Representations that Refer to the Image .	high dimensional representations ; stereo shape estimates ; complex scene configurations ; low-dimensional representation ; scene recipe ; real-world scenes ; image data ; regression coefficients ; material segmentation ; observed image ; shape recipes ; bandpassed shape ; low-level vision	<method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <material> <material> <otherscientificterm> <task>	1 0 8 ; 6 0 7	the goal of <task_12> is to estimate an underlying scene , given an <material_9> . <otherscientificterm_5> -lrb- eg , albedos or shapes -rrb- can be very complex , conventionally requiring <method_0> which are hard to estimate and store . we propose a <method_3> , called a <method_4> , that relies on the image itself to describe the <otherscientificterm_2> . <material_10> are an example : these are the <otherscientificterm_7> that predict the <otherscientificterm_11> from <material_6> . we describe the benefits of this <method_3> , and show two uses illustrating their properties : -lrb- 1 -rrb- we improve <task_1> by learning shape recipes at low resolution and applying <task_1> at full resolution ; -lrb- 2 -rrb- <material_10> implicitly contain information about lighting and materials and we use <task_1> for <task_8> .	12 9 5 13 -1 0 13 -1 3 4 2 10 13 -1 7 11 6 15 13 -1 1 14 13 -1
A nonlinear second-order digital oscillator for Virtual Acoustic Feedback .	virtual acoustic feedback ; instrument or sound source ; pitched real-time input ; guitar feedback effect ; nonlinear feedback oscillator ; musical tool ; sound palette ; computational techniques ; virtual instrument ; acoustic feedback ; virtual acoustics ; howling	<method> <material> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 1 7	the <otherscientificterm_3> , or <method_11> , is well known to the general public and identified with many rock music genres and it is the only case of <otherscientificterm_9> employed for musical purposes . <method_0> , is regarded as the extension of this phenomenon to any <material_1> by means of <otherscientificterm_10> and is meant to enrich the <otherscientificterm_6> of a musician . the study of the <otherscientificterm_9> as a <method_5> and <method_7> for its emulation have been scarcely addressed in literature . in this paper a <method_4> is proposed and its properties derived . the <method_4> does not necessarily need to be connected to a <otherscientificterm_8> , thus enables to process any kind of <material_2> .	3 11 9 0 12 -1 1 10 6 12 -1 5 7 13 12 -1 4 12 -1 12 -1
Learning Reliability of Parses for Domain Adaptation of Dependency Parsing .	natural language processing applications ; domain adaptation of dependency parsing ; conll 2007 shared task ; paraphrase acquisition ; dependency parser ; relation extraction ; parsing ; accuracy	<task> <task> <material> <task> <method> <task> <method> <metric>	2 5 4 ; 3 1 5 ; 5 6 0 ; 3 6 0 ; 6 0 0	the <metric_7> of <method_6> has exceeded 90 % recently , but this is not high enough to use <method_6> results practically in <task_0> such as <task_3> and <task_5> . we present a method for detecting reliable parses out of the outputs of a single <method_4> . this technique is also applied to <task_1> . our goal was to improve the performance of a state-of-the-art <method_4> on the data set of the domain adaptation track of the <material_2> , a formidable challenge .	7 6 0 3 5 10 11 12 13 8 -1 4 8 -1 1 8 -1 2 9 8 -1
CNNpack : Packing Convolutional Neural Networks in the Frequency Domain .	deep convolutional neural networks ; discrete cosine transform bases ; storage and computational requirements ; compression and speed-up ratios ; benchmark image datasets ; low-energy frequency coefficients ; cnn compression approach ; convolutional filters ; mobile devices ; high compression ; cluster centers ; frequency domain ; convolution operations ; images ; cnns ; accuracy	<method> <otherscientificterm> <otherscientificterm> <metric> <material> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method> <metric>	4 5 6 ; 12 3 14 ; 3 5 6 ; 5 0 9	deep convolutional neural networks -lrb- <method_14> -rrb- are successfully used in a number of applications . however , their <otherscientificterm_2> have largely prevented their widespread use on <material_8> . here we present an effective <method_6> in the <method_11> , which focuses not only on smaller weights but on all the weights and their underlying connections . by treating <method_7> as <material_13> , we decompose their representations in the <method_11> as common parts -lrb- i.e. , <otherscientificterm_10> -rrb- shared by other similar filters and their individual private parts -lrb- i.e. , individual residuals -rrb- . a large number of <otherscientificterm_5> in both parts can be discarded to produce <otherscientificterm_9> without significantly compromising <metric_15> . we relax the computational burden of <otherscientificterm_12> in <method_14> by linearly combining the convolution responses of <otherscientificterm_1> . the <metric_3> of the proposed <method_6> are thoroughly analyzed and evaluated on <material_4> to demonstrate its superiority over state-of-the-art methods .	14 16 -1 2 8 16 -1 6 11 16 -1 7 13 10 16 -1 5 20 16 -1 9 15 18 16 -1 12 1 17 19 16 -1
Resolving inter-frame interference in a transmit-reference ultra-wideband communication system .	transmit-reference ultra-wideband systems ; inter-frame interference ; signal processing data model ; frame length ; restrictive assumptions ; receiver algorithms ; channel length ; transmitter ; complexity	<method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric>	3 6 4	-- <method_0> are attractive due to their relatively low <metric_8> at both the <otherscientificterm_7> and the receiver . partly , this is achieved by making <otherscientificterm_4> such as a <otherscientificterm_3> which should be much larger than the <otherscientificterm_6> . this limits their use to low data rate applications . in this paper , we lift this restriction and allow <method_1> to occur . we propose a suitable <method_2> and corresponding <method_5> which take the <method_1> into account . the performance of the <method_2> are verified using simulations .	0 8 7 9 -1 4 3 6 10 9 -1 9 -1 1 9 -1 2 5 9 -1 9 -1
Capturing Difficulty Expressions in Student Online Q&A Discussions .	pedagogical assessment of online q&a discussions ; speech act framework ; high certainty expressions ; online dialogue analysis ; assessment tool ; discussion patterns ; difficulty expressions ; student discussions ; emotional expressions ; classification	<task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	1 0 8	we introduce a new application of <task_3> : supporting <task_0> . extending the existing <method_1> , we capture common <otherscientificterm_8> that often appear in <otherscientificterm_7> , such as frustration and degree of certainty , and present a viable approach for the <task_9> . we demonstrate how such dialogue information can be used in analyzing <otherscientificterm_7> and identifying difficulties . in particular , the <otherscientificterm_6> are aligned to <otherscientificterm_5> and student performance . we found that frustration occurs more frequently in longer discussions . the students who frequently express frustration tend to get lower grades than others . on the other hand , frequency of <otherscientificterm_2> is positively correlated with the performance . we expect such dialogue analyses can become a powerful <method_4> for instructors and education researchers .	3 0 10 -1 1 8 7 9 11 10 -1 10 -1 6 5 10 -1 10 -1 10 -1 10 -1 2 10 -1
Translation with Source Constituency and Dependency Trees .	phrasal nodes of constituency trees ; head-dependents relations of dependency trees ; chinese-english nist test sets ; constituency and dependency trees ; hierarchical phrase-based model ; translation model ; translation rules ; rules ; bleu	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <metric>	2 5 5 ; 5 0 3 ; 5 4 4 ; 2 5 4	we present a novel <method_5> , which simultaneously exploits the <otherscientificterm_3> on the source side , to combine the advantages of two types of trees . we take <otherscientificterm_1> as backbone and incorporate <otherscientificterm_0> as the source side of our <otherscientificterm_6> , and the target side as strings . our <otherscientificterm_7> hold the property of long distance reorderings and the compatibility with phrases . large-scale experimental results show that our <method_5> achieves significantly improvements over the constituency-to-string -lrb- +2.45 <metric_8> on average -rrb- and dependency-to-string -lrb- +0.91 <metric_8> on average -rrb- models , which only employ single type of trees , and significantly outperforms the state-of-the-art <method_4> -lrb- +1.12 <metric_8> on average -rrb- , on three <material_2> .	5 3 11 9 -1 1 0 6 9 -1 7 9 -1 8 10 12 13 9 -1
Automatic classification of environmental noise events by hidden Markov models .	hidden markov models -lrb- hmm 's -rrb- ; automatic classification of environmental noise sources ; average spectrum of noise event ; environmental noise recognition system ; noise monitoring system ; noise events ; human listeners ; acoustic signatures ; classification test ; time-frequency analysis ; hmm-based approach ; truck ; aircraft ; classifiers ; moped	<method> <task> <metric> <method> <method> <otherscientificterm> <material> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	14 1 12 ; 12 6 5 ; 2 5 10 ; 11 1 12 ; 7 0 1 ; 11 6 5 ; 14 6 5 ; 10 4 13 ; 11 1 14 ; 2 5 13 ; 13 4 10 ; 0 0 3	the <task_1> from their <material_7> recorded at the microphone of a <method_4> -lrb- nms -rrb- is an active subject of research nowadays . this paper shows how <method_0> can be used to build an <method_3> based on a <method_9> of the noise signal . the performance of the proposed <method_10> is evaluated experimentally for the classification of five types of <otherscientificterm_5> -lrb- car , <otherscientificterm_11> , <otherscientificterm_14> , <otherscientificterm_12> , train -rrb- . the <method_10> is found to outperform previously proposed <method_13> based on the <metric_2> with more than 95 % of correct classifications . for comparison , a <method_8> is performed with <material_6> for the same data which shows that the best <method_10> outper-forms the '' average '' human listener who achieves only 91.8 % of correct classification for the same task .	1 7 4 20 15 -1 0 3 9 27 15 -1 10 5 11 14 12 16 17 19 21 22 24 15 -1 13 2 18 23 25 26 15 -1 8 15 -1
Integrating articulatory features using Kullback-Leibler divergence based acoustic model for phoneme recognition .	kullback-leibler divergence based hmm system ; artic-ulatory features ; posterior probabilities of phonemes ; timit phoneme recognition task ; hmm-based asr system ; phoneme recognition accuracy ; observation features ; posterior probabilities ; multilayer perceptrons ; af probabilities ; phoneme probabilities ; features ; afs	<method> <method> <otherscientificterm> <task> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 3 0 ; 10 0 11 ; 9 0 11 ; 9 1 10 ; 1 3 4 ; 5 5 0 ; 5 5 3 ; 7 0 12	in this paper , we propose a novel framework to integrate <method_1> into <method_4> . this is achieved by using <otherscientificterm_7> of different <method_12> -lrb- estimated by <otherscientificterm_8> -rrb- directly as <otherscientificterm_6> in <method_0> . on the <task_3> , the proposed framework yields a <metric_5> of 72.4 % which is comparable to <method_0> using <otherscientificterm_2> as <otherscientificterm_11> -lrb- 72.7 % -rrb- . furthermore , a best performance of 73.5 % <metric_5> is achieved by jointly modeling <otherscientificterm_9> and <otherscientificterm_10> as <otherscientificterm_11> . this shows the efficacy and flexibility of the proposed approach .	1 4 18 13 -1 7 12 8 6 0 14 21 13 -1 3 5 2 11 19 20 13 -1 9 10 15 16 17 13 -1 13 -1
Tree quantization for large-scale similarity search and classification .	vector encoding scheme -lrb- tree quan-tization -rrb- ; image classification error ; lossy compact codes ; coding tree structure ; tree-based dynamic programming ; integer programming-based optimization ; product quantization ; tree quantization ; codeword numbers ; fast encoding ; fisher vectors ; retrieval performance ; neural codes ; training dataset ; high-dimensional vectors ; compression error ; accuracy	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric>	5 0 3 ; 12 1 10 ; 4 0 14 ; 0 0 2 ; 2 0 14 ; 9 1 15 ; 9 1 7 ; 12 1 9 ; 12 1 7 ; 10 1 7	we propose a new <method_0> that obtains <otherscientificterm_2> for <otherscientificterm_14> via <method_4> . similarly to several previous schemes such as <method_6> , these <method_6> correspond to <otherscientificterm_8> within multiple codebooks . we propose an <method_5> that jointly recovers the <otherscientificterm_3> and the codebooks by minimizing the <otherscientificterm_15> on a <material_13> . in the experiments with diverse visual descriptors -lrb- sift , <otherscientificterm_12> , <otherscientificterm_10> -rrb- , <method_7> is shown to combine <task_9> and state-of-the-art <metric_16> in terms of the <otherscientificterm_15> , the <metric_11> , and the <otherscientificterm_1> .	0 2 14 4 20 21 22 17 -1 6 8 17 -1 5 3 15 13 18 17 -1 12 10 7 9 16 11 1 19 23 24 25 26 27 17 -1
Combining continuous progressive model adaptation and factor analysis for speaker verification .	factor-analysis-based inter-session variability modelling ; continuous progressive speaker model adaptation ; gmm and svm configurations ; nist 2005 sre corpus ; adaptative score normalisation techniques ; speaker verification systems ; gmm mean supervectors ; progressive svm-based classification ; isv modelling process ; continuous model adaptation ; score shift ; adaptation process ; confidence measures ; progressive systems	<method> <method> <method> <material> <method> <method> <method> <method> <task> <task> <otherscientificterm> <task> <metric> <method>	0 0 5 ; 12 0 9 ; 4 0 2 ; 1 0 5	this paper proposes a novel technique of incorporating <method_0> in <method_5> that employ <method_1> . <task_9> involves the use of all encountered trials in the <task_11> through the assignment of <metric_12> . the proposed approach incorporates these <metric_12> in the general statistics used in the <task_8> . <method_7> was integrated into the system through the utilisation of <method_6> . the proposed system demonstrated a gain of 50 % over baseline results when trialled on the <material_3> . <method_4> were found to be beneficial to both <method_2> alleviating the detrimental effects of <otherscientificterm_10> in <method_13> .	0 5 1 9 15 18 14 -1 11 12 16 14 -1 8 7 14 -1 6 14 -1 3 4 14 -1 2 10 13 17 14 -1
Robust speech representation of voiced sounds based on synchrony determination with PLLs .	voiced parts of the speech signal ; high noise level case ; noisy speech recognition ; band-pass filter bank ; mel cepstrum features ; synchrony-based spectrum ; auditory system ; frequency distribution ; snr conditions ; synchrony effects ; spectral-like representation ; recognition ; coefficients	<material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm>	1 2 8 ; 7 0 10 ; 5 0 2 ; 9 3 6 ; 9 0 10	we propose to include <otherscientificterm_9> , known to exist in the <method_6> , to represent <material_0> in a robust way . the system decomposes the input signal by means of a <otherscientificterm_3> , and utilizes a bank of phase locked loops -lrb- plls -rrb- to obtain information on the frequencies present at a specific time . this information about the <otherscientificterm_7> is transformed into a <method_10> based on <otherscientificterm_9> . <task_2> experiments are performed using this <otherscientificterm_5> , which is transformed into a small set of <otherscientificterm_12> by using a transformation similar to that utilized for <otherscientificterm_4> . we show that <task_11> performance compared to <otherscientificterm_4> is advantageous , when measured over a range of <otherscientificterm_8> , especially in the <otherscientificterm_1> .	9 6 0 17 13 -1 3 13 -1 7 10 2 15 18 13 -1 5 12 4 16 13 -1 14 13 -1
Bayesian Multiple Target Localization .	constant factor approximation guarantee ; localizing multiple faces ; simulated data ; dyadic policy ; posterior distribution ; real images ; known distribution ; noisy setting	<otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	5 0 1 ; 0 0 7	we consider the problem of quickly localizing multiple targets by asking questions of the form '' how many targets are within this set '' while obtaining noisy answers . this setting is a generalization to multiple targets of the game of 20 questions in which only a single target is queried . we assume that the targets are points on the real line , or in a two dimensional plane for the experiments , drawn independently from a <otherscientificterm_6> . we evaluate the performance of a policy using the expected entropy of the <otherscientificterm_4> after a fixed number of questions with noisy answers . we derive a lower bound for the value of this problem and study a specific policy , named the <otherscientificterm_3> . we show that this policy achieves a value which is no more than twice this lower bound when answers are noise-free , and show a more general <otherscientificterm_0> for the <otherscientificterm_7> . we present an empirical evaluation of this policy on <material_2> for the problem of detecting multiple instances of the same object in an image . finally , we present experiments on <task_1> simultaneously on <material_5> .	8 -1 8 -1 6 8 -1 4 8 -1 8 -1 3 10 8 -1 0 7 8 -1 2 9 8 -1
Pose reconstruction with an uncalibrated Computed Tomography imaging device .	uncalibrated computed tomogra-phy imaging device ; 3-d pose of 3-d shape fiducials ; ct scan intrinsic parameters ; closed-form and numerical algorithms ; estimation of error bounds ; scaling transformation accounting ; freedom -lrb- rotation ; geometric transformation ; anisotropic scaling ; ct images ; image data ; rigid-body transformation ; cross-sectional images ; noise ; images ; translation	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <material> <material> <task> <material> <otherscientificterm> <material> <otherscientificterm>	14 0 1 ; 15 1 8 ; 5 0 2 ; 11 1 5	in this paper , we address the problem of precisely recovering the <otherscientificterm_1> from <material_14> obtained by means of an <method_0> . the main goal in this work is to model and estimate the <otherscientificterm_7> relating line fiducials to their projections in <material_12> . to do so , we propose techniques which solve the points to lines correspondence using <method_3> . a <otherscientificterm_7> with eight degrees of <otherscientificterm_6> , <otherscientificterm_15> and <method_8> -rrb- is used to model both a <task_11> and a <method_5> for <otherscientificterm_2> . furthermore , an <otherscientificterm_4> in space is given when <material_10> are affected by <otherscientificterm_13> . real experiments show that the proposed method provides good results on a set of <material_9> from many viewpoints .	1 14 0 17 16 -1 7 12 16 -1 3 16 -1 6 15 8 11 5 2 18 19 20 16 -1 4 10 13 16 -1 16 -1
Feature adaptation of hearing-impaired lip shapes : the vowel case in the cued speech context .	professional normal-hearing cs speaker ; deaf cs speaker ; manual cs information ; lip flow modeling ; classification models ; reference models ; deaf data ; french vowels ; classification	<method> <material> <otherscientificterm> <method> <method> <method> <material> <material> <task>	6 0 5 ; 4 0 0	the phonetic translation of cued speech -lrb- cs -rrb- gestures needs to mix the <otherscientificterm_2> together with the lips , taking into account the desynchronization delay -lrb- attina et al. -lsb- 2 -rsb- , aboutabit et al. -lsb- 4 -rsb- -rrb- between these two flows of information . this contribution focuses on the <method_3> in the case of <material_7> . previously , <method_4> have been developed for a <method_0> -lrb- aboutabit et al. , -lsb- 7 -rsb- -rrb- . these <method_4> are used as a reference . in this study , we process the case of a <material_1> and discuss the possibilities of <task_8> . the best performance -lrb- 92.8 % -rrb- is obtained with the adaptation of the <material_6> to the <method_5> .	2 9 -1 3 7 9 -1 4 0 11 9 -1 9 -1 1 9 -1 8 10 9 -1
Towards a Possibilistic Logic Handling of Preferences .	logical representation of preferences ; utility or value functions ; aggregation of preferences ; weighted logical setting ; utility function ; logical propositions ; possibilistic logic ; decision theory ; prioritized goals ; reasoning purposes ; encoding preferences ; expression modes ; constraints ; expressivity	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 7 ; 10 3 7 ; 3 0 11	the classical way of <task_10> in <method_7> is by means of <otherscientificterm_1> . however agents are not always able to deliver such a function directly . in this paper , we relate three different ways of specifying preferences , namely by means of a set of particular types of <otherscientificterm_12> on the <otherscientificterm_4> , by means of an ordered set of <otherscientificterm_8> expressed by <otherscientificterm_5> , and by means of an ordered set of subsets of possible candidates reaching the same level of satisfaction . these different <otherscientificterm_11> can be handled in a <otherscientificterm_3> , here the one of <otherscientificterm_6> . the <task_2> pertaining to different criteria can then be handled by fusing sets of <otherscientificterm_8> . apart from a better <otherscientificterm_13> , the benefits of a <otherscientificterm_0> are to put them in a suitable format for <otherscientificterm_9> , or for modifying or revising them .	10 7 1 15 16 14 -1 14 -1 12 4 8 5 14 -1 11 3 6 17 14 -1 14 -1 2 14 -1
Minimum Bayes Error Feature Selection for Continuous Speech Recognition .	minimum bayes error ; word error rate ; class densities ; cepstral features ; lda features ; linear transformation	<otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <task>	1 5 3	we consider the problem of designing a <task_5> such as to achieve <otherscientificterm_0> -lrb- or probability of misclassification -rrb- . two avenues will be explored : the first is to maximize the cents - average divergence between the <otherscientificterm_2> and the second is to minimize the union bhattacharyya bound in the range of cents . while both approaches yield similar performance in practice , they out-perform standard <method_4> and show a 10 % relative improvement in the <metric_1> over state-of-the-art <otherscientificterm_3> on a large vocabulary telephony speech recognition task .	5 0 6 -1 2 6 -1 4 1 3 7 6 -1
Constrained nonlinear minimum mse estimation .	minimum mean-squared error estimation ; elds of signal processing ; constrained estimation problems ; closed form formula ; restricted estimator ; estimator	<task> <method> <task> <method> <method> <method>	3 0 2	we address the problem of <task_0> where the <method_5> is constrained to belong to a pre-deened set of functions . we derive a simple <method_3> that reveals the structure of the <method_4> for a wide class of constraints . using this <method_3> we study various types of <task_2> that arise commonly in the <method_1> and communication .	0 5 6 -1 3 4 6 -1 2 1 7 6 -1
Latent topic random fields : Learning using a taxonomy of labels .	topic-dependent probabilistic classifier ; latent topic model ; roughly-specified object boundaries ; coarsely labeled images ; joint label-and-image space ; image labeling ; context representation ; image regions ; semantic hierarchy ; missing labels ; real-world datasets ; input data ; co-occurring patterns ; image features ; images ; specificity	<method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <material> <metric>	0 0 7 ; 4 2 6 ; 1 0 6 ; 15 2 14 ; 9 1 2	an important problem in <task_5> concerns learning with <material_14> labeled at varying levels of <metric_15> . we propose an approach that can incorporate <material_14> with labels drawn from a <otherscientificterm_8> , and can also readily cope with <otherscientificterm_9> , and <otherscientificterm_2> . we introduce a new form of <method_1> , learning a novel <method_6> in the <otherscientificterm_4> by capturing <otherscientificterm_12> within and between <otherscientificterm_13> and object labels . given a topic , the <method_1> generates the <material_11> , as well as a <method_0> to predict labels for <material_7> . we present results on two <material_10> , demonstrating significant improvements gained by including the <material_3> .	5 14 15 20 16 -1 8 9 2 21 16 -1 1 6 4 12 13 18 19 16 -1 11 0 7 17 16 -1 10 16 -1
Strategies to reduce design time in multimodal/multilingual dialog applications .	semiautomatic generation of human-machine dialog systems ; speech and web ; designer 's intervention ; guided interaction ; overanswering dialogs ; flow model ; dialog applications ; service data ; confirmation handling	<task> <material> <method> <otherscientificterm> <task> <method> <task> <material> <task>	5 1 3 ; 4 1 8 ; 4 6 6 ; 4 1 4 ; 8 6 6	in this paper , we present a complete platform for the <task_0> , that using as input a description of the database of the service , a <method_5> with the different states of the final application and a <otherscientificterm_3> step by step with the <method_2> , generates dialogs to access the <material_7> in different languages and two modalities , <material_1> , simultaneously . we describe in detail several strategies that have been followed to reduce the time needed to do the design using the mentioned information . we also address important issues in <task_6> as mixed initiative and <task_4> , <task_8> and how to provide the user long lists of information .	0 5 3 2 7 1 10 9 -1 9 -1 6 4 11 12 13 14 9 -1
A Bayesian Model for Simultaneous Image Clustering , Annotation and Object Segmentation .	heterogeneous mix of components ; spatially contiguous objects ; logistic stick-breaking process ; non-parametric bayesian model ; variational bayesian analysis ; object-feature mixture models ; image classes ; mixture models ; image databases ; image features ; object types ; inference	<method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <task>	8 0 11 ; 2 0 1 ; 4 0 11	a <method_3> is proposed for processing multiple images . the analysis employs <otherscientificterm_9> and , when present , the words associated with accompanying annotations . the <method_3> clusters the images into classes , and each image is segmented into a set of objects , also allowing the opportunity to assign a word to each object -lrb- localized labeling -rrb- . each object is assumed to be represented as a <method_0> , with this realized via <method_7> linking <otherscientificterm_9> to <otherscientificterm_10> . the number of <otherscientificterm_6> , number of <otherscientificterm_10> , and the characteristics of the <method_5> are inferred nonparametrically . to constitute <otherscientificterm_1> , a new <method_2> is developed . <task_11> is performed efficiently via <method_4> , with example results presented on two <material_8> .	3 12 -1 9 12 -1 12 -1 0 7 10 12 -1 6 5 12 -1 14 12 -1 1 2 11 13 15 12 -1
The Cramer-Rao bound for the estimation of noisy phase signals .	noisy phase monocomponent signals ; radar and communications ; maximum likelihood solution ; noise free phase ; real world applications ; additive noise ; cramèr-rao bound	<otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	4 0 1	this paper deals with <otherscientificterm_0> in <otherscientificterm_5> . this model is more appropriate for <task_4> in particular for <task_1> . the problem is introduced and a <method_2> is proposed . specifically , the <otherscientificterm_6> is explicitly derived and compared to the case of <otherscientificterm_3> .	0 5 7 -1 4 1 8 7 -1 2 7 -1 6 3 7 -1
Joint motion estimation and clock synchronization for a wireless network of mobile nodes .	cramer rao bound ; initial pairwise distances ; single clock reference ; localization and synchronization ; unknown clock skews ; relative radial velocities ; relative motion ; static network ; wireless network ; clock offsets ; node	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	4 1 1 ; 10 3 7 ; 4 1 9 ; 1 1 5 ; 9 1 5 ; 9 1 1	localization and synchronization are critical challenges for a <method_8> , which are conventionally solved independently . recently , various estimators have been proposed to jointly synchronize and localize a <otherscientificterm_10> in a <method_7> based on two way communication . in this paper , we present a novel and generic model based on two way communication between nodes , which are in <otherscientificterm_6> with respect to each other . furthermore , for the entire <method_7> we propose a closed form extended global least squares -lrb- egls -rrb- solution to solve for all the <otherscientificterm_4> , <otherscientificterm_9> , <otherscientificterm_1> and <otherscientificterm_5> using a <otherscientificterm_2> within the <method_7> . a new <method_0> is derived and the proposed fusion center based extended global least squares -lrb- egls -rrb- solution is shown to be asymptotically optimal .	8 11 -1 10 7 13 11 -1 6 11 -1 4 9 1 5 12 14 15 16 17 11 -1 2 11 -1
A Spatiotemporal Motion Model for Video Summarization .	compact description of a video sequence ; video browsing and retrieval ; temporally localized motion estimates ; dominant motion assumption ; generic temporal constraint ; image map ; motion model ; content summarization ; dominant motion ; visual summarization ; temporal consistency ; robustness ; compression ; mosaicing	<task> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <metric> <task> <task>	5 0 0 ; 5 1 8 ; 4 0 7 ; 13 1 9 ; 4 0 6 ; 11 5 4 ; 12 1 13 ; 8 0 0 ; 1 1 12	the <task_0> through a single <otherscientificterm_5> and a <otherscientificterm_8> has applications in several domains , including <task_1> , <task_12> , <task_13> , and <task_9> . building such a <task_0> requires the capability to register all the frames with respect to the dominant object in the scene , a task which has been , in the past , addressed through <material_2> . in this paper , we show how the lack of <otherscientificterm_10> associated with such estimates can undermine the validity of the <otherscientificterm_3> , leading to oscillation between different scene interpretations and poor registration . to avoid this oscillation , we augment the <method_6> with a <otherscientificterm_4> which increases the <metric_11> against competing interpretations , leading to more meaningful <task_7> .	0 5 8 1 12 13 9 15 16 18 21 22 23 14 -1 2 14 -1 10 3 14 -1 17 19 20 14 -1
Expert Finding for Community-Based Question Answering via Ranking Metric Network Learning .	community-based question answering site ; ranking metric network learning framework ; learning ranking metric embedding ; random-walk based learning method ; ranking metric network embedding ; recurrent neural networks ; relative quality rank ; user model ; question-answering activities ; large-scale dataset ; question routing ; social relations ; cqa data ; question answering	<task> <method> <task> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <material> <task> <otherscientificterm> <material> <task>	5 0 3 ; 3 0 4 ; 5 0 4 ; 3 0 13 ; 9 5 3 ; 8 0 7	expert finding for <task_13> is a challenging <task_13> in <task_0> , arising in many applications such as <task_10> and the identification of best answers . in order to provide high-quality experts , many existing approaches learn the <method_7> mainly from their past <otherscientificterm_8> in cqa sites , which suffer from the spar-sity <task_13> of <material_12> . in this paper , we consider the <task_13> of expert finding from the viewpoint of <task_2> . we propose a novel <method_1> for expert finding by exploiting both users ' <otherscientificterm_6> to given questions and their <otherscientificterm_11> . we then develop a <method_3> with <method_5> for <task_4> . the extensive experiments on a <material_9> from a real world cqa site show that our <method_3> achieves better performance than other state-of-the-art solutions to the <task_13> .	13 0 10 14 -1 7 8 12 20 14 -1 2 14 -1 1 6 11 14 -1 3 15 16 17 14 -1 5 4 18 19 14 -1
Detecting deletions in ASR output .	conditional random field models ; deletion-informed confidence estimation approach ; overall confidence estimation ; deletion detection scores ; deletion-informed confidence estimation ; deletion confidence scores ; deletion confidence score ; classification task ; detecting deletions ; non-sequential model ; sequence structure ; confidence score ; deletion	<method> <method> <metric> <metric> <task> <metric> <metric> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 3	in this work , the novel task of <task_8> within automatic speech recognition -lrb- asr -rrb- system output is investigated . <task_4> is proposed as an approach which simultaneously yields a <otherscientificterm_11> in a word being correct , as well as a <metric_6> which indicates whether a <otherscientificterm_12> is likely to occur in the output . the sequential nature of <method_0> is exploited as a means through which this can be achieved . it is shown that this <otherscientificterm_10> is crucial in yielding useful <metric_3> , with an equivalent <method_9> proven to be unsuitable for the task . the <method_1> is also shown to outperform one where <metric_5> are estimated as a <task_7> separate from that of <metric_2> .	8 4 13 -1 11 6 12 13 -1 0 13 -1 10 3 9 14 13 -1 1 13 -1
Inference Graphs : A New Kind of Hybrid Reasoning System .	logic of arbitrary and indefinite objects ; inference graphs ; hybrid reasoners ; natural deduction ; subsumption reasoning	<method> <method> <method> <method> <method>	3 1 4	hybrid reasoners combine multiple types of reasoning , usually subsumption and prolog-style resolution . we outline a system which combines <method_3> and <method_4> using <method_1> implementing a <method_0> .	5 -1 3 4 1 0 2 6 5 -1
Near-optimal Batch Mode Active Learning and Adaptive Submodular Optimization .	natural diminishing returns condition ; batch-mode active learning tasks ; batch mode active learning ; multi-stage influence maximization ; batch-mode active learning ; optimal batch-mode policy ; social networks ; adaptive submodularity ; sequential strategy ; active learning ; greedy strategy ; crowdsourcing ; heuristics	<otherscientificterm> <task> <method> <task> <task> <method> <method> <otherscientificterm> <method> <method> <method> <method> <method>	6 2 3 ; 12 0 4	active learning can lead to a dramatic reduction in labeling effort . however , in many practical implementations -lrb- such as <method_11> , surveys , high-throughput experimental design -rrb- , it is preferable to query labels for batches of examples to be labelled in parallel . while several <method_12> have been proposed for <task_4> , little is known about their theoretical performance . we consider <method_2> and more general information-parallel stochastic optimization problems that exhibit <otherscientificterm_7> , a <otherscientificterm_0> . we prove that for such problems , a simple <method_10> is competitive with the <method_5> . in some cases , surprisingly , the use of batches incurs competitively low cost , even when compared to a fully <method_8> . we demonstrate the effectiveness of our approach on <task_1> , where it outperforms the state of the art , as well as the novel problem of <task_3> in <method_6> .	13 -1 11 13 -1 12 4 15 13 -1 2 7 0 13 -1 10 5 13 -1 13 -1 8 14 13 -1
Detecting and Localizing 3D Object Classes using Viewpoint Invariant Reference Frames .	detection and localization of general 3d object classes ; multiview and viewpoint invariant representations ; multi-view and viewpoint invariant representations ; public color feret database ; class of 3d faces ; viewpoint invariant reference frame ; reference frame localization error ; false positive detections ; 3d object class ; local scale-invariant features ; iterative learning algorithm ; viewpoint invariant representation ; cmu profile database ; consistent geometrical interpretation ; modeling and detection ; viewpoint invariant approach ; image features ; reference frame ; object class ; average precision ; multi-view representation ; data-driven manner ; viewpoint ; features ; detection	<task> <task> <method> <material> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <task>	3 0 12 ; 9 0 24 ; 24 0 1 ; 3 0 4 ; 23 1 17 ; 19 5 15 ; 7 1 19	in this paper , we investigate <task_0> by relating <otherscientificterm_9> to a <otherscientificterm_5> . this can generally be achieved by either a <method_20> , where <otherscientificterm_23> and <otherscientificterm_17> are modeled as a collection of distinct views , or by a <method_11> , where <otherscientificterm_23> and <otherscientificterm_17> are mod-eled independently of <otherscientificterm_22> . we compare <method_2> trained and tested on the same data , where the <method_15> results in fewer <metric_7> and higher <metric_19> . we present a new , <method_10> to determine an optimal <otherscientificterm_5> from training images in a <method_21> . the learned optimal <otherscientificterm_17> is centrally located with respect to the <otherscientificterm_8> and to <otherscientificterm_16> in a given view , thereby minimizing <otherscientificterm_6> as predicted by theory and maintaining a <otherscientificterm_13> with respect to the underlying <otherscientificterm_18> . <task_14> based on the optimal <otherscientificterm_17> improves <task_24> performance for both <task_1> . experimentation is performed on the <material_4> , using the <material_3> for training , the <material_12> for testing and sift <otherscientificterm_16> .	0 9 5 27 25 -1 20 23 17 11 22 30 25 -1 2 15 7 19 31 32 25 -1 10 21 25 -1 25 -1 8 16 6 13 18 14 28 25 -1 24 1 26 29 25 -1
On estimation of a speaker 's confusion matrix from sparse data .	speaker 's confusion matrix ; non-negative matrix factorisation ; mean confusion matrix ; speech recognisers ; confusion matrices ; sparse data ; confusion matrices ; accuracy	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <metric>	4 0 3	confusion matrices have been widely used to increase the <metric_7> of <method_3> , but usually a <otherscientificterm_2> , averaged over many speakers , is used . however , analysis shows that <otherscientificterm_6> for individual speakers vary considerably , and so there is benefit in obtaining estimates of <otherscientificterm_6> for individual speakers . unfortunately , there is rarely enough data to make reliable estimates . we present a technique for estimating the elements of a <otherscientificterm_0> given only <material_5> from the speaker . it utilizes <method_1> to find structure within <otherscientificterm_6> , and this structure is exploited to make improved estimates . results show that under certain conditions , this technique can give estimates that are as good as those obtained with twice the number of utterances available from the speaker .	7 3 2 9 8 -1 6 8 -1 8 -1 0 5 8 -1 1 8 -1 8 -1
Learning Concept Embeddings with Combined Human-Machine Expertise .	caltech ucsd birds dataset ; unstructured set of pictographic characters ; prime and nonprime numbers ; automatic machine similarity kernels ; low-dimensional concept embedding algorithm ; subjective human taste ; concept embeddings ; human expertise ; human supervision ; bird classifiers ; human insight ; snack embeddings ; training datasets ; deep-learned features ; mnist ; snack	<material> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method>	7 2 4 ; 7 1 3 ; 13 0 11 ; 12 0 9 ; 15 0 6 ; 3 1 4	this paper presents our work on '' <method_15> , '' a <method_4> that combines <otherscientificterm_7> with <otherscientificterm_3> . both parts are complimentary : <otherscientificterm_10> can capture relationships that are not apparent from the object 's visual similarity and the machine can help relieve the human from having to exhaustively specify many constraints . we show that our <method_11> are useful in several tasks : distinguishing <otherscientificterm_2> on <method_14> , discovering labeling mistakes in the <material_0> with the help of <otherscientificterm_13> , creating <material_12> for <method_9> , capturing <otherscientificterm_5> on a new dataset of 10,000 foods , and qualitatively exploring an <material_1> . comparisons with the state-of-the-art in these tasks show that <method_15> produces better <method_6> that require less <otherscientificterm_8> than the leading methods .	15 4 7 3 17 18 22 16 -1 10 16 -1 11 2 14 0 13 12 9 5 19 20 16 -1 1 21 16 -1
Efficient Simulation of Biological Neural Networks on Massively Parallel Supercomputers with Hypercube Architecture .	temporal dynamics of spike interactions ; computation-ally most demanding task ; neural network simulation ; biologically realistic neu-rons ; nontrivial single-cell dynamics ; primary visual system ; neural networks ; biological data ; structure	<otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm>	3 0 2 ; 4 2 3 ; 7 0 8	we present a <method_2> which we implemented on the massively parallel connection machine 2 . in contrast to previous work , this <method_2> is based on <otherscientificterm_3> with <otherscientificterm_4> , high connectivity with a <otherscientificterm_8> modelled in agreement with <material_7> , and preservation of the <otherscientificterm_0> . we simulate <method_6> of 16,384 neurons coupled by about 1000 synapses per neuron , and estimate the performance for much larger systems . communication between neurons is identified as the <task_1> and we present a novel method to overcome this bottleneck . the <method_2> has already been used to study the <method_5> of the cat .	2 9 -1 3 4 8 7 0 10 11 12 9 -1 6 9 -1 1 9 -1 5 9 -1
Symbolic Model Checking for One-Resource RB + - ATL .	forward search of the state space ; rb ± atl ; symbolic model-checking algorithm ; symbolic implementation ; model-checking problem ; model-checking algorithm	<otherscientificterm> <method> <method> <method> <task> <method>	4 0 1 ; 1 6 1 ; 5 0 1 ; 2 0 1 ; 0 0 5	rb ± <method_1> is an extension of <method_1> where it is possible to model consumption and production of several resources by a set of agents . the <task_4> for <method_1> is known to be decidable . however the only available <method_5> for <method_1> uses a <otherscientificterm_0> , and hence does not have an efficient <method_3> . in this paper , we consider a fragment of <method_1> , 1rb ± <method_1> , that allows only one resource type . we give a <method_2> for this fragment of <method_1> , and evaluate the performance of an mcmas-based implementation of the <method_2> on an example problem that can be scaled to large state spaces .	1 8 6 -1 4 7 6 -1 5 0 3 9 11 6 -1 6 -1 2 10 6 -1
Using Error-Correcting Codes for Text Classification .	error correcting output coding ; text classification tasks ; real-world data set ; error-correcting codes ; text classifiers ; random codes ; accuracy	<method> <task> <material> <material> <task> <material> <metric>	3 1 5 ; 6 5 1	this paper explores in detail the use of <method_0> for learning <task_4> . we show that the <metric_6> of a naive bayes classifier over <task_1> can be significantly improved by taking advantage of the error-correcting properties of the code . we also explore the use of different kinds of codes , namely <material_3> , <material_5> , and domain and data-specific codes and give experimental results for each of them . the <method_0> scales well to large data sets with a large number of classes . experiments on a <material_2> show a reduction in classification error by up to 66 % over the traditional naive bayes classifier . we also compare our empirical results to semi-theoretical results and find that the two closely agree .	0 4 7 -1 6 1 9 7 -1 3 5 8 7 -1 7 -1 2 7 -1 7 -1
Particle filter beamforming for acoustic source localization in a reverberant environment .	acoustic source localization ; intermediate time-delay estimates ; speech enhancement applications ; single-step approach ; steered beamforming ; source location ; localization estimates ; two-step procedure ; source trajectory ; particle filtering ; beamformer ; reverberation	<method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm>	1 0 7 ; 3 0 5 ; 7 0 0 ; 3 0 2 ; 3 0 11 ; 1 0 0 ; 9 0 5 ; 6 0 10	traditional <method_0> uses a <method_7> requiring <otherscientificterm_1> from pairs of microphones . an alternative <method_3> is proposed in this paper in which <method_9> is used to estimate the <otherscientificterm_5> through <otherscientificterm_4> . this <method_3> is especially attractive in <task_2> , where the <method_6> are typically used to steer a <method_10> at a later stage . simulation results show that the <method_3> is robust to <otherscientificterm_11> , and is able to accurately follow the <otherscientificterm_8> .	0 7 1 13 15 18 12 -1 3 9 5 4 14 19 12 -1 2 6 10 16 20 12 -1 11 8 17 12 -1
Railway Infrastructure System Diagnosis Using Empirical Mode Decomposition and Hilbert Transform .	intrinsic mode functions ; empirical mode decomposition ; simulated and experimental signals ; railway infrastructure component ; intrinsic mode functions ; measurement signal ; track/vehicle transmission ; periodic patterns ; hilbert transform ; track circuit ; diagnosis scheme ; instantaneous frequency ; physical meaning ; emd	<method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method>	10 0 3	this paper introduces a <method_10> of a <method_3> based on a combined use of <method_1> and <method_8> . this <method_3> is dedicated to <task_6> referred as <method_9> . the aim is to detect its working state from one <otherscientificterm_5> which can be viewed as a superposition of several oscillations and <otherscientificterm_7> called <method_0> . for this application , it will be shown that <otherscientificterm_12> can be assigned to each mode that <method_13> tries to extract . furthermore , when the <method_8> of the <method_0> is performed , we show that the changing of <otherscientificterm_11> can be linked to the existence of defect . the performances are illustrated on both <material_2> .	10 3 1 8 15 14 -1 6 9 14 -1 5 7 0 14 -1 12 13 14 -1 11 14 -1 14 -1
Foreign accent conversion through voice morphing .	continuum of accent transformations ; voice morphing strategy ; pulse density modulation ; foreign speaker ; native speaker ; spectral detail ; spectral slope ; pair-wise fashion ; acoustic quality ; speaker identity ; spectral morphing ; parallel recordings ; accent conversions ; averaging pulses ; foreign accent ; arctic speakers	<otherscientificterm> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <material> <method> <material> <task> <metric> <otherscientificterm> <material>	2 1 13 ; 9 1 14 ; 1 0 0 ; 5 0 10 ; 2 0 10	we present a <method_1> that can be used to generate a <otherscientificterm_0> between a <material_3> and a <material_4> . the <method_1> performs a cepstral decomposition of speech into <otherscientificterm_6> and <otherscientificterm_5> . <task_12> are then generated by combining the <otherscientificterm_6> of the <material_3> with a morph of the <otherscientificterm_5> of the <material_4> . <method_10> is achieved by representing the <otherscientificterm_5> through <otherscientificterm_2> and <metric_13> in a <otherscientificterm_7> . the <method_1> is validated on <material_11> from two <material_15> using both objective and subjective measures of <metric_8> , <material_9> and <otherscientificterm_14> .	1 0 3 4 19 16 -1 6 5 12 16 -1 10 16 -1 2 13 7 17 20 21 16 -1 11 15 8 9 14 18 16 -1
Fast search in Hamming space with multi-index hashing .	problem context open problem ; binary codes ; hamming distance	<task> <otherscientificterm> <otherscientificterm>	2 2 0	problem context open problem : exact sub-linear nearest neighbor search in <otherscientificterm_2> on <otherscientificterm_1> .	2 1 0 4 3 -1
Efficient bit assignment strategy for perceptual audio coding .	mpeg-4 aac verification model ; frame-level bit assignment methods ; low computational complexity ; bit allocation strategy ; bit assignment algorithm ; low rates ; mpeg-4 aac ; max-bnlr scheme ; audio coding ; band-level ; tb-anmr	<method> <method> <metric> <method> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <method>	3 0 4 ; 2 2 10 ; 2 2 7 ; 7 4 0 ; 5 2 8 ; 7 6 3 ; 3 0 6	for the purpose of efficient <task_8> at <otherscientificterm_5> , a new <method_3> is proposed in this paper . the basic idea behind this <method_3> is '' give bits to the band with the maximum nmr-gain/bit '' or '' retrieve bits from the band with the maximum bits/nmr-loss '' . the notion of '' bit-use efficiency '' is suggested and <method_3> can be employed to construct a <method_4> operated at <otherscientificterm_9> as compared to the traditional <method_1> . based on this <method_4> a new <method_3> , called <method_7> , is designed for the <task_6> . simulation results show that the performance of the <method_7> is significantly better than that of the <method_0> and is close to that of <method_10> -lsb- 3 -rsb- , which is the -lrb- nearly -rrb- optimal solution . moreover , the <method_7> has the advantages of <metric_2> comparing to <method_10> .	8 5 3 16 11 -1 11 -1 4 9 1 12 11 -1 7 6 17 18 11 -1 15 11 -1 0 10 13 14 11 -1
Deep Quantization Network for Efficient Image Retrieval .	deep quantization network architecture ; hand-crafted or machine-learned features ; pairwise cosine loss layer ; image retrieval datasets ; large-scale multimedia retrieval ; suboptimal hash coding ; deep image representations ; supervised hashing methods ; product quantiza-tion loss ; image retrieval ; semantic similarity ; data pairs ; dimension-reduced representation ; supervised hashing ; image representation ; quantization step ; bottleneck representation ; convolution-pooling layers ; supervised hashing ; hashing quality ; quantization error ; binary codes ; similarity-preserving learning ; hashing methods ; hash coding ; hashing ; sub-network	<method> <otherscientificterm> <method> <material> <task> <method> <method> <method> <metric> <task> <otherscientificterm> <material> <method> <method> <method> <method> <method> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <method>	15 0 21 ; 0 4 23 ; 7 0 9 ; 18 0 24 ; 10 0 24 ; 2 1 8 ; 17 3 26 ; 12 0 22 ; 15 4 24 ; 0 0 12 ; 2 0 22 ; 25 0 4 ; 13 0 24 ; 0 0 14 ; 3 5 0 ; 14 0 24 ; 0 0 18 ; 2 0 24 ; 12 0 24 ; 0 0 6	hashing has been widely applied to approximate nearest neighbor search for <task_4> . <method_13> improves the quality of <method_24> by exploiting the <otherscientificterm_10> on <material_11> and has received increasing attention recently . for most existing <method_7> for <task_9> , an image is first represented as a vector of <otherscientificterm_1> , then quantized by a separate <method_15> that generates <otherscientificterm_21> . however , <method_5> may be produced , since the <otherscientificterm_20> is not statistically minimized and the <method_15> is not optimally compatible with the <method_24> . in this paper , we propose a novel <method_0> for <task_18> , which learns <method_14> for <method_24> and formally control the <otherscientificterm_20> . the <method_0> constitutes four key components : -lrb- 1 -rrb- a <method_26> with multiple <otherscientificterm_17> to capture <method_6> ; -lrb- 2 -rrb- a fully connected bottleneck layer to generate <method_12> optimal for <method_24> ; -lrb- 3 -rrb- a <method_2> for <task_22> ; and -lrb- 4 -rrb- a <metric_8> for controlling <metric_19> and the quantizability of <method_16> . extensive experiments on standard <material_3> show the proposed <method_0> yields substantial boosts over latest state-of-the-art <method_23> .	4 13 39 27 -1 24 10 11 32 40 27 -1 7 9 1 15 21 28 30 27 -1 5 20 36 27 -1 0 18 14 31 41 43 44 27 -1 33 34 35 37 38 45 46 47 27 -1 26 17 6 12 2 22 8 19 16 29 42 27 -1
Semantic segmentation using regions and parts .	scanning-windows part models ; real world images ; global appearance cues ; region-based object detectors ; pascal segmentation challenge ; class-specific scores ; bottom-up regions ; pixel classification ; articulated objects ; recognizing objects ; articulated categories ; voc2010	<method> <material> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <material> <task> <otherscientificterm> <method>	0 1 2 ; 5 0 6	we address the problem of segmenting and <task_9> in <material_1> , focusing on challenging <otherscientificterm_10> such as humans and other animals . for this purpose , we propose a novel design for <task_3> that integrates efficiently top-down information from <method_0> and <otherscientificterm_2> . our detectors produce <otherscientificterm_5> for <otherscientificterm_6> , and then aggregate the votes of multiple overlapping candidates through <method_7> . we evaluate our approach on the <task_4> , and report competitive performance with respect to current leading techniques . on <method_11> , our method obtains the best results in 6/20 categories and the highest performance on <material_8> .	9 1 10 12 -1 3 0 2 13 12 -1 5 6 7 14 12 -1 4 12 -1 11 8 12 -1
Low-power bit-serial Viterbi decoder for next generation wide-band CDMA systems .	add-compare-select units ; low-power bit-serial viterbi decoder chip ; three-layer metal cmos technology ; high speed convolu-tional decoding ; wide-band cdma mobile systems ; wireless atm lans ; power-efficient trace-back scheme ; trace-back operations ; bit-serial arithmetic ; coding rate ; application-specific memory ; 2mbps operation ; acs operations	<method> <method> <method> <task> <method> <task> <method> <task> <method> <metric> <method> <otherscientificterm> <otherscientificterm>	8 0 0 ; 4 1 5 ; 6 0 7 ; 10 0 7	this paper presents a <method_1> with the <metric_9> r = 1 = 3 and the constraint length k = 9 -lrb- 256 states -rrb- . this <method_1> has been implemented using 0.5 m <method_2> and is targeted for <task_3> for next generation wireless applications such as <method_4> and <task_5> . the <method_1> is expected to operate at 20mbps under 3.3 v and at 2mbps under 1.8 v . the <method_0> have been designed using <method_8> , which has made it feasible to execute 256 <otherscientificterm_12> in parallel . for <task_7> , we have developed a novel <method_6> and an <method_10> , which was designed considering that 256 bits should be written simultaneously for write operations but only one bit needs to be accessed for read operations . we have estimated that the <method_1> dissipates only 10mw at <otherscientificterm_11> under 1.8 v.	1 9 13 -1 2 3 4 5 15 13 -1 13 -1 0 8 12 14 13 -1 7 6 10 16 17 13 -1 13 -1
Non-stationary feature extraction for automatic speech recognition .	short-time fourier transform based features ; pitch-adaptive gammatone filter bank ; non-stationary signal analysis ; speech recognition systems ; acoustic features ; asr framework ; noise robustness ; voiced speech ; mfcc	<method> <method> <method> <method> <otherscientificterm> <method> <metric> <material> <method>	4 1 8 ; 2 3 5 ; 8 6 3 ; 8 4 8 ; 1 0 4 ; 4 4 8 ; 0 0 3 ; 8 6 0	in current <method_3> mainly <method_0> like <method_8> are applied . dropping the short-time stationarity assumption of the <material_7> , this paper introduces the <method_2> into the <method_5> . we present new <otherscientificterm_4> extracted by a <method_1> . the <metric_6> was proved on aurora 2 and 4 tasks , where the proposed <otherscientificterm_4> outperform the standard <method_8> . furthermore , successful combination experiments via <method_8> indicate the differences between the new <otherscientificterm_4> and <method_8> .	3 0 8 12 16 17 9 -1 7 2 5 11 9 -1 4 1 14 9 -1 6 15 9 -1 10 13 9 -1
Learning based automatic face annotation for arbitrary poses and expressions from frontal images only .	automatic annotation of visually deformable objects ; active appearance model ; virtual images of unseen faces ; manual annotation of training images ; automatically annotating face images ; learning based approach ; correspondences between landmarks ; non-rigid deformable models ; annotated frontal image ; frontal image ; reconstructed images ; view-based aams ; unseen images ; statistical approaches ; landmark locations ; maximum range ; virtual images ; arbitrary pose ; tracking ; fitting ; texture	<task> <method> <otherscientificterm> <material> <task> <method> <otherscientificterm> <method> <material> <material> <material> <method> <material> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <task> <otherscientificterm>	4 0 19 ; 4 0 1 ; 19 1 18 ; 16 0 11 ; 5 0 0 ; 1 0 18 ; 1 6 7 ; 8 0 0 ; 13 0 7	statistical approaches for building <method_7> , such as the <method_1> , have enjoyed great popularity in recent years , but typically require tedious <material_3> . in this paper , a <method_5> for the <task_0> from a single <material_8> is presented and demonstrated on the example of <task_4> that can be used for building <method_1> for <task_19> and <task_18> . this <method_5> employs the idea of initially learning the <otherscientificterm_6> in a <material_9> and a set of training images with a face in arbitrary poses . using this learner , <otherscientificterm_2> at any <otherscientificterm_17> for which the learner was trained can be reconstructed by predicting the new <otherscientificterm_14> and warping the <otherscientificterm_20> from the <material_9> . <method_11> are then built from the <material_16> and used for automatically annotating <material_12> , including images of different facial expressions , at any random pose within the <otherscientificterm_15> spanned by the virtually <material_10> . the <method_5> is experimentally validated by <task_4> from three different databases .	7 1 3 28 30 21 -1 5 0 8 4 19 18 22 23 24 26 27 29 21 -1 6 9 21 -1 2 17 21 -1 14 20 11 25 21 -1 16 12 15 10 21 -1
Learning ordinal discriminative features for age estimation .	local manifold structure of facial images ; public available images of groups dataset ; ordinal discriminative feature learning ; facial age estimation ; rank correlation ; redundant information ; aging process ; nonlinear correlation ; aging faces ; feature selection ; fg-net dataset ; locality information ; ordinal information	<otherscientificterm> <material> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm>	7 1 4	in this paper , we present a new method for <task_3> based on <method_2> . considering the temporally ordinal and continuous characteristic of <method_6> , the proposed method not only aims at preserving the <otherscientificterm_0> , but also it wants to keep the <otherscientificterm_12> among <otherscientificterm_8> . moreover , we try to remove <otherscientificterm_5> from both the <otherscientificterm_11> and <otherscientificterm_12> as much as possible by minimizing <otherscientificterm_7> and <otherscientificterm_4> . finally , we formulate these two issues into a unified optimization problem of <method_9> and present an efficient solution . the experiments are conducted on the <material_1> and the <material_10> , and the experimental results demonstrate the power of the proposed method against the state-of-the-art methods .	3 2 13 -1 6 0 12 8 13 -1 5 11 7 4 14 13 -1 9 13 -1 1 10 13 -1
The Set Covering Machine with Data-Dependent Half-Spaces .	support vector machine ; natural data sets ; set covering machine ; data-dependent balls ; model selection ; data-dependent half-spaces ; generalization error ; features	<method> <material> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 2 2 ; 2 4 3 ; 5 0 2	we examine the <method_2> when <method_2> uses <otherscientificterm_5> for its set of <otherscientificterm_7> and bound its <otherscientificterm_6> in terms of the number of training errors and the number of half-spaces <method_2> achieves on the training data . we show that <method_2> provides a favorable alternative to <otherscientificterm_3> on some <material_1> . compared to the <method_0> , the <method_2> with <otherscientificterm_5> produces substantially sparser clas-sifiers with comparable -lrb- and sometimes better -rrb- generalization . furthermore , we show that our bound on the <otherscientificterm_6> provides an effective guide for <task_4> .	2 5 7 6 11 8 -1 3 1 10 8 -1 0 9 8 -1 4 8 -1
Distributed genetic algorithm to discover a wavelet packet best basis for speech recognition .	wavelet packet best basis decomposition ; mel-scaled subband decomposition ; distributed genetic algorithm ; speech recognition models ; feature extraction module ; priori '' reference ; global learning scheme ; speech modeling ; fitness value ; speech-modeling algorithm ; wavelet topology ; reference system ; connectionist system ; neural network ; speech recognition ; simulated fitness ; speech models ; space	<task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm>	8 1 14 ; 2 0 6 ; 6 0 4 ; 6 0 16 ; 10 0 12 ; 9 0 6 ; 14 0 11 ; 15 0 11	in the learning process of <task_7> , many choices or settings are defined '' a priori '' or are resulting from years of experimental work . in this paper , instead , a <method_6> is proposed based on a <method_2> combined with a standard <method_9> . the <method_3> are now created out of a pre-defined <otherscientificterm_17> of solutions . furthermore , this <method_6> enables to learn the <method_16> as well as the best <method_4> . experimental validation is performed on the task of discovering the <task_0> , knowing that the '' a <otherscientificterm_5> is the <otherscientificterm_1> . two experiments are presented , a <method_11> using a <otherscientificterm_15> and a second one that uses the <task_14> performance as <otherscientificterm_8> . in the latter , each element of the <otherscientificterm_17> is a <method_12> defined by a <method_10> and its associated <method_13> .	7 18 -1 6 2 9 20 24 18 -1 3 17 18 -1 16 4 21 22 18 -1 0 5 1 18 -1 19 25 26 18 -1 11 15 14 8 23 18 -1
Piecewise Volterra filters based on the threshold decomposition operator .	piecewise volterra filters ; pwv lters partition r n ; class of lters ; hard nonlinear structures ; multilinear tensor forms ; partition boundaries continuity ; multivariate polynomials ; parameter estimation ; linear problem ; pwv 's ; lter taps ; hy-per-rectangular lattice ; volterra lter ; lter	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <material> <otherscientificterm> <otherscientificterm> <method> <method>	11 0 1 ; 11 0 0 ; 8 0 9 ; 0 0 1	in this paper we report our results concerning the study of multivariate functions of threshold-decomposed signals . in particular we show that <otherscientificterm_4> of the decomposed signal yield a <otherscientificterm_2> that we propose to call <method_0> . a <method_13> can be viewed as a transformation of r n ! r , where n is the number of <otherscientificterm_10> . <method_1> using a <otherscientificterm_11> , and assign a <method_12> to each of the partition regions . at the <otherscientificterm_5> between the <otherscientificterm_6> is preserved resulting in class c 0 piecewise polynomials . <method_0> constitute an eecient alternative for describing some systems rich in <otherscientificterm_3> , especially since <method_7> remains a <task_8> for <material_9> .	14 -1 4 2 0 14 -1 13 10 1 14 -1 11 12 14 -1 5 6 15 16 18 14 -1 14 -1 3 7 8 9 17 14 -1
High Order Regularization for Semi-Supervised Learning of Structured Output Problems .	semi-supervised structured output learning ; image segmentation tasks ; discrete optimization algorithms ; high order regular-izers ; structured output problems ; multi-dimensional outputs ; unlabeled examples ; unlabeled data ; model predictions ; semi-supervised learning ; cardinality regularizer ; labeled data ; posterior regulariza-tion ; max-margin framework ; graph regularizer ; discriminative model	<task> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <method> <material> <method> <method> <method> <method>	7 0 9 ; 13 0 0 ; 9 0 15 ; 14 6 1 ; 10 6 1 ; 7 0 13 ; 14 1 10 ; 1 5 13	semi-supervised learning , which uses <material_7> to help learn a <method_15> , is especially important for <task_4> , as considerably more effort is needed to label its <otherscientificterm_5> versus standard single output problems . we propose a new <method_13> for <task_0> , that allows the use of powerful <method_2> and <otherscientificterm_3> defined directly on <otherscientificterm_8> for the <otherscientificterm_6> . we show that our <method_13> is closely related to <method_12> , and the two <method_13> optimize special cases of the same objective . the new <method_13> is instantiated on two <task_1> , using both a <method_14> and a <method_10> . experiments also demonstrate that this <method_13> can utilize <material_7> from a different source than the <material_11> to significantly improve performance while saving labeling effort .	7 15 4 5 17 19 16 -1 13 0 2 3 8 6 18 16 -1 12 16 -1 1 14 10 20 21 23 24 16 -1 22 16 -1
Low-Rank Tensor Constrained Multiview Subspace Clustering .	ten-sor nuclear norm minimization problem ; benchmark image datasets ; subspace representation matrices ; low-rank tensor constraint ; multiview sub-space clustering ; ℓ 2,1-norm regularizer ; high order correlations ; affinity matrix ; minimization problem ; inference process ; linear equalities ; subspace representations ; lt-msc method ; low-rank constraint ; complementary information ; multi-view data ; accuracy ; clustering	<task> <material> <method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <material> <metric> <method>	3 0 14 ; 7 0 17 ; 1 5 12 ; 5 1 10	in this paper , we explore the problem of <task_4> . we introduce a <otherscientificterm_3> to explore the <otherscientificterm_14> from multiple views and , accordingly , establish a novel method called low-rank tensor constrained multiview subspace clustering -lrb- lt-msc -rrb- . our method regards the <method_2> of different views as a <otherscientificterm_3> , which captures dexterously the <otherscientificterm_6> underlying <material_15> . then the <otherscientificterm_3> is equipped with a <otherscientificterm_13> , which models elegantly the cross information among different views , reduces effectually the redundancy of the learned <method_11> , and improves the <metric_16> of <method_17> as well . the <method_9> of the <method_7> for <method_17> is formulated as a <task_0> , constrained with an additional <method_5> and some <otherscientificterm_10> . the <task_8> is convex and thus can be solved efficiently by an augmented lagrangian alternating direction minimization -lrb- al-adm -rrb- method . extensive experimental results on four <material_1> show the effectiveness of the proposed <method_12> .	4 18 -1 3 14 19 18 -1 2 6 15 18 -1 13 11 16 17 18 -1 9 20 22 18 -1 7 0 5 10 18 -1 8 21 18 -1
Cost-Optimal Planning with Landmarks .	satisficing planning ; cost-optimal heuristic search ; admissible heuristic estimates ; multi-path dependent heuristics ; best-first search procedure ; solution plan ; cost-optimal planning ; planning landmarks ; planning landmarks ; heuristics	<task> <method> <task> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method>	8 0 0 ; 9 3 3 ; 9 0 4 ; 2 0 6	planning landmarks are facts that must be true at some point in every <otherscientificterm_5> . previous work has very successfully exploited <otherscientificterm_8> in <task_0> . we propose a methodology for deriving <task_2> for <task_6> from a set of <otherscientificterm_8> . the resulting <method_9> fall into a novel class of <method_3> , and we present a simple <method_4> exploiting such <method_9> . our empirical evaluation shows that this framework favorably competes with the state-of-the-art of <method_1> .	5 10 -1 8 0 11 10 -1 2 6 14 10 -1 9 3 4 12 13 10 -1 1 7 10 -1
Underdetermined Blind Separation of Audio Sources from the Time-Frequency Representation of their Convolutive Mixtures .	time-frequency distribution values ; blind separation of nonstationary sources ; time-frequency domain ; underdetermined convolutive mixture case ; tf domain ; tf point ; subspace projection ; active sources ; tf-nondisjoint ; disjoint	<otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm>	6 0 1 ; 3 0 1	this paper considers the <task_1> in the <task_3> . we introduce two methods based on the sparsity assumption of the sources in the <otherscientificterm_2> . the first one assumes that the sources are <otherscientificterm_9> in the <otherscientificterm_4> ; i.e. there is at most one source signal present at a given point in the <otherscientificterm_4> . in the second method , we relax this assumption by allowing the sources to be <otherscientificterm_8> to a certain extent . in particular , the number of sources present -lrb- active -rrb- at a <otherscientificterm_5> should be strictly less than the number of sensors . in that case , the <task_1> can be achieved thanks to <method_6> which allows us to identify the <material_7> and to estimate their corresponding <otherscientificterm_0> .	1 3 12 10 -1 2 10 -1 9 4 10 -1 8 10 -1 5 10 -1 11 10 -1
Region-of-interest based rate control scheme for high efficiency video coding .	region of interest quality ; rate control scheme ; rate control algorithm ; target bit rates ; subjective quality evaluation ; global bit rate ; videoconferencing system ; bit allocation ; coding unit ; objective metrics ; rois	<metric> <method> <method> <metric> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	1 0 6	in this paper , we propose a new <method_1> designed for the newest high efficiency video coding -lrb- hevc -rrb- standard , and aimed at enhancing the quality of regions of interest -lrb- roi -rrb- . our <method_1> allocates a higher bit rate to the region of interest while keeping the <otherscientificterm_5> close to the assigned target value . this <method_1> is developed for a <method_6> , where the <otherscientificterm_10> -lrb- typically , faces -rrb- are automatically detected and each <otherscientificterm_8> is classified in a region of the interest map . this map is given as input to the <method_2> and the <otherscientificterm_7> is made accordingly . experimental results show that the proposed <method_1> achieves accurate <metric_3> and provides an improvement in the <metric_0> , both in <metric_9> and based on <metric_4> .	1 11 -1 5 11 -1 6 10 8 12 11 -1 2 11 -1 7 11 -1
Image segmentation with a bounding box prior .	interactive image segmentation frameworks ; global energy minimization framework ; user-provided object bounding box ; publicly available dataset ; fractional lp solution ; np-hard integer program ; graph cut algorithm ; user-provided box ; bounding box ; linear relaxation ; topological prior ; energy minimization ; excessive shrinking ; hard constraints ; standalone heuristic ; thresholding-based rounding ; optimization strategies ; interaction paradigm ; rounding method ; pinpointing	<method> <method> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <method> <method>	18 0 6 ; 13 2 1 ; 6 0 4 ; 6 0 16 ; 1 0 10 ; 19 6 16 ; 19 6 6 ; 13 0 10 ; 4 4 15 ; 8 0 10 ; 9 6 16 ; 0 0 17 ; 18 0 4	user-provided object <otherscientificterm_8> is a simple and popular <method_17> considered by many existing <method_0> . however , these frameworks tend to exploit the provided <otherscientificterm_8> merely to exclude its exterior from consideration and sometimes to initialize the <method_11> . in this paper , we discuss how the <otherscientificterm_8> can be further used to impose a powerful <otherscientificterm_10> , which prevents the solution from <otherscientificterm_12> and ensures that the <otherscientificterm_7> bounds the segmentation in a sufficiently tight way . the <otherscientificterm_10> is expressed using <otherscientificterm_13> incorporated into the <method_1> leading to an <method_5> . we then investigate the possible <method_16> including <method_9> as well as a new <method_6> called <method_19> . the latter can be used either as a <method_18> for the <method_4> , which is provably better than <method_15> , or as a fast <method_14> . we evaluate the proposed algorithms on a <material_3> , and demonstrate the practical benefits of the new <otherscientificterm_10> both qualitatively and quantitatively .	8 17 0 32 20 -1 11 20 -1 10 12 7 30 20 -1 13 1 5 22 25 28 20 -1 16 24 26 27 31 20 -1 9 6 19 21 23 29 33 20 -1 18 4 15 14 20 -1
Watermarking of speech signals using the sinusoidal model and frequency modulation of the partials .	audio/speech signals ; speech signals ; watermarking task ; sinusoidal model ; modulation	<task> <material> <task> <method> <otherscientificterm>	3 0 2 ; 0 0 2 ; 3 0 0	in this paper , the application of the <method_3> for <task_0> to the <task_2> is proposed . the basic idea is that adequate <otherscientificterm_4> of medium rank partials -lrb- frequency -rrb- trajectories is not perceptible and thus this <otherscientificterm_4> may contain the data to be embedded in the signal . the <otherscientificterm_4> -lrb- encoding -rrb- and estimation -lrb- decoding -rrb- of the message are described in this paper and preliminary promising results are given in the case of <material_1> .	3 0 2 6 7 8 5 -1 4 5 -1 1 5 -1
Image enhancement using color and spatial information .	real blurred and noisy color image ; color image enhancement ; weighted cost function ; enhancement capabilities ; spatial information ; filter	<material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 0 1 ; 5 0 3	* 564 -rrb- +6 in this paper , a new <method_5> that is performing <task_1> is presented . the <method_5> is achieving this through the minimization of a <otherscientificterm_2> . the weights are determined using potential functions which are calculated in such a way as to convey <otherscientificterm_4> . application of the proposed <method_5> on a <material_0> is performed to verify its <otherscientificterm_3> .	5 1 7 6 -1 2 6 -1 4 6 -1 0 3 8 6 -1
Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning .	linear function approximation representations of q ; policy gradient reinforcement learning algorithms ; state action value function ; policy gradient reinforcement learning ; performance gradient estimates ; function approximation representation ; non-zero bias term ; basis functions ; function approximation ; bias term	<method> <method> <otherscientificterm> <task> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	8 0 0 ; 8 0 2 ; 9 0 2	we address two open theoretical questions in <task_3> . the first concerns the efficacy of using <method_8> to represent the <otherscientificterm_2> , q. theory is presented showing that <method_0> can degrade the rate of convergence of <metric_4> by a factor of o -lrb- m l -rrb- relative to when no <method_8> of q is used , where m is the number of possible actions and l is the number of <otherscientificterm_7> in the <method_5> . the second concerns the use of a <otherscientificterm_9> in estimating the <otherscientificterm_2> . theory is presented showing that a <otherscientificterm_6> can improve the rate of convergence of <metric_4> by o -lrb- 1 − -lrb- 1/m -rrb- -rrb- , where m is the number of possible actions . experimental evidence is presented showing that these theoretical results lead to significant improvement in the convergence properties of <method_1> .	3 10 -1 8 2 0 4 7 5 11 12 10 -1 9 13 10 -1 6 10 -1 10 -1
Cluster-based user simulations for learning dialogue strategies .	cluster-based user simulation technique ; cluster-based user simulations ; spoken dialogue systems ; dialogue strategies ; cluster-based technique ; reinforcement learning ; random base-line ; conversational interaction ; user simulations ; dialogue management ; clarification strategies ; mutual understanding	<method> <method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm>	1 5 0 ; 10 0 5 ; 2 0 11 ; 3 0 2 ; 3 0 11 ; 0 0 8 ; 4 0 8 ; 10 0 8 ; 8 0 9 ; 8 0 5	good <method_3> in <method_2> help to ensure and maintain <otherscientificterm_11> and thus play a crucial role in robust <otherscientificterm_7> . we focus on <method_10> and build <method_8> which are critical for <task_5> , which is a cheap and principled way to automatically optimise <task_9> . in this paper we present a novel <method_4> for building <method_8> which show varying , but complete and consistent behaviour with respect to real users . we use this <method_4> to build <method_8> and we also introduce the <method_0> which allows us to evaluate <method_8> with respect to these desiderata . we show that the <method_0> performs significantly better -lrb- at p < 0.01 -rrb- than decisions made using either the one most likely action or a <otherscientificterm_6> . the <method_1> reduce the average error of these other <method_0> by 53 % and 34 % respectively .	3 2 11 7 15 16 17 12 -1 10 8 5 9 14 20 21 22 12 -1 4 12 -1 0 18 19 12 -1 12 -1 6 13 12 -1
On the effect of snr and superdirective beamforming in speaker diarisation in meetings .	arrival smoothing ; digital mems microphone array ; corpus of meetings ; instrumented meeting room ; audio signal degradation ; diarisation error rate ; snr analogue ; noise reduction ; superdirective beamforming ; delay-sum beamformer ; speaker diarisation ; super-directive beamforming ; index terms ; mems microphones ; beamforming techniques ; diar-isation systems ; beamforming schemes	<method> <otherscientificterm> <material> <otherscientificterm> <task> <metric> <method> <task> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method>	14 3 15 ; 16 0 4 ; 5 5 9 ; 7 1 16	this paper examines the effect of sensor performance on <task_10> in meetings and investigates the use of more advanced <method_14> , beyond the typically employed <method_9> , for mitigating the effects of poorer sensor performance . we present <method_11> and investigate how different time difference of <method_0> and <method_14> influence the performance of state-of-the-art <method_15> . we produced and transcribed a new <material_2> recorded in the <otherscientificterm_3> using a high <method_6> and a newly developed low snr <otherscientificterm_1> -lrb- dmma .2 -rrb- . this research demonstrates that <method_9> has a significant effect on the <metric_5> and that simple <task_7> and <method_16> suffice to overcome <task_4> due to the lower snr of modern <otherscientificterm_13> . <otherscientificterm_12> -- speaker diarisation in meetings , <otherscientificterm_1> , time difference of arrival -lrb- tdoa -rrb- , superdirective beamforming	10 14 9 17 -1 11 0 15 18 17 -1 2 3 6 1 17 -1 5 7 19 20 21 17 -1 16 4 13 12 17 -1
Incremental Truncated LSTD .	temporal difference learning algorithms ; least-squares temporal difference algorithms ; incremental low-rank lstd -lrb- -rrb- algorithm ; computation and storage complexity ; high-dimensional energy allocation domain ; truncated low-rank approximation ; linear time complexity ; reinforcement learning ; computational efficiency ; sample efficiency ; bias-variance trade-off ; rank parameter ; value function ; computational complexity ; policy evaluation ; features ; rank ; lstd	<method> <method> <method> <metric> <task> <otherscientificterm> <metric> <task> <metric> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <method>	8 1 9 ; 3 5 2 ; 0 0 12 ; 13 1 9 ; 2 0 14 ; 13 5 2 ; 9 5 2	balancing between <metric_8> and <metric_9> is an important goal in <task_7> . <method_0> stochastically update the <otherscientificterm_12> , with a <metric_6> in the number of <otherscientificterm_15> , whereas <method_1> are sample efficient but can be quadratic in the number of <otherscientificterm_15> . in this work , we develop an efficient <method_2> that progresses towards the goal of better balancing computation and <metric_9> . the <method_2> reduces the <metric_3> to the number of <otherscientificterm_15> times the chosen <otherscientificterm_11> while summarizing past samples efficiently to nearly obtain the <metric_9> of <method_17> . we derive a simulation bound on the solution given by <otherscientificterm_5> , illustrating a <otherscientificterm_10> dependent on the choice of <otherscientificterm_16> . we demonstrate that the <method_2> effectively balances <metric_13> and <metric_9> for <task_14> in a benchmark task and a <task_4> .	8 9 7 0 19 18 -1 12 6 15 1 21 18 -1 2 18 -1 3 11 17 20 18 -1 18 -1 5 10 16 22 23 24 25 18 -1
Quantitative Evaluation of Explanation-Based Learning as an Optimisation Tool for a Large-Scale Natural Language System .	sri core language engine ; machine learning technique ; total processing time ; atis corpus ; explanation-based learning ; explanation-based learning	<method> <method> <metric> <material> <method> <task>	4 1 1 ; 1 0 0 ; 2 5 1 ; 4 0 0	this paper describes the application of <method_4> , a <method_1> , to the <method_0> , a large scale general purpose natural language analysis system . the idea is to bypass normal morphological , syntactic and -lrb- partly -rrb- semantic processing , for most input sentences , instead using a set of learned <method_1> . <task_5> is used to extract the learned <method_1> automatically from sample sentences submitted by a user and thus tune the system for that particular user . by indexing the learned <method_1> efficiently , it is possible to achieve dramatic speed-ups . performance measurements were carried out using a training set of 1500 sentences and a separate test set of 100 sentences , all from the <material_3> . a set of 680 learned <method_1> was derived from the training set . these <method_1> covered 90 percent of the test sentences and reduced the <metric_2> to a third . an overall speed-up of 50 percent was accomplished using a set of only 250 learned <method_1> .	4 1 0 7 8 10 6 -1 5 6 -1 6 -1 6 -1 6 -1 3 6 -1 9 6 -1 2 6 -1
Integrated speech enhancement and coding in the time-frequency domain .	wavelet packet transform algorithm ; subtractive-type enhancement algorithm ; rough masking model ; masking threshold constraints ; time-frequency transform domain ; speech enhancement ; auditory modeling ; noisy signal ; speech coecients ; fft processing ; auditory spectrum ; quantization noise	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	3 0 4 ; 3 0 8 ; 5 3 6	this paper addresses the problem of merging <task_5> and coding in the context of an <method_6> . the <otherscientificterm_7> is rst processed by a fast <method_0> to obtain an <otherscientificterm_10> , from which a <method_2> is estimated . then , this model is used to rene a <method_1> . the enhanced <material_8> are then encoded in the same <otherscientificterm_4> using <otherscientificterm_3> for <otherscientificterm_11> . the advantage of the proposed method is that both enhancement and coding are performed with the transform coecients , without making use of the additional <method_9> .	5 6 15 12 -1 7 0 10 2 12 -1 1 12 -1 8 4 3 11 13 14 12 -1 9 12 -1
Development of bilingual ASR system for MediaParl corpus .	frequency domain linear prediction-based features ; automatic speech recognition system ; tandem and hybrid acoustic modeling approaches ; bilingual deep neural networks ; language-specific asr system ; bilingual mediaparl corpus ; entropy-based decoding-graph selection ; reverberant recordings ; ac-cented speech ; accented speech ; reverberation	<method> <method> <method> <method> <method> <material> <method> <material> <material> <material> <otherscientificterm>	7 1 9 ; 1 0 5 ; 1 4 4 ; 1 0 8 ; 3 0 1 ; 3 0 2 ; 0 0 2 ; 0 0 3 ; 3 0 8 ; 2 0 8	the development of an <method_1> for the <material_5> is challenging for several reasons : -lrb- 1 -rrb- <material_7> , -lrb- 2 -rrb- <material_9> , and -lrb- 3 -rrb- no prior information about the language . in that context , we employ <method_0> to reduce the effect of <otherscientificterm_10> , exploit <method_3> applied in <method_2> to significantly improve <method_1> for <material_8> and develop a fully <method_1> using <method_6> . our experiments indicate that the proposed <method_1> performs similar to a <method_4> if approximately five seconds of speech are available .	1 5 7 9 12 13 11 -1 0 10 3 2 8 6 15 16 17 18 19 20 21 11 -1 4 14 11 -1
A new quality measure for topic segmentation of text and speech .	baseline one-best topic model ; topic segmentation quality measure ; topic segmentation quality ; relative error reduction ; topic segmen-tation algorithms ; large multimedia collections ; speech recognition lattices ; speech segments ; topic boundaries ; quality measure ; content navigation ; topicality information ; speech recognition ; transcription quality ; spoken language ; lattices	<method> <metric> <metric> <metric> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <task> <metric> <material> <otherscientificterm>	1 5 0 ; 3 5 9 ; 6 0 2 ; 9 0 4 ; 11 0 10 ; 11 0 13 ; 3 5 0 ; 9 5 0	the recent proliferation of <material_5> has gathered immense attention from the speech research community , because <task_12> enables the transcription and indexing of such <material_5> . <otherscientificterm_11> can be used to improve <metric_13> and enable <task_10> . in this paper , we give a novel <metric_9> for <method_4> that improves over previously used measures . our <metric_9> takes into account not only the presence or absence of <otherscientificterm_8> but also the content of the text or <otherscientificterm_7> labeled as topic-coherent . additionally , we demonstrate that <metric_2> of <material_14> can be improved using <otherscientificterm_6> . using <otherscientificterm_15> , improvements over the <method_0> are observed when measured with the previously existing <metric_1> , as well as the new <metric_9> proposed in this paper -lrb- 9.4 % and 7.0 % <metric_3> , respectively -rrb- .	5 12 11 16 -1 13 10 21 22 16 -1 9 4 20 16 -1 8 7 16 -1 2 14 6 19 16 -1 15 17 18 23 24 16 -1
Region Extraction from Multiple Images .	global minimization of the energy functional ; polynomial time graph algorithm ; dense optical flow ; high intensity gradients ; optical flow discontinuities ; disparity map ; region identification ; energy functional ; intensity values ; multi-dimensional space ; ratio form ; heuristic energy	<task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	2 1 5 ; 1 0 0 ; 10 0 7	we present a method for <task_6> in multiple images . a set of regions in different images and the correspondences on their boundaries can be thought of as a boundary in the <otherscientificterm_9> formed by the product of the individual image domains . we minimize an <otherscientificterm_7> on the space of such boundaries , thereby identifying simultaneously both the optimal regions in each image and the optimal correspondences on their boundaries . we use a <otherscientificterm_10> for the <otherscientificterm_7> , thus enabling the <task_0> using a <method_1> , among other desirable properties . we choose a simple form for this energy that favours boundaries that lie on <otherscientificterm_3> in each image , while encouraging correspondences between boundaries in different images that match <otherscientificterm_8> . the latter tendency is weighted by a novel <method_11> that encourages the boundaries to lie on disparity or <otherscientificterm_4> , although no <otherscientificterm_2> or <otherscientificterm_5> is computed .	6 12 -1 9 12 -1 7 12 -1 10 0 1 14 15 12 -1 12 -1 3 8 13 12 -1
The Distribution Family of Similarity Distances .	object and scene recognition algorithms ; assessing similarity between features ; feature extraction algorithms ; scene categorization tasks ; distribution of distances ; similarity functions ; feature vector ; feature values ; object recognition ; feature similarity ; l p-norms ; features ; distribution ; images	<method> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	8 1 3 ; 5 0 4	assessing similarity between <otherscientificterm_11> is a key step in <task_8> and <task_3> . we argue that knowledge on the <otherscientificterm_4> generated by <otherscientificterm_5> is crucial in deciding whether <otherscientificterm_11> are similar or not . intuitively one would expect that similarities between <otherscientificterm_11> could arise from any <otherscientificterm_12> . in this paper , we will derive the contrary , and report the theoretical result that <otherscientificterm_10> -- a class of commonly applied distance metrics -- from one <otherscientificterm_6> to other vectors are weibull-distributed if the <otherscientificterm_7> are correlated and non-identically distributed . besides these assumptions being realistic for <material_13> , we experimentally show them to hold for various popular <method_2> , for a diverse range of <material_13> . this fundamental insight opens new directions in the assessment of <otherscientificterm_9> , with projected improvements in <method_0> .	11 8 3 15 14 -1 4 5 16 14 -1 12 14 -1 10 6 7 14 -1 13 14 -1 2 14 -1
A New d-DNNF-Based Bound Computation Algorithm for Functional E-MAJSAT .	probabilistic conformant planner ; branch-and-bound search tree ; compilation language d-dnnf ; computing upper bounds ; map solver ; e-majsat problem ; branch-and-bound solver ; functional e-majsat	<method> <otherscientificterm> <method> <task> <method> <task> <method> <method>	7 0 5 ; 6 0 7 ; 4 1 0	we present a new algorithm for <task_3> for an optimization version of the <task_5> called <method_7> . the algorithm utilizes the <method_2> which underlies several state-of-the-art algorithms for solving related problems . this bound computation can be used in a <method_6> for solving <method_7> . we then present a technique for pruning values from the <otherscientificterm_1> based on the information available after each bound computation . we evaluated the proposed techniques in a <method_4> and a <method_0> . in both cases , our experiments showed that the new techniques improved the efficiency of state-of-the-art solvers by orders of magnitude .	3 5 7 9 8 -1 2 8 -1 6 10 8 -1 1 8 -1 4 0 11 8 -1 8 -1
Clustering via Concave Minimization .	wisconsin diagnostic breast cancer database ; wisconsin prognostic breast cancer database ; k-median training set correct-ness ; fast nite k-median algorithm ; piecewise-linear concave function ; linear programs ; k-median algorithm ; polyhedral distance ; closed form ; bilinear program ; bilinear function ; real-world databases ; polyhedral set ; survival curves ; polyhe-dral set	<material> <material> <metric> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 2 5 ; 2 4 6 ; 0 5 6 ; 12 0 4	the problem of assigning m points in the n-dimensional real space r n to k clusters is formulated as that of determining k centers in r n such that the sum of distances of each point to the nearest center is minimized . if a <otherscientificterm_7> is used , the problem can be formulated as that of minimizing a <otherscientificterm_4> on a <otherscientificterm_12> which is shown to be equivalent to a <method_9> : minimizing a <otherscientificterm_10> on a <otherscientificterm_14> . a <method_3> consisting of solving few <method_5> in <otherscientificterm_8> leads to a stationary point of the <method_9> . computational testing on a number of <material_11> was carried out . on the <material_0> , <metric_2> was comparable to that of the <method_6> , however its testing set correctness was better . additionally , on the <material_1> , distinct and clinically important <otherscientificterm_13> were extracted by the <method_6> , whereas the <method_6> failed to obtain such distinct <otherscientificterm_13> for the same database .	15 -1 7 4 12 9 10 14 19 15 -1 3 5 8 16 15 -1 15 -1 11 17 18 15 -1 0 2 6 15 -1
Time-frequency based biological sequence querying .	time-frequency methods ; widely-accepted blast alignment approach ; gapped query-based alignment methods ; highly-localized basis functions ; tf plane ; biological sequences ; low-complexity regions ; repetitive segments ; querying approaches ; signicance improvement ; sub-sequence ; pre-processing	<method> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method>	3 0 4 ; 0 0 5 ; 3 0 0 ; 4 0 2	we investigate the use of <method_0> to query <material_5> in search of regions of similarity or critical relationships among the sequences . existing <method_8> are insensitive to repeats , especially in <otherscientificterm_6> , and do not provide much support for efciently querying sub-sequences with inserts and deletes -lrb- or gaps -rrb- . our <method_0> uses <otherscientificterm_3> and multiple transformations in the <method_4> to map characters in a sequence as well as different properties of a <otherscientificterm_10> , such as its position in the sequence or number of gaps between sub-sequences . we analyze <method_2> using transformations in the <method_4> while demonstrating the <method_0> 's possible operation in real-time without <method_11> . the <method_0> 's performance is compared to the <method_1> , and a <method_9> is observed for queries with <otherscientificterm_7> .	0 5 14 12 -1 8 6 12 -1 3 4 10 13 15 12 -1 2 16 12 -1 11 12 -1
Spatially Binned ROC : A Comprehensive Saliency Metric .	graph based visual saliency ; dynamic visual attention ; adaptive whitening saliency ; context-aware saliency ; information maximiza-tion ; datasets of human fixations ; randomly sampled fixations ; shuffled roc metric ; saliency algorithm development ; visual salience ; saliency algorithm ; spatial biases ; algorithm ranking ; central fixations ; spatial bias ; saliency algorithms ; large-scale benchmarking ; roc metrics ; bias	<method> <method> <method> <method> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm>	4 1 1 ; 16 6 8 ; 7 0 17 ; 6 0 7	a recent trend in <method_8> is <task_16> and <task_12> with ground truth provided by <material_5> . in order to accommodate the strong <otherscientificterm_18> humans have toward <otherscientificterm_13> , <method_7> is common to replace traditional <method_17> with a <method_7> which uses <otherscientificterm_6> from other images in the database as the negative set . however , the shuffled roc introduces a number of problematic elements , including a fundamental assumption that <method_7> is possible to separate <otherscientificterm_9> and image spatial arrangement . we argue that <method_7> is more informative to directly measure the effect of <otherscientificterm_14> on algorithm performance rather than try to correct for <method_7> . to capture and quantify these known sources of <otherscientificterm_18> , we propose a novel metric for measuring <method_10> performance : the spatially binned roc -lrb- sproc -rrb- . this metric provides direct insight into the <otherscientificterm_11> of a <method_10> without sacrificing the intuitive raw performance evaluation of traditional <method_17> . by quantitatively measuring the <otherscientificterm_18> in <method_15> , researchers will be better equipped to select and optimize the most appropriate algorithm for a given task . we use a baseline measure of inherent algorithm <otherscientificterm_18> to show that <method_2> -lsb- 14 -rsb- , attention by <method_4> -lsb- 8 -rsb- , and <method_1> -lsb- 20 -rsb- provide the least spatially biased results , suiting them for tasks in which there is no information about the underlying <otherscientificterm_14> of the stimuli , whereas algorithms such as <method_0> -lsb- 18 -rsb- and <method_3> -lsb- 15 -rsb- have a significant inherent central <otherscientificterm_18> .	8 16 12 5 21 19 -1 18 13 7 17 6 22 23 19 -1 9 19 -1 14 19 -1 19 -1 10 19 -1 11 19 -1 15 20 19 -1
Multiple Path Coordination for Mobile Robots : A Geometric Algorithm .	mobile robot motion coordination ; so-called coordination diagram ; bounding box representation ; geometric based approach ; robot paths	<task> <otherscientificterm> <method> <method> <otherscientificterm>	2 0 3	this paper presents a <method_3> for multiple <task_0> . all the <otherscientificterm_4> being computed independently , we address the problem of coordinating the motion of the robots along their own path in such a way they do not collide each other . the proposed <method_3> is based on a <method_2> of the obstacles in the <otherscientificterm_1> . the <method_3> is resolution-complete . its efficiency is illustrated by examples involving more than 100 robots .	3 0 5 -1 4 5 -1 2 1 6 5 -1 5 -1 5 -1
The One-Shot similarity kernel .	conditionally positive definite kernel ; one-shot similarity measure ; one-shot similarity score ; one-shot score ; face recognition ; multi-class identification ; descriptor generation ; image representation ; lda ; classifier	<otherscientificterm> <metric> <metric> <metric> <task> <task> <task> <task> <method> <method>	1 0 7 ; 1 0 4 ; 5 1 6	the <metric_1> has recently been introduced in the context of <task_4> where <metric_1> was used to produce state-of-the-art results . given two vectors , their <metric_2> reflects the likelihood of each vector belonging in the same class as the other vector and not in a class defined by a fixed set of '' negative '' examples . the potential of this approach has thus far been largely un-explored . in this paper we analyze the <metric_3> and show that : -lrb- 1 -rrb- when using a version of <method_8> as the underlying <method_9> , this score is a <otherscientificterm_0> and may be used within kernel-methods -lrb- e.g. , svm -rrb- , -lrb- 2 -rrb- <metric_1> can be efficiently computed , and -lrb- 3 -rrb- that <metric_1> is effective as an underlying mechanism for <task_7> . we further demonstrate the effectiveness of the <metric_2> in a number of applications including <task_5> and <task_6> .	1 4 12 10 -1 2 10 -1 10 -1 3 8 9 0 11 10 -1 7 13 10 -1
Nonparametric Risk and Stability Analysis for Multi-Task Learning Problems .	simulated and real data ; transfer learning framework ; multi-task/transfer learning problems ; multi-task learning ; reweighting matrix ; source domain ; task relations ; smoothness assumptions ; multi-task learning ; transfer learning	<material> <method> <task> <task> <method> <material> <task> <otherscientificterm> <method> <method>	1 0 8	multi-task learning attempts to simultaneously leverage data from multiple domains in order to estimate related functions on each domain . for example , a special case of <method_8> , <method_9> , is often employed when one has a good estimate of a function on a <material_5> , but is unable to estimate a related function well on a target domain using only target data . <task_2> are usually solved by imposing some kind of '' smooth '' relationship among/between tasks . in this paper , we study how different <otherscientificterm_7> on <task_6> affect the upper bounds of algorithms proposed for these <task_2> under different settings . for general <method_8> , we study a family of algorithms which utilize a <method_4> on task weights to capture the smooth relationship among tasks , which has many instantiations in existing literature . furthermore , for <method_8> in a <method_1> , we study the recently proposed algorithms for the '' model shift '' , where the conditional distribution p -lrb- y | x -rrb- is allowed to change across tasks but the change is assumed to be smooth . in addition , we illustrate our results with experiments on both <material_0> .	10 -1 8 9 5 2 10 -1 10 -1 7 6 10 -1 10 -1 4 11 10 -1 1 10 -1
Structural Symmetries for Fully Observable Nondeterministic Planning .	nondeterministic planning ; fast downward planner ; lao ⇤ algorithm ; symmetry reduction techniques ; heuristic search ; structural symmetries ; fond planning ; symmetry reduction ; classical planning	<task> <method> <method> <method> <method> <task> <task> <task> <task>	1 2 2 ; 5 1 6 ; 7 0 8 ; 2 4 2 ; 5 1 7 ; 3 0 0 ; 4 0 8	symmetry reduction has significantly contributed to the success of <task_8> as <method_4> . however , it is an open question if <method_3> can be lifted to fully observable <task_0> . we generalize the concepts of <task_5> and <task_7> to <task_6> and specifically to the <method_2> . our base implementation of <method_2> in the <method_1> is competitive with the <method_2> - based fond planner mynd . our experiments further show that <task_7> can yield strong performance gains compared to our base implementation of <method_2> .	8 4 12 16 9 -1 3 0 15 9 -1 5 7 6 2 11 14 9 -1 1 10 13 9 -1 9 -1
Low bitrate audio coding using generalized adaptive gain shape vector quantization across channels .	severe truncation of the side channel ; audio codecs code multi-channel sources ; low bitrate audio coding scheme ; low bitrate coding method ; loss of higher frequencies ; loss of spatial image ; low bitrate coding methods ; low decoder complexity ; audio codec ; muffled sound ; spectrum truncation ; stereo content ; audio coding ; coded channels ; side channel ; low frequencies ; low bitrates ; redundancy	<otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 4 ; 6 0 8 ; 7 2 11 ; 2 0 5	audio coding at <otherscientificterm_16> suffers from artifacts due to <otherscientificterm_10> . typical <material_1> using transforms across the channels to remove <otherscientificterm_17> such as middle -lrb- mid -rrb- - side -lrb- m/s -rrb- coding . at <otherscientificterm_16> , the spectrum of the <otherscientificterm_13> is truncated and the spectrum of the channels with lower energy , such as the <otherscientificterm_14> , is truncated severely , sometimes entirely . this results in a <otherscientificterm_9> due to truncation of all <otherscientificterm_13> beyond a certain frequency . it also results in a <otherscientificterm_5> even at <otherscientificterm_15> due to <otherscientificterm_0> . previously we have developed a <method_3> to combat the <otherscientificterm_4> caused by <otherscientificterm_10> . in this paper , we present a novel <method_2> to mitigate the <otherscientificterm_5> . listening tests show that the combination of the two <method_6> results in a <method_8> that can get good quality even at bitrates as low as 32kbps for <material_11> with <otherscientificterm_7> .	16 10 18 -1 1 17 18 -1 13 14 18 -1 9 18 -1 5 15 0 18 -1 19 18 -1 3 4 22 18 -1 2 20 21 18 -1
On radius control of tree-pruned sphere decoding .	multiple-input and multiple-output channels ; lattice independent radius selection scheme ; dynamic radius update strategy ; sphere radius control strategy ; inter search radius control ; radius control strategy ; candidate lattice point ; negligible performance penalty ; sphere decoding ; computational complexity ; complexity	<material> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <task> <metric> <metric>	0 5 5 ; 5 0 8 ; 10 5 5	in this paper , we propose a novel <method_5> for <task_8> referred to as <method_4> that provides further improvement of the <metric_9> with minimal extra cost and <metric_7> . the proposed <method_5> focuses on the <method_3> when a <otherscientificterm_6> is found . for this purpose , the <method_2> as well as the <method_1> are jointly exploited . from simulations in <material_0> , it is shown that the proposed <method_5> provides a substantial improvement in <metric_10> with near-ml performance .	5 8 4 9 7 13 11 -1 3 6 11 -1 2 1 11 -1 0 10 12 14 11 -1
Speaker verification by integrating dynamic and static features using subspace method .	robust normalization of speech feature variations ; dynamic and static features ; principal component analysis ; robust speaker verification ; speaker verification method ; speaker information ; speaker eigenspace ; subspace method ; time difference ; speech data ; speaker verification ; speech features ; phonetic information ; speech data ; speaker recognition ; gmm	<task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <material> <task> <method>	5 0 3 ; 12 0 5 ; 12 3 13 ; 7 0 4 ; 9 2 5 ; 1 3 6 ; 4 1 15 ; 9 5 12 ; 12 1 5 ; 2 0 7 ; 2 0 4 ; 6 0 10	in <task_14> , it is a problem that variation of <otherscientificterm_11> is caused by sentences and <otherscientificterm_8> . <material_13> includes a <otherscientificterm_12> and a <otherscientificterm_5> . if they are separated each other , <method_3> will be realized by using only the <otherscientificterm_5> . however , it is difficult to separate the <otherscientificterm_5> from the <otherscientificterm_12> included in <material_9> at present . from this viewpoint , we propose a <method_4> using a <method_7> based on <method_2> in order to extract only the <otherscientificterm_5> included in <material_9> . we also propose <otherscientificterm_1> of each speaker presented in the <otherscientificterm_6> as well as their integration for <task_0> . we carried out comparative experiments between the proposed <method_4> and conventional <method_15> to show an effectiveness of our proposed <method_4> . as a result , integrated <otherscientificterm_1> in <otherscientificterm_6> were shown to be effective for <task_10> .	14 11 8 13 16 -1 12 5 19 25 16 -1 3 17 16 -1 9 18 24 16 -1 4 7 2 20 21 26 27 16 -1 1 6 22 16 -1 0 23 16 -1 15 28 16 -1
Theory-Guideed Induction of Logic Programs by Inference of Regular Languages .	theory-guided induction of logic programs ; resolution-based approaches ; recursive clauses ; recursive denition ; base clauses ; resolution steps ; covering technique ; logic program ; nite-state automata ; resolvents ; generalization	<task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task>	4 1 2 ; 1 0 0	previous <method_1> to <task_0> produce hypotheses in the form of a set of re-solvents of a theory , where the <otherscientificterm_9> represent allowed sequences of <otherscientificterm_5> for the initial theory . there are , however , many characterizations of allowed sequences of <otherscientificterm_5> that can not be expressed by a set of <otherscientificterm_9> . one approach to this <task_0> is presented , the system mer-lin , which is based on an earlier technique for learning <method_8> that represent allowed sequences of <otherscientificterm_5> . merlin extends the previous technique in three ways : i -rrb- negative examples are considered in addition to positive examples , ii -rrb- a new strategy for performing <task_10> is used , and iii -rrb- a technique for converting the learned automaton to a <method_7> is included . results from experiments are presented in which merlin outperforms both a system using the old strategy for performing <task_10> , and a traditional <method_6> . the latter result can be explained by the limited expressiveness of hypotheses produced by covering and also by the fact that covering needs to produce the correct <otherscientificterm_4> for a <otherscientificterm_3> before producing the <otherscientificterm_2> . merlin on the other hand does not require that particular examples of the base cases are given , since both <otherscientificterm_4> and <otherscientificterm_2> can be inferred from a single example .	1 0 9 5 13 11 -1 11 -1 8 11 -1 11 -1 10 7 11 -1 6 11 -1 4 3 2 12 11 -1
A Fast Semidefinite Approach to Solving Binary Quadratic Problems .	binary quadratic programs ; semidefinite programming ; computer vision problems ; large scale problems ; dual optimization approach ; spectral methods ; sdp formulations ; image segmen-tation ; relaxation methods ; computational complexity ; sdp formulation ; large-scale bqps ; complexity ; registration ; co-segmentation ; clustering	<method> <method> <task> <task> <method> <method> <method> <task> <method> <metric> <method> <task> <metric> <task> <task> <task>	10 0 0 ; 10 0 11 ; 12 5 5 ; 10 4 6 ; 15 1 7 ; 5 1 1 ; 0 0 2 ; 10 0 4 ; 15 1 14 ; 14 1 13 ; 10 0 6 ; 7 1 14	many <task_2> can be formulated as <method_0> . two classic <method_8> are widely used for solving <method_0> , namely , <method_5> and <method_1> , each with their own advantages and disadvantages . <method_0> is simple and easy to implement , but its bound is loose . <method_0> has a tighter bound , but its <metric_9> is high for <task_3> . we present a new <method_10> for <method_0> , with two desirable properties . first , <method_10> has a similar relaxation bound to conventional <method_6> . second , compared with conventional <method_6> , the new <method_10> leads to a significantly more efficient and scalable <method_4> , which has the same degree of <metric_12> as <method_5> . extensive experiments on various applications including <task_15> , <task_7> , <task_14> and <task_13> demonstrate the usefulness of our <method_10> for solving <task_11> .	2 0 23 16 -1 8 5 1 22 16 -1 16 -1 9 3 16 -1 10 17 16 -1 6 27 16 -1 19 20 24 16 -1 4 12 18 21 25 26 28 16 -1
Learning to classify complex patterns using a VLSI network of spiking neurons .	complex patterns of mean firing rates ; network of integrate-and-fire neurons ; perceptron learning rule ; bistable synapses ; local spike ; vlsi network ; plastic synapses ; synaptic weights ; learning	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	4 0 3 ; 3 0 1	we propose a compact , low power <method_5> of spiking neurons which can learn to classify <otherscientificterm_0> on -- line and in real -- time . the <method_1> is connected by <otherscientificterm_3> that can change their weight using a <otherscientificterm_4> -- based plasticity mechanism . <task_8> is supervised by a teacher which provides an extra input to the output neurons during training . the <otherscientificterm_7> are updated only if the current generated by the <otherscientificterm_6> does not match the output desired by the teacher -lrb- as in the <otherscientificterm_2> -rrb- . we present experimental results that demonstrate how this <method_5> is able to robustly classify uncorrelated linearly separable spatial patterns of mean firing rates .	5 0 9 -1 1 3 4 8 10 11 9 -1 9 -1 7 6 2 9 -1 9 -1
Surface Geometry from Cusps of Apparent Contours .	geometry of the surface ; nonsingular apparent contours ; epipolar parametrization ; viewer motion ; surface geometry ; spatio-temporal derivatives ; perspective projection ; apparent contours ; gauss curvature ; for-mulae ; ego-motion	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	8 6 4	it is known that the deformations of the <otherscientificterm_7> of a surface under <otherscientificterm_6> and <otherscientificterm_3> enable the recovery of the <otherscientificterm_0> , for example by utilising the <method_2> . these methods break down with <otherscientificterm_7> that are singular i.e. with cusps . in this paper we study this situation in detail and show how , nevertheless , the <otherscientificterm_4> -lrb- including the <otherscientificterm_8> and mean curvature of the surface -rrb- can be recovered by following the cusps . indeed the <method_9> are much simpler in this case and require lower <otherscientificterm_5> than in the general case of <otherscientificterm_1> . we give a simulated example , and also show that following cusps does not by itself provide us with information on <otherscientificterm_10> .	7 6 3 0 2 11 -1 11 -1 4 8 12 11 -1 9 5 1 11 -1 11 -1
Variational Bayesian image modelling .	hidden markov random fields ; hmrf-based segmentation methods ; real world images ; model selection problems ; variational bayesian framework ; image segmentation ; inference problems ; image models ; model selection ; graphical models ; variational approach ; density estimation ; image modelling ; inference	<method> <method> <material> <task> <method> <task> <task> <method> <task> <method> <method> <task> <task> <task>	2 5 4 ; 10 0 0 ; 2 5 1 ; 13 1 11 ; 4 4 1 ; 11 1 8 ; 0 6 9 ; 10 0 5 ; 0 0 12 ; 4 0 13 ; 10 0 4 ; 4 0 11 ; 0 0 5 ; 4 0 8	we present a <method_4> for performing <task_13> , <task_11> and <task_8> in a special class of <method_9> -- <method_0> . <method_0> are particularly well suited to <task_12> and in this paper , we apply <method_0> to the problem of <task_5> . unfortunately , <method_0> are notoriously hard to train and use because the exact <task_6> they create are intractable . our main contribution is to introduce an efficient <method_10> for performing approximate <task_13> of the <method_4> of <method_0> , which we can then apply to the <task_11> and <task_3> that arise when learning <method_7> from data . with this <method_10> , we can conveniently tackle the problem of <task_5> . we present experimental results which show that our <method_4> outperforms recent <method_1> on <material_2> .	4 13 11 8 9 0 18 20 21 24 26 28 14 -1 12 5 23 27 14 -1 6 14 -1 10 3 7 16 25 14 -1 22 14 -1 15 17 19 14 -1
Fast Automatic Single-View 3-d Reconstruction of Urban Scenes .	stepwise search of 3-d model parameters ; conditional random field models ; model fitting problem ; 3-d model structure ; estimating 3-d structure ; vertical walls ; ground plane ; computational efficiency ; chain graphs ; 3-d reconstruction ; ground-vertical boundary ; continuous polyline	<otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	5 1 6 ; 2 0 9 ; 6 0 3	we consider the problem of <task_4> from a single still image of an outdoor urban scene . our goal is to efficiently create <method_3> which are visually pleasant . we chose an appropriate <method_3> and formulate the task of <task_9> as <task_2> . our <method_3> are composed of a number of <otherscientificterm_5> and a <otherscientificterm_6> , where <otherscientificterm_10> is a <otherscientificterm_11> . we achieve <metric_7> by special preprocessing together with <otherscientificterm_0> dividing the problem into two smaller sub-problems on <otherscientificterm_8> . the use of <method_1> for both problems allows to various cues . we infer orientation of <otherscientificterm_5> of 3-d model vanishing points .	4 12 -1 3 12 -1 9 2 14 12 -1 5 6 10 11 13 15 12 -1 7 0 8 12 -1 1 12 -1 12 -1
A multi-view approach to consensus clustering in multi-modal MRI .	unified segmentation of tumoral lesions ; multi-view consensus clustering methodology ; classification and seg-mentation purposes ; high dimensional diffusion information ; discrimination of diseased tissue ; multi-modal mri images ; un-supervised base segmentations ; manifold learning step ; dissimilar imaging data ; information domains ; cluster ensembles ; mri modality ; voxel-based data ; geometric constrains ; vectorial dissimilarity-spaces ; heterogeneity assessment ; dti-mr ; dimension-ality ; dce-mri	<task> <method> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method>	9 1 17 ; 1 0 14 ; 1 0 5 ; 18 4 16 ; 5 0 4 ; 0 0 15 ; 1 0 11 ; 5 0 0 ; 6 1 10 ; 1 0 16	it has been shown that the combination of <material_5> can improve the <task_4> . the fusion of <material_8> for <task_2> however , is not a trivial task , as there is an inherent difference in <otherscientificterm_9> , <otherscientificterm_17> and scales . this work proposes a <method_1> for the integration of <material_5> into a <task_0> for <task_15> . using a variety of metrics and distance functions this <method_1> calculates multiple <otherscientificterm_14> for each <otherscientificterm_11> and makes use of <method_10> to combine a set of <otherscientificterm_6> into an unified partition of the <material_12> . the <method_1> is demonstrated in application to <method_18> and <method_16> , for which a <otherscientificterm_7> is implemented in order to account for the <otherscientificterm_13> of the <otherscientificterm_3> .	5 4 24 19 -1 8 2 9 17 20 19 -1 1 0 15 22 25 27 19 -1 14 11 10 6 12 21 26 28 19 -1 18 23 29 19 -1
PARMA : A Predicate Argument Aligner .	cross-document , semantic predicate ; linguistic resources ; discrimina-tive model ; translation data ; textual entailment ; question answering ; f1 ; parma	<task> <material> <method> <material> <task> <task> <metric> <method>	1 3 7 ; 1 3 2	we introduce <method_7> , a <method_7> for <task_0> and argument alignment . our <method_7> combines a number of <material_1> familiar to researchers in areas such as recognizing <task_4> and <task_5> , integrating <material_1> into a simple <method_2> . <method_7> achieves state of the art results on an existing and a new dataset . we suggest that previous efforts have focussed on data that is biased and too easy , and we provide a more difficult dataset based on <material_3> with a low base-line which we beat by 17 % <metric_6> .	7 0 8 -1 1 4 5 2 9 10 8 -1 8 -1 3 6 8 -1
A Transition-based Model for Joint Segmentation , POS-tagging and Normalization .	joint word segmentation ; annotated microblog corpora ; annotated corpus ; text normalization ; text corpora ; pos tagging ; error reduction ; word segmentation ; segmentation accuracy ; transition-based model ; microblogs	<task> <material> <material> <task> <material> <task> <metric> <task> <metric> <method> <material>	5 1 3 ; 9 0 7 ; 8 5 9 ; 0 1 5 ; 4 5 9 ; 10 0 2 ; 9 0 5 ; 9 0 0 ; 0 1 3 ; 9 0 3	we propose a <method_9> for <task_0> , <task_5> and <task_3> . different from previous methods , the <method_9> can be trained on standard <material_4> , overcoming the lack of <material_1> . to evaluate our <method_9> , we develop an <material_2> based on <material_10> . experimental results show that our <method_9> can help improve the performance of <task_7> on <material_10> , giving an <metric_6> in <metric_8> of 12.02 % , compared to the traditional approach .	9 0 5 3 12 15 18 19 20 21 11 -1 4 1 16 11 -1 2 10 17 11 -1 7 6 8 13 14 11 -1
Beam-Width Prediction for Efficient Context-Free Parsing .	charniak and berkeley parsers ; cyk chart cell ; beam-search pruning parameters ; log linear model ; statistical grammars ; nlp applications ; syntactic parsing ; model space ; syntactic analyses ; coarse-to-fine pruning ; berkeley parser ; grammar ; pruning ; accuracy ; parser	<method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <method> <method> <method> <method> <task> <metric> <method>	11 0 10 ; 14 4 10 ; 8 0 5	efficient decoding for <task_6> has become a necessary research area as <method_4> grow in <metric_13> and size and as more <task_5> leverage <method_8> . we review prior methods for <task_12> and then present a new framework that unifies their strengths into a single approach . using a <method_3> , we learn the optimal <otherscientificterm_2> for each <otherscientificterm_1> , effectively predicting the most promising areas of the <otherscientificterm_7> to explore . we demonstrate that our method is faster than <method_9> , exemplified in both the <method_0> , by empirically comparing our <method_14> to the <method_10> using the same <method_11> and under identical operating conditions .	6 4 13 5 8 18 15 -1 12 15 -1 3 2 1 7 15 -1 9 0 14 10 11 16 17 15 -1
Pitch-synchronous time-scaling for high-frequency excitation regeneration .	bandwidth extension of speech ; pitch-synchronous timescale transformation ; low bit coding of wide-band speech ; high-frequency regeneration of the excitation signal ; missing low or high frequency components ; linear prediction narrow-band residual ; glottal flow waveform ; narrow-band signal ; periodic characteristics ; high-band excitation ; regenerated excitation ; high-pass signal ; side information ; shape	<task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 1 ; 1 0 9 ; 1 0 11	the goal of <task_0> is to extrapolate the <method_4> of the wide-band speech -lrb- 50-8000 hz -rrb- based entirely on information contained in a <otherscientificterm_7> -lrb- 300-3400 hz -rrb- . in this paper we propose a new method for <task_3> , using the correlation between the <otherscientificterm_13> of the <otherscientificterm_6> and the spectrum of the voice source . the <otherscientificterm_9> is generated by performing a <method_1> on the <otherscientificterm_5> to generate an <otherscientificterm_11> that retains the <otherscientificterm_8> of the original signal but with a larger open quotient . this method is easy to implement and does not introduce discontinuities in the spectrum of the <otherscientificterm_10> . it can be used in applications for <task_0> where no <otherscientificterm_12> is transmitted or for <otherscientificterm_2> .	0 4 7 14 -1 3 13 6 14 -1 9 1 5 11 8 15 16 17 14 -1 14 -1 10 14 -1
Learning to Schedule Straight-Line Code .	scheduling straight-line code ; instruction scheduling problem ; heuristic scheduling algorithm ; supervised learning methods ; learning task ; instruction scheduling ; computer architectures ; heuristic algorithm ; execution efficiency ; execution speed ; features ; compiler	<otherscientificterm> <task> <method> <method> <task> <task> <method> <method> <metric> <metric> <otherscientificterm> <method>	4 0 1 ; 7 0 5	execution speed of programs on modern <method_6> is sensitive , by a factor of two or more , to the order in which instructions are presented to the processor . to realize potential <metric_8> , it is now customary for an optimizing <method_11> to employ a <method_7> for <task_5> . these <method_7> are painstakingly hand-crafted , which is expenseive and time-consuming . we show how to cast the <task_1> as a <task_4> , so that one obtains the <method_2> automatically . our focus is the narrower problem of <otherscientificterm_0> , also known as a basic block of instructions . our empirical results show that just a few <otherscientificterm_10> are adequate for quite good performance at this task for a real modern processor , and that any of several <method_3> perform nearly optimally with respect to the <otherscientificterm_10> used .	6 12 -1 8 11 7 5 14 12 -1 12 -1 1 4 2 13 12 -1 0 12 -1 12 -1
Reconstructing the world * in six days .	adaptive , online , iconic image clustering approach ; large-scale , structure-from-motion framework ; image crowd-sourced photo collection ; connected component discovery ; augmented bag-of-words representation ; data scal-ability ; streaming-based framework ; data compactness ; model completeness ; city-scale modeling ; world-scale modeling ; images ; registration ; scalability	<method> <method> <material> <task> <method> <task> <method> <task> <metric> <method> <task> <material> <task> <metric>	6 0 3 ; 9 0 1	we propose a novel , <method_1> that advances the state of the art in <task_5> from <method_9> -lrb- millions of <material_11> -rrb- to <task_10> -lrb- several tens of millions of <material_11> -rrb- using just a single computer . the main enabling technology is the use of a <method_6> for <task_3> . moreover , our <method_1> employs an <method_0> based on an <method_4> , in order to balance the goals of <task_12> , comprehensiveness , and <task_7> . we demonstrate our proposal by operating on a recent publicly available 100 million <material_2> containing <material_11> geographically distributed throughout the entire world . results illustrate that our <method_1> does not compromise <metric_8> , but achieves unprecedented levels of efficiency and <metric_13> .	1 5 9 11 10 16 14 -1 6 3 15 14 -1 0 4 12 7 14 -1 2 14 -1 14 -1
Neural Computation with Winner-Take-All as the Only Nonlinear Operation .	weighted sums of the input variables ; -lrb- linear -rrb- weighted sums ; universal computational power cents ; soft winner-take-all unit ; multi-layer perceptron ; nonlinear units ; boolean function ; nonlinear unit ; computational unit ; neural circuits ; neural networks ; neural vlsi ; positive weights ; continuous function ; synapses ; winner-take-all ; neurophysiology ; inhibitory ; microcircuits ; perceptron	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	8 4 19 ; 7 0 9 ; 18 0 15 ; 4 0 9	everybody '' knows '' that <method_10> need more than a single layer of <otherscientificterm_5> to compute interesting functions . we show that this is false if one employs <method_15> as <otherscientificterm_7> : any <otherscientificterm_6> can be computed by a single ¡ - <method_15> unit applied to <otherscientificterm_0> . any <otherscientificterm_13> can be approximated arbitrarily well by a single <otherscientificterm_3> applied to <otherscientificterm_0> . only <otherscientificterm_12> are needed in these <otherscientificterm_1> . this may be of interest from the point of view of <otherscientificterm_16> , since only 15 % of the <otherscientificterm_14> in the cortex are <otherscientificterm_17> . in addition it is widely believed that there are special <otherscientificterm_18> in the cortex that compute <method_15> . our results support the view that <method_15> is a very useful basic <method_8> in <material_11> : cents it is wellknown that <method_15> of # input variables can be computed very efficiently with $ ¥ # transistors -lrb- and a total wire length and area that is linear in # -rrb- in analog vlsi -lsb- lazzaro et al. , 1989 -rsb- cents we show that <method_15> is not just useful for special purpose computations , but may serve as the only <otherscientificterm_7> for <method_9> with <otherscientificterm_2> we show that any <otherscientificterm_4> needs quadratically in # many gates to compute <method_15> for # input variables , hence <method_15> provides a substantially more powerful <method_8> than a <method_19> -lrb- at about the same cost of implementation in analog vlsi -rrb- . complete proofs and further details to these results can be found in -lsb- maass , 2000 -rsb- .	10 5 20 -1 15 7 6 0 20 -1 13 3 20 -1 12 1 20 -1 16 14 17 20 -1 23 20 -1 18 21 22 24 20 -1 8 11 9 2 20 -1
A Description Classifier for the Predicate Calculus .	full first order predicate calculus ; description classifier ; scalar inequalities ; dual representations ; subsumption computations ; predicate calculus ; predicate variables ; auto-socratic elaboration ; equality ; classifier ; cardinality	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	9 4 1 ; 10 1 2 ; 2 1 6 ; 3 3 9 ; 3 1 7 ; 10 1 8 ; 8 1 6 ; 8 1 2	a <method_1> organizes concepts and relations into a taxonomy based on the results of <otherscientificterm_4> applied to pairs of relation definitions . until now , <method_1> have only been designed to operate over definitions phrased in highly restricted subsets of the <otherscientificterm_5> . this paper describes a <method_9> able to reason with definitions phrased in the <otherscientificterm_0> , extended with sets , <otherscientificterm_10> , <otherscientificterm_8> , <otherscientificterm_2> , and <otherscientificterm_6> . the performance of the new <method_9> is comparable to that of existing <method_1> . our <method_9> introduces two new techniques , <method_3> and <otherscientificterm_7> , that may be expected to improve the performance of existing <method_1> .	1 4 11 -1 5 11 -1 9 0 10 8 2 6 13 14 17 18 19 11 -1 12 11 -1 3 7 15 16 11 -1
Multistrategy Learning for Information Extraction .	information extraction ; electronic bulletin board posts ; pre-deened structured summaries ; term-space text classiication ; electronic seminar announcements ; machine learning paradigms ; relational rule induction ; probability of cor-rectness ; reuters collection ; multistrat-egy approach ; regression models ; extraction accuracy ; rote memorization ; text documents ; ie domains ; non-traditional domains ; newswire articles ; mul-tistrategy approaches ; web pages ; learner conndence ; learners	<task> <material> <material> <task> <material> <method> <task> <otherscientificterm> <material> <method> <method> <metric> <method> <material> <material> <otherscientificterm> <material> <method> <material> <otherscientificterm> <method>	6 6 5 ; 12 6 5 ; 20 0 0 ; 16 0 14 ; 12 1 3 ; 3 6 5 ; 1 1 18 ; 3 1 6	information extraction -lrb- <task_0> -rrb- is the problem of lling out <material_2> from <material_13> . we are interested in performing <task_0> in <otherscientificterm_15> , where much of the text is often ungrammatical , such as <material_1> and <material_18> . we suggest that the best approach is one that takes into account many diierent kinds of information , and argue for the suitability of a <method_9> . we describe <method_20> for <task_0> drawn from three separate <method_5> : <method_12> , <task_3> , and <task_6> . by building <method_10> mapping from <otherscientificterm_19> to <otherscientificterm_7> and combining probabilities appropriately , it is possible to improve <metric_11> over that achieved by any individual learner . we describe three diierent <method_17> . experiments on two <material_14> , a collection of <material_4> from a university computer science department and a set of <material_16> describing corporate acquisitions from the <material_8> , demonstrate the eeec-tiveness of all three <method_17> .	0 2 13 21 -1 15 1 18 28 21 -1 9 21 -1 20 5 12 3 6 22 23 24 26 27 29 21 -1 10 19 7 21 -1 11 21 -1 17 25 21 -1
Interactive tone mapping for High Dynamic Range video .	gaussian mixture model ; hdr image tone mapping ; interactive tone mapping scheme ; hdr video sequences ; scrib-ble/stroke based interface ; edge preserving filtering ; user input information ; local tone manipulation ; hdr video ; film post-production ; temporal consistency ; video sequence	<method> <task> <method> <material> <method> <method> <otherscientificterm> <method> <material> <task> <metric> <material>	2 0 6 ; 4 0 7 ; 2 0 7 ; 4 0 6 ; 2 0 3	despite considerable progress in <task_1> for the past decade , little work has been done for <material_8> . for applications such as <task_9> , the capability of <method_7> is highly regarded by the content creators . this paper presents an <method_2> for <material_3> . <method_2> provides a simple <method_4> for <method_7> and is capable of propagating <otherscientificterm_6> throughout a <material_11> by using <method_0> and <method_5> . the experimental results demonstrated its effectiveness for <task_1> as well as its flexibility for users to easily and intuitively manipulate the appearance of the video while maintaining <metric_10> .	1 8 12 -1 9 7 12 -1 2 3 17 12 -1 4 6 11 0 5 13 14 15 16 12 -1 10 12 -1
Implementation of cooperative communications using software defined radios .	measured bit error rate ; software defined radio testbed ; maximum ratio combining technique ; cooperative physical layer protocols ; three-node cooperative communication system ; cooperative coded systems ; hard decision decoding ; bit error rate ; spatial diversity ; destination receiver ; radio nodes ; relay nodes ; wireless link ; cooperative communications ; wireless network ; cooperative systems	<metric> <method> <method> <method> <method> <method> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <method> <method>	0 5 4 ; 2 1 5 ; 2 1 15 ; 6 0 5 ; 15 1 5 ; 8 0 13 ; 8 2 14 ; 6 0 15	-- <method_13> leverages the <otherscientificterm_8> available in a <method_14> enabling multiple <otherscientificterm_10> work together to improve the overall system performance . when a <method_9> combines the signal from an originating source with the associated signals from <otherscientificterm_11> , significant improvements in the <metric_7> performance can be achieved . this paper details the <metric_0> performance of a <method_4> operating in a <method_1> . the measured performances of several types of <method_3> are compared to similar systems operating over a single <material_12> . the measured results include <method_15> operating with a <method_2> and two <method_5> using <method_6> .	13 8 14 10 22 23 16 -1 9 11 7 16 -1 0 4 1 17 16 -1 3 12 16 -1 15 2 5 6 18 19 20 21 24 16 -1
Formalising Multi-layer Corpora in OWL DL - Lexicon Modelling , Querying and Consistency Control .	syntactically and semantically annotated salsa/tiger corpus ; typed logical representation language ; xml-based query languages ; lexicon model ; graph structure ; consistency control ; multi-layered annotation ; owl dl	<material> <material> <material> <method> <otherscientificterm> <task> <task> <material>	7 6 1	we present a general approach to formally modelling corpora with <task_6> , thereby inducing a <method_3> in a <material_1> , <material_7> . this model can be interpreted as a <otherscientificterm_4> that offers flexible querying func-tionality beyond current <material_2> and powerful methods for <task_5> . we illustrate our approach by applying it to the <material_0> .	6 3 1 7 9 8 -1 4 2 5 8 -1 0 8 -1
Locally-Constrained Region-Based Methods for DW-MRI Segmentation .	locally-constrained region based approach ; diffusion-weighted magnetic resonance images ; full fiber bundle region ; segmenting fiber bundles ; region-based flows ; computational speed ; fiber bundle ; cingulum bundle ; open curves ; fiber bundles ; ease-of-use ; voxels	<method> <material> <otherscientificterm> <task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	10 1 5	in this paper , we describe a method for <task_3> from <material_1> using a <method_0> . from a pre-computed optimal path , the algorithm propagates outward capturing only those <otherscientificterm_11> which are locally connected to the <otherscientificterm_6> . rather than attempting to find large numbers of <otherscientificterm_8> or single fibers , which individually have questionable meaning , this method segments the <otherscientificterm_2> . the strengths of this approach include its <metric_10> , <metric_5> , and applicability to a wide range of <otherscientificterm_9> . in this work , we show results for segmenting the <otherscientificterm_7> . finally , we explain how this approach and extensions thereto overcome a major problem that typical <otherscientificterm_4> experience when attempting to segment neural <otherscientificterm_9> .	3 1 0 12 -1 11 6 12 -1 8 2 12 -1 10 5 9 13 12 -1 7 12 -1 12 -1
Decoding Cursive Scripts .	adaptive probabilistic acyclic automata ; spotting and segmentation of cursive scripts ; discrete motor control symbols ; online cursive handwriting recognition ; training and recognition algorithms ; level language model ; modeling methods ; stochastic automata ; pattern recognition ; intelligible components ; writing trajectories ; dynamic encoding ; compact representation ; learning algorithm ; control sequences ; writing tra-jectory	<method> <task> <otherscientificterm> <task> <method> <method> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	4 4 6 ; 3 6 8 ; 13 0 7 ; 14 0 0	online cursive handwriting recognition is currently one of the most intriguing challenges in <task_8> . this study presents a novel approach to this <task_3> which is composed of two complementary phases . the first is <otherscientificterm_11> of the <otherscientificterm_15> into a compact sequence of <otherscientificterm_2> . in this <method_12> we largely remove the redundancy of the script , while preserving most of its <method_9> . in the second phase these <otherscientificterm_14> are used to train <method_0> for the important ingredients of the <otherscientificterm_10> , e.g. letters . we present a new and efficient <method_13> for such <method_7> , and demonstrate its utility for <task_1> . our experiments show that over 90 % of the letters are correctly spotted and identified , prior to any higher <method_5> . moreover , both the <method_4> are very efficient compared to other <method_6> , and the <method_4> are ` on-line ' adaptable to other writers and styles .	8 18 16 -1 3 16 -1 11 15 2 16 -1 12 9 16 -1 14 0 10 20 16 -1 13 7 19 16 -1 1 16 -1 5 17 16 -1
Buffer-constrained R-D optimized rate control for video coding .	r-d optimized macroblock level rate control ; buffer-constrained r-d optimized rate control ; viterbi algorithm ; nonzero coefficients ; frame level bit allocation ; progressive and interlaced video ; coding mode of macroblocks ; r-d data generation ; quality feedback scheme ; assured video quality ; r-d optimization ; isolated coefficient ; video coding ; quantization parameter ; fast heuristics ; computational cost ; computational complexity ; coding	<method> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <task> <method> <metric> <task> <otherscientificterm> <task> <otherscientificterm> <method> <metric> <metric> <task>	1 0 12 ; 13 0 0 ; 14 0 10 ; 9 5 8 ; 7 1 2 ; 16 5 14 ; 2 0 10 ; 14 0 7	buffer-constrained r-d optimized rate control for <task_12> is investigated in this work . a <method_4> is first presented based on a model of the relationship between the rate -lrb- r -rrb- and <otherscientificterm_3> . with the modelled r-nz relationship , a <method_8> is proposed to generate vbv -lrb- video buffer verifier -rrb- compliant bitstream with <metric_9> . then , a <method_0> is described by jointly selecting the <otherscientificterm_13> and the <otherscientificterm_6> in i , b and p pictures for both <material_5> . to avoid the irregularly large mv or one single <otherscientificterm_11> , we extend the set of <task_17> modes of mb by including zero mv and zero texture bits as two more candidates . finally , <method_14> are developed to reduce the <metric_16> of <task_7> and the <method_2> in <task_10> , which achieves <task_17> results close to the optimal one at a much lower <metric_15> .	12 19 18 -1 4 3 18 -1 8 9 22 18 -1 0 13 6 5 20 18 -1 11 17 18 -1 21 23 24 25 26 18 -1
On data-derived temporal processing in speech feature extraction .	automatic speech recognition ; cepstral mean subtraction ; speech feature extraction ; trained probability estimator ; word recognition tests ; temporal filter design ; contextual frames ; delta calculation ; preprocessing configurations ; temporal processing ; modulation-spectral features ; lda filters ; rasta filtering ; phone classification ; reverberation conditions ; robustness ; reverberation ; filtering	<task> <otherscientificterm> <task> <method> <task> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <task>	9 1 17 ; 7 1 1 ; 9 3 2 ; 11 0 5 ; 2 0 0 ; 5 0 10 ; 12 1 7 ; 8 0 5	temporal processing and <task_17> in <task_2> are commonly used to aid in performance and <metric_15> in <task_0> . among the techniques successfully employed are <method_12> , <method_7> , and <otherscientificterm_1> . the work here explores the use of <method_5> using <method_11> to further enhance performance using a few <method_8> . in addition to <method_12> , we apply the <method_5> to <otherscientificterm_10> and cepstra while making sure that the assumptions of <method_11> are observed . we additionally test the use of <method_5> that have been trained in different <otherscientificterm_14> , noting from previous work that the presence of <otherscientificterm_16> alters the preferred frequency range of the derived <method_5> . our tests indicate a consistent advantage in <task_13> . <task_4> , in contrast , reveal that the <method_11> often do not improve upon the existing <method_5> previously used . they can also be made less effectual by allowing <otherscientificterm_6> to a <method_3> .	17 2 15 0 19 21 23 18 -1 12 7 1 20 25 18 -1 5 11 8 22 26 18 -1 10 24 18 -1 14 16 18 -1 18 -1 13 4 18 -1 18 -1
Applying Co-Training to Reference Resolution .	manual labeling ; reference resolution ; co-training ; classifier	<task> <task> <method> <method>	2 0 1 ; 3 0 1 ; 2 0 3	in this paper , we investigate the practical applicability of <method_2> for the task of building a <method_3> for <task_1> . we are concerned with the question if <method_2> can significantly reduce the amount of <task_0> work and still produce a <method_3> with an acceptable performance .	2 3 1 5 6 4 -1 0 7 4 -1
Recurrent neural network predictors for EEG signal compression .	recurrent neural networks ; eeg data recording ; recurrent neural predictor ; dpcm scheme ; computational cost ; digital electroencephalography ; training strategy ; pre-dictors	<method> <task> <method> <method> <metric> <method> <method> <method>	5 0 1 ; 0 0 7 ; 3 0 1	the progress of <method_5> gave rise to the problem of <task_1> . in this paper a <method_3> for <task_1> is discussed . in particular the performance of a class of <method_7> based on <method_0> is presented . the <method_6> is accurately described and the results of a comparison with some other classical linear and static neural predictors are given . the proposed <method_2> demonstrates to be competitive with the others in ooering good performance at a very low <metric_4> .	5 1 9 8 -1 3 11 8 -1 7 0 10 8 -1 6 8 -1 2 4 8 -1
Improved Spoken Query Transcription Using Co-Occurrence Information .	syntactic and grammatical structure ; voice queries automatic transcription ; voice search recognition ; co-occurrence based approach ; mobile web ; scoring function ; co-occurrence level ; relative accuracy ; speech applications ; spoken queries ; co-occurrence information ; spoken queries ; language modeling ; keywords ; accuracy	<otherscientificterm> <material> <task> <method> <material> <otherscientificterm> <otherscientificterm> <metric> <task> <material> <otherscientificterm> <material> <task> <otherscientificterm> <metric>	5 1 6 ; 12 0 8 ; 3 0 1 ; 14 5 1 ; 2 4 8 ; 12 0 2	spoken queries are a natural medium for searching the <material_4> . <task_12> for <task_2> offers different challenges compared to more conventional <task_8> . the challenges arise from the fact that <material_11> are usually a set of <otherscientificterm_13> and do not have a <otherscientificterm_0> . this paper describes a <method_3> to improve the <metric_14> of <material_1> . with the right choice of <otherscientificterm_5> and <otherscientificterm_6> , we show that <otherscientificterm_10> gives a 2 % <metric_7> improvement over a state of the art system .	4 12 15 -1 2 8 17 20 21 15 -1 11 13 0 15 -1 3 14 1 18 19 15 -1 5 6 10 7 9 16 15 -1
Sample Complexity and Performance Bounds for Non-Parametric Approximate Linear Programming .	non-parametric approximate linear programming ; infinite action spaces ; markov decision processes ; value function approximation ; real world transitions ; approximation architecture ; smoothness assumption ; value function ; bellman equation ; approximate solution ; noise ; alp ; robustness	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric>	3 0 2 ; 12 2 10	one of the most difficult tasks in <method_3> for <method_2> is finding an <method_5> that is expressive enough to capture the important structure in the <otherscientificterm_7> , while at the same time not overfitting the training samples . recent results in <method_0> , have demonstrated that this can be done effectively using nothing more than a <otherscientificterm_6> on the <otherscientificterm_7> . in this paper we extend these results to the case where samples come from <otherscientificterm_4> instead of the full <otherscientificterm_8> , adding <metric_12> to <otherscientificterm_10> . in addition , we provide the first max-norm , finite sample performance guarantees for any form of <otherscientificterm_11> . <method_0> is amenable to problems with large -lrb- multidimensional -rrb- or even <otherscientificterm_1> , and does not require a model to select actions using the resulting <method_9> .	3 2 5 7 14 13 -1 0 6 13 -1 4 8 12 10 15 13 -1 13 -1 11 13 -1
Using computer simulation to compare two models of mixed-initiative .	restricted initiative model ; computer simulation ; human-human dialogues ; mixed-initiative dialogues ; solution quality ; unrestricted initiative ; mixed-initiative	<method> <method> <material> <otherscientificterm> <metric> <method> <otherscientificterm>	1 0 3	in this paper , we use <method_1> to better understand <otherscientificterm_3> . we compare two models of <otherscientificterm_6> : <method_5> , where either participant can take over control at any point ; and <method_0> where one participant keeps control and the other plays a secondary role , but greater than what single-initiative allows . we find that <method_0> results in similar <metric_4> as unrestricted , less communication effort , and similar or less reasoning effort . these results agree with our empirical studies on <material_2> , in which we find that participants seem to follow the <method_0> .	1 3 8 7 -1 6 5 0 7 -1 4 7 -1 2 7 -1
Matrix filters for passive sonar .	localiza-tion and detection problems ; linear filtering operation ; convex optimization problem ; measured sensor data ; matrix filters ; unwanted components ; passive sonar ; matrix filters ; minimal distortion ; sensor outputs ; matrix	<task> <method> <task> <material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm>	7 0 0 ; 7 0 5 ; 5 3 3 ; 7 0 6	this paper introduces <method_7> as a tool for <task_0> in <otherscientificterm_6> . the outputs of an array of sensors , at some given frequency , can be represented by a vector of complex numbers . a <method_1> on the <material_9> can be expressed as the multiplication of a <otherscientificterm_10> -lrb- called a <method_7> -rrb- times this vector . the purpose of a <method_7> is to attenuate <otherscientificterm_5> in the <material_3> while passing desired components with <otherscientificterm_8> . <method_4> are designed by defining an appropriate pass band and stop band and solving a <task_2> . this paper formulates the design of <method_7> for <otherscientificterm_6> and gives two examples .	7 0 6 12 11 -1 11 -1 1 9 10 11 -1 5 3 8 4 13 14 11 -1 2 11 -1 15 11 -1
An adaptive monopulse processor for angle estimation in a mainbeam jamming and coherent interference scenario .	terrain scattered interference ; monopulse and spatially adaptive monopulse ; dis-tortionless spatial array patterns ; spatially adaptive processing ; mainbeam jamming cancelation ; target angle estimation ; space-time monopulse processor ; monopulse radars ; mountaintop data ; interference suppression ; mainbeam jamming ; mainbeam jamming ; space-time processing ; array pattern ; coherent multi-path ; monopulse processing ; jammer	<method> <metric> <otherscientificterm> <method> <task> <task> <method> <method> <material> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method>	13 0 15 ; 12 3 15 ; 14 0 0 ; 4 1 5 ; 16 1 0	mainbeam jamming poses a particularly diicult challenge for conventional <method_7> . in such cases <method_3> provides some <task_9> when the target and <method_16> are not exactly co-aligned , but the resulting <otherscientificterm_13> is too distorted to be suitable for <task_15> . the presence of <otherscientificterm_14> in the form of <method_0> is normally considered a nuisance source of interference . however , it can also be exploited to suppress <method_11> with <method_12> . here we present a method for incorporating <method_12> into <task_15> to yield a <method_6> with <otherscientificterm_2> that can achieve far better <task_4> and <task_5> than has been previously possible . performance results for the <method_6> are obtained for <material_8> containing a <method_16> and <method_0> , that demonstrate a dramatic improvement in performance over conventional <metric_1> .	7 17 -1 3 9 16 13 15 18 17 -1 14 0 20 17 -1 11 12 17 -1 6 2 4 5 19 21 17 -1 22 17 -1
Fusion of Summation Invariants in 3D Human Face Recognition .	recognition of the 3d surface of human faces ; face recognition grand challenge v1 .0 dataset ; semi-local sum-mation invariant features ; 3d facial depth map ; 3d facial depth maps ; 3d facial data ; copyrighted component ; summation invariants ; rectangular region ; features ; ieee ; nose	<task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	8 0 3	however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any <method_6> of this work in other works must be obtained from the <material_10> . abstract a novel family of 2d and 3d geometrically invariant <otherscientificterm_9> , called <method_7> is proposed for the <task_0> . focusing on a <otherscientificterm_8> surrounding the <otherscientificterm_11> of a <otherscientificterm_3> , a subset of the so called <otherscientificterm_2> is extracted . then the similarity between a pair of <otherscientificterm_4> is computed to determine whether <otherscientificterm_2> belong to the same person . out of many possible combinations of these set of <otherscientificterm_9> , we select , through careful experimentation , a subset of <otherscientificterm_9> that yields best combined performance . tested with the <material_5> from the ongoing <material_1> , the proposed new <otherscientificterm_9> exhibit significant performance improvement over the baseline algorithm distributed with the dataset .	6 10 12 -1 9 7 0 12 -1 8 11 3 2 13 12 -1 4 12 -1 12 -1 12 -1
An Improved Spectral and Prosodic Transformation Method in STRAIGHT-based Voice Conversion .	former voice conversion system ; discrimination and speech quality ; excitation-dependent and excitation-independent components ; spectral conversion method ; straight spectrum ; prosodic characteristics ; prosodic conversion ; codebook mapping ; spectral representation ; mog model ; converted speech	<method> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <material>	9 0 8 ; 9 0 6 ; 9 0 5 ; 3 0 10 ; 4 3 2	this paper presents a novel <method_3> by considering the glottal effect on <otherscientificterm_4> to improve the performance of <method_0> based on <method_7> . by introducing <method_9> into <method_8> , <otherscientificterm_4> is decomposed into <method_2> , which are transformed separately . besides , <method_9> is adopted to measure the <otherscientificterm_5> of different speakers and realize <task_6> . listening test proves that proposed <method_3> can effectively improve the <metric_1> of <material_10> at the same time .	3 4 0 7 11 -1 9 8 2 12 16 11 -1 5 6 13 14 11 -1 1 10 15 11 -1
Using Color Compatibility for Assessing Image Realism .	realistic and unrealistic images ; recoloring image regions ; classifying composite images ; distributions of colors ; color combinations ; realistic com-positing ; natural images ; color distribution	<material> <task> <task> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm>	0 0 7 ; 2 1 1 ; 1 0 5	why does placing an object from one photograph into another often make the colors of that object suddenly look wrong ? one possibility is that humans prefer <otherscientificterm_3> that are often found in nature ; that is , we find pleasing these <otherscientificterm_4> that we see often . another possibility is that humans simply prefer colors to be consistent within an image , regardless of what they are . in this paper , we explore some of these issues by studying the color statistics of a large dataset of <material_6> , and by looking at differences in <otherscientificterm_7> in <material_0> . we apply our findings to two problems : 1 -rrb- <task_2> into realistic vs. non-realistic , and 2 -rrb- <task_1> for <task_5> .	3 4 8 -1 8 -1 6 7 0 8 -1 9 8 -1 2 1 5 10 11 8 -1
Block sparse excitation based all-pole modeling of speech .	block sparse excitation sequence ; sparse bayesian learning methods ; expectation-maximization based procedure ; weighted linear combination ; speech modeling task ; mixed excitation speech ; block sparse structure ; linear prediction approach ; generalized input sequence ; model parameters ; estimation procedure ; white noise ; all-pole filter ; unvoiced speech ; speech signal ; voiced speech	<otherscientificterm> <method> <method> <method> <task> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <material> <material>	13 1 5 ; 15 1 13 ; 0 0 12 ; 1 0 10 ; 15 1 5 ; 2 0 1	in this paper , it is shown that an appropriate model for <material_15> is an <method_12> excited by a <otherscientificterm_0> . the modeling approach is generalized in a novel manner to deal with a wide spectrum of <material_14> ; <material_15> , <material_13> and <material_5> . in this context , the input sequence to the all-pole model is modeled as a suitable <method_3> of a block sparse signal and <otherscientificterm_11> . we develop the corresponding <method_10> to reconstruct the <otherscientificterm_8> and <otherscientificterm_9> via <method_1> employing the <method_2> . rigorous experiments have been performed to show the efficacy of our proposed model for the <task_4> . by imposing a <otherscientificterm_6> on the input sequence , the problems associated with the commonly used <method_7> is alleviated leading to a more robust modeling scheme .	15 12 0 19 16 -1 14 13 5 17 18 21 16 -1 3 11 16 -1 10 8 9 1 2 20 22 16 -1 16 -1 4 16 -1
Integrated pronunciation learning for automatic speech recognition using probabilistic lexical modeling .	automatic speech recognition systems ; grapheme-to-phoneme converter ; lexical resource constrained asr tasks ; acoustic and lexical resources ; phoneme-based pronunciation lexicon ; phoneme-based asr system ; probabilistic lexical mod-eling ; grapheme-based asr approach ; asr system training ; hand crafted pronunciations ; asr system development ; g2p converters ; pronunciation learning ; g2p training ; stage approach ; pronunciations	<method> <method> <task> <material> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <method> <method> <task> <method> <method> <otherscientificterm>	7 4 14 ; 1 0 5 ; 7 0 6 ; 1 0 15 ; 12 0 6 ; 2 5 7	standard <method_0> use <otherscientificterm_4> prepared by linguistic experts . when the <otherscientificterm_9> fail to cover the vocabulary of a new domain , a <method_1> is used to extract <otherscientificterm_15> for new words and then a <method_5> is trained . <method_11> are typically trained only on the existing lexicons . in this paper , we propose a <method_7> in the framework of <task_6> that integrates <task_12> as a stage in <task_8> , and exploits both <material_3> -lrb- not necessarily from the domain or language of interest -rrb- . the proposed <method_7> is evaluated on four <task_2> and compared with the conventional two <method_14> where <method_13> is followed by <method_10> .	0 4 16 -1 9 1 15 5 11 18 20 16 -1 16 -1 7 6 12 8 3 19 21 16 -1 2 17 22 16 -1
A Game-Theoretic Model of Metaphorical Bargaining .	observed linguistic behavior ; modeling discourse ; game theory ; political communication ; computational linguists ; game-theoretic model	<otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method>	5 0 3 ; 2 0 1 ; 5 0 0	we present a <method_5> of bargaining over a metaphor in the context of <otherscientificterm_3> , find its equilibrium , and use <method_5> to rationalize <otherscientificterm_0> . we argue that <method_2> is well suited for <task_1> as a dynamic resulting from a number of conflicting pressures , and suggest applications of interest to <otherscientificterm_4> .	5 3 0 7 9 6 -1 2 1 4 8 6 -1
Background Subtraction on Distributions .	temporal variation of point statistics ; temporal variability of pixel intensities ; background modeling and subtraction scheme ; spatial variation of region statistics ; generic low-level detection metrics ; intensity or color distributions ; temporal variation of intensity ; background subtraction algorithms ; environmental monitoring applications ; detecting foreground objects ; processing power ; segmentation algorithms ; foreground objects ; monitoring applications ; application-dependent criteria ; distributional signatures ; tex-tured background	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm>	4 1 14 ; 15 0 9 ; 7 0 1 ; 4 5 2 ; 0 1 3	environmental <task_13> present a challenge to current <method_7> that analyze the <otherscientificterm_1> , due to the complex texture and motion of the scene . they also present a challenge to <method_11> that compare <otherscientificterm_5> between the foreground and the background in each image independently , because objects of interest such as animals have adapted to blend in . therefore , we have developed a <method_2> that analyzes the temporal variation of <otherscientificterm_5> , instead of either looking at <otherscientificterm_0> , or the <otherscientificterm_3> in isolation . <otherscientificterm_15> are less sensitive to movements of the <otherscientificterm_16> , and at the same time <otherscientificterm_15> are more robust than individual pixel statistics in <task_9> . they also enable slow background update , which is crucial in <task_13> where <otherscientificterm_10> comes at a premium , and where <otherscientificterm_12> , when present , may move less than the background and therefore disappear into it when a fast update scheme is used . our <method_2> compares favorably with the state of the art both in <metric_4> , as well as in <metric_14> .	13 7 1 20 17 -1 11 5 17 -1 2 0 3 15 22 17 -1 16 19 17 -1 9 17 -1 10 12 18 21 17 -1
Model-Based Tracking at 300Hz Using Raw Time-of-Flight Observations .	phase-based time-of-flight sensing ; low frame-rate depth image ; fast or unpredictable motion ; off-the-shelf depth camera ; model-based object tracking ; consumer depth cameras ; active illumination ; depth cameras ; raw captures ; fast-moving objects ; tracking ; accuracy ; robustness	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <metric> <metric>	8 0 4	consumer <otherscientificterm_7> have dramatically improved our ability to track rigid , articulated , and deformable 3d objects in real-time . however , <otherscientificterm_7> have a limited temporal resolution -lrb- frame-rate -rrb- that restricts the <metric_11> and <metric_12> of <task_10> , especially for <otherscientificterm_2> . in this paper , we show how to perform <task_4> which allows to reconstruct the object 's depth at an order of magnitude higher frame-rate through simple modifications to an <otherscientificterm_3> . we focus on <task_0> , which reconstructs each <otherscientificterm_1> from a set of short exposure ` raw ' infrared captures . these <material_8> are taken in quick succession near the beginning of each depth frame , and differ in the modulation of their <otherscientificterm_6> . we make two contributions . first , we detail how to perform <task_4> against these <material_8> . second , we show that by reprogramming the camera to space the <material_8> uniformly in time , we obtain a 10x higher frame-rate , and thereby improve the ability to track <otherscientificterm_9> .	7 13 -1 11 12 10 2 13 -1 4 3 13 -1 0 1 13 -1 8 13 -1 6 13 -1 14 13 -1 13 -1
Threshold Learning for Optimal Decision Making .	williams ' reinforce method ; modelling basal ganglia function ; wald 's cost function ; competitive stochastic evidence accumulation ; two-factor reward-modulated learning rule ; bayesian optimization ; gaussian process ; learning rule ; decision making ; decision optimality ; decision thresholds ; reward function ; neural networks ; threshold learning ; drift-diffusion model ; acquisition behaviour ; reinforce	<method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method>	7 0 1 ; 5 0 11 ; 5 4 16 ; 0 0 4 ; 0 0 15 ; 6 0 11 ; 11 0 13 ; 4 0 12	decision making under uncertainty is commonly modelled as a process of <otherscientificterm_3> to threshold -lrb- the <method_14> -rrb- . however , it is unknown how animals learn these <otherscientificterm_10> . we examine <task_13> by constructing a <otherscientificterm_11> that averages over many trials to <otherscientificterm_2> that defines <otherscientificterm_9> . these <otherscientificterm_11> are highly stochastic and hence challenging to optimize , which we address in two ways : first , a simple <method_4> derived from <method_0> for <method_12> ; and second , <method_5> of the <otherscientificterm_11> with a <method_6> . <method_5> converges in fewer trials than <method_16> but is slower computationally with greater variance . the <method_0> is also a better model of <otherscientificterm_15> in animals and a similar <method_7> has been proposed for <task_1> .	3 14 17 -1 10 17 -1 13 11 2 9 24 17 -1 4 0 12 5 6 19 21 23 25 17 -1 16 20 17 -1 18 22 17 -1
Minimisation of the maximum error signal in active control .	active control of acoustic signals ; multiple input multiple output systems ; uniform nal noise eld ; steepest descent iterative algorithm ; 1-norm minimisation algorithm ; measured data ; acoustic eld ; cancelling eld	<task> <method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm>	1 0 0 ; 4 0 2	this paper deals with <method_1> for <task_0> . these <method_1> are used when the <otherscientificterm_6> is complex and therefore a number of sensors are necessary to estimate the sound eld a n d a n umber of sources to create the <otherscientificterm_7> . a <method_3> is applied to minimise the p-norm of a <method_1> composed by the output signals of a microphone array . the existing algorithms deal with the 2-norm of this <method_1> . this paper describes a general framework that covers the existing <method_1> and then it focuses on the <method_4> . the <method_4> based on the 1-norm minimises the output signal which has the greatest power . it is shown by means of simulations using <material_5> from a real room that the <method_4> leads to a more <otherscientificterm_2> than the existing algorithms .	1 0 9 8 -1 6 7 8 -1 3 8 -1 8 -1 4 8 -1 8 -1 10 8 -1
Action Recognition from Arbitrary Views using 3D Exemplars .	temporal markov dependency ; smoothly moving camera ; 2d image information ; dimensional occupancy grids ; exemplar-based hmm ; view parameters ; image projections ; latent variables ; recognition phase ; 3d reconstruction ; prior knowledge ; recognition process ; recognition scenarios ; relative orienta-tions ; real datasets ; parameters ; recognition	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <task> <task> <otherscientificterm> <material> <otherscientificterm> <task>	9 0 2 ; 15 0 6 ; 7 0 6	in this paper , we address the problem of learning compact , view-independent , realistic 3d models of human actions recorded with multiple cameras , for the purpose of recognizing those same actions from a single or few cameras , without <otherscientificterm_10> about the <otherscientificterm_13> between the cameras and the subjects . to this aim , we propose a new framework where we model actions using three <otherscientificterm_3> , built from multiple viewpoints , in an <method_4> . the novelty is , that a <task_9> is not required during the <task_8> , instead learned <task_9> are used to produce <otherscientificterm_2> that is compared to the observations . <otherscientificterm_15> that describe <task_6> are added as <otherscientificterm_7> in the <task_11> . in addition , the <otherscientificterm_0> applied to <otherscientificterm_5> allows them to evolve during <task_16> as with a <otherscientificterm_1> . the effectiveness of the framework is demonstrated with experiments on <material_14> and with challenging <task_12> .	10 13 17 -1 3 4 17 -1 9 8 2 18 17 -1 15 19 20 17 -1 6 7 11 17 -1 0 5 16 1 17 -1
Non-negative source separation : range of admissible solutions and conditions for the uniqueness of the solution .	ordering and scale ambiguities ; non-negative mixing coefficients ; scale ambiguities ; source separation ; non-negative sources ; inde-terminacies ; indeterminacies	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm>	4 1 1 ; 4 1 6	a main issue in <task_3> is to deal with the <otherscientificterm_5> . well known are the <otherscientificterm_0> , but other types of <otherscientificterm_6> may also occur . in this paper we address these <otherscientificterm_6> in the case of <material_4> and <otherscientificterm_1> . on the one hand , we fully develop the case of two sources . on the other hand , in the general case we formulate necessary conditions for the uniqueness of the solution -lrb- up to <otherscientificterm_0> -rrb- .	3 5 7 -1 0 6 7 -1 4 1 8 9 7 -1 7 -1 2 7 -1
Learning coupled conditional random field for image decomposition with application on object categorization .	computational system of object categorization ; low level cues of contour ; adaptive fusion of visual information ; multiple decomposed visual cues ; single-layer random fields ; conditional random field ; natural images ; model learning ; discrimina-tive cues ; computational system ; object categorization	<method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <material> <method> <otherscientificterm> <method> <task>	3 0 10 ; 0 0 10	this paper proposes a <method_0> based on decomposition and <task_2> . a coupled <method_5> is developed to model the interaction between <otherscientificterm_1> and texture , and to decompose contour and texture in <material_6> . the advantages of using coupled rather than <method_4> are demonstrated with <method_7> and evaluation . <otherscientificterm_3> are adaptively combined for <task_10> to fully leverage different <otherscientificterm_8> for different classes . experimental results show that the proposed <method_0> of '' recognition-through-decomposition-and-fusion '' achieves better performance than most of the state-of-the-art methods , especially when only a limited number of training samples are available .	0 2 13 11 -1 5 1 6 11 -1 4 7 3 11 -1 10 8 12 11 -1 9 11 -1
Recurrent Cortical Amplification Produces Complex Cell Responses .	recurrent amplification of feedforward input ; recurrent cortical circuitry ; complex cell responses ; visual processing pathway ; cortical amplification ; recurrent mechanisms ; network model ; amplification	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm>	1 0 6	cortical <otherscientificterm_7> has been proposed as a mechanism for enhancing the selectivity of neurons in the primary visual cortex . less appreciated is the fact that the same form of <otherscientificterm_7> can also be used to de-tune or broaden selectivity . using a <method_6> with <otherscientificterm_1> , we propose that the spatial phase invariance of <otherscientificterm_2> arises through <otherscientificterm_0> . neurons in the <method_6> respond like simple cells at low gain and complex cells at high gain . similar <otherscientificterm_5> may play a role in generating invariant representations of feedforward input elsewhere in the <method_3> .	7 8 -1 8 -1 6 1 2 0 9 8 -1 8 -1 5 3 4 8 -1
On Interruptible Pure Exploration in Multi-Armed Bandits .	multi-armed bandits ; discriminative bucketing ; monte-carlo tree search algorithms ; sequential decision problems ; conservative uniform sampling ; interruptible setting ; non-interruptible strategies ; ε-greedy	<method> <method> <method> <task> <method> <otherscientificterm> <method> <method>	0 0 2 ; 1 4 7 ; 2 0 3	interruptible pure exploration in <method_0> is a key component of <method_2> for <task_3> . we introduce <method_1> , a novel family of strategies for pure exploration in <method_0> , which allows for adapting recent advances in <method_6> to the <otherscientificterm_5> , while guaranteeing exponential-rate performance improvement over time . our experimental evaluation demonstrates that the corresponding instances of <method_1> favorably compete both with the currently popular strategies ucb1 and <method_7> , as well as with the <method_4> .	0 2 3 9 11 8 -1 1 6 5 8 -1 7 4 10 8 -1
A Semiparametric Model for Bayesian Reader Identification .	aggregate features of eye movements ; word fixation durations ; parametric distribution family ; characteristic gaze patterns ; paramet-ric density models ; flexible semiparametric models ; saccade amplitudes ; gaussian process ; gaze control	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	6 1 1	we study the problem of identifying individuals based on their <otherscientificterm_3> during reading of arbitrary text . the motivation for this problem is an unobtrusive biomet-ric setting in which a user is observed during access to a document , but no specific challenge protocol requiring the user 's time and attention is carried out . existing models of individual differences in <otherscientificterm_8> during reading are either based on simple <otherscientificterm_0> , or rely on <method_4> to describe , for instance , <otherscientificterm_6> or <otherscientificterm_1> . we develop <method_5> of eye movements during reading in which densities are inferred under a <method_7> prior centered at a <method_2> that is expected to approximate the true distribution well . an empirical study on reading data from 251 individuals shows significant improvements over the state of the art .	3 9 -1 9 -1 8 0 4 6 1 10 9 -1 5 9 -1 7 2 9 -1
Bilingual Lexical Cohesion Trigger Model for Document-Level Machine Translation .	bilingual lexical cohesion trigger model ; nist chinese-english test sets ; hierarchical phrase-based machine translation ; document-level machine translation ; lexical cohesion	<method> <material> <task> <task> <otherscientificterm>	0 0 3 ; 0 0 2 ; 0 0 4 ; 4 0 3	in this paper , we propose a <method_0> to capture <otherscientificterm_4> for <task_3> . we integrate the <method_0> into <task_2> and achieve an absolute improvement of 0.85 bleu points on average over the baseline on <material_1> .	0 4 3 6 8 9 5 -1 2 1 7 5 -1
An approach to sequential grouping in cochannel speech .	sequential organization of cochannel speech ; segregated voiced speech ; onset/offset based analysis ; within-group concurrent pitches ; pretrained speaker models ; cochannel speech ; unvoiced segments ; unsupervised approach ; time-frequency segments ; sequential organization ; model-based methods ; model-based method ; cepstral features ; pretrained model ; speech segregation ; unvoiced speech	<material> <material> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <task> <method> <method> <otherscientificterm> <method> <task> <material>	14 5 11 ; 7 0 0 ; 7 4 11 ; 14 5 7 ; 13 0 7 ; 2 0 8 ; 4 0 10	model-based methods for <task_9> in <material_5> require <method_4> and often prior knowledge of participating speakers . we propose an <method_7> to <material_0> . based on <otherscientificterm_12> , we first cluster voiced speech into two speaker groups by maximizing the ratio of between-and within-group distances penalized by <otherscientificterm_3> . to group <material_15> , we employ an <method_2> to generate <method_8> . <otherscientificterm_6> are then labeled by the complementary portions of <material_1> . our <method_7> does not require any <method_13> and is computationally simple . evaluations and comparisons show that the proposed <method_7> outperforms a <method_11> in terms of <task_14> .	9 5 4 23 16 -1 7 0 18 16 -1 12 3 16 -1 15 2 8 6 22 16 -1 1 16 -1 13 21 16 -1 11 14 10 17 19 20 16 -1
Integrating dynamic speech modalities into context decision trees .	speaker 's dialect ; context decision trees ; speech recognition community ; janus speech recognizer ; error rate reductions ; speaking rate ; spoken utterance ; modality questions	<otherscientificterm> <otherscientificterm> <task> <method> <metric> <metric> <material> <otherscientificterm>	4 5 3 ; 1 0 2	context decision trees are widely used in the <task_2> . besides questions about pho-netic classes of a phone 's context , questions about their position within a word lee88 -rsb- and questions about the gender of the current speaker rc99 -rsb- have been used so far . in this paper we additionally incorporate questions about current modalities of the <material_6> like the <otherscientificterm_0> , the <metric_5> , the signal to noise ratio , the latter two of which may change while speaking one utterance . we present a framework that treats all these modalities in a uniform way . experiments with the <method_3> have produced <metric_4> of up to 10 % when compared to systems that do not use <otherscientificterm_7> .	2 10 8 -1 8 -1 6 0 5 8 -1 8 -1 9 8 -1
Classification Based on Symmetric Maximized Minimal Distance in Subspace -LRB- SMMS -RRB- .	support vector machines ; symmetric maximized minimal distance ; imposter samples ; classification algorithm ; decision boundary ; feature space ; face authentication ; smms ; subspace ; optimality	<method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <metric>	1 0 3	we introduce a new <method_3> based on the concept of <task_1> in subspace -lrb- <method_7> -rrb- . given the training data of authentic samples and <otherscientificterm_2> in the <otherscientificterm_5> , <method_7> tries to identify a <otherscientificterm_8> in which all the authentic samples are close to each other and all the <otherscientificterm_2> are far away from the authentic samples . the <metric_9> of the <otherscientificterm_8> is determined by maximizing the minimal distance between the authentic samples and the <otherscientificterm_2> in the <otherscientificterm_8> . we present a procedure to achieve such <metric_9> and to identify the <otherscientificterm_4> . the verification procedure is simple since we only need to project the test sample to the <otherscientificterm_8> and compare it against the <otherscientificterm_4> . using <task_6> as an example , we show that the proposed algorithm outperforms several other algorithms based on <method_0> .	3 1 7 11 10 -1 2 5 8 10 -1 9 10 -1 4 10 -1 10 -1 10 -1
Expectations for discourse genre identification : a prosodic study .	speaking style speech synthesis ; french -lrb- native speakers ; acoustic prosodic cues ; sport commentary speech ; non-native speakers ; contextual environment ; political speech ; sport commentary ; perceptual similarity ; identification ability ; discourse genres ; french ; speech	<task> <material> <otherscientificterm> <material> <material> <otherscientificterm> <material> <material> <otherscientificterm> <task> <otherscientificterm> <material> <material>	6 6 5 ; 6 1 3 ; 7 6 10 ; 3 6 5 ; 9 0 10	speech can be divided into <otherscientificterm_10> based on the <otherscientificterm_5> it occurs in -lrb- e.g. <material_6> , <material_3> , etc. -rrb- . the present study investigated whether listeners can distinguish between speech from different <otherscientificterm_10> on the basis of <otherscientificterm_2> only 1 . in a perception experiment with delexicalized speech 70 listeners with varying experience in <material_1> , <material_4> , and non-speakers -rrb- were asked to identify four different types of <otherscientificterm_10> -lrb- church service , political , journal , and <material_7> -rrb- . results revealed a fair <task_9> with a significant increase in performance with increasing experience in <material_11> . <task_9> was used to cluster <otherscientificterm_10> according to their <otherscientificterm_8> . the possible application of the results for the evaluation of <task_0> will be discussed .	10 5 6 3 14 15 17 13 -1 2 13 -1 1 4 7 16 13 -1 9 11 13 -1 18 13 -1 8 13 -1
Voice conversion in high-order eigen space using deep belief nets .	deep belief nets ; neural networks ; gaussian mixture model-based method ; subjective and objective criteria ; speaker individuality abstractions ; high-order eigen spaces ; voice conversion technique ; speaker individuality ; cepstrum space ; deep architecture ; inverse process ; phonologi-cal information ; abstractions	<method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	6 4 2 ; 1 0 4 ; 0 0 6	this paper presents a <method_6> using <method_0> to build <otherscientificterm_5> of the source/target speakers , where <method_6> is easier to convert the source speech to the target speech than in the traditional <otherscientificterm_8> . <method_0> have a <method_9> that automatically discovers <otherscientificterm_12> to maximally express the original input features . if we train the <method_0> using only the speech of an individual speaker , <method_6> can be considered that there is less <otherscientificterm_11> and relatively more <otherscientificterm_7> in the output features at the highest layer . training the <method_0> for a source speaker and a target speaker , we can then connect and convert the <otherscientificterm_4> using <method_1> . the converted abstraction of the source speaker is then brought back to the <otherscientificterm_8> using an <method_10> of the <method_0> of the target speaker . we conducted speaker-voice conversion experiments and confirmed the efficacy of our <method_6> with respect to <metric_3> , comparing <method_6> with the conventional <method_2> .	6 0 5 8 16 13 -1 9 12 13 -1 11 7 13 -1 15 13 -1 4 1 13 -1 10 14 13 -1
Bayesian context clustering using cross valid prior distribution for HMM-based speech recognition .	prior distribution determination technique ; variational bayesian method ; distribution determination technique ; hmm-based speech recognition ; posterior distributions ; statistical technique ; tuning parameters ; predictive distributions ; approximate version ; model selection ; prior distributions ; prior information ; cross validation ; model structure ; bayesian approach ; speech recognition ; model parameters	<method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm>	14 0 15 ; 16 0 9 ; 4 1 9 ; 2 0 7 ; 14 0 2 ; 12 0 2 ; 12 0 15 ; 5 0 7 ; 1 0 3 ; 2 0 15 ; 2 6 5	this paper proposes a <method_0> using <method_12> for <task_15> based on the <method_14> . the <method_2> is a <method_5> for estimating reliable <otherscientificterm_7> by marginalizing <otherscientificterm_16> and its <method_8> , the <method_1> has been applied to <task_3> . since <otherscientificterm_10> representing <otherscientificterm_11> about <otherscientificterm_16> affect the <otherscientificterm_4> and <method_9> , the determination of <otherscientificterm_10> is an important problem . however , it has not been thoroughly investigate in <task_15> . the proposed <method_2> can determine reliable <otherscientificterm_10> without <otherscientificterm_6> and select an appropriate <otherscientificterm_13> dependently on the amount of training data . continuous phoneme recognition experiments show that the proposed <method_2> achieved a higher performance than the conventional methods .	0 12 15 14 18 22 23 24 27 17 -1 2 5 7 16 8 1 3 21 25 26 28 17 -1 10 11 4 9 19 20 17 -1 17 -1 6 13 17 -1 17 -1
Factored sparse inverse covariance matrices .	fac-tored sparse inverse covariance matrices ; factored sparse inverse covariance gaussians ; observation probability density functions ; non-linear em update equations ; í 1/4 í factorization ; hmm-based speech recognition systems ; linear regressive coefficients ; conditional independence properties ; inverse covariance matrix ; full-covariance gaussians ; sparse patterns ; gaussian mixtures ; covariance matrices ; parsimony	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	6 0 4 ; 11 0 5 ; 11 0 2 ; 6 0 8 ; 2 0 5	most <method_5> use <method_11> as <otherscientificterm_2> . an important goal in all such <method_5> is to improve <otherscientificterm_13> . one method is to adjust the type of <otherscientificterm_12> used . in this work , <otherscientificterm_0> are introduced . based on <method_4> , the <otherscientificterm_8> can be represented using <otherscientificterm_6> which 1 -rrb- correspond to <otherscientificterm_10> in the <otherscientificterm_8> -lrb- and therefore represent <otherscientificterm_7> of the gaussian -rrb- , and 2 -rrb- , result in a method of partial tying of the <otherscientificterm_12> without requiring <otherscientificterm_3> . results show that the performance of <method_9> can be matched by <method_1> having significantly fewer parameters .	5 11 2 16 17 19 14 -1 13 14 -1 12 14 -1 0 14 -1 4 8 6 10 7 3 15 18 14 -1 9 1 14 -1
Enhanced wall clutter mitigation for compressed through-the-wall radar imaging using joint Bayesian sparse signal recovery .	compressed sensing through-the-wall radar imaging ; joint bayesian sparse approximation framework ; single-signal compressed sensing model ; sparsifying wavelet dictionary ; subspace projection technique ; sparse signal recovery ; wall clutter mitigation ; signal sparsity ; wall clutter ; high-quality images ; reconstruction accuracy ; antenna signal ; antenna location ; image formation ; sparsity	<task> <method> <method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <material> <metric> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	3 0 5 ; 4 0 13 ; 4 0 6 ; 6 0 0 ; 4 0 8	this paper addresses the problem of <task_6> in <task_0> , where a different set of frequencies is sensed at different antenna locations . a <method_1> is first employed to reconstruct all the signals simultaneously by exploiting <otherscientificterm_7> and correlations between antenna signals . this is in contrast to previous approaches where the signal at each <otherscientificterm_12> is reconstructed independently . furthermore , to promote <otherscientificterm_14> and improve <metric_10> , a <method_3> is employed in the <method_5> . following <task_6> , a <method_4> is applied to remove <otherscientificterm_8> , prior to <task_13> . experimental results on real data show that the proposed approach produces significantly higher <metric_10> and requires far fewer measurements for forming <material_9> , compared to the <method_2> , where each <otherscientificterm_11> is reconstructed independently .	6 0 19 15 -1 1 7 15 -1 12 15 -1 14 10 3 5 16 15 -1 4 8 13 17 18 20 15 -1 15 -1
Probabilistic linear discriminant analysis with bottleneck features for speech recognition .	prob-abilistic linear discriminant analysis ; hybrid deep neural networks ; large vocabulary conversational telephone speech corpus ; gaussian mixture models ; deep neural network ; word error reduction ; plda-based acoustic model ; dimensional acoustic features ; intra-frame feature correlations ; bottleneck features ; switchboard dataset ; recognition accuracy ; subspace gmms ; plda	<method> <method> <material> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <metric> <method> <method>	11 5 13 ; 12 1 11 ; 1 1 13 ; 7 0 6 ; 4 0 6 ; 0 0 6 ; 6 0 8 ; 3 0 6 ; 3 1 1 ; 12 1 1 ; 12 1 13 ; 4 0 9	we have recently proposed a new <method_6> based on <method_0> which enjoys the flexibility of using higher <otherscientificterm_7> , and is more capable to capture the <otherscientificterm_8> . in this paper , we investigate the use of <otherscientificterm_9> obtained from a <method_4> for the <method_6> . experiments were performed on the <material_10> -- a <material_2> . we observe significant <task_5> by using the <otherscientificterm_9> . in addition , we have also compared the <method_6> to three others using <method_3> , <method_12> and <method_1> , and <method_13> can achieve comparable or slightly higher <metric_11> from our experiments .	6 0 7 8 18 20 21 14 -1 9 4 19 26 14 -1 10 2 14 -1 5 14 -1 3 12 1 13 11 15 16 17 22 23 24 25 14 -1
A Discriminative Framework for Anomaly Detection in Large Videos .	classical density estimation approach ; temporal ordering of anomalies ; anomaly detection setting ; early context assumptions ; classical density estimation ; temporal ordering ; low-probability events ; training sequences ; training data ; complex videos ; discriminative learning ; high-dimensional models ; anomalies	<method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <material> <material> <method> <method> <otherscientificterm>	8 1 3 ; 0 0 2 ; 4 0 10	we address an <method_2> in which <material_7> are unavailable and <otherscientificterm_12> are scored independently of <otherscientificterm_5> . current algorithms in <method_2> are based on the <method_0> of learning <method_11> and finding <otherscientificterm_6> . these algorithms are sensitive to the order in which <otherscientificterm_12> appear and require either <material_8> or <otherscientificterm_3> that do not hold for longer , more <material_9> . by defining <otherscientificterm_12> as examples that can be distinguished from other examples in the same video , our definition inspires a shift in approaches from <method_4> to simple <method_10> . our contributions include a novel framework for <method_2> that is -lrb- 1 -rrb- independent of <task_1> , and -lrb- 2 -rrb- unsupervised , requiring no separate <material_7> . we show that our algorithm can achieve state-of-the-art results even when we adjust the setting by removing <material_7> from standard datasets .	2 7 12 5 13 -1 0 11 6 15 13 -1 8 3 9 14 13 -1 4 10 16 13 -1 13 -1 1 13 -1
It Takes Three to Tango : Triangulation Approach to Answer Ranking in Community Question Answering .	pairwise neural network architecture ; syntactic and semantic embeddings ; lexical similarity features ; answer ranking problem ; input components ; community forums ; feature types ; domain-specific features ; lexical matching ; relatedness	<method> <otherscientificterm> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	1 1 8 ; 7 1 1 ; 7 0 0 ; 2 1 7 ; 1 0 0 ; 8 1 7 ; 0 0 3 ; 8 0 0	we address the problem of answering new questions in <material_5> , by selecting suitable answers to already asked questions . we approach the task as an <task_3> , adopting a <method_0> that selects which of two competing answers is better . we focus on the utility of the three types of similarities occurring in the triangle formed by the original question , the related question , and an answer to the related comment , which we call relevance , <otherscientificterm_9> , and appropriateness . our proposed <method_0> models the interactions among all <method_4> using <otherscientificterm_1> , <method_8> , and <otherscientificterm_7> . it achieves state-of-the-art results , showing that the three similarities are important and need to be mod-eled together . our experiments demonstrate that all <otherscientificterm_6> are relevant , but the most important ones are the <otherscientificterm_2> , the <otherscientificterm_7> , and the <otherscientificterm_1> .	5 10 -1 3 0 17 10 -1 9 10 -1 4 1 8 7 11 13 15 16 18 10 -1 10 -1 12 14 10 -1
Written-domain language modeling for automatic speech recognition .	automatic speech recognition systems ; verbalization of written-domain vocabulary items ; lexical and non-lexical entities ; out-of-vocabulary ; written-domain language modeling approaches ; asr transcript rendering accuracy ; decomposition -- recomposition approach ; data sparsity problems ; verbal-domain language modeling ; finite-state modeling techniques ; verbal-domain language model ; written domain ; denormalization rules ; non-lexical entities ; verbal domain ; e-mail addresses ; speech recognition ; phone numbers ; language modeling ; dollar amounts ; language modeling ; urls ; en-glish	<task> <task> <otherscientificterm> <method> <method> <metric> <method> <task> <task> <method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <material> <task> <material> <task> <otherscientificterm> <task> <otherscientificterm> <material>	18 0 0 ; 19 6 13 ; 9 0 1 ; 6 0 3 ; 21 1 17 ; 15 6 13 ; 4 0 16 ; 10 0 4 ; 21 1 15 ; 9 0 20 ; 16 1 5 ; 17 6 13 ; 21 6 13 ; 15 1 17 ; 17 1 19	language modeling for <task_0> has been traditionally in the <material_14> . in this paper , we present <method_9> that we developed for <task_20> in the <material_11> . the first <method_9> we describe is for the <task_1> , which include <otherscientificterm_2> . the second <method_9> is the <method_6> to address the <method_3> and the <task_7> with <otherscientificterm_13> such as <otherscientificterm_21> , <material_15> , <material_17> , and <otherscientificterm_19> . we evaluate the proposed <method_4> on a very large vocabulary <task_16> system for <material_22> . we show that the <method_4> improves the <task_16> and the <metric_5> in the <material_11> over a baseline system using a <method_10> . in addition , the <method_4> is much simpler since <method_4> does not require complex and error-prone text normalization and <otherscientificterm_12> , which are generally required for <task_8> .	0 14 24 23 -1 9 20 11 33 23 -1 1 2 26 23 -1 6 3 7 13 21 15 17 19 25 27 28 29 32 35 36 37 38 23 -1 4 16 22 23 -1 5 30 31 34 23 -1 10 23 -1
Computation of the Quadrifocal Tensor .	extraction of camera matrices ; non-iterative linear algorithm ; projective scene reconstruction ; synthetic data ; iterative methods ; quadrifocal tensor ; iterative algorithms ; algebraic error ; algebraic ; accuracy	<task> <method> <task> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <metric>	1 0 7 ; 1 1 6 ; 3 5 4	this paper gives a practical and accurate algorithm for the computation of the <method_5> and <task_0> from it . previous methods for using the <method_5> in <task_2> have not emphasized <metric_9> of the algorithm in conditions of noise . methods given in this paper minimize <otherscientificterm_7> either through a <method_1> , or two alternative <method_6> . it is shown by experiments with <material_3> that the <method_4> , though minimizing <otherscientificterm_8> , rather than more correctly geometric error measured in the image , give almost optimal results .	5 0 10 -1 2 9 10 -1 7 1 6 11 12 10 -1 3 4 8 13 10 -1
Sparsity-based DOA estimation using co-prime arrays .	sparsity-based spatial spectrum estimation technique ; direction-of-arrival estimation ; co-prime array structure ; doa estimation performance ; co-prime arrays ; virtual aperture ; co-array aperture ; degrees-of-freedom	<method> <task> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <metric>	4 0 1	in this paper , we propose <method_4> for effective <task_1> . to fully utilize the <otherscientificterm_5> achieved in the difference co-array constructed from a <otherscientificterm_2> , <method_0> is exploited . compared to existing techniques , the proposed technique achieves better utilization of the <otherscientificterm_6> and thus results in increased <metric_7> as well as improved <metric_3> .	4 1 9 8 -1 5 2 0 8 -1 6 7 3 8 -1
Bayesian Model Averaging Naive Bayes -LRB- BMA-NB -RRB- : Averaging over an Exponential Number of Feature Models in Linear Time .	naive bayes ; globally optimal feature subset ; asymptotic limit of data ; nb feature models ; feature selection methods ; bayesian model ; feature selection ; predictor models ; nb model ; bma-nb classifier ; features ; classifiers ; bma ; classifier ; svms	<method> <otherscientificterm> <material> <method> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <method>	7 4 6 ; 14 6 11 ; 9 4 11 ; 12 4 6 ; 5 0 6	naive bayes -lrb- nb -rrb- is well-known to be a simple but effective <method_13> , especially when combined with <method_6> . unfortunately , <method_4> are often greedy and thus can not guarantee an optimal feature set is selected . an alternative to <method_6> is to use <method_5> averaging -lrb- <method_12> -rrb- , which computes a weighted average over multiple predictors ; when the different <method_7> correspond to different feature sets , <method_12> has the advantage over <method_6> that its predictions tend to have lower variance on average in comparison to any single model . in this paper , we show for the first time that <method_9> is possible to exactly evaluate <method_12> over the exponentially-sized powerset of <method_3> in linear-time in the number of <otherscientificterm_10> ; this yields an algorithm about as expensive to train as a single <method_8> with all <otherscientificterm_10> , but yet provably converges to the <otherscientificterm_1> in the <material_2> . we evaluate this novel <method_9> on a range of datasets showing that <method_9> never underperforms nb -lrb- as expected -rrb- and sometimes offers performance competitive -lrb- or superior -rrb- to <method_11> such as <method_14> and logistic regression while taking a fraction of the time to train .	13 6 15 -1 4 15 -1 5 12 7 16 19 20 15 -1 15 -1 9 3 10 8 1 2 17 18 15 -1
High quality voice morphing .	high spectral variance of unvoiced sounds ; voice morphing system ; natural phase dispersion ; unnatural phase dispersion ; speaker identification scores ; perceived audio quality ; phase incoherence ; voice morphing ; pitch scaling ; listening tests ; spectral envelope ; glottal coupling ; audio quality ; linear transformation ; voice morphing ; prosody	<otherscientificterm> <method> <task> <otherscientificterm> <metric> <metric> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <task> <otherscientificterm>	11 1 6 ; 6 1 3 ; 8 0 15 ; 9 5 1 ; 4 1 5 ; 10 1 8 ; 13 0 7	voice morphing is a technique for modifying a source speaker 's speech to sound as if <task_14> was spoken by some designated target speaker . most of the recent approaches to <task_7> apply a <method_13> to the <otherscientificterm_10> and <task_8> to modify the <otherscientificterm_15> . whilst these methods are effective , they also introduce artifacts arising from the effects of <otherscientificterm_11> , <otherscientificterm_6> , <otherscientificterm_3> and the <otherscientificterm_0> . a practical <method_1> must account for these if high <metric_12> is to be preserved . this paper describes a complete <method_1> and the enhancements needed for dealing with the various artifacts , including a novel method for synthesising <task_2> . each technique is assessed individually and the overall performance of the <method_1> evaluated using <otherscientificterm_9> . overall <task_14> is found that the enhancements significantly improve <metric_4> and <metric_5> .	14 16 -1 7 13 10 8 15 19 22 23 16 -1 11 6 3 0 17 18 16 -1 1 12 16 -1 16 -1 2 20 16 -1 9 21 16 -1
Local Occlusion Detection under Deformations Using Topological Invariants .	3d structure of man-made and natural scenes ; image sequences of natural scenes ; deforming cloth and hand motions ; well-defined local topologi-cal invariants ; zero false positive rate ; deforming 3d scene ; deforming scenes ; color variation ; spatio-temporal derivatives ; mathematical framework ; bounded deformations ; mathematical representation ; deforming objects ; occlusion detector ; matching ; occlusions ; occlusions ; occlu-sions	<task> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 0 0 ; 8 1 14 ; 9 0 15 ; 1 0 13	occlusions provide critical cues about the <task_0> . we present a <method_9> and algorithm to detect and localize <otherscientificterm_15> in image sequences of scenes that include <otherscientificterm_12> . our <method_13> works under far weaker assumptions than other detectors . we prove that <otherscientificterm_17> in <otherscientificterm_6> occur when certain <otherscientificterm_3> are not preserved . our framework employs these invariants to detect <otherscientificterm_15> with a <metric_4> under assumptions of <otherscientificterm_10> and <otherscientificterm_7> . the novelty and strength of this methodology is that it does not rely on <method_8> or <method_14> , which can be problematic in scenes including <otherscientificterm_12> , but is instead based on a <method_11> of the underlying cause of <otherscientificterm_15> in a <otherscientificterm_5> . we demonstrate the effectiveness of the <method_13> using <material_1> , including <otherscientificterm_2> .	0 19 18 -1 9 15 12 21 18 -1 13 18 -1 17 6 3 18 -1 4 10 7 18 -1 8 14 20 18 -1 11 5 22 18 -1
A language model adaptation approach based on text classification .	relative word error rate reductions ; pruned background lm ; domain lms ; k-means algorithm ; background lm ; linear interpolation ; lm adaptation ; text classification ; trigram lms	<metric> <method> <otherscientificterm> <method> <method> <method> <task> <task> <method>	2 0 6 ; 5 0 4 ; 3 0 7 ; 2 1 4 ; 0 5 1	in our paper , we divide the corpus into 8 domains through <task_7> using <method_3> , and calculate the <method_8> for each one . but the experiment shows the performance in some ones becomes worse . in order to solve this problem , we try to do the <task_6> based on the <otherscientificterm_2> . the adaptation is done by mixing the <otherscientificterm_2> with the <method_4> by a <method_5> . <metric_0> of between 5 and 10 % over the <method_1> are achieved .	7 3 8 12 9 -1 9 -1 6 2 10 9 -1 4 5 0 11 13 9 -1 1 14 9 -1
A Bayesian Approach for Policy Learning from Trajectory Preference Queries .	latent target policy ; learning control policies ; active query selection ; trajectory preference queries ; querying process ; random selection ; bayesian model ; policies	<otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm>	2 4 5 ; 3 0 1	we consider the problem of <method_1> via <otherscientificterm_3> to an expert . in particular , the <method_1> presents an expert with short runs of a pair of <otherscientificterm_7> originating from the same state and the expert indicates which trajectory is preferred . the <method_1> 's goal is to elicit a <otherscientificterm_0> from the expert with as few queries as possible . to tackle this problem we propose a novel <method_6> of the <method_4> and introduce two methods that exploit this <method_6> to actively select expert queries . experimental results on four benchmark problems indicate that our <method_6> can effectively learn <otherscientificterm_7> from <otherscientificterm_3> and that <method_2> can be substantially more efficient than <method_5> .	1 3 10 8 -1 7 8 -1 0 8 -1 6 4 8 -1 9 8 -1
Generating high performance pruned FFT implementations .	program generation system spiral ; intel core2duo multicore processor ; pruned fft algorithm ; kronecker product notation ; unused inputs ; multicore cpus ; fft implementations ; problem size ; fft ; vectorization	<method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <metric> <method> <otherscientificterm>	9 1 5 ; 2 0 0	we derive a recursive general-radix pruned cooley-tukey fast fourier transform -lrb- <method_8> -rrb- algorithm in <task_3> . the algorithm is compatible with <otherscientificterm_9> and parallelization required on state-of-the-art <otherscientificterm_5> . we include the <method_2> into the <method_0> , and automatically generate optimized implementations of the pruned <method_8> for the <method_1> . experimental results show that using the pruned <method_8> can indeed speed up the fastest available <metric_6> by up to 30 % when the <metric_7> and the pattern of <otherscientificterm_4> and outputs are known in advance .	8 3 10 -1 9 5 11 10 -1 2 0 1 12 10 -1 6 7 4 10 -1
Guiding a Constraint Dependency Parser with Supertags .	dependency parser of german ; models of su-pertags ; decision process ; supertag information ; weighted constraints ; parsing accuracy ; supertags ; accuracy	<method> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <metric>	3 0 0	we investigate the utility of <otherscientificterm_3> for guiding an existing <method_0> . using <otherscientificterm_4> to integrate the additionally available information , the <method_2> of the <method_0> is influenced by changing its preferences , without excluding alternative structural interpretations from being considered . the paper reports on a series of experiments using varying <method_1> that significantly increase the <metric_5> . in addition , an upper bound on the <metric_7> that can be achieved with perfect <method_6> is estimated .	3 0 9 8 -1 4 2 8 -1 1 5 8 -1 7 6 8 -1
Easy contextual intent prediction and slot detection .	sequential tagging problem ; error rate reductions ; predicted per-utterance ; asr process ; slu tasks ; slot detection ; svm feature ; intra-session utterances ; crf features ; intent prediction ; context ; discourse ; svm-hmms	<task> <metric> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method>	9 1 5 ; 0 0 9 ; 12 0 9	we investigate the incorporation of context into the spoken language understanding -lrb- slu -rrb- sub-tasks of <task_9> and <task_5> . using a corpus that contains information about whole sessions rather than just single utterances , we experiment with the incorporation of information from previous <otherscientificterm_7> into the <task_4> on a given utterance . for <task_5> , we find no significant increase using <otherscientificterm_8> indicating slots in previous utterances . for <task_9> , we achieve <metric_1> of upto 8.7 % by incorporating the intent of the previous utterance as an <otherscientificterm_6> , and similar gains when treating <task_9> as a <task_0> with <method_12> . u 1 get clip show me the -lsb- firefly -rsb- content − name -lsb- trailer -rsb- type show me the -lsb- firefly -rsb- content − name -lsb- trailer -rsb- type u 2 find info who directed -lsb- it -rsb- content − name − ref who directed -lsb- it -rsb- content − name − ref u 3 find content what else has -lsb- he -rsb- director − ref done what else has -lsb- he -rsb- director − ref done u 4 play content play -lsb- the avengers -rsb- content − name plane -lsb- avatars -rsb- content − name traditionally , both intents and -lsb- slots -rsb- are <otherscientificterm_2> , while ignoring previous utterances within the session . however , the data is gathered not one utterance at a time but one session at a time ; each utterance occurs in the context of a larger <otherscientificterm_11> . we examine the effect of incorporating information from previous <otherscientificterm_7> -lrb- ab hinc , context -rrb- . <otherscientificterm_10> can serve as an additional source of information and help get around other errors such as those introduced during the <otherscientificterm_3> .	9 5 14 13 -1 7 4 13 -1 8 13 -1 1 6 0 15 16 13 -1 12 13 -1 13 -1 2 13 -1 11 13 -1
Evaluating Information Content by Factoid Analysis : Human annotation and stability .	shared atomic information units ; duc information overlap measure ; weighted factoid score ; stable system rankings ; intrinsic summary evaluation ; string similarity ; system summary ; factoid annotation ; fac-toid scores ; unigrams	<otherscientificterm> <metric> <metric> <otherscientificterm> <task> <method> <method> <task> <metric> <otherscientificterm>	9 1 1 ; 2 0 3	we present a new approach to <task_4> , based on initial experiments in van halteren and teufel -lrb- 2003 -rrb- , which combines two novel aspects : comparison of information content -lrb- rather than <method_5> -rrb- in gold standard and <method_6> , measured in <otherscientificterm_0> which we call factoids , and comparison to more than one gold standard summary -lrb- in our data : 20 and 50 summaries respectively -rrb- . in this paper , we show that <task_7> is highly reproducible , introduce a <metric_2> , estimate how many summaries are required for <otherscientificterm_3> , and show that the <metric_8> can not be sufficiently approximated by <otherscientificterm_9> and the <metric_1> .	4 5 6 0 10 -1 7 2 3 11 12 10 -1
An Empirical Study of Information Synthesis Task .	information synthesis '' task ; information synthesis testbed ; n-gram overlap ; similarity metrics ; sentence overlap	<task> <method> <otherscientificterm> <metric> <otherscientificterm>	4 6 2	this paper describes an empirical study of the '' <task_0> , defined as the process of -lrb- given a complex information need -rrb- extracting , organizing and interrelating the pieces of information contained in a set of relevant documents , in order to obtain a comprehensive , non redundant report that satisfies the information need . two main results are presented : a -rrb- the creation of an <method_1> with 72 reports manually generated by nine subjects for eight complex topics with 100 relevant documents each ; and b -rrb- an empirical comparison of <metric_3> between reports , under the hypothesis that the best metric is the one that best distinguishes between manual and automatically generated reports . a metric based on key concepts overlap gives better results than metrics based on <otherscientificterm_2> -lrb- such as rouge -rrb- or <otherscientificterm_4> .	0 5 -1 1 3 5 -1 6 5 -1
Analysis by Synthesis : 3D Object Recognition by Object Reconstruction .	invariant features ; geometric interpretations of the world ; 3d object recognition datasets ; '' brute-force '' approach ; measured visual evidence ; forward synthesis model ; candidate reconstructions ; inverse estimation ; visual templates ; synthesis strategy ; inference ; recognition ; detection	<otherscientificterm> <otherscientificterm> <material> <method> <material> <method> <otherscientificterm> <task> <otherscientificterm> <method> <task> <task> <task>	5 0 1 ; 5 0 8 ; 0 0 8 ; 0 0 5 ; 8 0 7	we introduce a new approach for recognizing and reconstructing 3d objects in images . our approach is based on an analysis by <method_9> . a <method_5> constructs possible <otherscientificterm_1> , and then selects the interpretation that best agrees with the <material_4> . the <method_5> synthesizes <otherscientificterm_8> defined on <otherscientificterm_0> . these <otherscientificterm_8> are discriminatively trained to be accurate for <task_7> . we introduce an efficient <method_3> to <task_10> that searches through a large number of <otherscientificterm_6> , returning the optimal one . one benefit of such an approach is that <task_11> is inherently -lrb- re -rrb- constructive . we show state of the art performance for <task_12> and reconstruction on two challenging <material_2> of cars and cuboids .	13 -1 9 13 -1 5 1 4 14 13 -1 8 0 15 16 17 13 -1 7 18 13 -1 3 10 6 13 -1 11 13 -1 13 -1
Towards a domain-independent ASR-confidence classifier .	domain-independent binary classifier ; normalized mutual information ; across-domain clusters ; test domain ; cluster-specific classifiers ; natural clusters ; training data ; cluster purity ; asr hypothesis ; classifiers ; single-classifier	<method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <method>	4 4 0 ; 6 0 4 ; 7 1 1 ; 6 0 2 ; 2 1 4 ; 0 0 8 ; 0 0 3	this work addresses the problem of developing a <method_0> for a <material_3> given labeled data from several training domains where the <material_3> is not necessarily present in <material_6> . the <method_0> accepts or rejects the <otherscientificterm_8> based on the confidence generated by the <otherscientificterm_8> . in the proposed approach , <material_6> is grouped into <otherscientificterm_2> and separate <method_4> are trained . one of the main findings is that the <otherscientificterm_7> and the <otherscientificterm_1> of the clusters are not very high which suggests that the domains might not necessarily be <otherscientificterm_5> . the performance of these <method_4> is better than that of : -lrb- a -rrb- a single <method_0> trained on data from all the domains , and -lrb- b -rrb- a set of <method_9> trained separately for each of the training domains . at an operating point corresponding to low false accept , the correct accept of the proposed technique is on an average 2.3 % higher than that obtained by the <method_10> or the individual train-domain <method_9> .	0 3 6 18 11 -1 8 17 11 -1 2 4 13 15 16 11 -1 7 1 5 14 11 -1 12 11 -1 9 11 -1
Automatic Viseme Clustering for Audiovisual Speech Synthesis .	phoneme-based and viseme-based audiovisual speech synthesis techniques ; atomic units of speech ; many-to-one phoneme-to-viseme mapping ; standardized viseme set ; automatic viseme clustering ; visual speech information ; perceived synthesis quality ; visual speech synthesis ; viseme-based synthesis ; synthetic speech ; audiovisual coherence ; synthesis optimization ; mpeg-4 ; visemes	<method> <material> <method> <otherscientificterm> <task> <otherscientificterm> <metric> <task> <method> <material> <metric> <task> <material> <otherscientificterm>	10 0 11 ; 10 2 9 ; 13 2 1	a common approach in <task_7> is the use of <otherscientificterm_13> as <material_1> . in this paper , <method_0> are compared in order to explore the balancing between data availability and an improved <metric_10> for <task_11> . a technique for <task_4> is described and it is compared to the <otherscientificterm_3> described in <material_12> . both objective and subjective testing indicated that a phoneme-based approach leads to better synthesis results . in addition , the test results improve when more different <otherscientificterm_13> are defined . this raises some questions on the widely applied viseme-based approach . it appears that a <method_2> is not capable of describing all subtle details of the <otherscientificterm_5> . in addition , with <method_8> the <metric_6> is affected by the loss of <metric_10> in the <material_9> .	7 13 1 17 14 -1 0 10 11 15 14 -1 4 3 12 14 -1 14 -1 14 -1 14 -1 2 14 -1 5 16 14 -1
Automatic word stress marking and syllabification for Catalan TTS .	text-to speech systems ; linguistically rule-based automatic algorithms ; grapheme-to-phoneme conversion rules ; phonological syllabification algorithm ; catalan text-to-speech conversion ; stress marker algorithm ; orthographic syllabification algorithm ; word accuracy rates ; word stress marker ; prosody prediction ; synthetic intelligibility ; stress ; stress ; syllable	<task> <method> <otherscientificterm> <method> <task> <method> <method> <metric> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 6 1 ; 6 1 3 ; 5 1 6 ; 8 6 1 ; 3 6 1 ; 1 0 4 ; 8 1 6	stress and syllabification are essential attributes for several components in <task_0> . <otherscientificterm_11> are responsible for improving <otherscientificterm_2> and for enhancing the <otherscientificterm_10> , since <otherscientificterm_12> and <otherscientificterm_13> are key units in <task_9> . this paper presents three <method_1> for <task_4> : a <method_8> , an <method_6> and a <method_3> . the <method_1> were implemented and tested . the results gave rise to the following <metric_7> : 100 % for the <method_5> , 99.7 % for the <method_6> and 99.8 % for the <method_3> .	0 11 14 -1 2 10 12 13 9 14 -1 1 4 8 6 3 15 18 19 20 21 14 -1 14 -1 7 5 16 17 14 -1
Naturalness of an Utterance Based on the Automatically Retrieved Commonsense .	user 's behavior ; nlp achievements ; common knowledge ; holistic system ; commonsense processing ; random text-mining ; com-monsensical utterances ; affective computing ; word-spotting method ; keywords	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <material> <task> <method> <otherscientificterm>	4 1 7 ; 1 3 3	in this research we investigated <otherscientificterm_0> while facing a system coping with <otherscientificterm_2> about <otherscientificterm_9> and compared it with not only classic <method_8> but also with <method_5> . we show how even a simple implementation of our idea can enrich the conversation and increase the naturalness of computer 's utterances . our results show that even very <material_6> are more natural than classic approaches and also methods we developed to make a conversation more interesting . for arousing opinion exchange during the session , we will also briefly introduce our idea of combining latest <otherscientificterm_1> into one <method_3> where the main engine we want to base on <task_4> and <task_7> .	0 2 9 8 5 10 -1 10 -1 6 10 -1 1 3 11 12 10 -1
A Parameterless Line Segment and Elliptical Arc Detector with Enhanced Ellipse Fitting .	non-iterative ellipse fitting technique ; detected elliptical features ; elliptical arc detector ; parameter tuning ; line segment ; computer-generated images ; natural images ; algebraic distance ; gradient orientation ; accuracy	<method> <otherscientificterm> <method> <method> <method> <material> <material> <otherscientificterm> <otherscientificterm> <metric>	5 1 6 ; 5 5 2 ; 7 1 8 ; 9 5 1 ; 4 1 2 ; 6 5 2 ; 0 0 1	we propose a combined <method_4> and <method_2> , which formally guarantees the control of the number of false positives and requires no <method_3> . the <metric_9> of the <otherscientificterm_1> is improved by using a novel <method_0> , which merges the <otherscientificterm_7> with the <otherscientificterm_8> . the performance of the <method_2> is evaluated on <material_5> and on <material_6> .	4 2 3 15 10 -1 9 1 0 7 8 13 14 17 10 -1 5 6 11 12 16 10 -1
Differential Tracking based on Spatial-Appearance Model -LRB- SAM -RRB- .	recovery of all motion parameters ; spatial-appearance model ; large object scale changes ; maximum likelihood matching criterion ; tracking non-rigid objects ; localized matching criteria ; global spatial structures ; differential motion analysis ; dramatic appearance deformations ; dramatic appearance changes ; local appearances variations ; closed form solution ; global criteria ; appearance variations ; matching histograms ; local non-rigidity ; image regions ; motion parameters ; pixel-based ssd ; motion tracking ; partial occlusions ; appearance changes ; matching criterion ; scaling ; rotation	<task> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 0 ; 10 1 6 ; 24 6 17 ; 11 0 19 ; 1 0 11 ; 22 0 16 ; 2 1 20 ; 11 0 4 ; 14 6 12 ; 11 0 13 ; 8 1 2 ; 18 6 5	a fundamental issue in <method_7> is the compromise between the flexibility of the <otherscientificterm_22> for <otherscientificterm_16> and the ability of recovering the motion . <metric_5> , e.g. , <method_18> , may enable the <task_0> , but it does not tolerate much <otherscientificterm_21> . on the other hand , <otherscientificterm_12> , e.g. , <method_14> , can accommodate <otherscientificterm_9> , but may be blind to some <otherscientificterm_17> , e.g. , <otherscientificterm_23> and <otherscientificterm_24> . this paper presents a novel <method_11> that integrates the advantages of both in a principled way based on a <method_1> that combines <otherscientificterm_10> and <otherscientificterm_6> . this <method_11> can capture a large variety of <otherscientificterm_13> that are attributed to the <otherscientificterm_15> . at the same time , this <method_11> enables efficient <task_0> . a <otherscientificterm_3> is defined and rigorous analytical results are obtained that lead to a <method_11> to <task_19> . very encouraging results demonstrate the effectiveness and efficiency of the proposed <method_11> for <task_4> that exhibit <otherscientificterm_8> , <otherscientificterm_2> and <otherscientificterm_20> .	7 22 16 5 31 25 -1 18 0 21 37 25 -1 12 14 9 17 23 24 28 34 25 -1 11 1 10 6 27 30 25 -1 35 25 -1 13 15 26 25 -1 29 25 -1 3 19 32 33 36 25 -1
Speech quality measure for voIP using wavelet based bark coherence function .	wavelet based bark coherence function ; bark coherence function ; voip speech data ; digital mobile system ; wavelet series expansion ; time synchronization ; coherence function ; correlation coefficients ; internet telephony ; variable delay ; signal decomposition ; cognition module ; linear distortions ; loudness speech ; voip ; psqm	<method> <method> <material> <method> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <method>	1 0 14 ; 4 0 1 ; 0 0 9 ; 10 0 0 ; 0 4 15 ; 1 6 6 ; 14 6 8 ; 10 0 5 ; 1 6 11 ; 13 1 6 ; 2 0 5	the <method_1> -lsb- 1 -rsb- defines a <otherscientificterm_6> with <otherscientificterm_13> as a new <method_11> , robust to <otherscientificterm_12> due to the analog interface of <method_3> . preliminary experiments have shown the superiority of <method_1> over current measures . in this paper , a new <method_1> suitable for <task_14> is developed . the new <method_1> is based on the <method_4> that provides good frequency resolution while keeping good time locality . the proposed <method_0> is robust to <otherscientificterm_9> often observed in <task_8> such as <task_14> . we also show that the refinement of <task_5> after <task_10> can improve the performance of the <method_0> . the <task_5> was performed with <material_2> . the <otherscientificterm_7> and the standard error of estimates computed using the <method_0> showed noticeable improvement over the <method_15> that is recommended by <method_0> .	1 6 13 11 12 3 22 25 26 16 -1 16 -1 14 17 16 -1 4 18 16 -1 0 9 8 19 23 16 -1 5 10 20 24 16 -1 27 16 -1 2 21 16 -1
Efficient construction of long-range language models using log-linear interpolation .	medium-sized vocabulary wall street journal task ; distance word and class models ; smoothed 4-gram language model ; rescoring word lattices ; long-range language models ; grammar-based approaches ; model combinations ; penn treebank ; log-linear interpolation	<material> <method> <method> <task> <method> <method> <method> <material> <method>	8 0 4 ; 6 0 3 ; 0 0 6	in this paper we examine the construction of <method_4> using <method_8> and how this can be achieved effectively . particular attention is paid to the efficient computation of the normalisation in the <method_4> . using the <material_7> for experiments we argue that the perplexity performance demonstrated recently in the literature using <method_5> can actually be achieved with an appropriately <method_2> . using such a model as the baseline , we demonstrate how further improvements can be obtained using <method_8> to combine <method_1> . we also examine the performance of similar <method_6> for <task_3> on a <material_0> .	4 8 10 9 -1 9 -1 7 5 2 9 -1 1 9 -1 6 3 0 11 12 9 -1
Broadcast news transcription using HTK .	maximum likelihood linear regression ; clean and noisy read speech tasks ; large vocabulary speech recognition system ; htk large vocabulary systems ; unsupervised model adaptation ; cache-based language modelling ; dierent front-end analyses ; broadcast news transcription ; h4 evaluation ; decoder-guided segmentation ; segment clustering ; features	<method> <material> <method> <method> <method> <method> <method> <task> <task> <method> <method> <otherscientificterm>	1 0 7 ; 5 6 3 ; 11 2 3 ; 9 6 3 ; 9 1 10 ; 0 0 4 ; 2 6 3 ; 2 0 7 ; 10 6 11 ; 10 6 3 ; 10 1 5 ; 2 0 1 ; 9 6 11	this paper examines the issues in extending a <method_2> designed for <material_1> to handle <task_7> . results using the 1995 darpa h 4 e v aluation data set are presented for <method_6> and use of <method_4> using <method_0> . the <method_2> for the 1996 <task_8> is then described . <method_2> includes a number of new <otherscientificterm_11> over previous <method_3> including <method_9> , <method_10> , <method_5> , and combined map and mllr adaptation . the <method_2> runs in multiple passes through the data and the detailed results of each pass are given .	2 1 7 13 20 24 12 -1 6 4 0 18 12 -1 8 12 -1 11 3 9 10 5 14 15 16 17 19 21 22 23 25 12 -1 12 -1
Minimize the total power consumption for multiuser video transmission over CDMA wireless network : a two-step approach .	video coding bit rate ; transmitter power ¡ ; video compression complexity ; two-step fast algorithm ; computation burden ; cdma cell ; transmitter power ; signal processing ; full search ; complexity ; quality	<metric> <method> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <task> <task> <metric> <metric>	0 1 2 ; 7 1 6 ; 2 1 6	in this work , we consider a <method_5> with multiple terminals transmitting video signals . we minimize the sum of <task_7> and <otherscientificterm_6> while the received <metric_10> at each terminal is guaranteed . the system parameters to be adjusted include <metric_0> , <metric_2> and <otherscientificterm_6> . instead of <task_8> in the space of bit rate , <metric_9> , <method_1> for all users , we design a <method_3> to reduce the <otherscientificterm_4> in the base station . in our <method_3> , the search in the base station is over the space of <metric_9> only . our results indicate that for the same class of video users , the one who is closer to the base station compresses at less <metric_9> . this is used to further reduce the computation required by our <method_3> .	5 11 -1 7 6 10 13 11 -1 0 2 12 14 11 -1 8 9 1 3 4 11 -1 11 -1 11 -1 11 -1
Multi-view Sparse Co-clustering via Proximal Alternating Linearized Minimization .	proximal alternating linearized minimization algorithm ; multi-view co-clustering methods ; hypothesized clusters ; benchmark datasets ; sparse row ; features ; clusters ; co-clustering	<method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	1 4 0 ; 0 0 2 ; 3 5 0 ; 3 5 1	when multiple views of data are available for a set of subjects , <method_7> aims to identify subject <otherscientificterm_6> that agree across the different views . we explore the problem of <method_7> when the underlying <otherscientificterm_6> exist in different sub-spaces of each view . we propose a <method_0> that simultaneously decomposes multiple data matrices into <otherscientificterm_4> and columns vectors . this <method_0> is able to group subjects consistently across the views and simultaneously identify the subset of <otherscientificterm_5> in each view that are associated with the <otherscientificterm_6> . the proposed <method_0> can globally converge to a critical point of the problem . a simulation study validates that the proposed <method_0> can identify the <otherscientificterm_2> and their associated <otherscientificterm_5> . comparison with several latest <method_1> on <material_3> demonstrates the superior performance of the proposed <method_0> .	7 6 8 -1 8 -1 0 4 8 -1 5 8 -1 8 -1 10 8 -1 2 9 11 12 8 -1
Markerless Kinematic Model and Motion Capture from Volume Sequences .	model-free markerless motion capture of articulated kinematic structures ; synthetically generated volume sequences ; arbitrary kinematic topology ; human volume sequences ; captured volume sequence ; motion sequence ; kinematic postures ; kinematic model ; skeleton curve ; volume sequence ; joint angles ; skeleton curves ; nonlinear axes	<task> <material> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 7 ; 2 0 1 ; 7 0 5 ; 7 0 9	we present an approach for <task_0> . this approach is centered on our method for generating underlying <otherscientificterm_12> -lrb- or a <otherscientificterm_8> -rrb- of a volume of genus zero -lrb- i.e. , without holes -rrb- . we describe the use of <otherscientificterm_11> for deriving a <method_7> and motion -lrb- in the form of <otherscientificterm_10> over time -rrb- from a <material_4> . our motion capture method uses a <otherscientificterm_8> , found in each frame of a <material_9> , to automatically determine <otherscientificterm_6> . these <otherscientificterm_11> are aligned to determine a common <method_7> for the <material_9> . the derived <method_7> is then reapplied to each frame in the <material_9> to find the <otherscientificterm_5> suited to this <method_7> . we demonstrate our method on several types of motion , from <material_1> with an <otherscientificterm_2> , to <material_3> captured from a set of multiple calibrated cameras .	0 13 -1 12 8 13 -1 11 7 10 4 13 -1 9 6 13 -1 14 17 13 -1 16 13 -1 5 15 13 -1
Guiding an HPSG Parser using Semantic and Pragmatic Expectations .	natural language understanding ; domain independent grammar ; natural language generation ; socio-pragmatic context ; pragmatic knowledge ; speech acts ; socio-pragmatic knowledge ; syntactic knowledge ; pragmatic context ; search space ; parse ; introduction ; parser	<task> <method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	6 0 10 ; 1 1 12 ; 4 0 12 ; 5 0 2	1 efficient <task_2> has been successfully demonstrated using highly compiled knowledge about <material_5> and their related social actions . a design and prototype implementation of a <method_12> which utilizes this same <otherscientificterm_4> to efficiently guide parsing is presented . such guidance is shown to prune the <otherscientificterm_9> and thus avoid needless processing of pragmatically unlikely constituent structures . <method_11> the use of purely <otherscientificterm_7> during the <otherscientificterm_10> phase of <task_0> yields considerable local ambiguity -lrb- consideration of impossible subeonstituents -rrb- as well global ambiguity -lrb- construction of syntactically valid parses not applicable to the <otherscientificterm_3> -rrb- . this research investigates bringing <otherscientificterm_6> to bear during the <otherscientificterm_10> , while maintaining a <method_1> and <method_12> . the particular technique explored uses knowledge about the <otherscientificterm_8> to order the consideration of proposed <otherscientificterm_10> constituents , thus guiding the <method_12> to consider the best -lrb- wrt the expectations -rrb-	2 5 17 13 -1 12 4 16 13 -1 9 11 13 -1 7 10 0 3 13 -1 14 15 13 -1 6 1 13 -1
A Unified Learning Scheme : Bayesian-Kullback Ying-Yang Machines .	major supervised and unsu-pervised learnings ; em & em algorithm ; least square learning ; bayesian-kullback learning scheme ; maximum information preservation ; bayesian representations ; learning methods ; kullback divergence ; ying-yang machine ; helmholtz machine ; information geometry ; joint density	<task> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 1 1 ; 4 1 10 ; 5 0 11 ; 4 6 0 ; 2 6 0 ; 9 6 0 ; 2 1 1 ; 1 1 10 ; 8 6 3 ; 11 1 7 ; 2 1 4 ; 4 1 2 ; 10 6 0 ; 1 6 0 ; 1 1 9 ; 3 0 0	a <method_3> , called <method_8> , is proposed based on the two complement but equivalent <method_5> for <otherscientificterm_11> and their <otherscientificterm_7> . not only the <method_3> unifies existing <task_0> , including the classical maximum likelihood or <method_2> , the <method_4> , the <method_1> and <otherscientificterm_10> , the recent popular <otherscientificterm_9> , as well as other <method_6> with new variants and new results ; but also the <method_3> provides a number of new <method_6> .	3 8 5 11 7 15 21 22 12 -1 0 2 4 1 10 9 6 13 14 16 17 18 19 20 23 24 25 26 27 28 12 -1
A suboptimal embedding algorithm with low complexity for binary data hiding .	maximal likelihood algorithm ; weight approximation embedding ; linear embedding code ; suboptimal hiding algorithm ; parity check matrix ; binary embedding ; embedding procedure ; embedding distortion ; target vector ; embedding complexity ; binary data ; coset leader ; suboptimal wae ; wae ; complexity ; embedding	<method> <method> <method> <method> <method> <method> <method> <task> <otherscientificterm> <metric> <material> <method> <otherscientificterm> <method> <metric> <method>	3 0 5 ; 4 0 3 ; 6 0 3 ; 4 0 6 ; 0 0 11 ; 3 0 10 ; 1 0 3	-- a novel <method_3> for <material_10> based on <method_1> , <method_13> , is proposed . given a specified <method_15> rate , this <method_3> exhibits an advantage of efficient <method_5> with reduced <metric_9> . the <method_3> performs an <method_6> through a <method_4> . the optimal <method_15> based on <method_0> aims to locate the <method_11> to minimize the <task_7> . on the contrary , the <method_3> looks for a <otherscientificterm_8> close to the <method_11> in an efficiently iterative manner . given an <method_2> c -lrb- n , k -rrb- , the <metric_9> using the optimal <method_3> is o -lrb- 2 k -rrb- , while the <metric_14> in the <otherscientificterm_12> is reduced to o -lrb- sk -rrb- where s is the average iterations .	3 10 1 13 22 23 16 -1 15 5 9 17 16 -1 6 4 18 19 20 16 -1 0 11 7 21 16 -1 8 16 -1 2 16 -1
Concept-to-text Generation via Discriminative Reranking .	corpus of database records ; local and global features ; probabilistic context-free grammar ; judgment elicitation study ; hyper-graph structure ; weighted hypergraph ; scoring derivation ; decoding algorithm ; parsing problem ; content selection ; data-driven method ; concept-to-text generation ; atis domain ; discriminative system ; non-linguistic input ; bleu	<material> <otherscientificterm> <method> <task> <otherscientificterm> <method> <task> <method> <task> <task> <method> <task> <material> <method> <otherscientificterm> <metric>	15 1 3 ; 10 0 11 ; 3 5 10 ; 3 5 13 ; 7 0 6 ; 10 4 13 ; 1 0 4 ; 5 0 2 ; 15 0 13	this paper proposes a <method_10> for <task_11> , the task of automatically producing textual output from <otherscientificterm_14> . a key insight in our <method_10> is to reduce the tasks of <task_9> -lrb- '' what to say '' -rrb- and surface realization -lrb- '' how to say '' -rrb- into a common <task_8> . we define a <method_2> that describes the structure of the input -lrb- a <material_0> and text describing some of them -rrb- and represent <method_2> compactly as a <method_5> . the <otherscientificterm_4> encodes exponentially many derivations , which we rerank discriminatively using <otherscientificterm_1> . we propose a novel <method_7> for finding the best <task_6> and generating in this setting . experimental evaluation on the <material_12> shows that our <method_10> outperforms a competitive <method_13> both using <metric_15> and in a <task_3> .	10 11 14 18 16 -1 9 8 16 -1 2 0 5 24 16 -1 4 1 23 16 -1 21 16 -1 7 6 17 19 20 22 25 16 -1
An approach to continuous speech recognition based on layered self-adjusting decoding graph .	general re-entrant decoding network ; two level hashing structure ; layered self-adjusting decoding graph ; fast network expansion ; self-adjusting capability ; stack decoding ; scaolding layer ; ecient decoding ; dynamic decoding ; recognition resources ; decoder ; releasing	<method> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <task> <method> <material> <method> <task>	9 5 7 ; 6 0 5 ; 6 0 3	in this paper , an approach of continuous speech recognition based on <method_2> is described . it utilizes a <otherscientificterm_6> to support <task_3> and <task_11> . a <otherscientificterm_1> is also described . it introduces <method_4> i n <method_8> on <method_0> . in <task_5> , the <otherscientificterm_6> in the proposed approach enables the <method_10> to look several layers into the future so that long span inter-word context dependency can be exactly preserved . experimental results indicate that highly <task_7> can be achieved with a signicant savings on <material_9> .	2 12 -1 6 3 11 15 12 -1 1 12 -1 4 8 0 12 -1 5 10 14 12 -1 7 9 13 12 -1
Digital compensation of sampling instant errors in the track-and-hold portion of an ADC .	spurious free dynamic range ; high-speed high-resolution analog-to-digital converters ; track-and-hold circuits ; bipolar and mos technologies ; digital post compensation method ; background calibration configuration ; sampling instant error ; nonlinear th model ; input signal ; nonlinear behavior ; mathematical models ; energy-free method ; adc	<metric> <method> <method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	7 5 4 ; 10 0 3 ; 0 5 4 ; 10 0 12 ; 11 0 5 ; 11 0 4 ; 2 0 1 ; 4 0 12	track-and-hold -lrb- th -rrb- circuits in the front end of <method_1> typically limit <otherscientificterm_12> performance at high <otherscientificterm_8> frequencies . this paper develops <method_10> for <otherscientificterm_12> implemented in both <method_3> . the <method_10> are derived by analyzing the <task_6> and reveal that the <otherscientificterm_9> is dependent on the <otherscientificterm_8> and <method_4> 's derivatives . a <method_4> is then presented with <method_4> 's coefficients estimated using an <method_11> in a <otherscientificterm_5> . simulation results on a <method_7> show that the proposed <method_4> achieves a significant improvement in the <metric_0> . the <method_4> is also applied to a commercially available <otherscientificterm_12> to demonstrate <method_4> 's effectiveness .	1 12 8 20 13 -1 10 3 15 17 13 -1 6 9 4 13 -1 11 5 18 19 13 -1 7 0 14 16 13 -1 21 13 -1
Anytime Belief Revision .	computer-based belief revision architectures ; belief revision module ; anytime decision procedure ; belief revision systems ; belief revision strategy ; cin project ; theorem prover ; intelligent behaviour ; agm paradigm ; theory bases ; belief revision ; minimal change ; maxi-adjustments ; complexity ; guidelines ; protomethodology ; maxi-adjustment ; maxi-adjustment	<task> <method> <method> <method> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method>	14 0 15 ; 6 0 4 ; 2 1 1 ; 2 0 12 ; 14 0 3 ; 17 6 4 ; 8 0 3 ; 15 0 3 ; 4 0 9	belief revision is a ubiquitous process underlying many forms of <otherscientificterm_7> . the <method_8> is a powerful framework for modeling and implementing <method_3> based on the principle of <method_11> ; <method_8> provides a rich and rigorous foundation for <task_0> . <method_17> is a <method_4> for <otherscientificterm_9> that can be implemented using a standard <method_6> , and one that has been used successfully for several applications . in this paper we provide an <method_2> for <otherscientificterm_12> , and study its <metric_13> . furthermore , we outline a set of <otherscientificterm_14> that serve as a <method_15> for building <method_3> employing a <otherscientificterm_16> . the <method_2> is under development in the <method_1> of the <material_5> .	7 18 -1 8 3 11 0 17 25 18 -1 4 9 6 20 24 27 18 -1 2 12 13 22 18 -1 14 15 16 19 23 26 18 -1 21 18 -1
Locally optimal , buffer-constrained motion estimation and mode selection for video sequences .	r-d optimal motion search ; constant bit rate channel ; optimal mode selection ; motion search ; video sequences ; nominal method ; lagrange multiplier ; distortion ; rate	<method> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 4	we describe a method of using a <otherscientificterm_6> to make a locally optimal trade off between <otherscientificterm_8> and <otherscientificterm_7> in the <otherscientificterm_3> for <material_4> , while maintaining a <otherscientificterm_1> . simulation of this method shows that it gives up to 3.5 db psnr improvement in a high motion sequence . a locally rate-distortion -lrb- r-d -rrb- <method_2> mechanism is also described . this method also gives significant quality benefit over the <method_5> . though the benefit of these techniques is significant when used separately , when the <method_2> is combined with the <method_0> , it does not perform much better than the codec does with only the <method_0> .	6 8 7 3 4 1 10 9 -1 9 -1 2 9 -1 5 9 -1 0 9 -1
Computing Paraphrasability of Syntactic Variants Using Web Snippets .	syntactic variants of predicate phrases ; large-scale knowledge-base of paraphrases ; natural language processing tasks ; computing semantic equivalence ; data sparseness problem ; distributional similarity measures ; computing paraphrasability ; syntactic substitutability ; predicate phrases ; web snippets ; paraphrasability	<otherscientificterm> <method> <task> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	9 0 4 ; 3 1 7	in a broad range of <task_2> , <method_1> is anticipated to improve their performance . the key issue in creating such a resource is to establish a practical method of <task_3> and <otherscientificterm_7> , i.e. , <otherscientificterm_10> , between given pair of expressions . this paper addresses the issues of <task_6> , focusing on <otherscientificterm_0> . our model estimates <otherscientificterm_10> based on traditional <method_5> , where the <material_9> are used to overcome the <task_4> in handling <otherscientificterm_8> . several feature sets are evaluated through empirical experiments .	2 1 11 -1 3 7 10 13 11 -1 6 0 11 -1 5 9 4 8 12 11 -1 11 -1
Associative Memory via a Sparse Recovery Model .	binary -lrb- or q-ary -rrb- hopfield neural networks ; super-polynomial or exponential number of n-length vectors ; sparse recovery of signals ; near-linear number of coordinates ; neurally feasible algorithm ; sparse recovery problem ; generic random models ; iterative algorithm ; stored vectors ; linear constraints ; associative memory ; nearest neighbor ; structure ; vector	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	5 0 11 ; 6 0 1 ; 8 0 3 ; 4 0 13	an <otherscientificterm_10> is a <otherscientificterm_12> learned from a dataset m of vectors -lrb- signals -rrb- in a way such that , given a noisy version of one of the vectors as input , the nearest valid <otherscientificterm_13> from m -lrb- <method_11> -rrb- is provided as output , preferably via a fast <method_7> . traditionally , <method_0> are used to model the above <otherscientificterm_12> . in this paper , for the first time , we propose a model of <otherscientificterm_10> based on <otherscientificterm_2> . our basic premise is simple . for a dataset , we learn a set of <otherscientificterm_9> that every <otherscientificterm_13> in the dataset must satisfy . provided these <otherscientificterm_9> possess some special properties , it is possible to cast the task of finding <method_11> as a <task_5> . assuming <method_6> for the dataset , we show that it is possible to store <otherscientificterm_1> in a neural network of size o -lrb- n -rrb- . furthermore , given a noisy version of one of the <otherscientificterm_8> corrupted in <otherscientificterm_3> , the <otherscientificterm_13> can be correctly recalled using a <method_4> .	10 12 13 11 7 14 -1 0 14 -1 2 14 -1 14 -1 9 14 -1 15 14 -1 5 16 14 -1 6 1 17 18 14 -1
Class-based variable memory length Markov model .	word-based variable memory length markov model ; class-based variable memory length markov model ; variable memory length markov model ; class-based probabilistic suffix tree ; word-based bi-gram model ; class-based bi-gram model ; word-based tri-gram model ; model size ; learning algorithm ; word-class relation ; nodes	<method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	3 0 1 ; 1 4 4	in this paper , we present a <method_1> and its <method_8> . this is an extension of a <method_2> . our <method_1> is based on a <otherscientificterm_3> , whose <otherscientificterm_10> have an automatically acquired <otherscientificterm_9> . we experimentally compared our new <method_1> with a <method_4> , a <method_6> , a <method_5> , and a <method_0> . the results show that a <method_1> outperforms the other models in perplexity and <otherscientificterm_7> .	1 8 11 -1 2 11 -1 3 10 9 12 11 -1 4 6 5 0 13 11 -1 7 11 -1
Joint use of dynamical classifiers and ambiguity plane features .	shorter-term context of ambiguity plane features ; explicit modeling of long-term context ; acoustically monitoring cutter wear ; sparsely labeled training data ; hidden markov model state ; dynamic statistical models ; static classification techniques ; ambiguity plane features ; classification problems ; titanium	<otherscientificterm> <task> <task> <material> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm>	7 0 5 ; 5 0 8 ; 7 0 8	this paper argues for using <otherscientificterm_7> within <method_5> for <task_8> . the relative contribution of the two <method_5> are investigated in the context of <task_2> during milling of <otherscientificterm_9> , an application where it is known that standard <method_6> work poorly . experiments show that <task_1> via a <method_4> improves performance , but mainly by using this to augment <material_3> . an additional performance gain is achieved by using the <otherscientificterm_0> .	7 5 8 11 12 13 10 -1 2 9 6 10 -1 1 4 3 10 -1 0 10 -1
Variable-length acoustic units inference for text-to-speech synthesis .	acoustic units concatenation-based systems ; variable-length phonetic descriptions ; variable-length acoustic units ; acoustic units ; tts systems ; text-to-speech synthesis ; acoustic message	<method> <material> <otherscientificterm> <method> <method> <task> <material>	3 0 4 ; 0 0 5	the best voices in <task_5> are currently obtained via <method_0> . in such <method_0> , the choice of units whose concatenations will produce an <material_6> is a crucial stage . moreover , it can be observed that current <method_4> use <method_3> which most often correspond to <material_1> . in this article , an original framework is proposed which allows the automatic determination of an optimum set of <otherscientificterm_2> .	5 0 9 7 -1 6 7 -1 4 3 1 8 7 -1 2 7 -1
Low-power hybrid structure of digital matched filters for direct sequence spread spectrum systems .	digital matched filters ; direct sequence spread spectrum systems ; 128-tap dmf ; transposed-form structure ; low-power approaches ; direct-form structure ; area overhead ; hybrid structure ; dmfs	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method>	5 1 3 ; 3 0 4 ; 5 0 7 ; 0 0 1 ; 4 0 8	1 this paper presents a low-power structure of <method_0> , which is proposed for <method_1> . traditionally , <method_4> for <method_8> are based on either the <otherscientificterm_3> or the direct-form one . a new <method_7> that employs the <otherscientificterm_5> for local addition and the <otherscientificterm_3> for global addition is used to take advantages of both structures . for a <method_2> , the proposed <method_8> that processes 32 addends a cycle consumes 46 % less power at the expense of 6 % <otherscientificterm_6> as compared to the state-of-the-art low-power <method_8> -lsb- 7 -rsb- .	0 1 13 9 -1 4 8 3 11 14 9 -1 7 5 10 12 9 -1 2 6 9 -1
Knowledge Compilation Properties of Tree-of-BDDs .	knowledge compilation form ; d-dnnf compilation ; tree width ; matching tob ; decomposition heuris-tic ; clausal entailment ; tob compilations ; cnf ; complexity	<otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <metric>	1 4 3 ; 6 4 1	we present a <method_7> to tree-of-bdds -lrb- <method_7> -rrb- compiler with <metric_8> at most exponential in the <otherscientificterm_2> . we then present algorithms for interesting queries on <method_7> . although some of the presented query algorithms are in the worst case exponential in the <otherscientificterm_2> , our experiments show that <method_7> can answer non-trivial queries like <otherscientificterm_5> in reasonable time for several realistic instances . while our tob-tool compiles all the used 91 instances , <material_1> failed for 12 or 8 of them based on the <otherscientificterm_4> used . also , on the succeeded instances , a <material_1> is up to 1000 times larger than the <method_3> . the <material_6> are often an order of magnitude faster than the <material_1> . this makes <method_7> a quite interesting <otherscientificterm_0> .	7 8 2 9 -1 9 -1 5 9 -1 1 4 9 -1 10 9 -1 3 11 9 -1 6 9 -1
Protocols for real-time multimedia data transmission over the Internet .	non-guaranteed quality of service networks ; internet protocol ; real-time multimedia data streams ; signal compression applications ; networked multimedia services ; real-time data transmission ; network protocols ; architectural elements ; coding systems	<material> <material> <material> <task> <task> <task> <method> <otherscientificterm> <method>	2 0 0 ; 7 0 5	the explosive growth of the internet and the intranets have attracted a great deal of attention to the implementation and performance of <task_4> . which involve the transport of <material_2> over <material_0> based on the <material_1> . in this paper , i present an overview of the existing <otherscientificterm_7> supporting <task_5> over the internet . effective implementations of such systems require a thorough understanding of both the <method_6> and the <method_8> used for compressing the signals to be transmitted in real-time . the paper includes a section discussing the issues to be considered in designing <task_3> suitable for network use .	4 9 -1 2 0 1 10 9 -1 7 5 11 9 -1 6 8 9 -1 3 9 -1
Automatic Identification of Learners ' Language Background Based on Their Writing in Czech .	automatic identification of the learners ' l1 background ; speakers of indo-european languages ; non-content based features ; highly inflectional data ; svm classifier ; inflectional czech ; binary classification ; written data ; precision ; features ; recall ; orthography ; czech	<task> <material> <otherscientificterm> <material> <method> <material> <task> <material> <metric> <otherscientificterm> <metric> <task> <material>	3 0 2 ; 4 0 6 ; 8 1 10	the goal of this study is to investigate whether learners ' <material_7> in highly <material_5> can suggest a consistent set of clues for <task_0> . for our experiments , we use texts written by learners of <material_12> , which have been automatically and manually annotated for errors . we define two classes of learners : <material_1> and speakers of non-indo-european languages . we use an <method_4> to perform the <task_6> . we show that <otherscientificterm_2> perform well on <material_3> . in particular , <otherscientificterm_9> reflecting errors in <task_11> are the most useful , yielding about 89 % <metric_8> and the same <metric_10> . a detailed discussion of the best performing <otherscientificterm_9> is provided .	7 5 0 13 -1 12 13 -1 1 13 -1 4 6 15 13 -1 2 3 14 13 -1 9 11 8 16 13 -1 10 13 -1
A new class of lifting wavelet transform for guaranteeing losslessness of specific signals .	losslessness of specific signals ; rounding of signal values ; white balance signals ; lifting wavelet transform ; scaling coefficient values ; lossy coding ; lifting steps ; 9/7 wavelet ; scaling pairs ; white balance ; wavelet transform ; lossless coding ; lsi processors ; losslessness	<otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	10 0 2 ; 1 1 4 ; 3 0 0 ; 8 0 5	this paper proposes a new class of <method_3> which can guarantee <otherscientificterm_0> , e.g. <otherscientificterm_9> . the 5/3 <otherscientificterm_10> composed of two <method_6> can reconstruct an input signal without any loss and has been utilized for <method_11> . the <otherscientificterm_7> contains two more <method_6> and two <method_8> for effective <method_5> . however the <otherscientificterm_13> is not guaranteed due to <otherscientificterm_1> and <otherscientificterm_4> . this paper analyzes condition on word length -lrb- wl -rrb- and bit depth -lrb- bd -rrb- for the <otherscientificterm_13> and proposes a new class of <otherscientificterm_10> with '' dc lossless '' property which is a kind of specific <otherscientificterm_13> . this can be utilized as a standard condition for algorithms or <method_12> to guarantee no error from the <otherscientificterm_10> for <material_2> .	3 0 9 17 14 -1 10 6 11 14 -1 7 8 5 18 14 -1 13 1 4 16 14 -1 14 -1 15 14 -1
Minimizing energy functions on 4-connected lattices using elimination .	energy minimization algorithm ; multilabel problems ; binary problem ; 4-connected lattices ; eliminated variables ; elimination algorithm ; submodular problems ; nodes ; submodular ; alpha-expansion ; functions ; back-substitution ; max-flow ; images ; graph-cuts/max-flow ; graph	<method> <task> <task> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm>	9 0 1 ; 14 0 10 ; 5 0 0 ; 0 0 10 ; 0 0 2 ; 3 0 0 ; 0 0 6	we describe an <method_0> for <otherscientificterm_10> defined on <otherscientificterm_3> , of the type usually encountered in problems involving <material_13> . such <otherscientificterm_10> are often minimized using <method_14> , but this <method_0> is only applicable to <task_6> . in this paper , we describe an <method_0> that will solve any <task_2> , irrespective of whether it is <otherscientificterm_8> or not , and for <task_1> we use <otherscientificterm_9> . the <method_0> is based on the <method_5> , which eliminates <otherscientificterm_7> from the <otherscientificterm_15> until the remaining function is <otherscientificterm_8> . it can then be solved using <otherscientificterm_12> . values of <otherscientificterm_4> are recovered using <otherscientificterm_11> . we compare the <method_0> 's performance against alternative methods for solving <task_6> , with favourable results .	0 10 3 13 20 22 16 -1 14 6 18 16 -1 2 8 1 9 17 21 16 -1 5 7 15 19 16 -1 12 16 -1 4 16 -1 11 23 16 -1
Sparse Random Feature Algorithm as Coordinate Descent in Hilbert Space .	o -lrb- 1 / ϵ 2 -rrb- convergence ; ℓ 1-regularized objective function ; infinite-dimensional ℓ 1-regularized problem ; regression and classification tasks ; memory and prediction time ; sparse random features algorithm ; greedy boosting step ; sparse non-linear predictor ; randomized coordinate descent ; kernel method ; infinite-dimensional space ; random features ; kernel function ; approximate solver ; boosting approach ; hilbert space	<otherscientificterm> <otherscientificterm> <task> <task> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm>	5 0 7 ; 5 4 14 ; 13 0 2 ; 8 0 5	in this paper , we propose a <method_5> , which learns a <method_7> by minimizing an <otherscientificterm_1> over the <otherscientificterm_15> induced from a <method_12> . by interpreting the <method_5> as <otherscientificterm_8> in an <otherscientificterm_10> , we show the proposed <method_5> converges to a solution within ϵ-precision of that using an exact <method_9> , by drawing o -lrb- 1 / ϵ -rrb- random features , in contrast to the <otherscientificterm_0> achieved by current monte-carlo analyses of <material_11> . in our experiments , the <method_5> obtains a sparse solution that requires less <metric_4> , while maintaining comparable performance on <task_3> . moreover , as an <method_13> for the <task_2> , the <method_5> also enjoys better convergence guarantees than a <method_14> in the setting where the <otherscientificterm_6> can not be performed exactly .	5 7 1 15 12 17 16 -1 8 10 9 0 11 20 16 -1 4 3 16 -1 18 19 16 -1
Improving the Robustness of Deep Neural Networks via Stability Training .	general stability training method ; computer vision tasks ; common image processing ; small input distortions ; large-scale near-duplicate detection ; deep neural networks ; visual input ; inception architecture ; similar-image ranking ; neural network ; small perturbations ; noisy datasets ; feature embeddings ; deep architectures ; cropping ; rescaling ; classification ; compression	<method> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	4 1 8 ; 17 1 15 ; 8 1 16 ; 15 6 2 ; 12 3 9 ; 15 1 14 ; 8 1 11 ; 17 6 2 ; 14 6 2	in this paper we address the issue of output instability of <method_5> : <otherscientificterm_10> in the <otherscientificterm_6> can significantly distort the <otherscientificterm_12> and output of a <method_9> . such instability affects many <method_13> with state-of-the-art performance on a wide range of <task_1> . we present a <method_0> to stabilize <method_5> against <otherscientificterm_3> that result from various types of <method_2> , such as <otherscientificterm_17> , <otherscientificterm_15> , and <otherscientificterm_14> . we validate our method by stabilizing the state-of-the-art <method_7> -lsb- 11 -rsb- against these types of distortions . in addition , we demonstrate that our stabilized model gives robust state-of-the-art performance on <task_4> , <task_8> , and <task_16> on <material_11> .	5 10 6 12 9 23 18 -1 13 1 18 -1 0 3 2 17 15 14 20 22 24 26 27 18 -1 7 18 -1 19 21 25 18 -1
Zero-Shot Learning via Visual Abstraction .	zero-shot learning ; human pose dataset ; fine-grained visual categories ; difficult-to-describe concepts ; abstract visualizations ; visual concepts ; training data ; visual abstraction ; modality ; gaze ; concepts	<task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 6 ; 1 0 8 ; 8 0 6 ; 7 0 8	one of the main challenges in learning <otherscientificterm_2> is gathering training images . recent work in <task_0> circumvents this challenge by describing categories via attributes or text . however , not all <otherscientificterm_5> , e.g. , two people dancing , are easily amenable to such descriptions . in this paper , we propose a new <otherscientificterm_8> for <task_0> using <otherscientificterm_7> to learn <otherscientificterm_3> . specifically , we explore <otherscientificterm_10> related to people and their interactions with others . our proposed <otherscientificterm_8> allows one to provide <material_6> by manipulating <otherscientificterm_4> , e.g. , one can illustrate interactions between two clipart people by manipulating each person 's pose , expression , <otherscientificterm_9> , and gender . the feasibility of our <otherscientificterm_8> is shown on a <material_1> and a new dataset containing complex interactions between two people , where we outperform several baselines . to better match across the two domains , we learn an explicit mapping between the abstract and real worlds .	2 11 -1 0 11 -1 5 11 -1 8 7 3 15 11 -1 10 11 -1 6 4 12 14 11 -1 9 13 11 -1 1 11 -1
Coverage-Optimized Retrieval .	recommender systems ; retrieval set ; similarity-based retrieval	<method> <material> <task>	2 0 0	we present a generalization of <task_2> in <method_0> which ensures that for any case that is acceptable to the user , the <material_1> contains a case that is at least as good in an objective sense and so also likely to be acceptable . our approach recognizes that similarity to the target query is only one of several possible criteria according to which a given case might be considered at least as good as another .	2 0 1 4 3 -1 3 -1
A preconditioned Forward-Backward approach with application to large-scale nonconvex spectral unmixing problems .	nonconvex spectral unmixing problem ; non necessarily smooth function ; alternating minimization strategy ; lipschitz differen-tiable function ; optimization problems ; variable metrics ; optimization problem ; majorize-minimize principle ; inverse problems ; forward-backward algorithm ; large-size signals ; criterion	<task> <otherscientificterm> <method> <otherscientificterm> <task> <metric> <task> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	7 0 5 ; 9 0 6 ; 10 3 4	many <otherscientificterm_8> require to minimize a <otherscientificterm_11> being the sum of a <otherscientificterm_1> and a <otherscientificterm_3> . such an <task_6> can be solved with the <method_9> which can be accelerated thanks to the use of <metric_5> derived from the <otherscientificterm_7> . the convergence of this approach is guaranteed provided that the <otherscientificterm_11> satisfies some additional technical conditions . combining this method with an <method_2> will be shown to allow us to address a broad class of <task_4> involving <material_10> . an application example to a <task_0> will be presented .	8 11 1 3 12 -1 6 9 5 7 13 14 12 -1 12 -1 2 4 10 15 12 -1 0 12 -1
Sparse loading noisy PCA using an l0 penalty .	model based sparse principal component analysis method ; bayesian information criterion ; associated model selection method ; sparse pca method ; l 0 penalty ; generalized em algorithm ; iterative hard thresholding ; dna microarray data ; simulated data ; estimation method	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <material> <material> <method>	5 1 6 ; 9 4 3 ; 5 0 9 ; 6 0 9 ; 6 1 5 ; 7 0 3 ; 8 1 7 ; 8 0 3 ; 1 0 9	in this paper we present a novel <method_0> based on the <otherscientificterm_4> . we develop an <method_9> based on the <method_5> and <method_6> and an <method_2> based on <otherscientificterm_1> . the <method_9> is compared to a previous <method_3> using both <material_8> and <material_7> .	0 4 10 -1 9 5 6 2 1 11 13 14 15 19 10 -1 3 8 7 12 16 17 18 10 -1
Learning by Stretching Deep Networks .	stretched deep convolutional networks ; fixed network architecture ; object recognition tasks ; deep convolutional architectures ; weight matrix ; iterative manner ; ai tasks ; tractable algorithms ; deep architectures ; stretching ; backpropagation ; learning ; accuracy	<method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <method> <method> <task> <metric>	0 0 2 ; 5 2 3 ; 7 0 9	in recent years , <method_8> have gained a lot of prominence for <task_11> complex <task_6> because of their capability to incorporate complex variations in data within the model . however , these models often need to be trained for a long time in order to obtain good results . in this paper , we propose a technique , called ` stretch-ing ' , that allows the same models to perform considerably better with very little training . we show that <task_11> can be done tractably , even when the <otherscientificterm_4> is stretched to infinity , for some specific models . we also study <method_7> for implementing <method_9> in <otherscientificterm_3> in an <method_5> and derive bounds for its convergence . our experimental results suggest that the proposed <method_0> are capable of achieving good performance for many <task_2> . more importantly , for a <method_1> , one can achieve much better <metric_12> using <method_9> rather than <task_11> the weights using <method_10> .	8 11 6 13 -1 13 -1 13 -1 4 13 -1 15 16 13 -1 7 9 3 5 14 13 -1 0 2 13 -1
A differential entropy based method for determining the optimal embedding parameters of a signal .	synthetic time series ; phase space representation ; optimal embedding dimension ; time-delay neural network ; differential entropy ; adaptive filter ; embedding parameters ; time lag	<material> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	5 1 3 ; 2 1 7	a novel method for determining the set of parameters for a <method_1> of a time series is proposed . based upon the <otherscientificterm_4> , both the <otherscientificterm_2> , and <otherscientificterm_7> , are simultaneously determined . the choice of these parameters is closely related to the length of the optimal tap input delay line of an <method_5> or <method_3> . the method employs a single criterion -- the '' entropy ratio '' between the <method_1> of a signal and an ensemble of its surrogates -- and is first systematically tested on <material_0> for which the optimal <otherscientificterm_6> are known , after which it is verified on a number of benchmark real-world time series . the proposed entropy ratio method is shown to consistently outperform some well-established methods .	1 8 -1 4 2 7 10 8 -1 5 3 9 8 -1 0 6 8 -1 8 -1
Effect of initial phase in two tone separation using empirical mode decomposition .	empirical mode decomposition ; nonlinear and nonstationary signal processing ; tone separation problem ; theoretical background ; initial phase ; amplitude ratio ; adaptive method ; transition region ; frequency ratio	<method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric>	6 0 1 ; 0 0 2 ; 8 1 4 ; 0 6 6 ; 0 0 1	empirical mode decomposition -lrb- <method_0> -rrb- is an <method_6> for <task_1> . although the <method_6> is easy to implement and widely deployed , its <otherscientificterm_3> and limitations remain uncertain . this paper investigates the performance of <method_0> in two <task_2> , especially for the <otherscientificterm_7> between perfect separation and failure , with emphasis on the effect of the <otherscientificterm_4> . relationships between <otherscientificterm_5> , <metric_8> , <otherscientificterm_4> and performance are derived .	0 6 1 10 13 14 9 -1 3 9 -1 2 7 4 11 9 -1 5 8 12 9 -1
A Study of Information Retrieval Weighting Schemes for Sentiment Analysis .	support vector machines classifier ; document frequency smoothing ; feature weighting schemes ; binary unigram weights ; term frequency weights ; classification accuracy ; data sets ; information retrieval ; sublinear function ; sentiment analysis ; tf.idf scheme ; accuracy	<method> <task> <method> <otherscientificterm> <task> <metric> <material> <task> <otherscientificterm> <method> <method> <metric>	4 1 1 ; 8 0 4 ; 7 0 5 ; 3 2 0 ; 7 0 2 ; 8 0 1 ; 2 0 5	most <method_9> approaches use as baseline a <method_0> with <otherscientificterm_3> . in this paper , we explore whether more sophisticated <method_2> from <task_7> can enhance <metric_5> . we show that variants of the classic <method_10> adapted to <method_9> provide significant increases in <metric_11> , especially when using a <otherscientificterm_8> for <task_4> and <task_1> . the techniques are tested on a wide selection of <material_6> and produce the best <metric_11> to our knowledge .	9 0 3 16 12 -1 2 7 5 15 17 19 12 -1 10 11 8 4 1 13 14 18 12 -1 6 12 -1
Binaural deep neural network classification for reverberant speech segregation .	noisy and reverberant environments ; multisource and reverberant conditions ; dnn based binaural classification ; binaural speech segregation ; speech segregation algorithms ; deep neural networks ; human listening ; untrained configurations ; auditory scenes ; binary classification ; robustness	<otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <task> <otherscientificterm> <material> <method> <metric>	10 2 3 ; 9 0 10 ; 9 0 3	while <task_6> is robust in complex <material_8> , current <method_4> do not perform well in <otherscientificterm_0> . this paper addresses the <metric_10> in <task_3> by employing <method_9> based on <method_5> -lrb- dnns -rrb- . we systematically examine <method_2> to <otherscientificterm_7> . evaluations and comparisons show that <method_2> produces superior segregation performance in a variety of <otherscientificterm_1> .	6 8 4 0 11 -1 10 3 9 5 12 13 14 11 -1 2 7 11 -1 1 11 -1
Bayesian Active Appearance Models .	statistical models of shape and texture ; active appearance models ; calculation of texture parameters ; generic fitting scenarios ; latent texture space ; cost function ; bayesian formulation ; probabilistic model ; gaussian noise ; shape parameters ; gaussian prior ; simultaneous algorithms ; texture generation	<method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	8 1 10 ; 11 0 1 ; 5 0 9 ; 4 2 10 ; 8 1 4 ; 1 6 0 ; 1 0 3 ; 7 0 12 ; 6 0 0	in this paper we provide the first , to the best of our knowledge , <method_6> of one of the most successful and well-studied <method_0> , i.e. <method_1> . to this end , we use a simple <method_7> for <task_12> assuming both <otherscientificterm_8> and a <otherscientificterm_10> over a <otherscientificterm_4> . we retrieve the <otherscientificterm_9> by formulating a novel <otherscientificterm_5> obtained by marginalizing out the <otherscientificterm_4> . this results in a fast implementation when compared to other <method_11> for fitting <method_1> , mainly due to the removal of the <otherscientificterm_2> . we demonstrate that , contrary to what is believed regarding the performance of <method_1> in <task_3> , optimization of the proposed <otherscientificterm_5> produces results that outperform discriminatively trained state-of-the-art methods in the problem of facial alignment '' in the wild '' .	6 0 1 19 22 13 -1 7 12 8 10 4 14 17 18 21 13 -1 9 5 16 13 -1 11 2 15 13 -1 20 13 -1
Error Mining in Parsing Results .	missing and erroneous information ; automatically detecting errors ; pre-parsing processing chain ; error mining technique ; syntactic lexicon ; parsing systems ; parsing	<otherscientificterm> <task> <method> <method> <otherscientificterm> <task> <task>	4 1 2 ; 3 0 5 ; 3 0 6	we introduce an <method_3> for <task_1> in resources that are used in <task_5> . we applied this <method_3> on <task_6> results produced on several million words by two distinct <task_5> , which share the <otherscientificterm_4> and the <method_2> . we were thus able to identify <otherscientificterm_0> in these resources .	3 1 5 9 7 -1 6 4 2 8 10 7 -1 0 7 -1
Regression Model Fitting under Differential Privacy and Model Inversion Attack .	polynomial representation of the objective function ; differential privacy preserving regression models ; differential privacy preserving regression model ; sensitive and non-sensitive attributes ; differential privacy mechanisms ; model inversion attacks ; attribute privacy ; model utility ; model efficacy ; theoretical analysis ; privacy budget ; released model ; functional mechanism	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <method>	4 0 5 ; 3 0 2 ; 11 0 5	differential privacy preserving regression models guarantee protection against attempts to infer whether a subject was included in the training set used to derive a model . it is not designed to protect <otherscientificterm_6> of a target individual when <otherscientificterm_5> are launched . in <otherscientificterm_5> , an adversary uses the <method_11> to make predictions of sensitive attributes -lrb- used as input to the model -rrb- of a target individual when some background information about the target individual is available . previous research showed that existing <method_4> can not effectively prevent <otherscientificterm_5> while retaining <metric_8> . in this paper , we develop a novel approach which leverages the <method_12> to perturb coefficients of the <method_0> but effectively balances the <otherscientificterm_10> for <otherscientificterm_3> in learning the <method_2> . <method_9> and empirical evaluations demonstrate our approach can effectively prevent <otherscientificterm_5> and retain <method_7> .	13 -1 6 5 13 -1 11 16 13 -1 4 8 14 13 -1 15 13 -1 12 0 10 3 2 9 13 -1
Semantic Segmentation Using Multiple Graphs with Block-Diagonal Constraints .	image semantic segmentation ; learning affinity matrix ; real-world image datasets ; multi-view affinity graph ; closed form solution ; affinity matrix ; semantic space ; visual spaces ; dissimilar superpixels ; pairwise potential ; semantic label ; unlabeled images ; label-confidence matrix ; block-diagonal constraints ; divide-and-conquer strategy ; optimization	<task> <task> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <method>	13 0 5 ; 9 0 8 ; 5 1 12 ; 6 0 3 ; 15 0 1	in this paper we propose a novel method for <task_0> using multiple graphs . the <method_3> is constructed by leveraging the consistency between <otherscientificterm_6> and multiple <otherscientificterm_7> . with <otherscientificterm_13> , we enforce the <otherscientificterm_5> to be sparse such that the <otherscientificterm_9> for <otherscientificterm_8> is close to zero . by a <method_14> , the <method_15> for <task_1> is decomposed into several subproblems that can be solved in parallel . using the neighborhood relationship between superpixels and the consistency between <otherscientificterm_5> and <otherscientificterm_12> , we infer the <otherscientificterm_10> for each superpixel of <material_11> by minimizing an objective whose <method_4> can be easily obtained . experimental results on two <material_2> demonstrate the effectiveness of our method .	0 16 -1 3 6 7 20 16 -1 13 5 9 8 17 18 16 -1 14 15 1 21 16 -1 12 10 11 4 19 16 -1 16 -1
Distinguishing second harmonic generation images of mouse preterm labor via wavelet-based texture features .	second harmonic generation microscopy images ; detecting mouse preterm labor ; premature cervical remodeling ; normal pregnant cervix ; wavelet-based texture features ; image processing system ; artificial collagen gels ; shg microscopy ; shg images ; texture features ; image features ; image processing ; detection rates ; features ; images ; mifepristone	<material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <material> <method>	9 0 11 ; 9 0 7 ; 4 0 7 ; 5 0 1 ; 10 0 4 ; 2 6 8 ; 15 6 8 ; 0 0 5 ; 10 0 7	this paper presents an <method_5> for <task_1> using <material_0> . two classes of <material_8> are considered : <otherscientificterm_3> and <otherscientificterm_2> induced by <method_15> . among the commonly used <otherscientificterm_9> in <task_11> , <otherscientificterm_4> together with previously utilized <otherscientificterm_10> for <method_7> of <otherscientificterm_6> are identified to form an effective set of <otherscientificterm_13> for distinguishing the two classes of <material_14> . the results obtained indicate that correct <metric_12> above 98 % are achievable .	5 1 0 20 24 16 -1 8 3 2 15 22 23 16 -1 9 11 4 10 7 6 13 14 17 18 19 21 25 16 -1 12 16 -1
On the Partition Function and Random Maximum A-Posteriori Perturbations .	max-statistics of random variables ; randomly perturbed models ; ragged energy landscapes ; map solvers ; map inference ; partition function ; graph-cuts	<otherscientificterm> <material> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	6 6 3 ; 1 0 4 ; 5 0 0	in this paper we relate the <otherscientificterm_5> to the <otherscientificterm_0> . in particular , we provide a novel framework for approximating and bounding the <otherscientificterm_5> using <method_4> on <material_1> . as a result , we can use efficient <method_3> such as <otherscientificterm_6> to evaluate the corresponding <otherscientificterm_5> . we show that our method excels in the typical '' high signal-high coupling '' regime that results in <otherscientificterm_2> difficult for alternative approaches .	5 0 10 7 -1 4 1 9 7 -1 3 6 8 7 -1 2 7 -1
Adaptive Hedge .	decision-theoretic online learning ; hedge algorithm ; learning rate ; simulation study ; probabilistic setting ; parameter	<task> <method> <metric> <method> <otherscientificterm> <otherscientificterm>	1 0 0	most methods for <task_0> are based on the <method_1> , which takes a <otherscientificterm_5> called the <metric_2> . in most previous analyses the <metric_2> was carefully tuned to obtain optimal worst-case performance , leading to suboptimal performance on easy instances , for example when there exists an action that is significantly better than all others . we propose a new way of setting the <metric_2> , which adapts to the difficulty of the <task_0> : in the worst case our procedure still guarantees optimal performance , but on easy instances it achieves much smaller regret . in particular , our adaptive method achieves constant regret in a <otherscientificterm_4> , when there exists an action that on average obtains strictly smaller loss than all other actions . we also provide a <method_3> comparing our approach to existing methods .	0 1 5 2 7 6 -1 6 -1 6 -1 6 -1 4 6 -1
Estimation of voice source and vocal tract characteristics based on multi-frame analysis .	multi-frame analysis method ; source-filter separation ; harmonic structure ; iterative approximation ; oversimplified models ; transfer function ; signal processing ; voiced speech	<method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <material>	5 3 6	this paper presents a new approach for estimating voice source and vocal tract filter characteristics of <material_7> . when it is required to know the <otherscientificterm_5> of a system in <task_6> , the input and output of the system are experimentally observed and used to calculate the function . however , in the case of <task_1> we deal with in this paper , only the output -lrb- speech -rrb- is observed and the characteristics of the system -lrb- vocal tract -rrb- and the input -lrb- voice source -rrb- must simultaneously be estimated . hence the estimate becomes extremely difficult , and it is usually solved approximately using <method_4> . we demonstrate that these characteristics are separable under the assumption that they are independently controlled by different factors . the separation is realised using an <method_3> along with the <method_0> , which we have proposed to find spectral envelopes of <material_7> with minimum interference of the <otherscientificterm_2> .	7 8 -1 5 6 9 8 -1 1 8 -1 8 -1 4 8 -1 8 -1
Acoustic target classification using distributed sensor arrays .	non-stationarity of target signatures ; distributed sensor arrays ; data fusion algorithm ; target classification ; data fusion ; accuracy	<otherscientificterm> <otherscientificterm> <method> <task> <method> <metric>	2 0 1 ; 1 0 3 ; 5 5 3	target <task_3> using <otherscientificterm_1> remains a challenging problem due to the <otherscientificterm_0> , large geographical area coverage of sensor arrays , and the requirements of time-critical and reliable information delivery . in this paper , we develop an algorithm to derive effective and stable features from both the frequency and the time-frequency domains of the acoustic signals . a modified <method_2> for <otherscientificterm_1> is also developed in order to integrate the <task_3> results from different sensors and provide fault-tolerance . by using <method_4> , the <metric_5> of the <task_3> can be increased by as many as 50 % .	3 1 0 8 6 -1 6 -1 2 7 6 -1 4 5 9 6 -1
Less is More : Significance-Based N-gram Selection for Smaller , Better Language Models .	significance-based n-gram selection ; modified kneser-ney smoothing ; selection method ; smoothing methods ; weighted-difference pruning ; smoothing method ; absolute discounting ; pruning method ; model size ; katz back-off ; perplexity	<method> <task> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <metric>	2 4 7 ; 8 1 10 ; 5 1 4 ; 9 1 6 ; 7 0 1 ; 9 6 3 ; 10 5 2 ; 6 6 3	the recent availability of large corpora for training n-gram language models has shown the utility of models of higher order than just trigrams . in this paper , we investigate methods to control the increase in <otherscientificterm_8> resulting from applying standard methods at higher orders . we introduce <method_0> , which not only reduces <otherscientificterm_8> , but also improves <metric_10> for several <method_3> , including <method_9> and <method_6> . we also show that , when combined with a new <method_5> and a novel variant of <method_4> , our <method_2> performs better in the trade-off between <otherscientificterm_8> and <metric_10> than the best <method_7> we found for <task_1> .	11 -1 8 11 -1 0 10 3 9 6 15 17 19 11 -1 5 4 2 12 13 14 16 18 11 -1
Minimum Proof Graphs and Fastest-Cut-First Search Heuristics .	approximations of sub-dag values ; game tree search algorithm ; heuristic evaluation time ; minimum proof graphs ; arbitrary dag inputs ; fastest-cut-first search heuristics ; minimum proof graph ; minimum game tree ; interior nodes ; linear time ; branching factor ; game tree ; minimax values ; nodes ; alpha-beta ; graphs	<otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	14 6 1 ; 5 0 3 ; 10 6 11	alpha-beta is the most common <method_1> , due to its high-performance and straightforward implementation . in practice one must find the best trade-off between <metric_2> and bringing the subset of <otherscientificterm_13> explored closer to a <otherscientificterm_6> . in this paper we present a series of structural properties of <method_3> that help us to prove that finding such <otherscientificterm_15> is np-hard for <otherscientificterm_4> , but can be done in <otherscientificterm_9> for trees . we then introduce the class of <method_5> that aim to approximate <method_3> by sorting moves based on <otherscientificterm_0> and sizes . to explore how various aspects of the <method_11> -lrb- such as <otherscientificterm_10> and distribution of move values -rrb- affect the performance of <method_14> we introduce the class of '' prefix value game trees '' that allows us to label <otherscientificterm_8> with true <otherscientificterm_12> on the fly without search . using these trees we show that by explicitly attempting to approximate a <method_7> we are able to achieve performance gains over <method_14> with common extensions .	1 17 16 -1 2 13 6 16 -1 3 15 4 9 16 -1 5 0 18 16 -1 19 16 -1 11 10 14 8 12 16 -1
Refining the Wrapper Approach - Smoothed Error Estimates for Feature Selection .	estimates of posterior probabilities ; leave-one-out error estimate ; posterior probability estimates ; classification error ; wrapper approach ; bayesian estimators ; error estimate ; bayesian estimation ; conjugate priors ; feature selection ; leave-one-out estimate ; error count ; bias ; jackknife	<otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <metric> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 2 5 ; 10 0 3 ; 0 0 11 ; 8 2 7 ; 13 0 12 ; 4 0 9	in the <method_4> for <task_9> , a popular criterion used is the <method_10> of the <otherscientificterm_3> . while being relatively unbiased , the <method_1> is nonetheless known to exhibit a large variance , which can be detrimental especially for small samples . we propose reducing its variance -lrb- i.e. smoothing -rrb- at two levels . at the first level , we smooth the <otherscientificterm_11> using <otherscientificterm_0> ; while at the second level , we smooth the <task_2> themselves using <method_7> with <otherscientificterm_8> . furthermore , we propose using the <otherscientificterm_13> to reduce the <otherscientificterm_12> inherent in <method_5> . we then show empirically that smoothing the <metric_6> gives improved performance in <task_9> .	4 9 10 3 16 20 14 -1 1 14 -1 14 -1 11 0 2 7 8 17 18 14 -1 13 12 5 15 19 14 -1 14 -1
Line Net Global Vectorization : an Algorithm and Its Performance Evaluation .	continuous vectorization of a line net ; degradation of image quality ; vectorizing line drawings ; graphic entity ; global algorithm ; seed segment ; raster image ; theoretical analysis ; vectorization algorithms ; entity ; noise ; tracking ; postprocessing ; vectorization	<otherscientificterm> <metric> <task> <otherscientificterm> <method> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task>	4 1 13 ; 4 0 3 ; 6 0 3 ; 4 0 2	in this paper , an efficient <method_4> for <task_2> is presented . <method_4> first extracts a <otherscientificterm_5> of a <otherscientificterm_3> from a <material_6> to obtain its direction and width , then tracks the pixels under the guidance of the direction so that the <task_11> can track through junctions and is not affected by <otherscientificterm_10> and <metric_1> . thus , an <otherscientificterm_9> will be vectorized in one step without <otherscientificterm_12> . the relations among lines are also used to realize the <otherscientificterm_0> . the speed and quality of <task_13> are greatly improved with this <method_4> . the performance evaluation is carried out both by <method_7> and by experiments . comparisons with other <method_8> are also made .	4 2 18 14 -1 5 3 6 11 10 1 16 17 14 -1 9 12 14 -1 0 14 -1 13 15 14 -1 14 -1 7 14 -1
Pitch-dependent GMMs for text-independent speaker recognition systems .	ergodic hidden markov models ; gaussian mixture models ; speaker recognition systems ; speaker 's identity ; long-term prosodic features ; short-term acoustic vectors ; statistical approach ; prosodic features ; pitch-dependent gmms	<method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	0 0 5 ; 1 1 0 ; 5 0 2 ; 8 0 6	gaussian mixture models -lrb- gmms -rrb- and <method_0> have been successfully applied to model <otherscientificterm_5> for <task_2> . <otherscientificterm_7> are known to carry information concerning the <otherscientificterm_3> and <otherscientificterm_7> can be combined with the <otherscientificterm_5> in order to increase the performance of the <task_2> . in this paper , a <method_6> using <method_8> for modeling speakers is presented . this new <method_6> is capable of simultaneously modeling the statistical distributions of the <otherscientificterm_5> and <otherscientificterm_4> .	0 5 2 7 10 11 9 -1 3 12 9 -1 6 8 13 9 -1 4 1 9 -1
The support vector decomposition machine .	singular value decomposition ; machine learning problems ; two-phase approaches ; fmri analysis ; classification algorithm ; dimensionality reduction ; lower-dimensional representations ; features ; classifier	<method> <task> <method> <task> <method> <method> <method> <otherscientificterm> <method>	4 0 8 ; 6 4 2 ; 7 2 1	in <task_1> with tens of thousands of <otherscientificterm_7> and only dozens or hundreds of independent training examples , <method_5> is essential for good learning performance . in previous work , many researchers have treated the <task_1> in two separate phases : first use an algorithm such as <method_0> to reduce the dimensionality of the data set , and then use a <method_4> such as na &#239; ve bayes or support vector machines to learn a <method_8> . we demonstrate that it is possible to combine the two goals of <method_5> and classification into a single learning objective , and present a novel and efficient algorithm which optimizes this objective directly . we present experimental results in <task_3> which show that we can achieve better learning performance and <method_6> than <method_2> can .	1 7 5 12 9 -1 0 4 8 10 9 -1 9 -1 11 9 -1
3D face recognition based on evolution of iso-geodesic distance curves .	evolution of iso-geodesic distance curves ; 3d face recognition method ; non-neutral face database ; evolution angle functions ; evolution angle function ; iso-geodesic distance curves ; weight function ; one-dimensional function ; euclidean invariant ; non-neutral faces ; neutral faces ; 3d face	<task> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 6 7 ; 10 1 9 ; 0 0 1	this paper presents a novel <method_1> by means of the <task_0> . specifically , the proposed <method_1> compares two neighboring <otherscientificterm_5> , and formalizes the evolution between them as a <otherscientificterm_7> , named <otherscientificterm_4> , which is <otherscientificterm_8> . the novelty of this paper consists in formalizing <otherscientificterm_11> by an <otherscientificterm_3> , and in computing the distance between two faces by that of two functions . experiments on face recognition grand challenge -lrb- frgc -rrb- ver2 .0 shows that our <method_1> works very well on both <otherscientificterm_10> and <otherscientificterm_9> . by introducing a <otherscientificterm_6> , we also show a very promising result on <material_2> .	1 0 15 12 -1 5 7 4 8 13 12 -1 11 3 12 -1 10 9 14 12 -1 6 12 -1
2-d Processing of Speech with Application to Pitch Estimation .	grating compression transform '' ; one-dimensional speech signal ; 2-d transformation maps harmonically-related signal components ; short-space 2-d fourier transform magnitude ; two-dimensional processing ; sine-wave-based pitch estimator ; additive white noise ; two-speaker pitch estimation ; gct-based pitch estimator ; sine-wave grating patterns ; speech pitch estimator ; smeared impulses ; time-frequency plane ; all-voiced speech ; gct plane ; narrowband spectrogram ; 2-d plane ; radial distance ; spectrogram	<method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 2 13 ; 0 6 10 ; 5 0 13 ; 8 4 5 ; 5 0 6	in this paper , we introduce a new approach to <task_4> of the <otherscientificterm_1> in the <otherscientificterm_12> . specifically , we obtain the <otherscientificterm_3> of a <otherscientificterm_15> of the signal and show that this <method_2> to a concentrated entity in the new <otherscientificterm_16> . we refer to this series of operations as the '' <method_0> , consistent with <otherscientificterm_9> in the <otherscientificterm_18> reduced to <otherscientificterm_11> . the <method_0> forms the basis of a <method_10> that uses the <otherscientificterm_17> to the largest peak in the <otherscientificterm_14> . using an average magnitude difference between pitch-contour estimates , the <method_8> is shown to compare favorably to a <method_5> for <material_13> in <otherscientificterm_6> . an extension to a basis for <task_7> is also proposed .	4 1 12 19 -1 3 15 2 16 19 -1 0 9 18 11 19 -1 10 17 14 21 19 -1 8 20 22 23 24 19 -1 5 13 6 19 -1
A Rate-Splitting Approach To Robust Multiuser MISO Transmission .	max-min degrees of freedom ; channel state information ; rate-splitting strategy ; classical robust design problems ; power minimization problem ; non-saturating max-min rate ; transmit power constraint ; multiuser miso systems ; non-scaling uncertainty regions ; rate constraint ; power minimization ; bounded uncertainties ; uncertainty regions ; feasibility problem ; rs-based designs ; multiuser interference ; snr ; precoders	<otherscientificterm> <task> <method> <task> <task> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <method>	17 0 0 ; 14 0 12 ; 0 6 8 ; 0 0 4 ; 15 2 13 ; 15 2 0 ; 0 0 14 ; 0 4 0 ; 6 1 10 ; 9 0 10 ; 11 2 7	for <method_7> with <otherscientificterm_11> in the <task_1> , we consider two <task_3> : maximizing the minimum rate subject to a <otherscientificterm_6> , and <method_10> under a <otherscientificterm_9> . contrary to conventional strategies , we propose a <method_2> where each message is divided into two parts , a common part and a private part . all common parts are packed into one super common message encoded using a shared codebook and decoded by all users , while private parts are independently encoded and retrieved by their corresponding users . we prove that <method_14> achieve higher <otherscientificterm_0> compared to conventional designs -lrb- <otherscientificterm_0> -rrb- for <otherscientificterm_12> that scale with <method_16> . for the special case of <otherscientificterm_8> , <otherscientificterm_0> contrasts with <otherscientificterm_0> and achieves a <metric_5> . in the <task_4> , <otherscientificterm_0> is shown to combat the <task_13> arising from <otherscientificterm_15> in <otherscientificterm_0> . a robust design of <method_17> for <otherscientificterm_0> is proposed , and performance gains over <otherscientificterm_0> are demonstrated through simulations .	7 11 1 3 6 10 9 27 28 29 18 -1 2 18 -1 18 -1 14 0 20 25 18 -1 12 16 21 26 18 -1 8 5 22 23 24 18 -1 4 13 15 19 18 -1
A Sparse Combined Regression-Classification Formulation for Learning a Physiological Alternative to Clinical Post-Traumatic Stress Disorder Scores .	post-traumatic stress disorder ; sparse combined regression-classification ; automated physiology-based objective diagnostic method ; predicting binary diagnostic decisions ; diagnostic score validity ; physiological ptsd score ; sparse combined regression-classification ; predicting physiological score ; virtual reality videos ; generic learning approaches ; peripheral physiology measures ; physiological diagnostic score ; binary diagnostic decisions ; cost function ; learning formulation ; peripheral physiology ; clinician-coded interview ; heart rate ; physiological score ; ptsd diagnosis ; mental pathologies ; learning generalizability ; classification	<task> <method> <method> <task> <metric> <metric> <method> <task> <material> <method> <method> <metric> <task> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <metric> <task> <task> <metric> <task>	10 0 3 ; 4 1 21 ; 22 0 13 ; 15 0 19 ; 6 4 9 ; 1 0 18 ; 8 1 15	current diagnostic methods for <task_20> , including <task_0> , involve a <method_16> , which can be subjective . <metric_17> and skin conductance , as well as other <method_10> , have previously shown utility in <task_3> . the <task_12> is easier , but misses important information on the severity of the patients condition . this work utilizes a novel experimental setup that exploits <material_8> and <otherscientificterm_15> for <task_19> . in pursuit of an <method_2> , we propose a <method_14> that integrates the description of the experimental data and expert knowledge on desirable properties of a <metric_11> . from a list of desired criteria , we derive a new <otherscientificterm_13> that combines regression and <task_22> while learning the salient features for <task_7> . the <metric_18> produced by <method_1> is assessed with respect to three sets of criteria chosen to reflect design goals for an objective , <metric_5> : parsimony and context of selected features , <metric_4> , and <metric_21> . for these criteria , we demonstrate that <method_6> performs better than more <method_9> .	20 0 16 17 23 -1 10 3 24 23 -1 12 23 -1 8 15 19 27 30 23 -1 2 14 11 23 -1 26 23 -1 13 22 7 25 29 23 -1 18 1 5 4 21 28 23 -1
Video anomaly recovery from compressed spectral imaging .	principal component pursuit ; 3-channel spectral video system ; spectrally compressed video frames ; recovery of video anomalies ; video surveillance applications ; recovery of anomalies ; g g g ; 2-d spatial information ; 3-d data cube ; analysis of anomalies ; spectrally compressed video ; video anomaly recovery ; sparse matrix ; stationary background ; cassi system ; 2-d measurement ; spectral signatures ; spectral information	<method> <method> <material> <task> <task> <task> <method> <otherscientificterm> <otherscientificterm> <task> <material> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	17 3 15 ; 10 0 16 ; 7 2 8 ; 2 0 11 ; 9 0 4 ; 14 0 8 ; 7 1 17 ; 17 2 8	this paper addresses the problem of <task_11> from a sequence of <material_2> . <task_9> occurring in both time and spectrum is important in <task_4> . we present a methodology for the <task_5> such as moving objects and their <otherscientificterm_16> from <material_10> . the <material_2> are obtained by using a coded aperture snapshot spectral imaging -lrb- cassi -rrb- system . the <method_14> encodes a <otherscientificterm_8> containing both <otherscientificterm_7> and <otherscientificterm_17> in a single <method_15> . in the proposed methodology , we use the <material_10> as columns of a large data matrix g g g. <method_0> is then used to decompose <method_6> into the <otherscientificterm_13> and a <otherscientificterm_12> capturing the anomalies in the foreground . the <otherscientificterm_12> is then used jointly with <method_6> to recover the <otherscientificterm_17> of the objects of interest . an example for the <task_3> in a <method_1> -lrb- rgb -rrb- is presented .	11 2 9 22 18 -1 4 23 18 -1 5 16 10 20 18 -1 18 -1 14 8 7 17 15 19 21 24 25 26 18 -1 0 6 18 -1 13 12 18 -1 18 -1
Shape Gradients for Histogram Segmentation using Active Contours .	segmentation of color histograms ; minimization of the distance ; region and boundary functionals ; classical calculus of variation ; shape derivative approach ; color histogram ; image segmentation ; region integrals ; theoretical framework ; video sequences ; numerical scheme ; evolution equation ; active contours ; active contour ; energy criterion ; image features ; statistical features ; derivative ; histograms	<task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	12 0 6 ; 4 0 6 ; 8 0 0 ; 8 0 1 ; 18 0 1	we consider the problem of <task_6> using <otherscientificterm_12> through the minimization of an <otherscientificterm_14> involving both <otherscientificterm_2> . these <task_6> are derived through a <method_4> instead of <otherscientificterm_3> . the <task_6> can be elegantly derived without converting the <otherscientificterm_7> into boundary integrals . from the <otherscientificterm_17> , we deduce the <otherscientificterm_11> of an <otherscientificterm_13> that makes it evolve towards a minimum of the criterion . we focus more particularly on <otherscientificterm_16> globally attached to the region and especially to the probability density functions of <otherscientificterm_15> such as the <otherscientificterm_5> of a region . a <method_8> is set for the <task_1> between two <method_18> for matching or tracking purposes . an application of this <method_8> to the <task_0> in <material_9> is then proposed . we briefly describe our <method_10> and show some experimental results .	6 12 14 2 20 19 -1 4 3 21 19 -1 7 19 -1 17 11 13 19 -1 16 15 5 19 -1 8 1 23 24 19 -1 18 22 19 -1 0 9 19 -1
A small footprint hybrid statistical/unit selection text-to-speech synthesis system for agglutinative languages .	unit selection based text-to-speech synthesis ; hybrid statistical unit selection tts system ; hmm-based tts approach ; intelligi-bility and quality scores ; baseline hts system ; a/b preference tests ; blizzard challenge tests ; unit selection scheme ; agglutinative languages ; embedded devices ; memory footprint ; speech	<method> <method> <method> <metric> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	4 4 4 ; 3 5 4 ; 8 0 4 ; 6 5 4 ; 2 0 9 ; 1 0 8 ; 5 5 4 ; 1 0 4	despite its success , <method_0> has has some disadvantages such as sudden discontinuities in <material_11> that distract the listeners . the <method_2> has been increasingly getting more attention from the tts research community . one of the advantage is the lack of spurious errors that are observed in the <method_7> . another advantage of the <method_2> is the small <otherscientificterm_10> requirement which makes <method_2> attractive for <otherscientificterm_9> . here , we propose a novel <method_1> for <otherscientificterm_8> that aims at improving the quality of the <method_4> while keeping the <otherscientificterm_10> small . the <metric_3> of the <method_4> are comparable to the mos scores of english reported in the <material_6> . listeners preferred the <method_4> over the <method_4> in the <otherscientificterm_5> .	0 11 12 -1 2 12 -1 7 12 -1 10 9 17 12 -1 1 8 4 15 18 20 12 -1 3 14 16 12 -1 6 13 19 12 -1
Introducing Geometry in Active Learning for Image Segmentation .	electron microscopy and magnetic resonance image volumes ; 3d image volumes ; natural 2d images ; active learning approach ; 2d planar patch ; segmentation classifier ; geometric priors ; annotation process ; annotation	<material> <material> <material> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm>	3 0 5 ; 6 0 7 ; 6 0 5 ; 5 0 7 ; 0 5 3 ; 3 0 6	we propose an <method_3> to training a <method_5> that exploits <otherscientificterm_6> to streamline the <task_7> in <material_1> . to this end , we use these priors not only to select voxels most in need of <otherscientificterm_8> but to guarantee that they lie on <otherscientificterm_4> , which makes it much easier to annotate than if they were randomly distributed in the volume . a simplified version of this <method_3> is effective in <material_2> . we evaluated our <method_3> on <material_0> , as well as on <material_2> . comparing our <method_3> against several accepted baselines demonstrates a marked performance increase .	3 5 6 7 1 10 11 12 13 15 9 -1 8 4 9 -1 2 9 -1 0 14 9 -1 9 -1
IRIS template protection using a digital modulation paradigm .	digital modulation paradigm ; biometric recognition systems ; template protection ; modulation constellations ; verification rates ; casia-irisv4 database ; iris biometrics ; template security ; turbo codes ; biometric cryptosystem ; intra-class variability ; soft-decoding ; security ; iris	<method> <task> <task> <otherscientificterm> <metric> <material> <task> <task> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <otherscientificterm>	0 0 7 ; 3 1 8 ; 11 2 3 ; 4 1 12 ; 9 0 6 ; 13 6 10 ; 5 5 9 ; 11 2 8 ; 2 3 1	template protection is an issue of paramount importance in the design of <task_1> . in this paper we present a <method_9> applied to <task_6> , where <task_7> is guaranteed by means of a framework inspired by the <method_0> . specifically , the properties of <otherscientificterm_3> and <otherscientificterm_8> with <method_11> are exploited to design a <method_9> with high performance in terms of both <metric_4> and <metric_12> , even while dealing with a <task_6> characterized by a high <otherscientificterm_10> such as the <otherscientificterm_13> . the effectiveness of the proposed <method_9> is evaluated by performing tests on the interval subset of the <material_5> .	1 23 14 -1 9 6 7 0 15 19 14 -1 3 8 11 4 12 10 13 16 17 18 20 22 14 -1 5 21 14 -1
Multi-scale Improves Boundary Detection in Natural Images .	boundary and object datasets ; multi-scale boundary detection problem ; local boundary cues ; poor localization ; small-scale detection ; natural images ; relative contrast ; single-scale approaches ; boundary detection ; human-marked groundtruth ; large-scale detection ; contrast ; localization ; classifier ; clutter	<material> <task> <otherscientificterm> <method> <task> <material> <otherscientificterm> <method> <task> <material> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	11 1 12 ; 10 1 3 ; 9 2 0 ; 12 1 6 ; 12 6 2 ; 1 4 7 ; 11 6 2 ; 6 6 2 ; 3 1 4 ; 10 1 4	in this work we empirically study the <task_1> in <material_5> . we utilize <otherscientificterm_2> including <otherscientificterm_11> , <otherscientificterm_12> and <otherscientificterm_6> , and train a <method_13> to integrate them across scales . our approach successfully combines strengths from both <task_10> -lrb- robust but <method_3> -rrb- and <task_4> -lrb- detail-preserving but sensitive to <otherscientificterm_14> -rrb- . we carry out quantitative evaluations on a variety of <material_0> with <material_9> . we show that <task_1> offers large improvements , ranging from 20 % to 50 % , over <method_7> . this is the first time that multi-scale is demonstrated to improve <task_8> on large datasets of <material_5> .	1 5 15 -1 2 11 12 6 13 16 19 20 22 23 15 -1 10 3 4 14 17 24 25 15 -1 0 9 18 15 -1 7 21 15 -1 8 15 -1
Non-Stationary Policy Learning in 2-Player Zero Sum Games .	adversarial zero-sum matrix games ; on-line sequence learning algorithm ; construction of agents ; on-line learning methods ; entropy pruning technique ; adversarial relationship ; multiagent environments ; non-stationary policies ; non-stationary policy ; elph	<otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	9 6 1	a key challenge in <otherscientificterm_6> is the <task_2> that are able to learn while acting in the presence of other agents that are simultaneously learning and adapting . these domains require <method_3> without the benefit of repeated training examples , as well as the ability to adapt to the evolving behavior of other agents in the environment . the difficulty is further exacerbated when the agents are in an <otherscientificterm_5> , demanding that a robust -lrb- i.e. winning -rrb- <otherscientificterm_8> be rapidly learned and adapted . we propose an <method_1> , <method_9> , based on a straightforward <method_4> that is able to rapidly learn and adapt to <otherscientificterm_7> . we demonstrate the performance of this <method_1> in a non-stationary learning environment of <otherscientificterm_0> .	6 2 10 -1 3 10 -1 5 8 10 -1 1 9 4 11 10 -1 7 10 -1
Optimal linear feature transformations for semi-continuous hidden Markov models .	lower dimensional subspace ; linear selection methods ; optimal feature reduction ; uniform statistical framework ; maximum-likelihood estimation problem ; recognition accuracy ; mapping features	<otherscientificterm> <method> <method> <method> <task> <metric> <task>	4 0 2 ; 5 5 1	linear discriminant or karhunen-lo eve transforms are established techniques for <task_6> into a <otherscientificterm_0> . this paper introduces a <method_3> , where the computation of the <method_2> is formalized as a <task_4> . the experimental evaluation of this suggested extension of <method_1> shows a slight improvement of the <metric_5> .	6 0 7 -1 3 2 4 8 7 -1 1 5 9 7 -1
Multi-microphone noise cancellation for improvement of hearing aid performance .	least mean squares algorithm ; acoustic speech and noise data ; binaural pre-processing of speech signals ; noise ratios ; simulated and real-room acoustics ; linear hearing aid ; hearing impaired volunteers ; noise cancellation ; processing mechanism ; speech signals ; acoustic environments ; signal characteristics ; wide-band signal ; sub-bands	<method> <material> <task> <metric> <otherscientificterm> <task> <task> <task> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 3 ; 0 0 9 ; 2 0 5	a scheme for <task_2> for input to a standard <task_5> has been investigated . the system is based on that of toner & campbell -lsb- l -rsb- who applied the <method_0> in <otherscientificterm_13> to <material_9> from various <otherscientificterm_10> and signal to <metric_3> . the processing scheme attempts to take advantage of the multiple inputs to perform <task_7> . the use of <otherscientificterm_13> enables a diverse <method_8> to be employed , where the <otherscientificterm_12> is split into smaller frequency limited <otherscientificterm_13> , which can subsequently he processed according to their <otherscientificterm_11> . the results of a large scale series of intelligibility tests are presented from experiments in which <material_1> , generated using <otherscientificterm_4> was tested on <task_6> .	2 5 17 14 -1 0 13 9 10 3 15 16 14 -1 7 14 -1 8 12 11 14 -1 14 -1
Line Buffer Wordlength Analysis for Line-Based 2-D DWT .	wordlength of line buffer ; on-chip line buffer ; line buffer wordlength ; line-based 2-d dwt ; overflow of coefficients ; round-off errors ; dynamic range ; reconstructed image ; analysis methodology ; psnr	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <metric>	8 0 0 ; 1 0 3	the <otherscientificterm_1> dominates the total area and power of <method_3> . therefore , the <otherscientificterm_2> has to be carefully designed to maintain the quality level due to the <otherscientificterm_6> growing and the <otherscientificterm_5> . in this paper , a complete <method_8> is proposed to derive the required <otherscientificterm_0> given the desired quality level of <material_7> . the proposed <method_8> can guarantee to avoid <otherscientificterm_4> , and the difference between predicted and experimental quality level is averagely 0.06 db in terms of <metric_9> .	1 3 12 10 -1 2 6 5 10 -1 8 0 7 11 10 -1 4 9 10 -1
Large-scale biophysical parameter estimation in single neurons via constrained linear regression .	spatial distribution of channel densities ; spatiotemporal pattern of synaptic input ; input-output function of single cells ; biophysically accurate multi-compartmental models ; noise level 5 -rrb- ; voltage sensitive imaging techniques ; spatiotemporal voltage signal ; constrained linear regression ; reversal potentials ; automatic estimation ; in-tercompartmental conductances ; noise level ; model datasets ; hand tuning ; accuracy	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <method> <metric>	0 1 1 ; 10 1 11	our understanding of the <otherscientificterm_2> has been substantially advanced by <method_3> . the large number of parameters needing <method_13> in these <method_3> has , however , somewhat hampered their applicability and inter-pretability . here we propose a simple and well-founded method for <task_9> of many of these key parameters : 1 -rrb- the <otherscientificterm_0> on the cell 's membrane ; 2 -rrb- the <otherscientificterm_1> ; 3 -rrb- the channels ' <otherscientificterm_8> ; 4 -rrb- the <otherscientificterm_10> ; and 5 -rrb- the <otherscientificterm_11> in each compartment . we assume experimental access to : a -rrb- the <otherscientificterm_6> in the dendrite -lrb- or some contiguous subpart thereof , e.g. via <method_5> -rrb- , b -rrb- an approximate kinetic description of the channels and synapses present in each compartment , and c -rrb- the morphology of the part of the neuron under investigation . the key observation is that , given data a -rrb- - c -rrb- , all of the parameters 1 -rrb- -4 -rrb- may be simultaneously inferred by a version of <method_7> ; this <method_7> , in turn , is efficiently solved using standard algorithms , without any '' local minima '' problems despite the large number of parameters and complex dynamics . the <metric_4> may also be estimated by standard techniques . we demonstrate the method 's <metric_14> on several <material_12> , and describe techniques for quantifying the uncertainty in our estimates .	2 3 15 -1 13 15 -1 9 0 1 8 10 11 16 17 15 -1 6 15 -1 5 15 -1 7 15 -1 15 -1
Image interpolation with directionlets .	directionally adaptive image interpolation ; numeric and visual quality ; sharpness of details ; multiple-direction wavelet transform ; low-resolution image ; interpolated image ; high-resolution image ; edge information ; directional features ; directionlets	<method> <metric> <otherscientificterm> <otherscientificterm> <material> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 7 ; 1 5 0 ; 9 6 3 ; 9 0 8 ; 0 0 8 ; 9 0 0 ; 3 0 0	we present a novel <method_0> based on a <otherscientificterm_3> , called <otherscientificterm_9> . the <method_0> uses <otherscientificterm_9> to efficiently capture <otherscientificterm_8> and to extract <otherscientificterm_7> along different directions from the <material_4> . then , the <material_6> is generated using this information to preserve <otherscientificterm_2> . our <method_0> outperforms the state-of-the-art methods in terms of both <metric_1> of the <material_5> .	0 3 9 13 17 10 -1 8 7 4 11 14 15 16 10 -1 6 2 10 -1 1 5 12 10 -1
Beyond cross-entropy : towards better frame-level objective functions for deep neural network training in automatic speech recognition .	large vocabulary continuous speech recognition ; deep neural network frame-level training ; relative word error rate reduction ; cross-entropy trained dnn system ; log posterior ratio ; cross-entropy objective function ; output layer ; switchboard task ; objective function ; softmax activation	<task> <task> <metric> <method> <metric> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	0 0 0 ; 2 5 3 ; 5 0 0 ; 9 1 5	we propose two approaches for improving the <otherscientificterm_8> for the <task_1> in <task_0> . the <task_0> used in <task_0> are often constructed with an <otherscientificterm_6> with <otherscientificterm_9> and the <otherscientificterm_5> is always employed in the frame-leveling training of <task_0> . the pairing of <otherscientificterm_9> and <otherscientificterm_5> contributes much in the success of <task_0> . the first approach developed in this paper improves the <otherscientificterm_5> by boosting the importance of the frames for which the <task_0> has low target predictions -lrb- low target posterior probabilities -rrb- and the second one considers jointly minimizing the cross-entropy and maximizing the <metric_4> between the target senone -lrb- tied-triphone states -rrb- and the most competing one . experiments on <task_7> demonstrate that the two proposed methods can provide 3.1 % and 1.5 % <metric_2> , respectively , against the already very strong conventional <method_3> .	8 1 0 10 -1 6 9 5 11 10 -1 13 14 10 -1 4 10 -1 12 10 -1
A study of probabilistic models for characterizing human heart beat dynamics in autonomic blockade control .	dynamic respiratory sinus arrhythmia analysis ; adaptive point process filtering paradigm ; index of vagal control dynamics ; human heart beat intervals ; analysis of autonomic control ; instantaneous rsa gain ; inverse gaussian model ; respiratory covariate measurements ; kolmogorov-smirnov test ; electrocardiogram data ; probabilistic models	<method> <method> <otherscientificterm> <material> <task> <otherscientificterm> <method> <method> <otherscientificterm> <material> <method>	6 0 5 ; 7 1 0 ; 6 0 4 ; 1 1 8	in this paper , we compare and validate different <method_10> of <material_3> for assessment of the <material_9> recorded with varying conditions in posture and pharmacological autonomic blockade . the models are validated using the <method_1> and <otherscientificterm_8> . the <method_6> was found to achieve the overall best performance in the <task_4> . we further improve the <method_6> by incorporating the <method_7> and present <method_0> . our results suggest the <otherscientificterm_5> computed from our proposed <method_6> as a potential <otherscientificterm_2> .	10 3 9 11 -1 1 8 15 11 -1 6 4 14 11 -1 7 0 13 11 -1 5 2 12 11 -1
Markov Models for Automated ECG Interval Analysis .	hidden markov and hidden semi-markov models ; overcomplete representation of the signal ; constituent waveform features ; hidden semi-markov models ; hidden markov model ; undecimated wavelet transform ; real ecg features ; state duration modelling ; electrocardiogram waveform ; state durations	<method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	5 0 1 ; 3 0 7	we examine the use of <method_0> for automatically segmenting an <otherscientificterm_8> into its <otherscientificterm_2> . an <otherscientificterm_5> is used to generate an <otherscientificterm_1> that is more appropriate for subsequent modelling . we show that the <otherscientificterm_9> implicit in a standard <method_4> are ill-suited to those of <otherscientificterm_6> , and we investigate the use of <method_3> for improved <method_7> .	0 8 2 10 -1 5 1 11 10 -1 9 4 6 3 7 12 10 -1
Reversed speech comprehension depends on the auditory efferent system functionality .	contralateral suppression of otoacoustic emissions ; degraded speech comprehension ; high and low level mechanisms ; medial olivocochlear bundle functionality ; degraded speech restoration ; low-level auditory mechanisms ; degraded speech ; physiological properties ; speech degradation ; auditory system ; reversion windows ; higher-level strategies ; lexical benefit ; interindividual variability ; pseudowords	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	5 0 4	in the present study we explore the implication of <otherscientificterm_2> in <otherscientificterm_1> in normal hearing subjects . in experiment 1 we compared the loss of intelligibility due to the increasing size of <otherscientificterm_10> in both words and <method_14> . results showed that words are generally reconstructed better than <method_14> , suggesting the existence of a <otherscientificterm_12> in <task_4> . moreover , there was greater variability between individuals when reconstructing <method_14> than words . in experiment 2 , we demonstrated that this <otherscientificterm_13> correlated with the subjects ' <otherscientificterm_3> , as measured by <method_0> . together these experiments highlight the importance of <method_5> in <task_4> . moreover they put forward the existence of major <otherscientificterm_13> in the capacity to reconstruct <material_6> , which correlates with the <otherscientificterm_7> of the <method_9> -lrb- low-level property -rrb- . in addition , our results also suggest the existence of multiple <method_11> that can compensate on-line for the lack of information caused by <otherscientificterm_8> .	2 1 15 -1 10 14 15 -1 12 4 15 -1 15 -1 13 3 0 15 -1 16 15 -1 5 15 -1 6 7 9 15 -1
Accurate positioning system based on street view recognition .	dynamically recognizing shop or building signs ; robust and accurate position estimation ; view-angle invariant distance estimation ; street view recognition ; m error estimation ; real user location ; gps scale data ; visual recognition technique ; vision-based technique ; gps map ; path refinement	<task> <task> <task> <task> <metric> <otherscientificterm> <material> <method> <method> <otherscientificterm> <method>	8 0 0 ; 7 1 6 ; 2 1 10	in this paper , an accurate and robust positioning system based on <task_3> is introduced . <method_8> is employed for <task_0> on the <otherscientificterm_9> . two mechanisms including <task_2> and <method_10> are proposed for <task_1> . through the combination of <method_7> and <material_6> , the <otherscientificterm_5> can be accurately inferred . experimental results demonstrate that the proposed system is reliable and feasible . compared with 20m error of position estimation provided by the gps , our system only has 0.97 <metric_4> .	3 8 11 -1 0 9 12 11 -1 2 10 1 14 11 -1 7 6 5 13 11 -1 11 -1 4 11 -1
Quasi text-independent speaker-verification based on pattern matching .	quasi text-independent speaker verification ; phonetically matched segments ; gaussian mixture models ; frame-level probabilities ; pattern matching ; speech signals ; speech recognizer	<task> <otherscientificterm> <method> <otherscientificterm> <task> <material> <method>	1 3 5	we present a new approach to <task_0> based on <task_4> . our method first seeks <otherscientificterm_1> in two <material_5> . for all aligned frame pairs of these segments we compute the probability that they were uttered by the same speaker . based on these <otherscientificterm_3> we take the decision whether the two signals were spoken by the same speaker or not . our method to find <otherscientificterm_1> does not depend on a <method_6> . we show that our system performs better than a baseline speaker verification system based on <method_2> when the signals are long enough . especially interesting is the fact that a combination of the devised system with the baseline system performs much better than either of the systems alone .	0 4 7 -1 1 5 8 7 -1 7 -1 3 7 -1 6 7 -1 2 7 -1 7 -1
Solving Everyday Physical Reasoning Problems by Analogy Using Sketches .	understanding common sense reasoning ; everyday physical reasoning problems ; bennett mechanical comprehension test ; qualitative reasoning research ; comparative analysis problems ; qualitative mechanics ; sketch annotations ; conceptual quantities ; physical world ; modeling decisions ; analogy	<task> <task> <material> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	8 2 0 ; 10 0 4 ; 5 1 10 ; 0 6 3	understanding common sense reasoning about the <otherscientificterm_8> is one of the goals of <task_3> . this paper describes how we combine <method_5> and <otherscientificterm_10> to solve <task_1> posed as sketches . the problems are drawn from the <material_2> , which is used to evaluate technician candidates . we discuss <task_6> , which define <otherscientificterm_7> in terms of visual measurements , how <task_9> are made by <otherscientificterm_10> , and how <otherscientificterm_10> can be used to frame <task_4> . experimental results support the plausibility of this approach .	8 3 12 15 11 -1 5 10 1 14 11 -1 2 11 -1 6 7 9 4 13 11 -1 0 11 -1
Translation Assistance by Translation of L1 Fragments in an L2 Context .	native language fragments ; foreign language fragments ; high-quality translation suggestions ; statistical language modelling ; translation assistance system ; second language learning ; word-sense dis-ambiguation baselines ; cross-lingual context ; contex-tual window ; translation assistance ; l2 context ; code switches ; classification-based approach ; language learners ; l2	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method>	7 0 2 ; 2 0 6 ; 3 1 6	in this paper we present new research in <task_9> . we describe a system capable of translating <otherscientificterm_0> to <otherscientificterm_1> in an <otherscientificterm_10> . practical applications of this research can be framed in the context of <task_5> . the type of <method_4> under investigation here encourages <method_13> to write in their target language while allowing them to fall back to their native language in case the correct word or expression is not known . these <otherscientificterm_11> are subsequently translated to <method_14> given the <otherscientificterm_10> . we study the feasibility of exploiting <otherscientificterm_7> to obtain <otherscientificterm_2> that improve over <method_3> and <otherscientificterm_6> . a <method_12> is presented that is indeed found to improve significantly over these baselines by making use of a <otherscientificterm_8> spanning a small number of neighbouring words .	9 15 -1 0 1 10 15 -1 5 15 -1 4 13 15 -1 11 14 15 -1 7 2 3 16 17 18 15 -1 6 15 -1
A corpus-based Chinese speech synthesis with contextual dependent unit selection .	corpus-based chinese speech synthesis system ; prosody parameter prediction ; unit selection procedure ; speaker 's utterances ; prosody feature modification ; corpus design ; synthesized speech ; synthesis unit ; context similarity	<method> <method> <method> <material> <method> <method> <material> <otherscientificterm> <otherscientificterm>	0 0 7 ; 2 6 0 ; 5 6 0 ; 5 1 2 ; 1 1 4	this paper describes the realization of a <method_0> , including the <method_5> and <method_2> . the <method_0> selects the <otherscientificterm_7> according to <otherscientificterm_8> between target unit and candidate unit . neither <method_1> nor <method_4> is needed . the informal test shows that the <material_6> is quite natural , and the speaking style of original speaker is preserved because units are all from the <material_3> .	0 5 2 11 12 13 9 -1 7 8 10 9 -1 1 4 14 9 -1 6 3 9 -1
Region Ranking SVM for Image Classification .	region evaluation function ; image classification algorithm ; pooling local information ; feature type ; ilsvrc2014 datasets ; local regions ; local information ; global decision ; average-pooling ; max-pooling ; image	<method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	8 1 9 ; 6 3 7	the success of an <method_1> largely depends on how it incorporates <otherscientificterm_6> in the <otherscientificterm_7> . popular approaches such as <method_8> and <method_9> are suboptimal in many situations . in this paper we propose region ranking svm -lrb- rrsvm -rrb- , a novel method for <task_2> from multiple regions . rrsvm exploits the correlation of <otherscientificterm_5> in an <otherscientificterm_10> , and it jointly learns a <method_0> and a scheme for integrating multiple regions . experiments on pascal voc 2007 , voc 2012 , and <material_4> show that rrsvm outperforms the methods that use the same <otherscientificterm_3> and extract features from the same set of <otherscientificterm_5> . rrsvm achieves similar to or better than the state-of-the-art performance on all datasets .	1 6 7 13 11 -1 8 9 12 11 -1 2 11 -1 5 10 0 11 -1 4 3 11 -1 11 -1
Ordinal Regression via Manifold Learning .	ordinal regression of high order data ; fixed , discrete rating scale ; ordinal regression approach ; high-dimensional feature space ; embedded nonlinear structure ; natural tensor structure ; machine learning ; implied rating ; intrinsic geometry ; ordinal regression ; data sets ; manifold learning ; data item ; ordinal regression ; images	<material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <task> <material>	2 0 9 ; 13 0 6 ; 11 0 2 ; 2 0 0 ; 10 5 2	ordinal regression is an important research topic in <task_6> . it aims to automatically determine the <otherscientificterm_7> of a <otherscientificterm_12> on a <otherscientificterm_1> . in this paper , we present a novel <method_2> via <method_11> , which is capable of uncovering the <otherscientificterm_4> of the data set according to the observations in the <otherscientificterm_3> . by optimizing the order information of the observations and preserving the <otherscientificterm_8> of the data set simultaneously , the proposed <method_2> provides the faithful <otherscientificterm_9> to the new coming data points . to offer more general solution to the data with <otherscientificterm_5> , we further introduce the multilinear extension of the proposed <method_2> , which can support the <material_0> like <material_14> . experiments on various <material_10> validate the effectiveness of the proposed <method_2> as well as its extension .	6 17 15 -1 7 12 1 15 -1 2 11 4 3 18 15 -1 8 9 16 15 -1 5 19 15 -1 0 14 20 15 -1
Rate-Agnostic -LRB- Causal -RRB- Structure Learning .	causal structure learning algorithms ; observed measurement data ; causal structure learning ; time series data ; dynamic causal graphs ; causal structure ; timescale mismatch ; extant algorithms ; undersampling	<method> <material> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	4 0 1 ; 0 0 4 ; 3 0 2 ; 1 0 4 ; 0 0 5	causal structure learning from <material_3> is a major scientific challenge . <method_7> assume that measurements occur sufficiently quickly ; more precisely , they assume approximately equal system and measurement timescales . in many domains , however , measurements occur at a significantly slower rate than the underlying system changes , but the size of the <otherscientificterm_6> is often unknown . this paper develops three <method_0> , each of which discovers all <otherscientificterm_4> that explain the <material_1> , perhaps given <method_8> . that is , these <method_0> all learn <otherscientificterm_5> in a `` rate-agnostic '' manner : they do not assume any particular relation between the measurement and system timescales . we apply these <method_0> to data from simulations to gain insight into the challenge of <method_8> .	3 7 12 9 -1 9 -1 6 9 -1 0 4 1 8 10 11 13 9 -1 5 14 9 -1 9 -1
Scalable Discrete Sampling as a Multi-Armed Bandit Problem .	synthetic and real-world large-scale problems ; multi-armed bandits problems ; large-scale inference problems ; finite reward population ; monte carlo methods ; large-scale bayesian inference ; discrete random variable ; sampling algorithms ; discrete distribution ; subsampling approach ; graphical models ; theoretical guarantees ; approximate algorithms ; approximate solution ; robustness	<task> <task> <task> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <metric>	12 0 0 ; 0 5 12 ; 5 1 10 ; 6 0 5 ; 14 5 12 ; 6 0 10 ; 9 0 13	drawing a sample from a <otherscientificterm_8> is one of the building components for <method_4> . like other <method_7> , <otherscientificterm_8> also suffers from high computational burden in <task_2> . we study the problem of sampling a <otherscientificterm_6> with a high degree of dependency that is typical in <task_5> and <method_10> , and propose an efficient <method_13> with a <method_9> . we make a novel connection between the <otherscientificterm_8> and <task_1> with a <otherscientificterm_3> and provide three algorithms with <otherscientificterm_11> . empirical evaluations show the <metric_14> and efficiency of the <method_12> in both <task_0> .	8 4 15 -1 7 2 15 -1 6 5 10 13 9 18 19 21 22 15 -1 1 3 11 15 -1 14 12 0 16 17 20 15 -1
Detection of overlapping acoustic events using a temporally-constrained probabilistic model .	event class-wise hidden markov models ; equivalent rectangular bandwidth spectrogram ; temporal succession of the templates ; polyphonic datasets of office sounds ; temporal evolution of sound events ; real and synthesized monophonic datasets ; probabilistic latent component analysis ; succession of spectral templates ; overlapping acoustic event detection ; frame-based and event-based metrics ; sound event dictionary ; acoustic scene simulator ; input time/frequency representation	<method> <method> <otherscientificterm> <material> <task> <material> <method> <otherscientificterm> <task> <method> <material> <method> <method>	8 0 4 ; 11 0 3 ; 0 0 10	in this paper , a system for <task_8> is proposed , which models the <task_4> . the system is based on <method_6> , supporting the use of a <material_10> where each exemplar consists of a <otherscientificterm_7> . the <otherscientificterm_2> is controlled through <method_0> . as <method_12> , the <method_1> is used . experiments are carried out on <material_3> generated using an <method_11> , as well as <material_5> for comparative purposes . results show that the proposed system outperforms several state-of-the-art methods for <task_8> on the same task , using both <method_9> , and is robust to varying event density and noise levels .	8 4 14 13 -1 6 10 7 13 -1 2 0 16 13 -1 12 1 13 -1 3 11 5 15 13 -1 9 13 -1
Action Recognition with a Bio-inspired Feedforward Motion Processing Model : The Richness of Center-Surround Interactions .	center-surround interactions of mt cells ; functional properties of mt cells ; bio -- inspired models ; action recognition task ; average recognition rate ; defining motion maps ; v1-mt cortical layers ; cortical cells ; visual space ; weizmann database ; motion representation ; classification method ; brain mechanisms ; velocity detectors ; mt level ; foveated structure ; action recognition ; motion pathway ; complex videos ; mt cells ; motion contrasts ; feedforward model ; feature vectors ; neurophysiology	<otherscientificterm> <otherscientificterm> <method> <task> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	4 5 11 ; 10 0 3 ; 10 0 14 ; 4 5 9 ; 7 0 8 ; 11 0 5 ; 22 0 5 ; 11 0 22	here we show that reproducing the <otherscientificterm_1> with various center -- surround interactions enriches <method_10> and improves the <task_16> performance . to do so , we propose a simplified bio -- inspired model of the <otherscientificterm_17> in primates : it is a <method_21> restricted to <otherscientificterm_6> , <otherscientificterm_7> cover the <otherscientificterm_8> with a <otherscientificterm_15> and , more importantly , we reproduce some of the richness of <otherscientificterm_0> . interestingly , as observed in <otherscientificterm_23> , our <otherscientificterm_19> not only behave like simple <method_13> , but also respond to several kinds of <otherscientificterm_20> . results show that this diversity of <method_10> at the <otherscientificterm_14> is a major advantage for an <task_3> . <task_5> as our <otherscientificterm_22> , we used a standard <method_11> on the <material_9> : we obtained an <metric_4> of 98.9 % , which is superior to the recent results by jhuang et al. -lrb- 2007 -rrb- . these promising results encourage us to further develop <method_2> incorporating other <method_12> and cortical layers in order to deal with more <material_18> .	1 10 16 24 -1 17 21 6 7 8 15 0 29 24 -1 23 19 13 20 24 -1 26 27 24 -1 14 3 5 25 28 30 31 32 24 -1 22 11 9 4 24 -1
Why Minimax Works : An Alternative Explanation .	deeper searches ; position values ; value dependence ; minimax principle ; pathological behavior ; game tree ; game trees ; heuristic function ; game-playing programs ; pathology ; noise ; minimax	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 8	in <method_8> relying on the <method_3> , <method_0> generally produce better evaluations . theoretical analyses , however , suggest that in many cases minimaxing amplifies the <otherscientificterm_10> introduced by the <otherscientificterm_7> used to evaluate the leaves of the <otherscientificterm_5> , leading to what is known as <otherscientificterm_4> , where <method_0> produce worse evaluations . in most of the previous research , positions were evaluated as losses or wins . dependence between the values of positions close to each other was identified as the property of realistic <otherscientificterm_6> that eliminates the <otherscientificterm_9> and explains why <otherscientificterm_11> is successful in practice . in this paper we present an alternative explanation that does not rely on <otherscientificterm_2> . we show that if real numbers are used for <otherscientificterm_1> , <otherscientificterm_1> tend to be further apart at lower levels of the <otherscientificterm_5> , which leads to a larger proportion of more extreme positions , where error is less probable . decreased probability of error in searches to greater depths is sufficient to eliminate the <otherscientificterm_9> and no additional properties of <otherscientificterm_6> are required .	8 3 0 13 12 -1 10 7 5 4 12 -1 12 -1 6 9 11 12 -1 12 -1 2 12 -1 1 12 -1
Graphical Models for Inference with Missing Data .	` missingness graphs ; consistent estimator ; formal representation ; causal mechanisms ; missingness ; graph	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 4 ; 0 6 2 ; 2 0 3	we address the problem of recoverability i.e. deciding whether there exists a <method_1> of a given relation q , when data are missing not at random . we employ a <method_2> called <method_0> ' to explicitly portray the <otherscientificterm_3> responsible for <otherscientificterm_4> and to encode dependencies between these <otherscientificterm_3> and the variables being measured . using this <method_2> , we derive conditions that the <otherscientificterm_5> should satisfy to ensure recoverability and devise algorithms to detect the presence of these conditions in the <otherscientificterm_5> .	1 6 -1 2 0 3 4 7 8 9 6 -1 5 6 -1
Generalized Method-of-Moments for Rank Aggregation .	generalized method-of-moments algorithms ; classical minorize-maximization algorithm ; consistent and inconsistent breakings ; generalized moment conditions ; statistical efficiency ; plackett-luce model ; full rankings ; pairwise comparisons	<method> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm>	7 0 0 ; 6 0 7 ; 0 4 1 ; 0 0 5 ; 6 0 0	in this paper we propose a class of efficient <method_0> for computing parameters of the <method_5> , where the data consists of <otherscientificterm_6> over alternatives . our <method_0> is based on breaking the <otherscientificterm_6> into <otherscientificterm_7> , and then computing parameters that satisfy a set of <otherscientificterm_3> . we identify conditions for the output of <method_0> to be unique , and identify a general class of <otherscientificterm_2> . we then show by theory and experiments that our <method_0> run significantly faster than the <method_1> , while achieving competitive <metric_4> .	0 5 6 12 8 -1 7 3 9 10 13 8 -1 2 8 -1 1 4 11 8 -1
Entropy-based criterion in categorical clustering .	heterogeneity of clusters ; clustering categorical data ; probabilistic clustering models ; entropy-type measures ; dissimilarity co-efficients ; entropy-based criterion ; partitions	<otherscientificterm> <task> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 1 ; 3 0 0	entropy-type measures for the <otherscientificterm_0> have been used for a long time . this paper studies the <otherscientificterm_5> in <task_1> . it first shows that the <otherscientificterm_5> can be derived in the formal framework of <method_2> and establishes the connection between the criterion and the approach based on <otherscientificterm_4> . an iterative monte-carlo procedure is then presented to search for the <otherscientificterm_6> minimizing the criterion . experiments are conducted to show the effectiveness of the proposed procedure .	0 9 7 -1 5 1 8 7 -1 2 4 7 -1 6 7 -1 3 7 -1
Lookahead-based algorithms for anytime induction of decision trees .	anytime induction of decision trees ; learning decision trees ; depth-k lookahead ; greedy algorithms ; constructed tree ; tree quality ; stochastic version ; time allocation ; decision trees ; learning time ; lookahead-based algorithms ; id3 ; tree	<task> <task> <method> <method> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm>	10 0 0 ; 5 1 9	the majority of the existing algorithms for <task_1> are greedy -- a <otherscientificterm_12> is induced top-down , making locally optimal decisions at each node . in most cases , however , the <otherscientificterm_4> is not globally optimal . furthermore , the <method_3> require a fixed amount of time and are not able to generate a better <otherscientificterm_12> if additional time is available . to overcome this problem , we present two <method_10> for <task_0> , thus allowing tradeoff between <metric_5> and <metric_9> . the first one is <method_2> , where a larger <otherscientificterm_7> permits larger k . the second algorithm uses a novel strategy for evaluating candidate splits ; a <method_6> of <method_11> is repeatedly invoked to estimate the size of the <otherscientificterm_12> in which each split results , and the one that minimizes the expected size is preferred . experimental results indicate that for several hard concepts , our proposed approach exhibits good anytime behavior and yields significantly better <otherscientificterm_8> when more time is available .	1 12 13 -1 4 13 -1 3 13 -1 10 0 5 9 14 15 13 -1 2 7 13 -1 13 -1 6 11 13 -1
Scalable Algorithms for Tractable Schatten Quasi-Norm Minimization .	singular value decomposition ; frobenius/nuclear hybrid and bi-nuclear quasi-norms ; eigenvalue decomposition ; schatten-p quasi-norm minimization algorithms ; representative matrix completion problems ; synthetic and real-world data ; tractable schatten quasi-norms ; large-scale problems ; rank function ; global convergence ; nuclear norm ; factor matrices	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 3 ; 10 0 8 ; 0 1 2 ; 2 0 3	the schatten-p quasi-norm -lrb- 0 < p < 1 -rrb- is usually used to replace the standard <otherscientificterm_10> in order to approximate the <otherscientificterm_8> more accurately . however , existing <method_3> involve <otherscientificterm_0> or <otherscientificterm_2> in each iteration , and thus may become very slow and impractical for <task_7> . in this paper , we first define two <otherscientificterm_6> , i.e. , the <otherscientificterm_1> , and then prove that <otherscientificterm_6> are in essence the schatten-2 / 3 and 1/2 quasi-norms , respectively , which lead to the design of very efficient algorithms that only need to update two much smaller <otherscientificterm_11> . we also design two efficient proximal alternating linearized minimization algorithms for solving <task_4> . finally , we provide the <otherscientificterm_9> and performance guarantees for our algorithms , which have better convergence properties than existing algorithms . experimental results on <material_5> show that our algorithms are more accurate than the state-of-the-art methods , and are orders of magnitude faster .	10 8 14 12 -1 3 0 2 7 13 15 16 12 -1 6 1 12 -1 11 12 -1 4 12 -1 9 12 -1
A latent analogy framework for grapheme-to-phoneme conversion .	global definition of analogous events ; -lrb- top-down -rrb- inductive learning ; synthesis of proper names ; maximum likelihood position scoring ; locally optimal sequence alignment ; external linguistic knowledge ; data-driven grapheme-to-phoneme conversion ; local context information ; globally relevant pronunciations ; out-of-vocabulary word ; phoneme transcription ; latent analogy ; graphemic form ; data-driven mapping ; supervision	<otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	3 0 10 ; 4 1 3 ; 4 0 10	data-driven grapheme-to-phoneme conversion involves either <method_1> or -lrb- bottom-up -rrb- pronunciation by analogy . as both approaches rely on <otherscientificterm_7> , they typically require some <otherscientificterm_5> , e.g. , individual grapheme/phoneme correspondences . to avoid such <otherscientificterm_14> , this paper proposes an alternative solution , dubbed pronunciation by <otherscientificterm_11> , which adopts a more <otherscientificterm_0> . for each <otherscientificterm_9> , a neighborhood of <otherscientificterm_8> is constructed through an appropriate <method_13> of its <otherscientificterm_12> . <task_10> then proceeds via <method_4> and <method_3> . this method was successfully applied to the <otherscientificterm_2> with a large diversity of origin .	1 15 -1 7 5 15 -1 14 11 0 15 -1 9 8 13 12 10 15 -1 4 3 16 17 18 15 -1 2 6 15 -1
Feature space maximum a posteriori linear regression for adaptation of deep neural networks .	relative word error rate reduction ; posteriori linear regression framework ; linear input network ; large vocabulary continuous speech recognition ; straightforward feature space adaptation method ; speaker independent cd-dnn-hmm systems ; feature space adaptation method ; dnn acoustic models ; robustness situation ; lin parameters ; fmaplin method ; adaptation process ; switchboard task ; dnn adaptation ; prior knowledge ; over-fitting ; parameters ; robustness	<metric> <method> <method> <task> <method> <method> <method> <method> <metric> <otherscientificterm> <method> <task> <task> <task> <otherscientificterm> <method> <otherscientificterm> <metric>	12 5 5 ; 16 0 7 ; 9 0 4 ; 0 5 2 ; 2 4 10	we propose a feature space maximum a <method_1> to adapt <otherscientificterm_16> for context dependent deep neural network hidden markov models -lrb- cd-dnn-hmms -rrb- . due to the huge amount of <otherscientificterm_16> used in <method_7> in <task_3> , the problem of <method_15> can be severe in <task_13> , thus often impair the <metric_17> of the adapted <task_13> . <method_2> as a <method_4> for <task_13> , similar to feature space maximum likelihood linear regression -lrb- fmllr -rrb- , can potentially suffer from the same <metric_8> . the proposed <method_4> is built based on map estimation of the <otherscientificterm_9> by incorporating <otherscientificterm_14> into the <task_11> . experimental results on the <task_12> show that against the <method_5> , <method_2> provides 4.28 % <metric_0> and the proposed <method_10> is able to provide further 1.15 % -lrb- totally 5.43 % -rrb- <metric_0> on top of <method_2> .	1 16 18 -1 7 3 15 13 17 2 20 18 -1 4 8 18 -1 9 14 21 18 -1 11 19 22 23 18 -1
Novel Codec Structures for Noise Feedback Coding of Speech .	noise feedback coding ; long-term and short-term noise spectral shaping ; packetcable 1.5 mandatory narrowband speech codec ; closed-loop vq codebook design ; long-term and short-term prediction ; nfc codec structures ; broadvoice ® 16 ; vq codebook search ; vector-quantization-based nfc ; scalar-quantization-based nfc ; codec structures	<task> <task> <method> <task> <task> <otherscientificterm> <material> <method> <material> <method> <method>	10 0 0 ; 7 1 3 ; 6 6 2 ; 9 0 8	this paper presents several novel <method_10> for <task_0> incorporating both <task_1> , as well as <task_4> . in addition , the paper generalizes the conventional <method_9> to <material_8> , and it lays the foundation for the associated efficient <method_7> and <task_3> . <material_6> , a <method_2> standardized by cablelabs ® for voice over cable in north america , is based on one of such novel <otherscientificterm_5> .	10 0 1 4 12 11 -1 9 8 7 3 6 13 15 11 -1 2 5 14 11 -1
Topic and Role Discovery in Social Networks .	social network analysis ; latent dirichlet allocation ; author-recipient-topic model ; author-topic model ; re-searcher 's email archive ; enron email corpus ; social network analysis ; topic distributions ; direction-sensitive messages ; language content	<task> <method> <method> <method> <material> <material> <task> <otherscientificterm> <material> <material>	1 0 2 ; 2 0 6 ; 2 0 7 ; 3 0 2 ; 8 0 2 ; 5 1 4	previous work in <task_0> has modeled the existence of links from one entity to another , but not the <material_9> or topics on those links . we present the <method_2> for <task_6> , which learns <otherscientificterm_7> based on the <material_8> sent between entities . the <method_2> builds on <method_1> and the <method_3> , adding the key attribute that distribution over topics is conditioned distinctly on both the sender and recipient -- steering the discovery of topics according to the relationships between people . we give results on both the <material_5> and a <material_4> , providing evidence not only that clearly relevant topics are discovered , but that the <method_2> better predicts people 's roles .	0 9 10 -1 2 6 7 8 12 13 15 10 -1 1 3 11 14 10 -1 5 4 16 10 -1
Parallel Variational Motion Estimation by Domain Decomposition and Cluster Computing .	parallel variational optical flow computation ; large-scale image processing problems ; real-time 2d image processing ; dedicated interface preconditioner ; variational approaches ; inter-process communication ; rectangular subdomains ; global solution ; local solutions ; lower-dimensional interface ; variational approach ; multi-grid iterations ; domain decomposition ; image plane ; pc-clusters ; pc-hardware ; iterations	<task> <task> <task> <method> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm>	4 0 1 ; 7 0 10 ; 7 0 6 ; 15 0 2	we present an approach to <task_0> on standard hardware by <method_12> . using an arbitrary partition of the <otherscientificterm_13> into <otherscientificterm_6> , the <method_7> to the <method_10> is obtained by iteratively combining <method_8> which can be efficiently computed in parallel by separate <otherscientificterm_11> for each subdomain . the approach is particularly suited for implementations on <method_14> because <task_5> between subdomains -lrb- i.e. processors -rrb- is minimized by restricting the exchange of data to a <otherscientificterm_9> . by applying a <method_3> , the necessary number of <otherscientificterm_16> between subdomains to achieve a fixed error is bounded independently of the number of subdomains . our approach provides a major step towards <task_2> using off-the-shelf <method_15> and facilitates the efficient application of <method_4> to <task_1> .	0 12 17 -1 13 6 7 10 8 11 19 20 17 -1 14 5 9 17 -1 3 16 17 -1 18 21 17 -1
Cepstral and long-term features for emotion recognition .	two-class and five-class emotion detection ; short-and long-term speech features ; logistic regression fusion ; unweighted recall value ; cepstral gmm ; fusion	<task> <otherscientificterm> <method> <metric> <method> <method>	3 5 5 ; 2 0 0	in this paper , we describe systems that were developed for the open performance sub-challenge of the interspeech 2009 emotion challenge . we participate in both <task_0> . for the <task_0> , the best performance is obtained by <method_2> of three systems . these systems use <otherscientificterm_1> . <method_5> allowed to an absolute improvement of 2.6 % on the <metric_3> compared with -lsb- 1 -rsb- . for the <task_0> , we submitted two individual systems : <method_4> vs. long-term gmm-ubm . the best result comes from a <method_4> and produces an absolute improvement of 3.5 % compared to -lsb- 6 -rsb- .	6 -1 0 6 -1 2 8 6 -1 1 5 6 -1 3 7 6 -1 4 6 -1 6 -1
An investigation of the application of dynamic sinusoidal models to statistical parametric speech synthesis .	statistical parametric speech synthesis ; mean opinion score test ; dynamic sinusoidal synthesis model ; pitch synchronous spectral analysis ; regularised cepstral coefficients ; cepstral representation ; perceptual criterion ; static amplitude ; statistical modelling ; preference test ; mel-cepstra ; speech	<method> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <method> <material>	2 0 11 ; 10 0 2 ; 2 0 0 ; 1 5 2 ; 3 0 10	this paper applies a <method_2> to <method_0> . for this , we utilise <otherscientificterm_4> to represent both the <otherscientificterm_7> and dynamic slope of selected sinusoids for <task_8> . during synthesis , a <method_2> is used to reconstruct <material_11> . a <metric_9> is conducted to compare the selection of different sinusoids for <method_5> . our results show that when integrated with <method_0> , a relatively small number of sinusoids selected according to a <otherscientificterm_6> can produce quality comparable to using all harmonics . a <material_1> shows that our proposed <method_2> is preferred to one using <method_10> from <method_3> .	2 0 15 12 -1 4 7 8 12 -1 11 13 12 -1 9 5 12 -1 6 12 -1 1 10 3 14 16 17 12 -1
Modeling and Classifying Breast Tissue Density in Mammograms .	probabilis-tic latent semantic analysis ; mias and ddsm datasets ; breast parenchymal tissue ; compact tissue representation ; statistical text literature ; local descriptors ; tissue densities ; unsupervised manner ; sift features ; generative model ; classification stage ; tissue distribution ; mam-mogram classification ; descriptors ; classifier ; mammogram ; texture ; classification	<method> <material> <otherscientificterm> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <method> <material> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	16 1 8 ; 14 4 0 ; 16 6 13 ; 5 0 14 ; 1 0 10 ; 8 6 13 ; 0 0 14 ; 5 1 0 ; 11 0 17 ; 0 0 3 ; 4 0 9	we present a new approach to model and classify <otherscientificterm_2> . given a <otherscientificterm_15> , first , we will discover the distribution of the different <otherscientificterm_6> in an <method_7> , and second , we will use this <method_11> to perform the <task_17> . we achieve this using a <method_14> based on <method_5> and <method_0> , a <method_9> from the <material_4> . we studied the influence of different <otherscientificterm_13> like <otherscientificterm_16> and <otherscientificterm_8> at the <material_10> showing that textons outperform <method_0> in all cases . moreover we demonstrate that <method_0> automatically extracts meaningful latent aspects generating a <method_3> based on their densities , useful for discriminating on <task_12> . we show the results of <material_10> over the <material_1> . we compare our method with approaches that classified these same <method_0> showing a better performance of our proposal .	2 18 -1 15 6 7 11 17 27 18 -1 14 5 0 9 4 22 25 26 29 18 -1 13 16 8 10 19 20 21 24 18 -1 3 28 18 -1 12 23 18 -1 1 18 -1
Unsupervised Extraction of Video Highlights via Robust Recurrent Auto-Encoders .	temporal structure of highlight segments ; short-form video sharing platforms ; shrinking exponential loss function ; web-crawled training data ; down-loaded edited videos ; robust recurrent auto-encoder ; social media websites ; unsupervised learning approach ; heuristic rules ; edited videos ; supervised techniques ; supervised learning ; unsupervised setting ; video class ; user-edited videos ; noise ; instagram ; youtube	<otherscientificterm> <method> <otherscientificterm> <material> <material> <material> <material> <method> <method> <material> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <method> <material>	12 0 7 ; 5 0 0 ; 5 0 15 ; 6 2 14 ; 8 1 11 ; 2 0 5 ; 17 6 6 ; 16 6 1 ; 14 0 5 ; 14 0 7	with the growing popularity of <method_1> such as <method_16> and vine , there has been an increasing need for techniques that automatically extract highlights from video . whereas prior works have approached this problem with <method_8> or <method_11> , we present an <method_7> that takes advantage of the abundance of <material_14> on <material_6> such as <material_17> . based on the idea that the most significant sub-events within a <otherscientificterm_13> are commonly present among <material_9> while less interesting ones appear less frequently , we identify the significant sub-events via a <material_5> trained on a collection of <material_14> queried for each particular class of interest . the <material_5> is trained using a proposed <otherscientificterm_2> that makes <material_5> robust to <otherscientificterm_15> in the <material_3> , and is configured with bidirectional long short term memory -lrb- lstm -rrb- -lsb- 5 -rsb- cells to better model the <otherscientificterm_0> . different from <method_10> , our <method_7> can infer highlights using only a set of <material_4> , without also needing their pre-edited counterparts which are rarely available online . extensive experiments indicate the promise of our proposed <method_7> in this challenging <method_12> .	1 16 26 18 -1 8 11 7 14 6 17 22 23 25 28 18 -1 13 9 5 27 18 -1 20 21 24 18 -1 2 15 3 0 18 -1 10 4 19 18 -1
Reconstruction of high resolution 3D visual information .	recovering high resolution albedo and depth maps ; high resolution luminance and depth information ; markov random fields ; priori knowledge of the scene ; expectation maximization ; low resolution camera images ; imaging process ; relative displacements ; image frames ; probabilistic framework ; statistical models ; geometrical techniques ; depth map ; surface orientations ; iterative algorithms ; surface reconstruction	<task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <method> <task>	5 0 1 ; 4 0 15 ; 11 0 10	given a set of <otherscientificterm_5> , it is possible to reconstruct <otherscientificterm_1> , specially i f the <otherscientificterm_7> of the <otherscientificterm_8> are known . we have proposed <method_14> for <task_0> that require no a <otherscientificterm_3> , and therefore do not depend on other methods , as regards boundary and initial conditions . the problem of <task_15> has been formulated as one of <method_4> and has been tackled in a <method_9> as-ing <method_2> -lsb- 1 -rsb- -lsb- 3 -rsb- . as for the <method_12> , our <method_14> is directly recovering surface heights without refering to <otherscientificterm_13> , whale increasing the resolution by camera jittering -lsb- 2 -rsb- . conventional <method_10> have been coupled with <method_11> to construct a general model of t.he world and the <task_6> .	5 1 7 8 17 16 -1 14 0 3 16 -1 15 4 9 2 18 16 -1 12 13 16 -1 19 16 -1
Event Detection and Domain Adaptation with Convolutional Neural Networks .	convolutional neural networks ; domain adaptation setting ; rich feature sets ; event detection problem ; error propagation ; feature-based systems ; external resources ; feature-based approaches ; feature engineering ; features	<method> <method> <material> <task> <task> <method> <material> <method> <method> <otherscientificterm>	0 0 3 ; 0 4 5 ; 2 1 4	we study the <task_3> using <method_0> that overcome the two fundamental limitations of the traditional <method_7> to this <task_3> : complicated <method_8> for <material_2> and <task_4> from the preceding stages which generate these <otherscientificterm_9> . the experimental results show that the <method_0> outper-form the best reported <method_5> in the general setting as well as the <method_1> without resorting to extensive <material_6> .	3 0 7 8 2 4 9 11 13 10 -1 5 1 6 12 10 -1
Dual Kalman Filtering Methods for Nonlinear Prediction , Smoothing and Estimation .	simulations of noisy time series ; forward-backward filters ; nonlinear noise reduction ; time series model ; linear case ; neural networks ; kalman frameworks ; noisy data ; signal processing ; model parameters ; smoothing ; prediction ; speech ; severa	<task> <method> <task> <method> <task> <method> <method> <material> <task> <otherscientificterm> <task> <task> <material> <otherscientificterm>	1 0 5	prediction , estimation , and <task_10> are fundamental to <task_8> . to perform these interrelated tasks given <material_7> , we form a <method_3> of the process that generates the data . taking noise in the system explicitly into account , maximum-likelihood and <method_6> are discussed which involve the dual process of estimating both the <otherscientificterm_9> and the underlying state of the system . we review several established methods in the <task_4> , and propose <otherscientificterm_13> ! extensions utilizing dual kalman filters -lrb- dkf -rrb- and <method_1> that are applicable to <method_5> . methods are compared on several <task_0> . we also include an example of <task_2> in <material_12> .	10 8 14 -1 7 3 14 -1 6 9 14 -1 4 13 1 5 14 -1 0 15 14 -1 14 -1 2 12 11 14 -1
Monte Carlo limit cycle characterization .	fixed-point iir digital filters ; iir digital filters ; fixed point representation ; monte carlo algorithm ; zero-input limit cycles ; high-order filters ; quantiza-tion function ; limit cycles ; state space ; numerical simulations ; filters	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	2 1 6 ; 10 0 2 ; 3 0 2 ; 3 0 7 ; 1 0 4 ; 3 0 0	the fixed point implementation of <method_1> usually leads to the appearance of <otherscientificterm_4> , which degrade the performance of the system . in this paper , we develop an efficient <method_3> to detect and characterize <otherscientificterm_7> in <method_0> . the proposed <method_3> considers <method_10> formulated in the <otherscientificterm_8> and is valid for any <method_2> and <otherscientificterm_6> . <method_9> on several <method_5> , where an exhaustive search is unfeasible , show the effectiveness of the proposed <method_3> .	1 4 16 11 -1 3 7 0 15 17 11 -1 10 8 2 6 9 12 13 14 11 -1 5 11 -1
VLSI high level synthesis of fast exact least mean square algorithms based on fast FIR filters .	processing and memory units ; acoustic echo cancellation ; high level synthesis ; theoretical arithmetic reduction ; dierent lter lengths ; algorithmic transformations ; computational load ; memory requirements ; fir case ; lms algorithms	<method> <task> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <method>	5 0 1	this paper relates experiences of <task_5> in <method_2> , in the area of <task_1> . the <method_0> are automatically designed for various equivalent <method_9> , in the <material_8> , with important <otherscientificterm_6> . the results obtained with <otherscientificterm_4> , give an accurate prototyping of new fast versions of the <method_9> . it also show that a <method_3> must be correlated to the associated increase of <otherscientificterm_7> .	5 2 1 11 10 -1 0 9 8 6 10 -1 4 10 -1 3 7 10 -1
View-invariant tensor null-space representation for multiple motion trajectory retrieval and classification .	tensor null space invariants ; ten-sor based null space affine invariants ; archiv-ing and searching motion events ; classification and retrieval system ; high order data classification ; multidimensional affine transformations ; consecutive motion events ; camera motions ; linear classifier ; retrieval	<method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	0 0 3 ; 0 0 2 ; 0 0 5	in this paper , we propose a novel general framework for <otherscientificterm_1> , namely , <method_0> with a <method_8> for <task_4> and <task_9> . we first derive <method_0> , which is perfectly invariant to <otherscientificterm_5> due to <otherscientificterm_7> for multiple motion trajectories in <otherscientificterm_6> . we subsequently propose an efficient <method_3> relying on <method_0> for <task_2> consisting of multiple motion trajectories . the simulation results demonstrate superior performance of the proposed <method_3> .	1 0 8 4 9 10 -1 5 7 6 13 10 -1 3 2 11 12 10 -1 10 -1
Group MRF for fMRI activation detection .	group markov random field -lrb- group mrf -rrb- ; functional magnetic resonance imaging ; synthetic and real fmri data ; stringent one-to-one voxel correspondence ; contextual image information ; active brain regions ; fmri group analysis ; intra-and inter-subject neighbors ; brain activation ; group information ; activation maps ; neighborhood system ; data analysis ; analysis techniques ; mrf	<method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <method>	2 5 13 ; 12 0 1	noise confounds present serious complications to accurate <task_12> in <task_1> . simply relying on <otherscientificterm_4> often results in unsatisfactory segmentation of <otherscientificterm_5> . to remedy this , we propose a novel <method_0> that extends the <method_11> to other subjects to incorporate <otherscientificterm_9> in modeling each subject 's <otherscientificterm_8> . our <method_0> has the distinct advantage of being able to regularize the states of both <otherscientificterm_7> without having to create a <otherscientificterm_3> as in standard <method_6> . also , our <method_0> can be efficiently implemented as a single <method_14> , hence enabling <method_10> of a group of subjects to be simultaneously and collaboratively segmented . we validate on both <material_2> and demonstrate superior performance over standard <method_13> .	12 1 17 15 -1 4 5 15 -1 0 11 9 8 15 -1 7 3 6 15 -1 14 10 15 -1 16 15 -1
Linear universal demosaicking of regular pattern color filter arrays .	high sensitivity rgbw cfas ; image signal processor design ; speed and quality optimizations ; finite impulse response filters ; noise reduction friendly ; noise induced arti-facts ; near poissonian noise ; optical pipeline ; rgbw patterns ; universal demosaicker ; filter weights ; demosaickers ; bayer ; cmy ; images ; cfas	<otherscientificterm> <method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <material> <material> <method>	12 6 15 ; 3 0 9 ; 1 0 15 ; 8 6 15 ; 12 1 13 ; 13 6 15 ; 13 1 8	we show that a recently developed <method_9> by the present authors greatly outperforms existing <method_11> when tested with a realistic <method_7> . we present <method_2> of this <method_11> for the case of regular pattern color filter arrays . we implement and extensively test optimized versions for several common <method_15> including <method_12> , <material_13> and several <otherscientificterm_8> . these tests show that the proposed algorithms outperform other <method_11> by a substantial margin while being faster than most of them . <otherscientificterm_0> are shown to have better performance than <method_12> demosaicked with previous algorithms . the proposed <method_9> is a set of <method_3> , which allows a single , efficient , <method_1> to support different <method_15> by changing its <otherscientificterm_10> . being linear , the <method_11> is free of <otherscientificterm_5> and outputs <material_14> with <otherscientificterm_6> which is <metric_4> .	9 11 7 16 -1 2 16 -1 15 12 13 8 17 20 21 22 23 16 -1 0 16 -1 16 -1 18 19 16 -1 3 1 10 16 -1
Photo-real talking head with deep bidirectional LSTM .	recurrent neural network architecture ; deep bidirec-tional lstm ; square error ; photo-real talking head system ; active-appearance-model ; lower face region ; subjective a/b test ; visual feature sequences ; audio/visual stereo data ; con-textual label sequences ; predicting visual sequence ; parallel temporal sequences ; audio/visual database ; temporal sequences ; long-range dependencies ; blstm layers ; regression model ; label sequence ; feed-forward layer ; audio/visual modeling ; hmm-based system ; network topologies ; objective measurement ; blstm ; rnns	<method> <method> <metric> <method> <method> <otherscientificterm> <metric> <material> <material> <material> <task> <material> <material> <material> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <task> <method> <otherscientificterm> <task> <method> <method>	8 0 11 ; 13 1 14 ; 1 0 16 ; 19 0 3 ; 2 0 10 ; 1 0 19 ; 1 0 3 ; 0 0 13 ; 9 6 11	long short-term memory -lrb- lstm -rrb- is a specific <method_0> that is designed to model <material_13> and their <otherscientificterm_14> more accurately than conventional <method_24> . in this paper , we propose to use <method_1> for <task_19> in our <method_3> . an <material_12> of a subject 's talking is firstly recorded as our training data . the <material_8> are converted into two <material_11> , i.e. , <material_9> obtained by forced aligning audio against text , and <material_7> by applying <method_4> on the <otherscientificterm_5> among all the training image samples . the deep <method_23> is then trained to learn the <method_16> by minimizing the sum of <metric_2> of <task_10> from <material_17> . after testing different <otherscientificterm_21> , we interestingly found the best network is two <otherscientificterm_15> sitting on top of one <otherscientificterm_18> on our datasets . compared with our previous <method_20> , the newly proposed <method_1> is better on both <task_22> and <metric_6> .	0 13 14 24 27 33 25 -1 1 19 3 29 31 32 25 -1 12 25 -1 8 11 9 7 4 5 26 34 25 -1 23 16 28 30 25 -1 2 10 17 25 -1 21 15 18 25 -1
Esprit-type algorithms for a received mixture of circular and strictly non-circular signals .	circular and strictly non-circular signals ; c-nc unitary esprit algorithms ; esprit-based parameter estimation algorithms ; estimation accuracy ; nc methods ; closed-form estimates	<otherscientificterm> <method> <method> <metric> <method> <method>	3 5 2 ; 5 1 1	recently , <method_2> have been developed to exploit the structure of signals from strictly second-order -lrb- so -rrb- non-circular -lrb- nc -rrb- sources . they achieve a higher <metric_3> and can resolve up to twice as many sources . however , these <method_4> assume that all the received signals are strictly non-circular . in this paper , we present the c-nc standard esprit and the <method_1> designed for the more practical scenario of a received mixture of <otherscientificterm_0> . assuming that the number of <otherscientificterm_0> is known , the two proposed <method_2> yield <method_5> and <method_1> also enables an entirely real-valued implementation . as a main result , it is shown that the <metric_3> of the presented <method_2> improves with an increasing number of strictly non-circular signals among a fixed number of sources . thereby , not only the <metric_3> of the strictly non-circular signals themselves is improved , but also the <metric_3> of the circular signals . these results are validated by simulations .	2 6 -1 3 6 -1 4 6 -1 1 0 6 -1 5 8 6 -1 7 6 -1 6 -1 6 -1
Predicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions .	deep convolutional neu-ral network ; caltech-ucsd bird and flower datasets ; zero-shot learning of visual categories ; roc and precision-recall curves ; visual category ; text features ; textual descriptions ; unseen categories ; embedding space ; semantic attributes ; textual description ; wikipedia articles ; features ; cnns ; modalities	<method> <material> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm>	11 6 6 ; 8 0 14	one of the main challenges in <task_2> is gathering <otherscientificterm_9> to accompany images . recent work has shown that learning from <otherscientificterm_6> , such as <material_11> , avoids the problem of having to explicitly define these attributes . we present a new model that can classify <otherscientificterm_7> from their <otherscientificterm_10> . specifically , we use <otherscientificterm_5> to predict the output weights of both the convolutional and the fully connected layers in a <method_0> . we take advantage of the architecture of <method_13> and learn <otherscientificterm_12> at different layers , rather than just learning an <otherscientificterm_8> for both <otherscientificterm_14> , as is common with existing approaches . the proposed model also allows us to automatically generate a list of pseudo-attributes for each <otherscientificterm_4> consisting of words from <material_11> . we train our models end-to-end using the <material_1> and evaluate both <material_3> . our empirical results show that the proposed model significantly outper-forms previous methods .	2 9 15 -1 6 11 16 15 -1 7 10 15 -1 5 0 15 -1 13 12 8 14 17 15 -1 15 -1 4 15 -1 1 3 15 -1
Spherical harmonic analysis of equalization in a reverberant room .	concise closed-form expression ; non-isotropic sound fields ; spherical harmonics ; sensor movement ; equalizer robustness ; statistical acoustics ; acoustic equalization ; reverberant environments ; directional microphone ; wave equation ; sound field	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 2 6 ; 0 0 3 ; 8 0 4	in this paper , we investigate the performance of <task_6> in <otherscientificterm_7> . we first highlight an efficient general <task_6> of a <otherscientificterm_10> using <otherscientificterm_2> . we then use this <task_6> to develop a <otherscientificterm_0> for robustness of equalization to <task_3> . this <otherscientificterm_0> is used -lrb- i -rrb- to characterize equalization performance for a general class of <otherscientificterm_1> and -lrb- ii -rrb- to quantify the improvements to <metric_4> that can be obtained by using a <otherscientificterm_8> . the <otherscientificterm_0> used here does not use any of the assumptions of <otherscientificterm_5> , but instead exploits the inherent properties of a <otherscientificterm_10> as described by the <otherscientificterm_9> .	6 7 12 11 -1 10 2 11 -1 0 3 13 11 -1 1 4 8 14 11 -1 5 11 -1
Transmission characteristics of outer ear canal .	enhancement of hearing sensitivity ; external outer ear canal ; external ear cavity subsystem ; elastic tympanic membrane ; finite element model ; external ear canal ; eigenvalue problem ; canal walls ; human dissections	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task>	2 1 3 ; 4 0 6 ; 4 0 8	the <task_6> is solved on the <method_4> of the <otherscientificterm_1> . the absorption of the <otherscientificterm_7> and the interaction between <otherscientificterm_2> and the <otherscientificterm_3> is considered . the results of the <method_4> are compared with experimental measurements on <task_8> . the calculations support hypothesis of possible influence of <otherscientificterm_5> on the <task_0> in 2-4 khz frequency range .	6 4 1 11 9 -1 7 2 3 10 9 -1 8 12 9 -1 5 0 9 -1
Coupled Space Learning for Image Style Transformation .	coupled gaussian mixture model ; bidirectional portrait style transforms ; inter-space correlation information ; image style transforms ; embedded hidden subspaces ; backward transform ; vector spaces ; embedded spaces ; forward transform ; face super-resolution ; mixture-model architecture ; learning framework ; inference ; coupling	<method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <otherscientificterm>	11 0 3 ; 0 0 4 ; 0 0 10 ; 0 0 2 ; 4 0 2 ; 9 1 1	in this paper , we present a new <method_11> for <task_3> . considering that the images in different style representations constitute different <otherscientificterm_6> , we propose a novel framework called <method_0> to learn the relations between different spaces and use <method_0> to infer the images from one style to another style . observing that for each style , only the components correlated to the space of the target style are useful for <task_12> , we first develop the <method_0> to pursue the <otherscientificterm_4> that best preserve the <otherscientificterm_2> . then we develop the coupled bidirectional transform algorithm to estimate the transforms between the two <otherscientificterm_7> , where the <otherscientificterm_13> between the <otherscientificterm_8> and the <otherscientificterm_5> is explicitly taken into account . to enhance the capability of modelling complex data , we further develop the <method_0> to generalize our framework to a <method_10> . the effectiveness of the framework is demonstrated in the applications including <task_9> and <task_1> .	11 3 15 14 -1 6 0 14 -1 12 4 2 16 18 19 14 -1 14 -1 7 13 8 5 17 14 -1 10 20 14 -1
Precision-Recall-Gain Curves : PR Analysis Done Right .	receiver operating characteristic curves ; arithmetic mean of precision values ; precision-recall curves ; interval of β values ; incoherent scale assumptions ; accuracy-based performance assessment ; f β score ; coordinate system ; binary classification ; performance metric ; convex hull ; precision-recall-gain curves ; model selection ; precision-recall-gain curve ; f β ; precision-recall analysis ; roc curves ; pr curves ; pr curve ; harmonic scale ; classifier	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	11 0 12	precision-recall analysis abounds in applications of <task_8> where true negatives do not add value and hence should not affect assessment of the <method_20> 's performance . perhaps inspired by the many advantages of <otherscientificterm_0> and the area under such curves for <task_5> , many researchers have taken to report <otherscientificterm_2> and associated areas as <metric_9> . we demonstrate in this paper that this practice is fraught with difficulties , mainly because of <otherscientificterm_4> -- e.g. , the area under a <otherscientificterm_18> takes the <otherscientificterm_1> whereas the <metric_6> applies the harmonic mean . we show how to fix this by plotting <otherscientificterm_17> in a different <method_7> , and demonstrate that the new <otherscientificterm_11> inherit all key advantages of <otherscientificterm_16> . in particular , the area under <otherscientificterm_11> conveys an expected f 1 score on a <otherscientificterm_19> , and the <otherscientificterm_10> of a <otherscientificterm_13> allows us to calibrate the <method_20> 's scores so as to determine , for each operating point on the <otherscientificterm_10> , the <otherscientificterm_3> for which the point optimises <otherscientificterm_14> . we demonstrate experimentally that the area under traditional <otherscientificterm_17> can easily favour models with lower expected f 1 score than others , and so the use of <otherscientificterm_11> will result in better <method_12> .	8 20 21 -1 0 5 2 9 21 -1 4 18 1 6 21 -1 21 -1 17 7 11 16 21 -1 19 10 13 3 14 22 21 -1
Efficient Sparse Group Feature Selection via Nonconvex Optimization .	nonconvex sparse group feature selection model ; sparse group feature selection ; sparse feature selection ; large-scale problems ; convex methods ; parameter estimation ; synthetic data ; real-world applications ; feature selection ; oracle estimator ; nonconvex paradigm ; high-dimensional data ; accuracy	<method> <task> <method> <task> <method> <task> <material> <task> <otherscientificterm> <method> <method> <material> <metric>	0 0 9 ; 6 1 7 ; 7 5 0 ; 2 0 11 ; 6 5 0 ; 10 0 1 ; 8 1 5	sparse <otherscientificterm_8> has been demonstrated to be effective in handling <material_11> . while promising , most of the existing works use <method_4> , which may be suboptimal in terms of the <metric_12> of <otherscientificterm_8> and <task_5> . in this paper , we expand a <method_10> to <task_1> , which is motivated by applications that require identifying the underlying group structure and performing <otherscientificterm_8> simultaneously . the main contributions of this article are twofold : -lrb- 1 -rrb- statistically , we introduce a <method_0> which can reconstruct the <method_9> . therefore , consistent <otherscientificterm_8> and <task_5> can be achieved ; -lrb- 2 -rrb- computationally , we propose an efficient algorithm that is applicable to <task_3> . numerical results suggest that the proposed <method_0> compares favorably against its competitors on <material_6> and <task_7> , thus achieving desired goal of delivering high performance .	8 11 17 13 -1 4 12 5 20 13 -1 10 1 19 13 -1 0 9 14 13 -1 13 -1 3 15 16 18 13 -1
Analysis of lombard effect under different types and levels of noise with application to in-set speaker ID systems .	inset speaker identification system ; noisy lombard speech ; test-token duration ; timit corpus ; lombard condition ; ut-scope database ; speech characteristics ; lombard speech ; noise types ; noise ; eer	<method> <material> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 2 0 ; 10 0 0 ; 7 0 0	1 this paper presents an analysis of <material_7> produced under different types and levels of <otherscientificterm_9> . the speech used for the analysis forms a part of the <material_5> and consists of sentences from the well-known <material_3> , spoken in the presence of highway , large crowd and pink <otherscientificterm_9> . differences are shown to exist in the <otherscientificterm_6> under these varying <otherscientificterm_8> . the deterioration of the <otherscientificterm_10> of an <method_0> trained on neutral and tested with <material_7> is also illustrated . a clear demarcation between the effect of <otherscientificterm_9> and lombard effect on <otherscientificterm_9> is also given by testing with <material_1> . the effect of <otherscientificterm_2> on system performance under the <otherscientificterm_4> is addressed . it is seen that test duration has no effect on the <otherscientificterm_10> under lombard effect . the average <otherscientificterm_10> for 3s test duration is 14 .	7 9 11 -1 5 3 11 -1 6 8 11 -1 10 0 13 14 11 -1 11 -1 1 12 11 -1 2 4 11 -1 11 -1
Acoustic-prosodic correlates of ` awkward ' prosody in story retellings from adolescents with autism .	autism spectrum disorders ; subjective perceptions of prosodic awkwardness ; objective intonation variability features ; atypical speech prosody ; diagnostic instrument algorithms ; perceived awkward rate/rhythm ; perceived awkwardness ; acoustic-prosodic features ; classification task ; automated methods ; rhythm cues ; diagnostic efficiency ; awkward speech ; speaking rate ; expressivity ; clarity ; volume ; intonation	<task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <material> <metric> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	13 1 10 ; 16 1 17 ; 11 1 15 ; 2 0 14 ; 3 4 4	atypical speech prosody is a primary characteristic of <task_0> , yet <method_3> is often excluded from <method_4> due to poor subjective reliability . robust , objective prosodic cues can enhance our understanding of those aspects which are atypical in autism . in this work , we connect objective signal-derived descriptors of prosody to <otherscientificterm_1> . subjectively , more <material_12> is less expressive -lrb- more monotone -rrb- and more often has <otherscientificterm_5> , <otherscientificterm_16> , and <otherscientificterm_17> . we also find <otherscientificterm_14> can be quantified through <otherscientificterm_2> , and that <metric_13> and <otherscientificterm_10> are highly predictive of <otherscientificterm_6> . <otherscientificterm_7> are also able to significantly differentiate subjects with <task_0> from typically developing -lrb- td -rrb- subjects in a <task_8> , emphasizing the potential of <method_9> for <metric_11> and <metric_15> .	0 3 4 23 18 -1 18 -1 1 18 -1 12 5 16 17 20 18 -1 14 2 13 10 6 7 19 22 18 -1 21 18 -1
Face detection , pose estimation , and landmark localization in the wild .	real-world , cluttered images ; wild '' annotated dataset ; dense graph structures ; mixtures of trees ; global elastic deformation ; pose estimation ; global mixtures ; commercial systems ; landmark estimation ; google picasa ; unified model ; face detection ; topological changes ; tree-structured models ; face benchmarks ; facial landmark ; viewpoint	<material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <task> <material> <method> <task> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm>	10 0 11 ; 11 1 5 ; 13 0 4 ; 10 0 5 ; 5 1 8 ; 10 4 7 ; 0 0 8 ; 3 0 10 ; 6 0 12	we present a <method_10> for <task_11> , <task_5> , and <task_8> in <material_0> . our <method_10> is based on a <otherscientificterm_3> with a shared pool of parts ; we <method_10> every <otherscientificterm_15> as a part and use <otherscientificterm_6> to capture <otherscientificterm_12> due to <otherscientificterm_16> . we show that <method_13> are surprisingly effective at capturing <otherscientificterm_4> , while being easy to optimize unlike <otherscientificterm_2> . we present extensive results on standard <metric_14> , as well as a new '' in the <material_1> , that suggests our <method_10> advances the state-of-the-art , sometimes considerably , for all three tasks . though our <method_10> is modestly trained with hundreds of faces , <method_10> compares favorably to <method_7> trained with billions of examples -lrb- such as <material_9> and face.com -rrb- .	10 11 5 8 0 18 19 21 22 24 17 -1 3 15 6 12 16 25 26 17 -1 13 4 2 20 17 -1 14 1 17 -1 23 17 -1
A PAC-Bayes approach to the Set Covering Machine .	non trivial margin-sparsity trade-off ; set covering machine ; pac-bayes perspective ; learning algorithm ; classifiers	<otherscientificterm> <task> <otherscientificterm> <method> <method>	3 0 1 ; 2 0 3	we design a new <method_3> for the <task_1> from a <otherscientificterm_2> and propose a pac-bayes risk bound which is minimized for <method_4> achieving a <otherscientificterm_0> .	3 1 2 4 0 6 7 5 -1
Top-down induction of clustering trees .	top-down induction of decision trees method ; order logical decision tree representation ; inductive logic programming system ; propositional and re-lational domains ; instance based learning ; first order clustering ; clustering	<method> <method> <method> <material> <method> <task> <method>	0 0 6	an approach to <method_6> is presented that adapts the basic <method_0> towards <method_6> . to this aim , it employs the principles of <method_4> . the resulting methodology is implemented in the <method_0> -lrb- top down induction of clustering trees -rrb- system for <task_5> . the <method_0> employs the first <method_1> of the <method_2> tilde . various experiments with <method_0> are presented , in both <material_3> .	6 0 8 7 -1 4 7 -1 5 7 -1 1 2 7 -1 3 7 -1
SACRY : Syntax-based Automatic Crossword puzzle Resolution sYstem .	crossword puzzle resolution system ; average clue reranking scores ; automatic crossword puzzle resolution ; cp resolution tasks ; answer list ; clue dataset ; answer position ; clue reranking ; answer extraction ; syntactic structures ; aggregated information ; min ; features ; rank ; webcrow ; accuracy	<method> <metric> <task> <task> <otherscientificterm> <material> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric>	0 0 9 ; 11 6 10 ; 7 1 8 ; 9 0 8 ; 9 0 7 ; 1 6 10 ; 14 0 0 ; 6 6 12 ; 12 0 0 ; 3 5 0	in this paper , we present our <method_0> , which exploits <otherscientificterm_9> for <task_7> and <task_8> . <method_0> uses a database -lrb- db -rrb- containing previously solved cps in order to generate the list of candidate answers . additionally , <method_0> uses innovative <otherscientificterm_12> , such as the <otherscientificterm_6> in the <otherscientificterm_13> and <otherscientificterm_10> such as the <otherscientificterm_11> , max and <metric_1> . our <method_0> is based on <method_14> , one of the most advanced systems for <task_2> . our extensive experiments over our two million <material_5> show that our <method_0> highly improves the quality of the <otherscientificterm_4> , enabling the achievement of unprecedented results on the complete <task_3> , i.e. , <metric_15> of 99.17 % .	0 9 7 8 17 19 20 21 16 -1 16 -1 12 6 13 10 11 1 18 22 24 25 16 -1 14 2 23 16 -1 5 4 26 16 -1
Incomplete Preferences in Single-Peaked Electorates .	incomplete preference profile ; real-world preference aggregation ; determining single-peakedness ; incomplete preferences ; single-peaked profiles ; polynomial-time algorithms ; voting systems	<otherscientificterm> <task> <task> <otherscientificterm> <material> <method> <method>	1 1 6	incomplete preferences are likely to arise in <task_1> and <method_6> . this paper deals with determining whether an <otherscientificterm_0> is single-peaked . this is essential information since many intractable voting problems become tractable for <material_4> . we prove that for incomplete profiles the problem of <task_2> is np-complete . despite this computational hardness result , we find two <method_5> for reasonably restricted settings .	1 6 8 7 -1 0 7 -1 4 7 -1 2 7 -1 5 3 7 -1
Optimal sub-graphical models .	subgraph h of g ; graph separation properties ; combinatorial optimization problems ; decomposition tree representation ; graphical model ; minimal separators ; junction-tree representation ; subgraphs h ; subgraphical model ; g ; complexity ; kl-divergence ; tree	<otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	6 0 9 ; 3 0 9	we investigate the problem of reducing the <metric_10> of a <method_4> -lrb- <otherscientificterm_9> , p <otherscientificterm_9> -rrb- by finding a <otherscientificterm_0> , chosen from a class of <otherscientificterm_7> , such that h is optimal with respect to <otherscientificterm_11> . we do this by first defining a <method_3> for <otherscientificterm_9> , which is closely related to the <method_6> for <otherscientificterm_9> . we then give an algorithm which uses this <method_3> to compute the optimal h ∈ h. gavril -lsb- 2 -rsb- and tarjan -lsb- 3 -rsb- have used <otherscientificterm_1> to solve several <task_2> when the size of the <otherscientificterm_5> in the <otherscientificterm_9> is bounded . we present an extension of this technique which applies to some important choices of h even when the size of the <otherscientificterm_5> of <otherscientificterm_9> are arbitrarily large . in particular , this applies to problems such as finding an optimal <method_8> over a -lrb- k − 1 -rrb- - <otherscientificterm_12> of a <method_4> over a k-tree -lrb- for arbitrary k -rrb- and selecting an optimal <method_8> with -lrb- a constant -rrb- d fewer edges with respect to <otherscientificterm_11> can be solved in time polynomial in | v -lrb- <otherscientificterm_9> -rrb- | using this formulation .	10 4 9 0 7 11 13 -1 3 6 14 15 13 -1 1 2 5 13 -1 13 -1 13 -1
Finding Ideographic Representations of Japanese Names Written in Latin Script via Language Identification and Corpus Validation .	three-tier filtering process ; bilingual lexicons ; chinese characters ; english-to-japanese back-transliteration ; language-specific mappings ; string copying ; attested bigrams ; latin script ; cjk name ; average precisions ; asian languages ; latin-scripted languages ; multilingual applications ; ideographic representations ; www ; japanese ; chinese ; computation	<method> <material> <material> <material> <material> <method> <otherscientificterm> <material> <otherscientificterm> <metric> <material> <material> <task> <method> <method> <material> <material> <task>	15 6 10 ; 16 1 15 ; 6 0 0 ; 16 6 10	multilingual applications frequently involve dealing with proper names , but names are often missing in <material_1> . this <task_12> is exacerbated for applications involving translation between <material_11> and <material_10> such as <material_16> , <material_15> and korean -lrb- cjk -rrb- where simple <method_5> is not a solution . we present a novel approach for generating the <method_13> of a <otherscientificterm_8> written in a <material_7> . the proposed approach involves first identifying the origin of the name , and then back-transliterating the name to all possible <material_2> using <material_4> . to reduce the massive number of possibilities for <task_17> , we apply a <method_0> by filtering first through a set of <otherscientificterm_6> , then through a set of attested terms , and lastly through the <method_14> for a final validation . we illustrate the approach with <material_3> . against test sets of <material_15> given names and surnames , we have achieved <metric_9> of 73 % and 90 % , respectively .	1 18 -1 12 11 10 16 15 5 19 20 22 18 -1 13 8 7 18 -1 2 4 18 -1 17 21 18 -1 0 6 14 18 -1 3 18 -1
Further investigations on EMG-to-speech conversion .	mapping surface electromyographic signals ; gaussian mixture model ; mapping of emg signals ; spectral distortion measure ; human articulatory apparatus ; emg-based speech-to-text systems ; silent speech interface ; audible signal ; speech signal ; facial muscles ; spoken speech ; electrode repositioning ; emg signal ; whispered speech ; speech waveforms ; electromyographic signals ; mapping	<task> <method> <task> <metric> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method>	1 0 2 ; 12 0 8 ; 9 0 15 ; 5 0 11 ; 16 0 10 ; 8 0 10 ; 13 4 10 ; 12 0 13 ; 0 0 6	our study deals with a <method_6> based on <task_0> to <otherscientificterm_14> . <otherscientificterm_15> recorded from the <otherscientificterm_9> capture the activity of the <otherscientificterm_4> and therefore allow to retrace speech , even when no <material_7> is produced . the <task_2> to speech is done via a <method_1> - based conversion technique . in this paper , we follow the lead of <method_5> and apply two major recent technological advances to our system , namely , we consider <method_5> , which are robust against <method_11> , and we show that <method_16> the <otherscientificterm_12> to <material_13> creates a better <otherscientificterm_8> than a <method_16> to normally <material_10> . we objectively evaluate the performance of our systems using a <metric_3> .	6 0 14 15 26 17 -1 9 4 7 20 17 -1 2 1 18 17 -1 5 11 16 12 13 8 19 21 22 23 24 25 17 -1 10 17 -1
Large Scale Sparse Clustering .	large-scale sparse clustering algorithm ; synthetic and real-world datasets ; large-scale sparse clustering ; large-scale clustering methods ; two-step optimization strategy ; dimension reduction techniques ; spare coding algorithm ; large-scale clustering ; nonlinear approximation ; large-scale data ; clustering refinement ; noise	<method> <material> <task> <method> <method> <method> <method> <task> <method> <material> <method> <otherscientificterm>	1 5 0 ; 8 0 6 ; 5 0 6 ; 4 0 2 ; 8 1 5	large-scale clustering has found wide applications in many fields and received much attention in recent years . however , most existing <method_3> can only achieve mediocre performance , because <method_3> are sensitive to the unavoidable presence of <otherscientificterm_11> in the <material_9> . to address this challenging problem , we thus propose a <method_0> . in this paper , we choose a <method_4> for <task_2> : 1 -rrb- k-means clustering over the <material_9> to obtain the initial clustering results ; 2 -rrb- <method_10> over the initial results by developing a <method_6> . to guarantee the scalabil-ity of the second step for <material_9> , we also utilize <method_8> and <method_5> to speed up the <method_6> . experimental results on both <material_1> demonstrate the promising performance of our <method_0> .	12 -1 3 11 9 12 -1 0 12 -1 4 2 10 6 16 12 -1 14 15 17 12 -1 8 5 13 12 -1
An Efficient Reactive Planner for Synthesizing Reactive Plans .	safety and liveness rules ; nonlinear forward-search method ; linear methods	<otherscientificterm> <method> <method>	1 4 2	we present a <method_1> suitable for planning the reactions of an agent operating in a highly unpredictable environment . we show that this <method_1> is more eecient than existing <method_2> . we then introduce the notion of <otherscientificterm_0> . this makes possible a sharper exploitation of the information retrieved when exploring the future of the agent .	1 3 -1 2 4 3 -1 0 3 -1 3 -1
Fast algorithm for least squares 2D linear-phase FIR filter design .	weighted least squares 2d linear-phase fir filter design ; weighted least squares filter design method ; quadrantally-symmetric filter design ; centro-symmetric filter design ; desired frequency response ; filter coefficients ; filter design ; orthonormal basis ; subspace ; storage	<method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 1 3	in this paper , we develop a new method for <method_0> . it poses the problem of <task_6> as the problem of projecting the <otherscientificterm_4> onto the <otherscientificterm_8> spanned by an appropriate <otherscientificterm_7> . we show how to compute the <otherscientificterm_7> efficiently in the cases of <task_2> and <method_3> . the design examples show that the proposed method is faster than a conventional <method_1> . also , the amount of <otherscientificterm_9> required to compute the <otherscientificterm_5> is greatly reduced .	0 10 -1 6 4 8 7 10 -1 2 3 11 10 -1 1 10 -1 9 5 10 -1
Generalized Latent Factor Models for Social Network Analysis .	multiplicative latent factor model ; minorization-maximization algorithm ; social network analysis ; social networks ; model parameters ; real-world networks ; stochastic equivalence ; directed links ; homophily modeling ; network structure ; linear-time complexity ; convergence guarantee ; homophily	<method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	10 1 11 ; 0 0 6 ; 0 0 3 ; 10 0 1 ; 8 0 0	homophily and <otherscientificterm_6> are two primary features of interest in <method_3> . recently , the <method_0> is proposed to model <method_3> with <material_7> . although <method_0> can capture <otherscientificterm_6> , it can not model well ho-mophily in <otherscientificterm_9> . however , many <method_5> exhibit <method_12> or both <method_12> and <otherscientificterm_6> , and hence the <otherscientificterm_9> of these <otherscientificterm_9> can not be mod-eled well by <method_0> . in this paper , we propose a novel model , called generalized latent factor model -lrb- glfm -rrb- , for <task_2> by enhancing <method_8> in <method_0> . we devise a <method_1> with <otherscientificterm_10> and <otherscientificterm_11> to learn the <otherscientificterm_4> . extensive experiments on some <method_5> show that glfm can effectively model <method_12> to dramatically outperform state-of-the-art methods .	6 3 13 -1 0 7 16 13 -1 9 15 13 -1 5 12 13 -1 2 8 18 13 -1 1 10 14 17 13 -1 11 4 13 -1
A spectrally efficient nonorthogonal amplify-and-forward protocol for cooperative wireless networks .	amplify-and-forward protocol ; nonorthogonal af protocol ; wireless systems ; decode-and-forward protocol ; orthogonal af ; cooperative protocols ; spectral efficiency ; error rate	<method> <method> <method> <method> <method> <method> <metric> <metric>	6 5 4 ; 6 5 5 ; 6 5 0	in <method_2> where half duplex transceivers are employed , most existing practical <method_5> achieve a <metric_6> of 0.5 symbols per channel use -lrb- pcu -rrb- . recently a <method_3> was developed to achieve a <metric_6> of 2/3 symbols pcu . but there is no practical <method_0> that can achieve a <metric_6> higher than 0.5 symbols pcu . in this paper , we develop a <method_1> which achieves a <metric_6> of 2/3 symbols pcu and provides almost the same bit <metric_7> as the traditional <method_4> which has a <metric_6> of 0.5 symbols pcu .	2 5 6 10 8 -1 3 8 -1 0 11 8 -1 1 7 4 9 8 -1
Better Approximation and Faster Algorithm Using the Proximal Average .	large-scale machine learning applications ; proximal gradient algorithm ; overlapping group lasso ; convex analysis tool ; nonsmooth approximation ; computational challenges ; nonsmooth losses/regularizers ; proxi-mal map ; smooth functions ; smoothing ; overhead	<task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	9 0 1	it is a common practice to approximate '' complicated '' functions with more friendly ones . in <task_0> , <method_6> that entail great <otherscientificterm_5> are usually approximated by <otherscientificterm_8> . we reexamine this powerful methodology and point out a <method_4> which simply pretends the linearity of the <otherscientificterm_7> . the new approximation is justified using a recent <method_3> -- proximal average , and yields a novel <method_1> that is strictly better than the one based on <method_9> , without incurring any extra <otherscientificterm_10> . numerical experiments conducted on two important applications , <otherscientificterm_2> and graph-guided fused lasso , corroborate the theoretical claims .	11 -1 0 6 5 8 11 -1 4 7 11 -1 3 1 9 10 12 11 -1 2 11 -1
Multifractal analysis and α-stable processes : a methodological contribution .	wavelet coeecient partition functions ; legendre multifractal spectrum ; fractional brownian motion ; sample paths ; self-similar-stable process ; multifractal time ; estimation procedure ; partition functions ; wavelet co-eecients ; multifractal spectrum	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	5 2 2 ; 5 1 4	this work is a contribution to the analysis of the procedure , based on <method_0> , commonly used to estimate the <otherscientificterm_1> . the procedure is applied to two examples , a <otherscientificterm_2> in <otherscientificterm_5> and a <otherscientificterm_4> , whose <otherscientificterm_3> exhibit irregularities that by eye appear very close . we observe that , for the second example , this analysis results in a qualitatively inaccurate estimation of its <otherscientificterm_9> , and a related masking of the-stable nature of the process . we explain the origin of this error through a detailed analysis of the <otherscientificterm_7> of the <otherscientificterm_4> . such a study is made possible by the speciic properties of the <method_8> of such processes . we indicate how the <method_6> might be modiied to avoid such errors .	0 1 10 -1 2 5 4 3 11 12 10 -1 9 10 -1 7 10 -1 10 -1 8 10 -1
A dynamic programming approach for fast and robust object pose recognition from range images .	computationally expensive training phase ; random sampling based approach ; automated manufacturing environments ; local belief propagation ; commodity depth sensors ; computer vision problem ; joint object recognition ; pose estimation ; range images ; robotics applications ; color information ; clear outliers ; dynamic programming ; real sequences	<otherscientificterm> <method> <task> <method> <method> <task> <task> <task> <material> <task> <otherscientificterm> <otherscientificterm> <method> <material>	4 0 5 ; 9 1 2	joint object recognition and <task_7> solely from <material_8> is an important task e.g. in <task_9> and in <task_2> . the lack of <otherscientificterm_10> and limitations of current <method_4> make this task a challenging <task_5> , and a standard <method_1> is prohibitively time-consuming . we propose to address this difficult problem by generating promising inlier sets for <task_7> by early rejection of <otherscientificterm_11> with the help of <method_3> -lrb- or <method_12> -rrb- . by exploiting data-parallelism our method is fast , and we also do not rely on a <otherscientificterm_0> . we demonstrate state-of-the art performance on a standard dataset and illustrate our approach on challenging <material_13> .	7 8 9 2 16 14 -1 10 4 5 1 15 14 -1 11 3 12 14 -1 0 14 -1 14 -1
Adaptive linear predictors for real-time tracking .	adaptive linear predictors ; pre-learned linear predictors ; full matrix inversion ; real-time template tracking ; linear predictors ; on-line modification ; template shape ; template size ; learning approaches ; tracking	<method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task>	2 0 6 ; 0 4 8 ; 4 0 3 ; 0 4 4	enlarging or reducing the <otherscientificterm_7> by adding new parts , or removing parts of the template , according to their suitability for <task_9> , requires the ability to deal with the variation of the <otherscientificterm_7> . for instance , <method_3> using <method_4> , although fast and reliable , requires using templates of fixed size and does not allow <method_5> of the predictor . to solve this problem we propose the <method_0> which enable fast online modifications of <method_1> . instead of applying a <otherscientificterm_2> for every modification of the <otherscientificterm_6> as standard approaches to learning <method_4> do , we just perform a fast update of this inverse . this allows us to learn the <method_0> in a much shorter time than standard <method_8> while performing equally well . we performed exhaustive evaluation of our <method_0> and compared <method_0> to standard <method_4> and other state of the art approaches .	7 9 10 -1 3 4 5 13 10 -1 0 1 10 -1 2 6 11 10 -1 12 10 -1 8 14 10 -1
Inferring White Matter Geometry from Di.usion Tensor MRI : Application to Connectivity Mapping .	synthetic and real diffusion mri datasets ; cerebral white matter connectivity mapping ; anisotropic diffusion of water molecules ; diffusion paths of water molecules ; consistent neural fibers reconstruction ; level set formulation scheme ; riemannian manifold m ; complex diffusion profiles ; geodesics of m ; diffusion tensor mri ; radial brownian motion ; global modelization ; brownian motion ; laplace-beltrami operator ; biological tissues ; distance function ; diffusion tensor ; exponential map ; direct mapping ; numerical scheme ; non-invasive technique ; dt-mri	<material> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method>	19 0 15 ; 20 0 2 ; 21 0 2 ; 19 0 8 ; 21 6 20 ; 17 0 15 ; 19 0 10 ; 17 0 5 ; 5 0 15 ; 5 0 10 ; 14 2 2 ; 0 5 5 ; 17 0 19	we introduce a novel approach to the <task_1> from <method_9> . <method_21> is the unique <method_20> capable of probing and quantifying the <otherscientificterm_2> in <otherscientificterm_14> . we address the problem of <task_4> in areas of <otherscientificterm_7> with potentially multiple fibers orientations . our method relies on a <method_11> of the acquired mri volume as a <method_6> and proceeds in 4 majors steps : first , we establish the link between <material_12> and diffusion mri by using the <method_13> on m . we then expose how the sole knowledge of the diffusion properties of water molecules on m is sufficient to infer its geometry . there exists a <method_18> between the <otherscientificterm_16> and the metric of m. next , having access to that metric , we propose a novel <method_5> to approximate the <otherscientificterm_15> related to a <otherscientificterm_10> on m. finally , a rigorous <method_19> using the <otherscientificterm_17> is derived to estimate the <otherscientificterm_8> , seen as the <otherscientificterm_3> . numerical experimentations conducted on <material_0> illustrate the potentialities of this <method_5> .	1 9 21 22 -1 20 2 14 24 25 27 33 22 -1 4 7 22 -1 11 6 12 13 22 -1 22 -1 23 26 28 29 30 31 32 35 22 -1 18 16 5 15 10 19 17 8 3 34 22 -1
A Generalized Student-t Based Approach to Mixed-Type Anomaly Detection .	posterior of high dimensional latent variables ; machine learning field ; error buffering component ; generalized linear model ; bayesian inference approach ; error buffering approach ; mixed-type data ; mixed-type attributes ; latent variables ; anomaly detection ; non-gaussian design ; computational optimizations ; mixed-type datasets ; student-t distribution ; anomaly detection ; laplace approximation ; buffdetect	<otherscientificterm> <task> <method> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <task> <method> <method> <material> <otherscientificterm> <task> <method> <method>	11 3 4 ; 13 0 3 ; 9 0 6 ; 13 0 2 ; 15 1 11 ; 15 0 4 ; 15 1 15 ; 12 0 14 ; 2 3 3	anomaly detection for <material_6> is an important problem that has not been well addressed in the <task_1> . there are two challenging issues for <material_12> , namely modeling mutual correlations between <otherscientificterm_7> and capturing large variations due to anomalies . this paper presents <method_16> , a robust <method_5> for <task_14> in <material_12> . a new variant of the <method_3> is proposed to <method_3> the dependency between <otherscientificterm_7> . the <method_3> incorporates an <method_2> based on <otherscientificterm_13> to absorb the variations caused by anomalies . however , because of the <method_10> , the problem becomes analytically intractable . we propose a novel <method_4> , which integrates <method_15> and several <method_11> , and is able to efficiently approximate the <otherscientificterm_0> by iteratively updating the <otherscientificterm_8> in groups . extensive experimental evaluations based on 13 benchmark datasets demonstrate the effectiveness and efficiency of <method_16> .	6 1 20 17 -1 12 7 17 -1 16 5 14 25 17 -1 3 17 -1 2 13 19 21 26 17 -1 10 17 -1 18 22 23 24 17 -1 4 15 11 0 8 17 -1
Machine learning of probabilistic phonological pronunciation rules from the Italian CLIPS corpus .	modeling and understanding of phonological processes ; phonological form of spontaneous sentences ; phonological pronunciation rules ; phonologi-cal replacement rules ; probabilistic rule set ; italian clips corpus ; regional italian accents ; phonetic surface form ; phonological concepts ; italian speech ; alignment technique ; machine-learning algorithm ; conditional probabilities ; technical analysis ; web-interface ; rule	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <method> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	10 0 1 ; 8 1 13 ; 11 0 3 ; 13 0 0	a blending of <method_8> and <method_13> is proposed to yield a better <task_0> . based on the manual segmentation and labeling of the <material_5> we automatically derive a probabilistic set of <otherscientificterm_2> : a new <method_10> is used to map the <otherscientificterm_1> onto the <otherscientificterm_7> . a <method_11> then calculates a set of <otherscientificterm_3> together with their <otherscientificterm_12> . a critical analysis of the resulting <material_4> is presented and discussed with regard to <otherscientificterm_6> . the <otherscientificterm_15> set presented here is also applied in the newly published web-service webmaus that allows a user to segment and phonetically label <material_9> via a simple <otherscientificterm_14> .	8 13 0 18 20 16 -1 5 2 10 1 7 17 16 -1 11 3 12 19 16 -1 4 6 16 -1 15 9 16 -1
Mean square analysis of a fast filtered-x affine projection algorithm .	active noise control applications ; filtered-x affine projection algorithm ; mean square error ; affine projection algorithm ; computationally demanding modified filtered-x scheme ; single-channel anc system ; energy conservation arguments ; steady-state behavior ; filtered-x scheme ; theoretical expressions ; signal distribution ; ap algorithms	<task> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	4 0 11 ; 3 0 0 ; 8 0 3	this paper provides an analysis of the <otherscientificterm_7> of the <method_1> . this efficient <method_3> for <task_0> is based on the <method_8> , unlike most <method_11> based on the more <method_4> . this study depends on <otherscientificterm_6> and does not require an specific <otherscientificterm_10> . the <otherscientificterm_9> derived for the <otherscientificterm_2> allowed to accurately predict the steady-state performance of the <method_3> for meaningful practical cases . simulation results of a <method_5> validate the analysis and the <otherscientificterm_9> derived .	7 1 12 -1 3 0 8 11 4 13 14 15 12 -1 6 10 12 -1 9 2 12 -1 5 12 -1
Comprehending and Generating Apt Metaphors : A Web-driven , Case-based Approach to Figurative Language .	hard cases -lrb- non-explicit metaphors ; marked-ness of similes ; cryptic allusions ; crossword puzzles ; hand-crafted resources ; figurative language ; tacit knowledge ; illustrative examples ; property-attribution metaphors ; computational agent ; metaphor ; case-base ; cate-gorizations ; wordnet ; simile	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm>	13 6 4	examples of <material_5> can range from the explicit and the obvious to the implicit and downright enigmatic . some simpler forms , like <otherscientificterm_14> , often wear their meanings on their sleeve , while more challenging forms , like <otherscientificterm_10> , can make <otherscientificterm_2> more akin to those of riddles or <otherscientificterm_3> . in this paper we argue that because the same concepts and properties are described in either case , a <method_9> can learn from the easy cases -lrb- explicit similes -rrb- how to comprehend and generate the <otherscientificterm_0> -rrb- . we demonstrate that the <otherscientificterm_1> allows for a large <method_11> of <material_7> to be easily acquired from the web , and present a system , called sardonicus , that uses this <method_11> both to understand <otherscientificterm_8> and to generate apt metaphors for a given target on demand . in each case , we show how the text of the web is used as a source of <otherscientificterm_6> about what <otherscientificterm_12> are allowable and what properties are most contextually appropriate . overall , we demonstrate that by using the web as a primary knowledge source , a system can achieve a robust and scalable competence with <otherscientificterm_10> while minimizing the need for <material_4> like <material_13> .	5 15 -1 14 10 2 3 15 -1 9 0 15 -1 1 15 -1 11 7 8 15 -1 6 12 16 15 -1
Co-localization in Real-World Images .	object discovery datasets ; weakly supervised localization ; convex quadratic program ; joint image-box formulation ; intra-class variation ; co-localization problem ; ground-truth annotations ; real-world images ; real-world settings ; inter-class diversity ; annotation noise ; co-segmentation ; imagenet ; co-localization	<material> <method> <method> <method> <otherscientificterm> <task> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <task>	3 0 5 ; 9 1 10 ; 4 1 9 ; 3 0 2 ; 11 1 1	in this paper , we tackle the problem of <task_13> in <material_7> . <task_13> is the problem of simultaneously localizing -lrb- with bounding boxes -rrb- objects of the same class across a set of distinct images . although similar problems such as <method_11> and <method_1> have been previously studied , we focus on being able to perform <task_13> in <otherscientificterm_8> , which are typically characterized by large amounts of <otherscientificterm_4> , <otherscientificterm_9> , and <otherscientificterm_10> . to address these issues , we present a <method_3> for solving the <task_5> , and show how <method_3> can be relaxed to a <method_2> which can be efficiently solved . we perform an extensive evaluation of our <method_3> compared to previous state-of-the-art approaches on the challenging pascal voc 2007 and <material_0> . in addition , we also present a large-scale study of <task_13> on <material_12> , involving <material_6> for 3,624 classes and approximately 1 million images .	13 7 14 -1 14 -1 11 1 8 4 9 10 16 17 19 14 -1 3 5 2 15 18 14 -1 14 -1 0 14 -1
Factor analysis based VTS discriminative adaptive training .	vts adaptive training ; discriminative vat ; diagonal corrupted speech covariance matrix ; noise robust speech recognition ; jaco-bian -lrb- loading matrix ; diverse noise-degraded training data ; diagonal loading matrices ; diagonal loading matrix ; in-car collected data ; canonical models ; optimal diagonalisation ; clean speech ; em-based approaches ; aurora4 task ; noise ; kl-divergence	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <method> <otherscientificterm> <material> <method> <method> <material> <method> <material> <otherscientificterm> <method>	8 5 1 ; 14 1 11 ; 5 0 9 ; 8 1 13 ; 13 5 1 ; 12 0 9	vector taylor series -lrb- vts -rrb- model based compensation is a powerful approach for <task_3> . an important extension to this approach is <method_0> , which allows <method_9> to be estimated on <material_5> . these <method_9> can be estimated using <method_12> , allowing simple extensions to <otherscientificterm_1> . however to ensure a <otherscientificterm_2> the <otherscientificterm_4> -rrb- relating the <otherscientificterm_14> and <material_11> is diagonalised . in this work an approach for yielding optimal <method_6> based on minimising the expected <method_15> between the <otherscientificterm_7> and '' correct '' distributions is proposed . the performance of <otherscientificterm_1> using the standard and <method_10> was evaluated on both <material_8> and the <material_13> .	3 16 -1 0 9 5 19 16 -1 12 1 22 16 -1 2 4 14 11 18 16 -1 6 15 7 16 -1 10 17 20 21 16 -1
Learning to Estimate Human Pose with Data Driven Belief Propagation .	data driven belief propagation monte carlo algorithm ; estimating 2-d human pose ; 2-d human pose estimation ; hand labeled images ; bottom-up reasoning mechanisms ; human body configuration ; bottom-up visual cues ; importance sampling functions ; 2-d body shapes ; single images ; image cues ; probabilistic inference ; estimation problem ; low-dimensional representations ; inference tasks ; statistical formulation ; markov network ; shape ; appearance ; edge	<method> <task> <task> <material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <task> <task> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 0 5 ; 12 0 5 ; 19 6 10 ; 13 0 8 ; 15 0 2 ; 18 1 19 ; 7 0 0 ; 6 0 7 ; 18 6 10 ; 15 0 14 ; 17 6 10 ; 18 1 17 ; 3 0 8 ; 15 0 1 ; 6 0 0 ; 17 1 19	we propose a <method_15> for <task_2> from <material_9> . the <otherscientificterm_5> is modeled by a <method_16> and the <task_12> is to infer pose parameters from <otherscientificterm_10> such as <otherscientificterm_18> , <otherscientificterm_17> , <otherscientificterm_19> , and color . from a set of <material_3> , we accumulate prior knowledge of <otherscientificterm_8> by learning their <method_13> for inference of pose parameters . a <method_0> , utilizing <method_7> built from <otherscientificterm_6> , is proposed for efficient <task_11> . contrasted to the few sequential statistical formulations in the literature , our <method_15> integrates both top-down as well as <method_4> , and can carry out the <task_14> in parallel . experimental results demonstrate the potency and effectiveness of the proposed <method_15> in <task_1> from <material_9> .	15 2 9 25 20 -1 5 16 12 10 18 17 19 21 22 23 26 29 31 32 36 20 -1 3 8 13 24 33 20 -1 0 7 6 11 27 28 35 20 -1 4 30 20 -1 14 34 20 -1
A Dimensional Contextual Semantic Model for music description and retrieval .	dimensional contextual semantic model ; categorical or dimensional models ; semantic music search engine ; high-level music descriptions ; dimensional models ; graded descriptions ; semantic descriptions ; description models ; semantic relation ; context-aware fashion ; semantic relations ; musical content ; polysemy	<method> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm>	0 0 2 ; 3 0 11 ; 7 0 0 ; 0 0 10	several paradigms for <material_3> have been proposed to develop effective system for browsing and retrieving <material_11> in large repositories . such paradigms are based on either <method_1> . the interest in <method_4> has recently grown a great deal , as they define a <otherscientificterm_8> between concepts through <otherscientificterm_5> . one problem that affects <otherscientificterm_6> is the ambiguity that often arises from using the same descriptor in different contexts . in order to overcome this difficulty , it is important to <method_0> and address <otherscientificterm_12> , which is the property of words to take on different meanings depending on the use-context . in this paper we propose a <method_0> for defining <otherscientificterm_10> among descriptors in a <method_9> . this <method_0> is here used for developing a <method_2> . in order to evaluate the effectiveness of our <method_0> , we compare this <method_0> with two systems that are based on different <method_7> .	3 11 15 13 -1 1 13 -1 4 8 5 13 -1 6 13 -1 0 12 13 -1 17 13 -1 10 9 14 13 -1 2 16 13 -1
Automatic lecture transcription by exploiting presentation slide information for language model adaptation .	plsa -lrb- probabilistic latent semantic analysis ; detection rate of content keywords ; global and local slide information ; keyword and topic information ; global topic adaptation ; language model adaptation ; automatic lecture transcription ; presentation slide information ; robust adaptation scheme ; real lectures ; cache model ; web text ; local preference ; recognition accuracy ; keywords	<method> <metric> <otherscientificterm> <otherscientificterm> <task> <task> <task> <otherscientificterm> <method> <material> <method> <material> <otherscientificterm> <metric> <otherscientificterm>	14 0 4 ; 5 0 6 ; 3 0 8	the paper addresses <task_5> for <task_6> by fully exploiting <otherscientificterm_7> used in the lecture . as the text in the presentation slides is small in its size and fragmentary in its content , a <method_8> is addressed by focusing on the <otherscientificterm_3> . several methods are investigated and combined ; first , <task_4> is conducted based on <method_0> -rrb- using <otherscientificterm_14> appearing in all slides . <material_11> is also retrieved to enhance the relevant text . then , <otherscientificterm_12> of the <otherscientificterm_14> are reflected with a <method_10> by referring to the slide used during each utterance . experimental evaluations on <material_9> show that the proposed method combining the <otherscientificterm_2> achieves a significant improvement of <metric_13> , especially in the <metric_1> .	5 6 7 17 15 -1 8 3 18 15 -1 4 0 14 11 16 15 -1 15 -1 12 10 15 -1 15 -1
Tied-state based discriminative training of context-expanded region-dependent feature transforms for LVCSR .	large vocabulary continuous speech recognition ; maximum mutual information criterion ; context-expanded region-dependent linear transforms ; switchboard-1 conversational telephone speech transcription task ; lattice-free , tied-state based discriminative training ; relative word error rate reduction ; lattice-based , boosted mmi training ; contextual weight expansion ; lattice-based discriminative training ; discriminative feature ; weight expansion ; long-span features ; acoustic modeling ; gmm-hmms ; hmms	<task> <otherscientificterm> <method> <task> <method> <metric> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <method>	11 1 10 ; 1 0 2 ; 11 1 8 ; 0 0 12 ; 2 1 14 ; 11 1 7 ; 8 0 2 ; 2 0 14 ; 11 1 2 ; 5 5 3	we present a new <method_9> transform approach to <task_0> using gaussian mixture density hidden markov models -lrb- <method_13> -rrb- for <task_12> . the feature transform is formulated with a set of <method_2> utilizing both <otherscientificterm_11> and <method_7> . the <method_2> are estimated by <method_4> using <otherscientificterm_1> , while the <method_13> are trained by conventional <method_6> . compared with two baseline systems , which use <method_2> with either <otherscientificterm_11> or <otherscientificterm_10> only and are trained using the conventional <method_8> for both <method_2> and <method_14> , the proposed approach achieves a <metric_5> of 10 % and 6 % respectively on <task_3> .	9 0 13 12 19 15 -1 2 11 7 21 24 15 -1 4 1 6 17 15 -1 10 8 14 5 3 16 18 20 22 23 25 15 -1
A closed form recursive solution for Maximum Correntropy training .	maximum correntropy criterion ; closed form recursive solution ; adaptive systems training ; maximum correntropy criterion ; gradient based training ; weighted least squares ; pdf s ; closed form ; rls algorithm ; random variables ; adaptive filters ; filter weights ; error pdf ; correntropy ; non-gaussian ; cross-correntropy	<method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <material> <otherscientificterm>	1 4 4 ; 1 0 10 ; 1 0 11 ; 1 4 8 ; 3 0 2 ; 4 4 8 ; 0 0 1	this paper presents a <method_1> for training <method_10> using the <method_0> . <otherscientificterm_13> has been recently proposed as a robust similarity measure between two <otherscientificterm_9> or signals , when the <otherscientificterm_6> involved are heavy tailed and <material_14> . maximizing the <otherscientificterm_15> between the output of an <method_10> and the desired response leads to the <method_3> for <task_2> . we show that a <otherscientificterm_7> , <method_1> of the <method_11> using this <otherscientificterm_7> yields a simple <otherscientificterm_5> like formulation . our simulations show that training the <method_11> using this <method_1> is much faster than <method_4> , and more accurate than the <method_8> in cases where the <material_12> is <material_14> and heavy tailed .	1 10 0 13 18 23 16 -1 9 6 14 16 -1 15 3 2 21 16 -1 7 11 5 16 -1 4 8 17 19 20 22 16 -1
Catch Me If You Can : Pursuit and Capture in Polygonal Environments with Obstacles .	simply-connected polygons of n vertices ; o -lrb- log n -rrb- pursuers ; minimum feature size assumption ; minimum feature size property ; discrete time steps ; deterministic search strategy ; arbitrary polygonal environment ; visibility-based pursuit evasion ; line-of-sight detection ; maximum speed ; simply-connected n-gons ; minimum distance	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 8	we resolve a several-years old open question in <task_7> : how many pursuers are needed to capture an evader in an <otherscientificterm_6> with obstacles ? the evader is assumed to be adversarial , moves with the same <otherscientificterm_9> as pursuers , and is '' sensed '' by a pursuer only when it lies in line-of-sight of that pursuer . the players move in <otherscientificterm_4> , and the capture occurs when a pursuer reaches the position of the evader on its move . our main result is that o -lrb- √ h + log n -rrb- pursuers can always win the game with a <method_5> in any polygon with n vertices and h obstacles -lrb- holes -rrb- . in order to achieve this bound , however , we argue that the environment must satisfy a <otherscientificterm_3> , which essentially requires the <otherscientificterm_11> between any two vertices to be of the same order as the speed of the players . without the <method_2> , we show that ω -lrb- n / log n -rrb- pursuers are needed in the worst-case even for <otherscientificterm_0> ! this reveals an unexpected subtlety that seems to have been overlooked in previous work claiming that <otherscientificterm_1> can always win in <otherscientificterm_10> . our lower bound also shows that capturing an evader is inherently more difficult than just '' seeing '' it because <otherscientificterm_1> are prov-ably sufficient for <task_8> even against an arbitrarily fast evader in simple n-gons .	7 6 9 12 -1 4 12 -1 12 -1 5 12 -1 3 11 12 -1 2 0 1 12 -1 10 12 -1 8 13 12 -1
Improving WFST-based G2P Conversion with Alignment Constraints and RNNLM N-best Rescoring .	recurrent neural network language model ; word accuracy ; grapheme-to-phoneme conversion ; wfst-based g2p framework ; em-driven alignment algorithm ; n-best rescoring mechanism ; alignment algorithm ; open-source toolkit ; g2p conversion ; g2p datasets ; structural constraints	<method> <task> <task> <method> <method> <method> <method> <method> <task> <material> <otherscientificterm>	9 5 0 ; 7 0 3 ; 5 0 8 ; 0 0 8 ; 3 0 6	this work introduces a modified wfst-based multiple to multiple <method_4> for <task_2> , and preliminary experimental results applying a <method_0> as an <method_5> for <task_8> . the <method_6> leverages the <method_3> and introduces several simple <otherscientificterm_10> which yield a small but consistent improvement in <task_1> on a selection of standard base-lines . the <method_0> further extends these gains and achieves state-of-the-art performance on four standard <material_9> . the system is also shown to be significantly faster than existing solutions . finally , the complete <method_3> is provided as an <method_7> .	4 2 0 5 8 14 15 11 -1 6 3 10 1 16 11 -1 9 12 11 -1 11 -1 7 13 11 -1
Efficient Approach to Solve the Minimal Labeling Problem of Temporal and Spatial Qualitative Constraints .	qualitative constraint network ; minimal labeling problem ; region connection calculus ; qualitative temporal and topological relations ; interval algebra ; artificial intelligence approaches ; ◆ g-consistency ; patchwork property ; partial consistency ; chordal qcns ; rcc-8	<method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	4 6 5 ; 6 6 8 ; 9 1 8 ; 4 1 2 ; 0 0 3 ; 10 6 2 ; 2 6 5	the <method_4> and a subset of the <method_2> , namely <method_10> , are the dominant <method_5> for representing and reasoning about <otherscientificterm_3> respectively . such <otherscientificterm_3> can be formulated as a <method_0> . in this paper , we focus on the <task_1> and we propose an algorithm to efficiently derive all the feasible base relations of a <method_0> . our algorithm considers <method_9> and a new form of <otherscientificterm_8> which we define as <otherscientificterm_6> . further , the proposed algorithm uses tractable subclasses of relations having a specific <otherscientificterm_7> for which-consistency implies the consistency of the input <method_0> . experi-mentations with <method_0> of <method_4> and <method_10> show the importance and efficiency of this new approach .	4 2 10 5 3 12 15 17 18 11 -1 0 16 11 -1 1 11 -1 9 8 6 13 14 11 -1 7 11 -1 11 -1
Optical Flow via Locally Adaptive Fusion of Complementary Data Costs .	minimum description length constraint ; optical flow estimation energy model ; single or fixed data model ; data and regularization terms ; locally varying data term ; middlebury optical flow benchmark ; optical flow estimation algorithms ; multiple data models ; optical flow framework ; complementary data models ; state-of-the art methods ; matching ambiguity ; ill-posed problems ; optical flow ; data models	<method> <method> <method> <otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	9 4 10 ; 6 0 12	many state-of-the-art <method_6> optimize the <otherscientificterm_3> to solve <otherscientificterm_12> . in this paper , in contrast to the conventional <method_8> that uses a <method_2> , we study a novel framework that employs <otherscientificterm_4> that adaptively combines different multiple types of <method_14> . the locally adaptive data term greatly reduces the <otherscientificterm_11> due to the complementary nature of the <method_7> . the optimal number of <method_9> is learnt by minimizing the redundancy among them under the <method_0> . from these chosen <method_14> , a new <method_1> is designed with the weighted sum of the <method_7> , and a convex optimization-based highly effective and practical solution that finds the <otherscientificterm_13> , as well as the weights is proposed . comparative experimental results on the <material_5> show that the proposed method using the <method_9> outperforms the <method_10> .	6 3 12 17 15 -1 8 2 4 14 15 -1 11 7 15 -1 9 0 15 -1 1 15 -1 13 16 15 -1
Extracting Semantic Orientations of Words using Spin Model .	semantic orientations of words ; intractable actual probability function ; spins of electrons ; approximate probability function ; mean field approximation ; semantic orienta-tions ; parameter selection ; semantic ori-entations ; english lexicon ; seed words ; magnetization ; accuracy	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric>	4 0 3	we propose a method for extracting <otherscientificterm_0> : desirable or undesirable . regarding <otherscientificterm_7> as <otherscientificterm_2> , we use the <method_4> to compute the <otherscientificterm_3> of the system instead of the <otherscientificterm_1> . we also propose a criterion for <task_6> on the basis of <otherscientificterm_10> . given only a small number of <otherscientificterm_9> , the proposed method extracts <otherscientificterm_5> with high <metric_11> in the experiments on <material_8> . the result is comparable to the best value ever reported .	0 12 -1 7 2 4 3 1 13 12 -1 6 10 12 -1 9 5 11 8 12 -1 12 -1
On the value of pairwise constraints in classification and consistency .	real world classification datasets ; labeled and pairwise examples ; optimal linear decision boundary ; asymptotic variance ; pairwise constraints ; binary variable ; simulated datasets ; decision boundary ; classification	<material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task>	6 1 0	in this paper we consider the problem of <task_8> in the presence of <otherscientificterm_4> , which consist of pairs of examples as well as a <otherscientificterm_5> indicating whether they belong to the same class or not . we propose a method which can effectively utilize <otherscientificterm_4> to construct an estimator of the <otherscientificterm_7> , and we show that the resulting estimator is sign-insensitive consistent with respect to the <otherscientificterm_2> . we also study the <otherscientificterm_3> of the estimator and extend the method to handle both <material_1> in a natural way . several experiments on <material_6> and <material_0> are conducted . the results not only verify the theoretical properties of the proposed method but also demonstrate its practical value in applications .	8 4 5 9 -1 7 2 9 -1 3 1 9 -1 6 0 10 9 -1 9 -1
Large-Scale Syntactic Language Modeling with Treelets .	overlapping windows of tree context ; generative , syntactic language model ; overlapping windows of linear context ; n-gram language model estimation techniques ; automatically parsed text ; n-gram language models ; n-gram models ; positive data ; grammaticality tasks ; discriminative models ; generative baselines	<otherscientificterm> <method> <otherscientificterm> <method> <material> <method> <method> <material> <task> <method> <otherscientificterm>	9 0 8 ; 3 0 4 ; 1 4 9 ; 3 0 1 ; 1 0 8 ; 6 1 10 ; 2 0 5	we propose a simple <method_1> that conditions on <otherscientificterm_0> -lrb- or treelets -rrb- in the same way that <method_5> condition on <otherscientificterm_2> . we estimate the parameters of our <method_1> by collecting counts from <material_4> using standard <method_3> , allowing us to train a <method_1> on over one billion tokens of data using a single machine in a matter of hours . we evaluate on perplexity and a range of <task_8> , and find that we perform as well or better than <method_6> and other <otherscientificterm_10> . our <method_1> even competes with state-of-the-art <method_9> hand-designed for the <task_8> , despite training on <material_7> alone . we also show fluency improvements in a preliminary machine translation experiment .	1 0 5 2 18 11 -1 4 3 13 15 11 -1 8 6 10 17 11 -1 9 12 14 16 11 -1 7 11 -1
Coping imbalanced prosodic unit boundary detection with linguistically-motivated prosodic features .	imbalanced prosodic unit boundary detection ; linguistically motivated prosodic features ; machine learning techniques ; prosodically defined units ; decision tree classifier ; prosodic boundary information ; defined prosodic units ; asr processing ; minority class ; c4 .5 ; bmpm	<task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method>	0 0 3 ; 2 0 0 ; 1 0 5 ; 2 0 3	continuous speech input for <task_7> is usually pre-segmented into speech stretches by pauses . in this paper , we propose that smaller , <otherscientificterm_3> can be identified by tackling the problem on <task_0> using five <method_2> . a parsimonious set of <otherscientificterm_1> has been proven to be useful to characterize <otherscientificterm_5> . furthermore , <method_10> is prone to have true positive rate on the <otherscientificterm_8> , i.e. the <otherscientificterm_6> . as a whole , the <method_4> , <method_9> , reaches a more stable performance than the other algorithms .	7 11 -1 3 0 2 12 13 15 11 -1 1 5 14 11 -1 10 8 6 11 -1 4 9 11 -1
Automatic Kinematic Chain Building from Feature Trajectories of Articulated Objects .	minimum spanning tree ; non-rigid articulated parts ; segmented motion subspaces ; articulated object tracking ; affine projections ; spectral clustering ; data sets ; feature trajectories ; human motions ; kinematic chain ; articulated object ; feature tra-jectories ; articulated objects ; local sampling ; graph ; structure	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	13 1 5 ; 4 0 11	we investigate the problem of learning the <otherscientificterm_15> of an <otherscientificterm_10> , i.e. its <otherscientificterm_9> , from <otherscientificterm_11> under <otherscientificterm_4> . we demonstrate this possibility by proposing an algorithm which first segments the trajectories by <method_13> and <method_5> , then builds the <otherscientificterm_9> as a <otherscientificterm_0> of a <otherscientificterm_14> constructed from the <otherscientificterm_2> . we test our method in challenging <material_6> and demonstrate the ability to automatically build the <otherscientificterm_9> of an <otherscientificterm_10> from <otherscientificterm_7> . the algorithm also works when there are multiple <otherscientificterm_12> in the scene . furthermore , we take into account <otherscientificterm_1> that exist in <otherscientificterm_8> . we believe this advance will have impact on <task_3> and dynamical <otherscientificterm_15> from motion .	15 10 9 11 4 18 16 -1 13 5 0 14 2 17 16 -1 6 7 16 -1 12 16 -1 1 8 16 -1 16 -1
Context-Sensitive Decision Forests for Object Detection .	context-sensitive decision forests-a new perspective ; context-based decision criteria ; tud data set ; decision forest framework ; regression mode selection ; object detection problem ; contextual information ; inference time ; split criterion ; intermediate prediction ; tree-structured classifiers ; pedestrian detection ; trees ; classification ; training	<method> <otherscientificterm> <material> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <task> <task>	3 0 5 ; 9 0 1 ; 8 0 4 ; 6 0 3 ; 1 0 3 ; 10 0 9 ; 0 0 6	in this paper we introduce <method_0> to exploit <otherscientificterm_6> in the popular <method_3> for the <task_5> . they are <method_10> with the ability to access <task_9> -lrb- here : <task_13> and regression -rrb- information during <task_14> and <otherscientificterm_7> . this <task_9> is available for each sample and allows us to develop <otherscientificterm_1> , used for refining the <method_3> . in addition , we introduce a novel <method_8> which in combination with a priority based way of constructing the <otherscientificterm_12> , allows more accurate <method_4> and hence improves the current context information . in our experiments , we demonstrate improved results for the task of <task_11> on the challenging <material_2> when compared to state-of-the-art methods .	0 6 3 5 16 19 22 15 -1 10 9 13 14 7 21 15 -1 1 17 20 15 -1 8 12 4 18 15 -1 15 -1
Bilingual Correspondence Recursive Autoencoder for Statistical Machine Translation .	bilingual correspondence recursive autoencoder ; semantic and structural similarity features ; nist chinese-english test sets ; recursive au-toencoder reconstruction error ; structural alignment consistency error ; alignment-consistent phrase structures ; learning semantic representations ; statistical machine translation ; bilingual phrase representations ; cross-lingual reconstruction error ; neu-ral network model ; joint objective ; semantic relations ; word alignments ; tree structures ; bilingual constraints ; bilingual phrases ; smt system	<method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method>	2 5 10 ; 8 1 14 ; 0 6 10 ; 0 0 1 ; 1 3 17 ; 6 0 7 ; 4 1 9 ; 10 0 15 ; 8 1 1 ; 1 3 0 ; 13 3 0 ; 3 1 4	learning semantic representations and <otherscientificterm_14> of <material_16> is beneficial for <task_7> . in this paper , we propose a new <method_10> called <method_0> to model <material_16> in translation . we incorporate <otherscientificterm_13> into <method_0> to allow <method_10> freely access <otherscientificterm_15> at different levels . <method_0> minimizes a <otherscientificterm_11> on the combination of a <otherscientificterm_3> , a <otherscientificterm_4> and a <otherscientificterm_9> so as to not only generate <otherscientificterm_5> , but also capture different levels of <otherscientificterm_12> within <material_16> . in order to examine the effectiveness of <method_0> , we incorporate both <otherscientificterm_1> built on <method_8> and <otherscientificterm_14> learned by <method_0> into a state-of-the-art <method_17> . experiments on <material_2> show that our <method_10> achieves a substantial improvement of up to 1.55 bleu points over the baseline .	14 16 7 24 18 -1 10 0 21 18 -1 13 15 26 29 18 -1 11 3 4 9 5 12 25 30 18 -1 1 8 20 22 23 27 28 18 -1 17 19 18 -1
Using graphical models for mixed-initiative dialog management systems with realtime Policies .	reference system ; air travelling information system ; error recognition capabilities ; statistical dialog models ; average dialog length ; speech recognition systems ; natural spoken dialogs ; specifity rate ; dialog modeling ; user utterances ; system flexibility ; sensitivity rate	<method> <method> <metric> <method> <metric> <method> <material> <metric> <task> <material> <metric> <metric>	11 2 2 ; 7 2 2 ; 3 0 5 ; 4 5 0	in this paper , we present a novel approach for <task_8> , which extends the idea underlying the partially observable markov decision processes -lrb- pomdps -rrb- , i. e. it allows for calculating the <task_8> in real-time and thereby increases the <metric_10> . the use of <method_3> is particularly advantageous to react adequately to common errors of <method_5> . comparing our results to the <method_0> , we achieve a relative reduction of 31.6 % of the <metric_4> . furthermore , the proposed system shows a relative enhancement of 64.4 % of the <metric_11> in the <metric_2> using the same <metric_7> in both systems . the achieved results are based on the <method_1> with 21 650 <material_9> in 1 585 <material_6> .	8 10 12 -1 3 5 15 12 -1 0 4 16 12 -1 11 2 7 13 14 12 -1 12 -1
Large vocabulary continuous speech recognition using WFST-based linear classifier for structured data .	weighted finite state transducer ; large vocabulary continuous speech recognition task ; sequential multiclass data ; large-scale linear classifier ; distributed perceptron algorithm ; hidden markov models ; wfst-based decoding process ; information source models ; decoding graph ; linear models ; training method ; n-gram models ; structured data ; wfst-based decoding ; linear classifier ; acoustic models ; discriminative approach	<method> <task> <material> <method> <method> <method> <method> <method> <method> <method> <method> <method> <material> <task> <method> <method> <method>	14 0 6 ; 13 0 3 ; 5 6 7 ; 2 6 12 ; 9 0 8 ; 4 0 3 ; 10 0 3 ; 11 6 7 ; 7 3 8 ; 3 0 13 ; 4 0 13 ; 12 0 14 ; 5 1 11	this paper describes a <method_16> that further advances the framework for <method_0> based decoding . the <method_16> introduces additional <method_9> for adjusting the scores of a <method_8> composed of conventional <method_7> -lrb- e.g. , <method_5> and <method_11> -rrb- , and reviews the <method_6> as a <method_14> for <material_12> -lrb- e.g. , <material_2> -rrb- . the difficulty with the <method_16> is that the number of dimensions of the additional <method_9> becomes very large in proportion to the number of arcs in a <method_0> , and our previous study only applied it to a small task -lrb- timit phoneme recognition -rrb- . this paper proposes a <method_10> for a <method_3> employed in <task_13> by using a <method_4> . the experimental results show that the proposed <method_16> was successfully applied to a <task_1> , and achieved an improvement compared with the performance of the minimum phone error based discrimina-tive training of <method_15> .	16 0 17 -1 9 8 7 5 11 6 14 12 2 18 20 21 22 25 26 29 30 17 -1 17 -1 19 23 24 27 28 17 -1 10 3 13 4 17 -1
Supervised clustering of streaming data for email batch detection .	detecting batches of emails ; sequential decoding procedure ; jointly generated messages ; streaming nature ; collective information ; supervised clustering ; linear time ; decoding problem ; spam emails ; decoding procedures ; email batches ; collective attributes ; spam	<task> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <material> <method> <material> <otherscientificterm> <otherscientificterm>	6 2 7	we address the problem of <task_0> that have been created according to the same template . this problem is motivated by the desire to filter <otherscientificterm_12> more effectively by exploiting <otherscientificterm_4> about entire batches of <material_2> . the application matches the problem setting of <method_5> , because examples of correct clusterings can be collected . known <method_9> for <method_5> are cubic in the number of instances . when decisions can not be reconsidered once they have been made -- owing to the <otherscientificterm_3> of the data -- then the <task_7> can be solved in <otherscientificterm_6> . we devise a <method_1> and derive the corresponding optimization problem of <method_5> . we study the impact of <otherscientificterm_11> of <material_10> on the effectiveness of recognizing <material_8> .	0 13 -1 12 4 2 13 -1 5 13 -1 9 13 -1 3 7 6 14 13 -1 1 13 -1 13 -1
Reconfigurable processing : the solution to low-power programmable DSP .	dynamic reconfigura-tion of hardware modules ; low-power programmable dsp ; wireless communication components ; wireless communication ; low-power solutions ; application-specific approach ; power dissipation ; programmable environment ; power reduction ; instruction-based engines	<method> <method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <method>	4 0 5 ; 5 0 4 ; 9 0 3 ; 0 0 1	one of the most compelling issues in the design of <method_2> is to keep <otherscientificterm_6> between bounds . while <method_4> are readily achieved in an <method_5> , doing so in a <otherscientificterm_7> is a substantially harder problem . this paper presents an approach to <method_1> that is based on the <method_0> . this technique has shown to yield at least an order of magnitude of <metric_8> compared to traditional <method_9> for problems in the area of <task_3> .	2 6 10 -1 4 5 7 11 12 10 -1 1 0 14 10 -1 8 9 3 13 10 -1
Modeling and equalization of audio systems using Kautz filters .	equalization of audio systems ; transfer function modeling ; auditory frequency resolution ; loudspeaker response equalization ; audio signal processing ; frequency warping ; kautz filters ; frequency warping ; related resolution ; laguerre filters ; guitar body ; allpass structures	<task> <method> <task> <task> <task> <task> <method> <method> <task> <method> <material> <otherscientificterm>	7 1 8 ; 10 1 3 ; 11 0 5 ; 1 1 3 ; 9 0 5 ; 11 1 9 ; 6 0 0	frequency warping using <otherscientificterm_11> or <method_9> has found increasingly applications in <task_4> due to good match with the <task_2> . <method_6> are an extension where the <method_7> and <task_8> can have more freedom . in this paper we discuss the properties of <method_6> and how <method_6> meet typical requirements found in modeling and <task_0> . case studies include <method_1> of the <material_10> and <task_3> .	11 9 4 2 6 15 17 18 12 -1 7 8 13 12 -1 0 19 12 -1 1 10 3 5 14 16 12 -1
Improving automatic speech recognition using tangent distance .	automatic speech recognition ; telephone line recorded german digit strings ; gaussian mixture densities ; tangent distance ; high dimensional feature space ; image object recognition ; probabilistic framework ; prototype vector ; variance modelling ; sietill corpus ; gmd approach ; observation vector ; minimum distance ; model parameters ; classifiers ; manifold ; classification	<task> <material> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <task> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	4 2 15 ; 1 5 10 ; 13 0 10 ; 2 0 0 ; 9 5 10 ; 2 0 3 ; 3 0 0	in this paper we present a new approach to <task_8> in <task_0> that is based on <method_3> . using <method_3> , <method_14> can be made invariant w.r.t. small <method_14> of the data . such <method_14> generate a <otherscientificterm_15> in a <otherscientificterm_4> when applied to an <otherscientificterm_11> . while conventional <method_14> determine the distance between an observation and a <otherscientificterm_7> , <method_3> approximates the <otherscientificterm_12> between their manifolds , resulting in <task_16> that is invariant w.r.t. the underlying transformation . recently , this approach was successfully applied in <task_5> . in this paper we describe how <method_3> can be incorporated into <task_0> based on <method_2> . the proposed method is embedded into a <method_6> . experiments performed on the <material_9> for <material_1> show a significant improvement in comparison with a conventional <method_10> using a comparable amount of <otherscientificterm_13> .	8 0 3 17 -1 14 17 -1 15 4 11 18 17 -1 7 12 16 17 -1 5 17 -1 21 23 24 17 -1 2 17 -1 6 19 20 22 17 -1
The I4U system in NIST 2008 speaker recognition evaluation .	i4u speaker recognition system ; cepstral features ; classifiers	<method> <otherscientificterm> <method>	1 1 2 ; 2 3 0 ; 1 3 0	this paper describes the performance of the <method_0> in the nist 2008 speaker recognition evaluation . the <method_0> consists of seven subsystems , each with different <otherscientificterm_1> and <method_2> . we describe the <method_0> and report on its core test results as they were submitted , which were among the best-performing submissions . the i4u effort was led by the	0 3 -1 1 2 4 5 6 3 -1 3 -1 3 -1
A Learning Scheme for Generating Expressive Music Performances of Jazz Standards .	expressive music performances of monophonic jazz melodies ; induced expressive transformation model ; inexpressive melody descriptions ; melody synthesis component ; expressive transformation model ; machine learning component ; melodic transcription component ; extracted acoustic features ; acoustic features ; learning scheme ; expressive audio ; monophonic recordings	<material> <method> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <material>	1 0 2 ; 11 0 8 ; 3 0 4 ; 2 1 5 ; 6 1 5 ; 4 1 5 ; 6 0 8 ; 2 0 4 ; 2 0 3 ; 1 0 4 ; 1 0 3 ; 9 0 10	we describe our approach for generating <material_0> . it consists of three components : -lrb- a -rrb- a <method_6> which extracts a set of <otherscientificterm_8> from <material_11> , -lrb- b -rrb- a <method_5> which induces an <method_4> from the set of <otherscientificterm_7> , and -lrb- c -rrb- a <method_3> which generates expressive mono-phonic output -lrb- midi or audio -rrb- from <material_2> using the <method_1> . in this paper we concentrate on the <method_5> , in particular , on the <method_9> we use for generating <material_10> from a score .	0 12 -1 6 8 11 5 4 7 3 2 1 13 14 15 16 17 18 19 20 21 22 23 12 -1 9 10 24 12 -1
Opponent Modeling in Deep Reinforcement Learning .	deep q-network ; deep reinforcement learning ; simulated soccer game ; trivia game ; secondary agents ; explicit modeling ; multi-agent settings ; opponent modeling ; parameterized strategies ; mixture-of-experts architecture ; neural-based models ; probabilistic models ; policy ; multitasking ; supervision	<method> <method> <material> <material> <method> <method> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm>	13 0 5 ; 11 1 8 ; 10 0 12 ; 2 1 3	opponent modeling is necessary in <otherscientificterm_6> where <method_4> with competing goals also adapt their strategies , yet it remains challenging because strategies interact with each other and change . most previous work focuses on developing <method_11> or <method_8> for specific applications . inspired by the recent success of <method_1> , we present <method_10> that jointly learn a <otherscientificterm_12> and the behavior of opponents . instead of explicitly predicting the opponent 's action , we encode observation of the opponents into a <method_0> ; however , we retain <method_5> -lrb- if desired -rrb- using <method_13> . by using a <method_9> , our model automatically discovers different strategy patterns of opponents without extra <otherscientificterm_14> . we evaluate our models on a <material_2> and a popular <material_3> , showing superior performance over <method_0> and its variants .	6 4 15 -1 11 8 17 15 -1 1 10 12 18 15 -1 0 5 13 16 15 -1 9 15 -1 14 19 15 -1
Structure-based and template-based automatic speech recognition - comparing parametric and non-parametric approaches .	speech recognition algorithms ; beyond-hmm '' frameworks ; acoustic modeling ; speech features ; phonetic detail ; speech recognition ; hmms	<method> <method> <task> <otherscientificterm> <otherscientificterm> <task> <method>	4 3 0 ; 5 0 2 ; 6 0 2 ; 2 0 5	this paper provides an introductory tutorial for the interspeech07 special session on '' structure-based and template-based automatic speech recognition '' . the purpose of the special session is to bring together researchers who have special interest in novel techniques that are aimed at overcoming weaknesses of <method_6> for <task_2> in <task_5> . numerous such approaches have been taken over the past dozen years , which can be broadly classified into structured-based -lrb- parametric -rrb- and template-based -lrb- non-parametric -rrb- ones . in this paper , we will provide an overview of both approaches , focusing on the incorporation of long-range temporal dependencies of the <otherscientificterm_3> and <otherscientificterm_4> in <method_0> . we will provide a high-level survey on major existing work and systems using these two types of '' <method_1> . the contributed papers in this special session will elaborate further on the related topics .	7 -1 6 2 5 9 10 11 7 -1 7 -1 8 7 -1 3 4 0 7 -1 1 7 -1
Three Generative , Lexicalised Models for Statistical Parsing .	wall street journal text ; lexicalised context-free grammar ; statistical parsing model ; constituent precision/recall ; probabilistic treatment ; genera-tive model ; sub-categorisation ; wh-movement	<material> <method> <method> <metric> <method> <method> <otherscientificterm> <otherscientificterm>	0 5 2 ; 3 5 2	in this paper we first propose a new <method_2> , which is a <method_5> of <method_1> . we then extend the <method_2> to include a <method_4> of both <otherscientificterm_6> and <otherscientificterm_7> . results on <material_0> show that the <method_2> performs at 88.1 / 87.5 % <metric_3> , an average improvement of 2.3 % over -lrb- collins 96 -rrb- .	2 5 1 8 -1 4 6 7 8 -1 0 3 9 10 8 -1
Efficient Squared Curvature .	submodular and super-modular pairwise potentials ; length based regularization ; computing squared curvature ; high angular resolutions ; trust region framework ; low angular resolution ; computer vision ; elongated structures ; integral geometry ; length ; curvature	<otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 3 ; 1 0 6	curvature has received increasing attention as an important alternative to <method_1> in <task_6> . in contrast to <otherscientificterm_9> , it preserves <otherscientificterm_7> and fine details . existing approaches are either inefficient , or have <otherscientificterm_5> and yield results with strong block artifacts . we derive a new model for <task_2> based on <otherscientificterm_8> . the model counts responses of straight line triple cliques . the corresponding energy decomposes into <otherscientificterm_0> . we show that this energy can be efficiently minimized even for <otherscientificterm_3> using the <method_4> . our results confirm that we obtain accurate and visually pleasing solutions without strong artifacts at reasonable runtimes .	1 6 13 11 -1 9 7 11 -1 5 11 -1 2 8 11 -1 11 -1 0 11 -1 3 4 12 11 -1 11 -1
A Game-theoretic Machine Learning Approach for Revenue Maximization in Sponsored Search .	game-theoretic machine learning approach ; bilevel optimization framework ; predicted bid sequences ; empirical revenue maximization ; genetic programming algorithm ; auction mechanism ; markov model ; machine learning ; game theory ; prediction period ; historical data ; monetization channel ; search engines ; sponsored search	<method> <method> <material> <method> <method> <method> <method> <method> <method> <otherscientificterm> <material> <method> <method> <method>	7 1 8 ; 3 0 5 ; 1 0 5 ; 13 6 11 ; 8 0 0 ; 0 0 5 ; 10 0 6 ; 11 0 12	sponsored search is an important <method_11> for <method_12> , in which an <method_5> is used to select the ads shown to users and determine the prices charged from advertisers . there have been several pieces of work in the literature that investigate how to design an <method_5> in order to optimize the revenue of the <method_12> . however , due to some unrealistic assumptions used , the practical values of these studies are not very clear . in this paper , we propose a novel <method_0> , which naturally combines <method_7> and <method_8> , and learns the <method_5> using a <method_1> . in particular , we first learn a <method_6> from <material_10> to describe how advertisers change their bids in response to an <method_5> , and then for any given <method_5> , we use the learnt <method_6> to predict its corresponding future bid sequences . next we learn the <method_5> through <method_3> on the <material_2> . we show that the empirical revenue will converge when the <otherscientificterm_9> approaches infinity , and a <method_4> can effectively optimize this empirical revenue . our experiments indicate that the proposed <method_0> is able to produce a much more effective <method_5> than several baselines .	11 12 5 18 22 14 -1 14 -1 14 -1 0 7 8 15 17 19 20 14 -1 1 21 14 -1 6 10 16 14 -1 3 2 14 -1 9 4 14 -1
Integrated Feature Normalization and Enhancement for robust Speaker Recognition using Acoustic Factor Analysis .	speaker/utterance dependent gaussian mixture model ; acoustic factor analysis transformation ; signal sub-space based speech enhancement schemes ; low-rank covariance structure of cepstral features ; factor analysis based channel compensation methods ; mixture dependent feature transformation ; acoustic feature eigenvector directions ; lower dimensional subspace ; feature dimensionality reduction ; factor analysis model ; probabilistic mixture alignment ; acoustic feature space ; acoustic features ; afa parameter ; feature space ; speaker recognition ; variance normalization ; i-vector system ; super-vector domain ; de-correlation ; super-vectors ; enhancement	<method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <metric>	4 0 15 ; 19 1 16 ; 16 1 21 ; 10 0 13 ; 19 1 21 ; 8 1 19 ; 8 0 1	state-of-the-art <method_4> for <task_15> are based on the assumption that <method_0> mean <method_20> can be constrained to lie in a <otherscientificterm_7> , which does not consider the fact that conventional <otherscientificterm_12> may also be constrained in a similar way in the <otherscientificterm_14> . in this study , motivated by the <otherscientificterm_3> , we propose a <method_9> in the <otherscientificterm_11> instead of the <otherscientificterm_18> and derive a <method_5> . we demonstrate that , the proposed <method_1> performs <method_8> , <metric_19> , <otherscientificterm_16> and <metric_21> at the same time . the transform applies a square-root wiener gain on the <otherscientificterm_6> , and is similar to the <method_2> . we also propose several methods of adaptively selecting the <otherscientificterm_13> for each mixture . the proposed feature transform is applied using a <method_10> , and is integrated with a conventional <method_17> . experimental results on the telephone trials of the nist sre 2010 demonstrate the effectiveness of the proposed <method_9> .	4 15 0 20 7 12 14 23 22 -1 3 9 11 18 5 22 -1 1 8 19 16 21 24 25 27 28 29 22 -1 6 22 -1 2 22 -1 13 26 22 -1 10 17 22 -1
Verification of Knowledge-Based Programs over Description Logic Actions .	description logic knowledge base ; physical and sensing actions ; dl-based action language ; general domain knowledge ; proce-dure 's complexity ; agent 's knowledge ; primitive actions ; programming constructs ; epistemic dl ; test conditions ; knowledge-based program ; knowledge-based programs ; restricted fragment ; verification	<material> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <task>	2 0 1 ; 6 1 7 ; 7 1 9 ; 2 0 11	a <method_10> defines the behavior of an agent by combining <otherscientificterm_6> , <method_7> and <otherscientificterm_9> that make explicit reference to the <otherscientificterm_5> . in this paper we consider a setting where an agent is equipped with a <material_0> providing <otherscientificterm_3> and an incomplete description of the initial situation . we introduce a corresponding new <method_2> that allows for representing both <otherscientificterm_1> , and that we then use to build <method_11> with <otherscientificterm_9> expressed in the <material_8> . after proving undecidability for the general case , we then discuss a <otherscientificterm_12> where <task_13> becomes decidable . the provided proof is constructive and comes with an upper bound on the <metric_4> .	10 6 7 9 5 16 17 14 -1 0 3 14 -1 2 1 11 8 15 18 14 -1 12 13 14 -1 14 -1
Evaluating spoken language model based on filler prediction model in speech recognition .	japanese national diet record ; filler prediction model ; language model ; domain-relevant topics ; transcribed corpora ; fillers ; recognition	<material> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task>	1 0 2	we propose a method that uses a <method_1> for building a <method_2> that includes <otherscientificterm_5> from a corpus without <otherscientificterm_5> . in our method , a <method_1> is trained from a corpus that does not cover <otherscientificterm_3> . it recovers <otherscientificterm_5> in inexact <material_4> in the target domain , and then a <method_2> that includes <otherscientificterm_5> is built from the corpora . the results of an evaluation of the <material_0> showed that a model using our method achieves higher <task_6> performance than conventional ones .	1 2 5 8 7 -1 3 7 -1 4 7 -1 0 6 7 -1
Collective Information Extraction with Relational Markov Networks .	conditional random fields ; information extraction systems ; generalization of crfs -rrb- ; relational markov networks ; undirected graphical models ; arbitrary dependencies ; statistical methods ; ie systems ; overall accuracy ; biomedical text ; protein names	<method> <method> <method> <method> <method> <otherscientificterm> <method> <task> <metric> <material> <otherscientificterm>	4 0 6 ; 9 0 10 ; 0 6 4 ; 0 0 6	most <method_1> treat separate potential extractions as independent . however , in many cases , considering influences between different potential extractions could improve <metric_8> . <method_6> based on <method_4> , such as <method_0> , have been shown to be an effective approach to learning accurate <task_7> . we present a new ie method that employs <method_3> -lrb- a <method_2> , which can represent <otherscientificterm_5> between extractions . this allows for '' collective information extraction '' that exploits the mutual influence between possible extractions . experiments on learning to extract <otherscientificterm_10> from <material_9> demonstrate the advantages of this approach .	1 11 -1 8 6 11 -1 4 0 7 12 14 15 11 -1 3 2 5 11 -1 11 -1 10 9 13 11 -1
A hybrid speech recognizer combining HMMs and polynomial classification .	hidden markov models ; polynomial of gaussian distributions ; conversational speech recognition task ; hybrid speech recognizer ; emission probabilities ; polynomial classifier ; feature vector ; density values ; feature space ; emission probability ; gaus-sians ; polynomial ; classifier	<method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	0 3 3 ; 5 3 3 ; 0 1 5 ; 6 2 11 ; 12 0 6 ; 5 0 10 ; 1 0 9	in this paper , we present a <method_3> combining <method_0> and a <method_5> . in our <method_3> the <otherscientificterm_4> are not modeled as a mixture of <method_10> but are calculated by the <method_5> . however , we do not apply the <method_12> directly to the <otherscientificterm_6> but we make use of the <otherscientificterm_7> of cents gaussians clustering the <otherscientificterm_8> . that means we model the <otherscientificterm_9> as a <otherscientificterm_1> of # - th degree . as most of these <otherscientificterm_7> are approximately zero for a single <otherscientificterm_6> the calculation of a <otherscientificterm_11> can be done very efficiently . the usefulness of this <method_3> was successfully tested on a large <task_2> .	3 0 5 14 15 16 13 -1 4 10 19 13 -1 12 6 7 8 18 13 -1 9 1 20 13 -1 11 17 13 -1 13 -1
Graphical model approach to pitch tracking .	graphi-cal model toolkit ; transition cost functions ; maximum likelihood sense ; pitch tracking parameters ; graphical model framework ; pitch transition ; probabilistic inference ; graphical models ; voicing decision ; pitch estimation ; pitch trackers ; parameter tuning ; probabilistic dependencies ; dynamic programming	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <task> <task> <method> <method> <otherscientificterm> <method>	4 0 3 ; 9 1 8 ; 1 0 10 ; 13 0 10 ; 2 0 4 ; 7 0 12 ; 4 0 10 ; 0 0 6	many <method_10> based on <method_13> require meticulous design of local cost and <otherscientificterm_1> . the forms of these functions are often empirically determined and their parameters are tuned accordingly . <method_11> usually requires great effort without a guarantee of optimal performance . this work presents a <method_4> to automatically optimize <otherscientificterm_3> in the <otherscientificterm_2> . therein , <otherscientificterm_12> between pitch , <otherscientificterm_5> and acoustical observations are expressed using the language of <method_7> , and <method_6> is accomplished using the <method_0> . experiments show that this <method_4> not only expedites the design of a <method_10> , but also yields remarkably good performance for both <task_9> and <task_8> .	10 13 1 17 18 14 -1 11 14 -1 14 -1 4 3 2 15 19 14 -1 12 5 7 6 0 20 22 14 -1 16 21 14 -1
Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning .	dense and low-dimensional feature spaces ; informative ` condensed feature represen-tations ; semi-supervised learning technique ; dependency parsing data ; supervised nlp systems ; conll-2003 ner data ; supervised data ; unsupervised data ; supervised learning ; nlp tasks ; features ; ptb-iii	<otherscientificterm> <otherscientificterm> <method> <material> <method> <material> <material> <material> <task> <task> <otherscientificterm> <material>	7 0 1 ; 11 0 3 ; 7 0 8 ; 7 1 6 ; 6 0 8	this paper proposes a novel approach for effectively utilizing <material_7> in addition to <material_6> for <task_8> . we use <material_7> to generate <otherscientificterm_1> ' from the original feature set used in <method_4> . the main contribution of our method is that it can offer <otherscientificterm_0> for <task_9> while maintaining the state-of-the-art performance provided by the recently developed high-performance <method_2> . our method matches the results of current state-of-the-art systems with very few <otherscientificterm_10> , i.e. , f-score 90.72 with 344 <otherscientificterm_10> for <material_5> , and uas 93.55 with 12.5 k <otherscientificterm_10> for <material_3> derived from <material_11> .	7 6 8 15 16 17 12 -1 1 4 13 12 -1 0 9 2 12 -1 10 5 3 11 14 12 -1
No penalty no tears : Least squares in high-dimensional linear models .	ordinary least squares ; least squares fitting ; numerical exercises ; three-step algorithms ; penalization-based approaches ; generalized version ; hard thresholding ; linear models ; ridge regression ; default method ; sample size ; dimensionality	<method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm>	0 0 7 ; 9 0 7 ; 6 0 3 ; 8 0 0 ; 1 0 3 ; 1 1 6	ordinary least squares -lrb- <method_0> -rrb- is the <method_9> for fitting <method_7> , but is not applicable for problems with <otherscientificterm_11> larger than the <otherscientificterm_10> . for these problems , we advocate the use of a <method_5> of <method_0> motivated by <method_8> , and propose two novel <method_3> involving <method_1> and <otherscientificterm_6> . the <method_3> are methodologically simple to understand intuitively , computationally easy to implement efficiently , and theoretically appealing for choosing models consistently . <method_2> comparing our methods with <method_4> in simulations and data analyses illustrate the great potential of the proposed <method_3> .	0 9 7 11 10 13 14 12 -1 5 8 3 1 6 15 16 17 18 12 -1 2 12 -1 4 12 -1
The Effect of Corpus Size in Combining Supervised and Unsupervised Training for Disambiguation .	unannotated corpus of newswire text ; supervised and unsuper-vised learning ; prepositional phrase attachment ; collins ' parser ; relative clause attachment ; wall street journal ; attachment decisions ; lexical statistics ; unannotated corpus ; unsupervised learning ; unsupervised component ; corpus size ; supervised component	<material> <method> <otherscientificterm> <method> <otherscientificterm> <material> <task> <material> <material> <method> <method> <otherscientificterm> <method>	4 6 6 ; 3 0 12 ; 5 0 3 ; 2 6 6 ; 0 0 7 ; 7 0 10 ; 9 0 7 ; 1 0 11 ; 1 0 6 ; 0 0 10 ; 4 1 2	we investigate the effect of <otherscientificterm_11> in combining <method_1> for two types of <task_6> : <otherscientificterm_4> and <otherscientificterm_2> . the <method_12> is <method_3> , trained on the <material_5> . the <method_10> gathers <material_7> from an <material_0> . we find that the combined system only improves the performance of the <method_3> for small training sets . surprisingly , the size of the <material_8> has little effect due to the noisi-ness of the <material_7> acquired by <method_9> .	11 1 6 4 2 14 17 21 22 24 13 -1 12 3 5 15 16 13 -1 10 7 0 18 19 23 13 -1 13 -1 8 9 20 13 -1
Statistical methods for topic segmentation .	multimedia archival and retrieval systems ; english and mandarin tdt3 corpora ; statistical natural language processing ; automatic topic segmentation ; manually segmented corpus ; information retrieval techniques ; machine learning ; topic segmentation ; nist	<task> <material> <method> <task> <material> <method> <method> <task> <material>	2 1 5 ; 6 1 2 ; 3 0 0	automatic topic segmentation is an important t e c hnology for <task_0> . in this paper we present an algorithm for <task_7> which uses a combination of <method_6> , <method_2> , and <method_5> . the performance of this algorithm is measured by considering the misses and false alarms on a <material_4> . we present our results on the widely used tdt2 and tdt3 corpora provided by <material_8> . most of the techniques described are independent of the source language . we demonstrate this by applying the algorithm on both the <material_1> with only minor changes .	0 12 9 -1 7 6 2 5 10 11 9 -1 4 9 -1 8 9 -1 9 -1 1 3 9 -1
Material recognition in the wild with the Materials in Context Database .	materials in context database ; large-scale , open dataset of materials ; convolu-tional neural networks ; mean class accuracy ; simultaneous material recognition ; real-world material recognition ; rich surface texture ; full images ; well-sampled dataset ; material recognition ; cnn classifiers ; real-world images ; patch-based classification ; lighting conditions ; real-world materials ; deep learning ; recognizing materials ; material databases ; classifying materials ; pixel ; geometry ; patches ; clutter	<method> <material> <method> <metric> <task> <task> <otherscientificterm> <material> <material> <task> <method> <material> <task> <otherscientificterm> <otherscientificterm> <method> <task> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	21 0 18 ; 15 0 9 ; 0 6 8 ; 20 1 13 ; 20 2 14 ; 21 1 4 ; 6 2 14 ; 6 1 20 ; 6 1 13 ; 4 1 7 ; 13 1 22 ; 0 0 5 ; 8 0 5	recognizing materials in <material_11> is a challenging task . <otherscientificterm_14> have <otherscientificterm_6> , <otherscientificterm_20> , <otherscientificterm_13> , and <otherscientificterm_22> , which combine to make the problem particularly difficult . in this paper , we introduce a new , <material_1> in the wild , the <method_0> , and combine this dataset with <method_15> to achieve <task_9> and segmentation of images in the wild . <method_0> is an order of magnitude larger than previous <material_17> , while being more diverse and well-sampled across its 23 categories . using <method_0> , we train <method_2> -lrb- cnns -rrb- for two tasks : <task_18> from <otherscientificterm_21> , and <task_4> and segmentation in <material_7> . for <task_12> on <method_0> we found that the best performing <method_0> can achieve 85.2 % <metric_3> . we convert these trained <method_10> into an efficient fully convolutional framework combined with a fully connected conditional random field -lrb- crf -rrb- to predict the material at every <otherscientificterm_19> in an image , achieving 73.1 % <metric_3> . our experiments demonstrate that having a large , <material_8> such as <method_0> is crucial for <task_5> and segmentation .	11 14 23 -1 6 20 13 22 27 28 30 31 32 34 23 -1 1 0 15 9 25 23 -1 17 23 -1 2 18 24 29 33 23 -1 21 4 7 23 -1 12 3 23 -1 10 19 26 35 36 23 -1
A data-driven approach for estimating the time-frequency binary mask .	time-frequency unit ; binary mask estimator ; localized bayes risk ; false alarm rates ; binary mask ; local snr ; priori snr ; posteriori snr ; instantaneous snr ; sensitivity metric ; decision-directed approach ; data-driven approach ; snr ; classification	<otherscientificterm> <method> <otherscientificterm> <metric> <method> <otherscientificterm> <method> <method> <otherscientificterm> <metric> <method> <method> <method> <task>	10 0 1 ; 1 0 12 ; 11 0 1 ; 9 5 11 ; 10 0 12 ; 11 0 13 ; 6 1 7 ; 2 0 8 ; 9 0 13	the ideal <method_4> , often used in robust speech recognition applications , requires an estimate of the <otherscientificterm_5> in each <otherscientificterm_0> . a <method_11> is proposed for estimating the <otherscientificterm_8> of each t-f unit . by assuming that the a <method_6> and a <method_7> are uniformly distributed within a small region , the <otherscientificterm_8> is estimated by minimizing the <otherscientificterm_2> . the <method_1> derived by the proposed <method_11> is evaluated in terms of hit and <metric_3> . compared to the <method_1> that uses the <method_10> to compute the <method_12> , the proposed <method_11> yielded substantial improvements -lrb- up to 40 % -rrb- in <task_13> performance , when assessed in terms of a <metric_9> which is based on the difference between the hit and <metric_3> .	4 5 0 14 -1 11 8 14 -1 6 7 2 21 22 14 -1 1 3 17 14 -1 10 12 15 16 18 19 20 23 14 -1
Extraction and Verification of KO-OU Expressions from Large Corpora .	large-scale electronic corpus ; ko-ou expression data ; grammatical form ; ko-ou relation ; ko element ; japanese language ; ou element ; japanese ; concord	<material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm>	3 6 2	in the <material_5> , as a predicate is placed at the end of a sentence , the content of a sentence can not be inferred until reaching the end . however , when the content is complicated and the sentence is long , people want to know at an earlier stage in the sentence whether the content is negative , affirmative , or interrogative . in <material_7> , the <otherscientificterm_2> called the <otherscientificterm_3> exists . the <otherscientificterm_3> is a kind of <otherscientificterm_8> . if a <otherscientificterm_4> appears , then an <otherscientificterm_6> appears in the latter part of a sentence . it is being pointed out that the <otherscientificterm_3> gives advance notice to the element that appears in the latter part of a sentence . in this paper , we present the method of extracting automatically the <material_1> from <material_0> and verify the usefulness of the <material_1> .	5 9 -1 9 -1 7 2 3 10 9 -1 8 9 -1 4 6 9 -1 9 -1 9 -1
Exploiting Syntactic Patterns as Clues in Zero-Anaphora Resolution .	intra-sentential and inter-sentential zero-anaphora resolution ; learning-based anaphora resolution model ; rich syntactic pattern features ; zero-anaphora resolution problem ; syntactic patterns ; zero-anaphora resolution ; intra-sentential zero-anaphora ; japanese ; zero-pronouns ; accuracy	<task> <method> <otherscientificterm> <task> <otherscientificterm> <task> <material> <material> <otherscientificterm> <metric>	2 0 1 ; 2 0 6 ; 3 3 0 ; 1 0 6	we approach the <task_3> by decomposing <task_3> into <task_0> . for the former problem , <otherscientificterm_4> of the appearance of <otherscientificterm_8> and their antecedents are useful clues . taking <material_7> as a target language , we empirically demonstrate that incorporating <otherscientificterm_2> in a state-of-the-art <method_1> dramatically improves the <metric_9> of <material_6> , which consequently improves the overall performance of <task_5> .	3 0 13 10 -1 4 8 10 -1 7 2 1 9 6 5 11 12 14 10 -1
Accelerometer-based gesture recognition via dynamic-time warping , affinity propagation , & compressive sensing .	accelerometer-based gesture recognition systems ; dynamic time warping ; affinity propagation algorithms ; dictionary of gestures ; user-independent recognition accuracy ; gesture recognition system ; acceleration-based gesture recognition ; user-dependent recognition ; gesture recognition ; published studies ; gesture sequence ; statistical methods ; compressive sensing ; 3-axis accelerometer	<method> <method> <method> <material> <metric> <method> <task> <task> <task> <material> <material> <method> <method> <method>	13 0 5 ; 5 4 11 ; 4 5 11 ; 12 0 8 ; 1 0 5 ; 4 5 5 ; 0 4 11 ; 7 1 4 ; 1 1 2 ; 2 0 5	we propose a <method_5> based primarily on a single <method_13> . the <method_5> employs <method_1> and <method_2> for training and utilizes the sparse nature of the <material_10> by implementing <method_12> for <task_8> . a dictionary of 18 gestures or classes is defined and a database of over 3,700 repetitions is created from 7 users . our <material_3> is the largest in <material_9> related to <task_6> , to the best of our knowledge . the proposed <method_5> achieves almost perfect <task_7> and a <metric_4> that is competitive with the <method_11> that require significantly a large number of training samples and with the other <method_0> available in literature .	5 13 15 14 -1 1 2 10 12 8 18 19 23 24 14 -1 14 -1 3 9 6 14 -1 7 4 11 16 17 20 21 22 14 -1
Optimal Pricing for Improving Efficiency of Taxi Systems .	taxi drivers ' congestion costs ; taxi driver 's strategy space ; taxi fare structure ; atom schedule method ; infeasible pure strategies ; profit-driven decisions ; taxi drivers ; scheduling constraints ; computational inten-siveness ; market variance	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	3 0 6	in beijing , most <method_6> intentionally avoid working during peak hours despite of the huge customer demand within these peak periods . this dilemma is mainly due to the fact that <otherscientificterm_0> are not reflected in the current <otherscientificterm_2> . to resolve this problem , we propose a new <method_3> to provide <method_6> with extra incentives to work during peak hours . this differs from previous studies of taxi market by considering <otherscientificterm_9> over multiple periods , <method_6> ' <otherscientificterm_5> , and their <otherscientificterm_7> regarding the interdependence among different periods . the major challenge of this research is the <method_8> to identify optimal strategy due to the exponentially large size of a <otherscientificterm_1> and the <otherscientificterm_7> . we develop an <method_3> to overcome these issues . it reduces the magnitude of the problem while satisfying the constraints to filter out <method_4> . simulation results based on real data show the effectiveness of the proposed <method_3> , which opens up a new door to improving the efficiency of taxi market in megacities -lrb- e.g. , beijing -rrb- .	6 10 -1 0 2 10 -1 3 11 10 -1 9 5 7 10 -1 8 10 -1 1 10 -1 10 -1 4 10 -1
Radiobot-CFF : a spoken dialogue system for military training .	call for fire radio dialogues ; interactive information components ; artillery fire missions ; spoken dialogue system ; information-state dialogue manager	<material> <method> <task> <method> <method>	1 2 4	we describe a <method_3> which can engage in <material_0> to help train soldiers in proper procedures for requesting <task_2> . we describe the domain , an <method_4> with a novel system of <method_1> , and provide evaluation results .	3 0 2 5 -1 4 1 6 5 -1
A cine MRI-based study of sibilant fricatives production in post-glossectomy speakers .	acoustic and articulatory data ; cine magnetic resonance images ; dimensional vocal tract reconstructions ; missing unilateral tongue tissue ; precise tongue control ; air flow bypass ; tongue surface shapes ; post-glossectomy speakers ; area functions ; primary closure ; constriction locations ; tongue surfaces ; acoustic spectra ; sibilant fricatives ; constriction ; constrictions	<material> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 3 ; 2 1 6 ; 12 1 6 ; 6 1 10 ; 1 1 2	post-glossectomy patients -lrb- t2 tumors resected with <otherscientificterm_9> , the red lines indicate the midline of the tongues -rrb- abstract glossectomy changes properties of the tongue and negatively affects patients ' speech production . among the most difficult consonants to produce in the <otherscientificterm_7> , the <otherscientificterm_13> / s / and / sh / are often problematic . to better understand these problems in production , this study analyzed <material_0> of / s / and / sh / from three subjects : one normal speaker and two <otherscientificterm_7> with abnormal / s / or / sh . based on <material_1> , three <otherscientificterm_2> , <otherscientificterm_6> behind <otherscientificterm_15> , and <otherscientificterm_8> were analyzed . our results show that in each patient , contrary to normal , / s / and / sh / were quite similar in <otherscientificterm_12> , <otherscientificterm_6> , and <otherscientificterm_10> . in the abnormal / s / , the <otherscientificterm_3> created an <otherscientificterm_5> which made the <otherscientificterm_14> further backward . the abnormal / sh / may be explained by the lack of <metric_4> after surgery . in addition , the <otherscientificterm_11> in the patients were more asymmetric in the back and were not grooved for / s / anterior to the <otherscientificterm_14> .	9 16 -1 7 13 16 -1 0 16 -1 1 18 21 16 -1 2 6 15 8 19 20 16 -1 12 10 17 16 -1 3 5 14 16 -1 4 16 -1
Java Visual Speech Components for Rapid Application Development of GUI Based Speech Processing Applications .	gui based speech processing applications ; external pitch values ; java framework ; power plot ; java programs ; speech signal ; speech file ; object-oriented design ; standard components ; transcription ; spectrogram	<task> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <task> <otherscientificterm>	5 1 3 ; 8 3 4 ; 3 1 10 ; 2 0 0 ; 8 0 5	in this paper , we describe a new <method_2> for an easy and efficient way of developing new <task_0> . <method_8> are provided to display the <material_5> , the <otherscientificterm_3> , and the <otherscientificterm_10> . furthermore , a component to create a new <task_9> and to display and manipulate an existing <task_9> is provided , as well as a component to display and manually correct <otherscientificterm_1> . these <method_8> can be easily embedded into own <method_4> . <method_8> can be synchronized to display the same region of the <otherscientificterm_6> . the <method_7> provides base classes for rapid development of own components .	2 0 8 15 11 -1 5 3 10 12 14 16 11 -1 9 1 11 -1 4 13 11 -1 6 11 -1 7 11 -1
Network topology discovery using finite mixture models .	unicast end-to-end packet pair delay measurements ; hierarchical topology construction algorithm ; network topology estimation strategy ; unsupervised learning algorithms ; map criterion ; mixture models ; network tree ; leaf nodes ; delay co-variances ; mixture components ; leaf pairs ; tree	<method> <method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	2 0 6 ; 3 0 9 ; 1 0 11 ; 0 0 2 ; 5 0 2 ; 4 0 10	in this article we propose a <method_2> using <method_0> that is based on <method_5> for the <otherscientificterm_8> . an <method_3> is applied to estimate the number of <method_9> and delay covariances . the <otherscientificterm_10> are clustered by a <otherscientificterm_4> and passed to a <method_1> to rebuild the <otherscientificterm_11> . results from an ns simulation show that our <method_2> can identify a <method_6> with 8 <otherscientificterm_7> .	2 0 5 8 16 17 12 -1 3 9 14 12 -1 10 4 1 11 15 18 12 -1 6 7 13 12 -1
Endpoint detection in noisy environment using a Poincare recurrence metric .	nonstationary and transient time series ; recurrence point variability algorithm ; detection of state transitions ; recurrence time statistics ; poincaré recurrence points ; poincaré recurrence metric ; speech endpoint detection ; fractal structure ; chaotic systems ; speech recognition ; recurrence points ; stationarity change ; noisy environments ; low snr ; time series ; noise	<otherscientificterm> <method> <task> <metric> <otherscientificterm> <metric> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 9 ; 1 0 2 ; 5 0 11 ; 12 2 9 ; 3 0 8	speech <task_9> continues to be a challenging problem particularly for <task_9> in <otherscientificterm_12> . in this paper , we address this problem from the point of view of fractals and chaos . by studying <metric_3> for <method_8> , we find the nonstationarity and transience in a <otherscientificterm_14> are due to non-recurrence and lack of <otherscientificterm_7> in the signal . a <metric_5> is designed to determine the <otherscientificterm_11> for <task_9> . we consider the small area of beginning and ending of an utterance as transient . for <otherscientificterm_0> , we expect the average number of <otherscientificterm_4> for each given small block will be different for different blocks of data subsets . however , the average number of <otherscientificterm_10> will stay nearly constant . the resulting <method_1> is shown to be well suited for the <task_2> in a <otherscientificterm_14> and is very robust for different types of <otherscientificterm_15> , especially for <otherscientificterm_13> .	9 12 20 16 -1 16 -1 3 8 14 7 21 16 -1 5 11 17 19 16 -1 16 -1 0 4 16 -1 16 -1 10 18 16 -1
Solving Distributed Constraint Optimization Problems Using Logic Programming .	distributed constraint optimization problems ; answer set programming ; memory limitations ; dcop algorithm ; logic programs ; logic programming ; multi-agent problems ; asp-dpop	<task> <method> <otherscientificterm> <method> <method> <method> <task> <method>	1 0 0 ; 1 0 6	this paper explores the use of <method_1> in solving <task_0> . it makes the following contributions : -lrb- i -rrb- it shows how one can formulate <method_1> as <method_4> ; -lrb- ii -rrb- it introduces <method_7> , the first <method_3> that is based on <method_5> ; -lrb- iii -rrb- it experimentally shows that <method_7> can be up to two orders of magnitude faster than <method_1> -lrb- its imperative-programming counterpart -rrb- as well as solve some problems that <method_1> fails to solve due to <otherscientificterm_2> ; and -lrb- iv -rrb- it demonstrates the applicability of <method_1> in the wide array of <task_6> currently modeled as <method_1> .	1 0 9 8 -1 4 7 3 5 2 10 8 -1
Boosting Decision Trees .	quinlan 's c4 .5 algorithm ; data mining problems ; information ratio criterion ; probability distribution ; boosring ensemble ; knowledge discovery ; decision trees ; boosting algorithm ; decision tree ; trees	<method> <task> <metric> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	8 0 6 ; 7 0 6 ; 5 1 1	a new <method_7> of freund and schapire is used to improve the performance of <otherscientificterm_6> which are constructed usin : the <metric_2> of <method_0> . this <method_7> iteratively constructs a series of <otherscientificterm_6> , each <otherscientificterm_8> being trained and pruned on examples that have been filtered by previously trained <otherscientificterm_9> . examples that have been incorrectly classified by the previous <otherscientificterm_9> in the ensemble are resampled with higher probability to give a new <otherscientificterm_3> for the next ace in the ensemble to tnin on . results from optical cha-xc : er reco ~ tion -lrb- ocr -rrb- , and <task_5> and <task_1> show that in comparison to single <otherscientificterm_9> , or to <otherscientificterm_9> trained independenrly _ or to <otherscientificterm_9> trained on subsets of the feature space , the <method_4> is much better .	7 6 2 0 10 -1 8 9 11 12 10 -1 3 10 -1 5 13 10 -1
Cross Language Text Classification via Subspace Co-regularized Multi-view Learning .	cross language text classification tasks ; subspace co-regularized multi-view learning method ; multilingual text classification problems ; cross language text classification ; multi-view learning methods ; cross language classification ; domain adaptation methods ; parallel documents ; inductive methods ; classification model ; parallel corpora ; machine translation ; label knowledge ; labeling cost ; classifier	<material> <method> <task> <task> <method> <method> <method> <material> <method> <method> <material> <method> <otherscientificterm> <metric> <method>	10 0 1 ; 10 0 11 ; 11 0 1 ; 5 0 12 ; 6 1 4 ; 1 4 8 ; 1 0 3 ; 0 5 1	in many <task_2> , the documents in different languages often share the same set of categories . to reduce the <metric_13> of training a <method_9> for each individual language , it is important to transfer the <otherscientificterm_12> gained from one language to another language by conducting <method_5> . in this paper we develop a novel <method_1> for <task_3> . this <method_1> is built on <material_10> produced by <method_11> . <method_1> jointly minimizes the training error of each <method_14> in each language while penalizing the distance between the subspace representations of <material_7> . our empirical study on a large set of <material_0> shows the proposed <method_1> consistently outperforms a number of <method_8> , <method_6> , and <method_4> .	2 15 -1 13 9 12 5 19 15 -1 1 3 22 15 -1 10 11 16 17 18 15 -1 14 7 15 -1 20 21 23 15 -1
Semi-supervised dimensionality reduction on data with multiple representations for label propagation on facial images .	state of the art methods ; person identity label propagation ; must-link and cannot-link constraints ; priori pairwise information ; semi-supervised dimensionality reduction ; label information ; image data ; stereo videos ; linear combination ; projection matrix ; data representations ; facial images ; locality information ; stereo movies	<method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <material> <method> <otherscientificterm> <method> <material> <otherscientificterm> <material>	11 0 4 ; 9 0 9 ; 12 1 3 ; 7 0 11	in this paper a novel method is introduced for <task_4> on <material_11> extracted from <material_7> . it operates on <material_6> with multiple representations and calculates a <otherscientificterm_9> that preserves <otherscientificterm_12> and a <otherscientificterm_3> , in the form of <otherscientificterm_2> between the various <method_10> , as well as <otherscientificterm_5> for a percentage of the data . the final <method_10> is a <method_8> of the projections of all <method_10> . the performance of the proposed semi-supervised multiple locality preserving projections method was evaluated in <task_1> on <material_11> extracted from <material_13> . experimental results showed that the proposed method outperforms <method_0> .	4 11 7 15 18 14 -1 6 9 12 3 2 10 5 16 17 14 -1 8 14 -1 1 13 14 -1 0 14 -1
A Deep Learning Approach to Unsupervised Ensemble Learning .	rbm-based deep neural net ; restricted boltzmann machine ; simulated and real-world datasets ; unsupervised ensemble learning ; deep learning methods ; conditional independence assumption ; posterior probabilities ; hidden node ; classifiers ; crowdsourcing	<method> <method> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	5 0 8	we show how <method_4> can be applied in the context of <task_9> and <task_3> . first , we prove that the popular model of dawid and skene , which assumes that all <method_8> are conditionally independent , is equivalent to a <method_1> with a single <otherscientificterm_7> . hence , under this model , the <otherscientificterm_6> of the true labels can be instead estimated via a trained <method_1> . next , to address the more general case , where <method_8> may strongly violate the <otherscientificterm_5> , we propose to apply <method_0> . experimental results on various <material_2> demonstrate that our proposed dnn approach outperforms other state-of-the-art methods , in particular when the data violates the <otherscientificterm_5> .	4 9 3 10 -1 8 1 7 10 -1 6 10 -1 5 0 11 10 -1 2 10 -1
Sparse seismic imaging using variable projection .	sparse signal and auxiliary parameters ; large-scale sparse deconvolution problems ; sparse green 's function ; seismic imaging example ; variable projection technique ; signal processing problems ; signal of interest ; spar-sity promoting optimization ; seismic experimental data ; sparsity optimization ; auxiliary information ; source signature ; variable projection ; deconvolution techniques	<otherscientificterm> <task> <otherscientificterm> <material> <method> <task> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <method> <method>	8 0 2 ; 12 1 7 ; 9 0 2 ; 4 0 0	we consider an important class of <task_5> where the <otherscientificterm_6> is known to be sparse , and can be recovered from data given <otherscientificterm_10> about how this data was generated . for example , a <otherscientificterm_2> may be recovered from <material_8> using <method_9> when the <otherscientificterm_11> is known . unfortunately , in practice this information is often missing , and must be recovered from data along with the signal using <method_13> . in this paper , we present a novel methodology to simultaneously solve for the <otherscientificterm_0> using a recently proposed <method_4> . our main contribution is to combine <method_12> with <method_7> , obtaining an efficient algorithm for <task_1> . we demonstrate the algorithm on a <material_3> .	5 6 10 14 -1 2 8 9 11 15 17 14 -1 13 14 -1 0 4 18 14 -1 12 16 14 -1 7 1 14 -1
Signal recovery in shift-invariant spaces from partial frequency data .	partial frequency content ; signal recovery ; frequency content ; shift-invariant spaces ; signal bandwidth ; reconstruction ability ; pre-processing	<material> <task> <material> <otherscientificterm> <otherscientificterm> <metric> <method>	6 0 5	this paper studies conditions under which a signal can be reconstructed from <material_0> . we focus on signals in <otherscientificterm_3> generated by multiple generators . for these signals , we derive a lower bound on the necessary <otherscientificterm_4> as well as sufficient conditions on the generators such that <task_1> is possible . when the available <material_2> is not sufficient to recover the signal , we propose appropriate <method_6> that can improve the <metric_5> .	0 7 -1 3 7 -1 4 1 7 -1 2 6 5 8 7 -1
Waiting cycle analysis on H. 246 decoder run in PAC Duo platform .	dual core data partition ; pac duo platform ; multi core scenarios ; waiting cycle analysis ; inter core synchronization ; execution speed ; dual-core decoders ; resource contention ; function partition ; dual core ; inter-core synchronization ; cache miss ; data partition	<otherscientificterm> <method> <otherscientificterm> <method> <task> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	5 2 9 ; 11 6 6 ; 7 1 11 ; 8 2 9 ; 10 6 6 ; 7 6 6 ; 4 1 7 ; 12 1 8 ; 8 1 0 ; 10 1 7	two approaches for parallelization of h. 264 decoder , <otherscientificterm_12> and <otherscientificterm_8> , are realized on a <method_1> , which contains two parallel architecture core digital signal processors -lrb- pacdsp 's -rrb- . eight baseline cif sequences are decoded and their execution cycles and waiting cycles are examined . there are three roots hindering the performance of <method_6> : <task_10> , <otherscientificterm_7> , and <otherscientificterm_11> . through the <method_3> , the major reasons causing the degradation of <otherscientificterm_9> h. 246 decoders are found . the <task_4> and <otherscientificterm_7> principally slow down the <metric_5> of the <otherscientificterm_9> with <otherscientificterm_8> and <otherscientificterm_0> , respectively . the precious experience and analysis will help the software and hardware designers explore the mechanisms to improve performance of the <otherscientificterm_2> .	12 8 1 21 13 -1 13 -1 6 10 7 11 15 16 18 19 23 13 -1 3 9 13 -1 4 5 0 14 17 20 22 13 -1 13 -1
Intelligibility detection of pathological speech using asymmetric sparse kernel partial least squares classifier .	un-weighted accuracy ; speech production system ; unhealthy social behavior ; automatic intel-ligibility detection ; pathological speech ; pathological speech ; intelligibility detection ; articulatory mechanisms ; physical problem ; voice and/or ; voice disorders ; pathological voices ; voice abuse ; disease ; illness	<metric> <method> <otherscientificterm> <task> <material> <material> <task> <method> <task> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm>	8 2 1 ; 2 1 12	pathological speech usually refers to the <otherscientificterm_10> resulting from atypicalities in <otherscientificterm_9> in the <method_7> due to <otherscientificterm_13> , <otherscientificterm_14> or other <task_8> in the <method_1> . it may increase <otherscientificterm_2> and <material_12> , and dramatically affect the patients ' quality of life . therefore , <task_3> of <material_4> has an important role in the opportune treatment of <material_11> . this paper proposes to use asymmetric sparse kernel partial least squares classifier -lrb- askplsc -rrb- for <task_6> of <material_4> . the proposed approach achieves an <metric_0> of 74.0 % , which is 7.34 % relative improvement of baseline system of an <metric_0> of 68.90 % for the pathology sub-challenge of interspeech 2012 speaker trait challenge .	10 9 7 13 14 8 1 16 15 -1 2 12 17 15 -1 3 4 11 15 -1 6 15 -1 0 15 -1
Dialog act tagging with support vector machines and hidden Markov models .	text and acoustic features ; dense low-dimensional acoustic features ; sparse high-dimensional text features ; linear support vector machines ; hcrc maptask corpus ; sequence labelling algorithms ; hidden markov models ; dialog act tagging ; support vector machines ; posterior probabilities	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <method> <method> <task> <method> <otherscientificterm>	5 0 9 ; 2 1 1 ; 3 1 6	we use a combination of <method_3> and <method_6> for <task_7> in the <material_4> , and obtain better results than those previously reported . <method_8> allow easy integration of <otherscientificterm_2> and <otherscientificterm_1> , and produce <otherscientificterm_9> usable by <method_5> . the relative contribution of <otherscientificterm_0> for each class of dialog act is analyzed .	3 6 7 4 8 13 10 -1 2 1 9 5 11 12 10 -1 0 10 -1
Sparse kernel approximations for efficient classification and detection .	low-dimensional and dense features ; high-dimensional and sparse ones ; bundle optimisation methods ; arbitrary additive kernels ; pascal voc data ; sparse feature encoding ; deformable part models ; non-linear kernels ; fisher kernels ; memory use ; sparse features ; arbitrary kernels ; intersection kernel ; product quantisation ; image classification ; object detection ; features ; learning	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <task>	10 0 11 ; 5 0 13 ; 8 0 14 ; 8 1 15 ; 2 0 10	efficient <task_17> with <method_7> is often based on extracting <otherscientificterm_16> from the data that '' linearise '' the kernel . while most constructions aim at obtaining <otherscientificterm_0> , in this work we explore <otherscientificterm_1> . we give a method to compute <otherscientificterm_10> for <otherscientificterm_11> , re-deriving as a special case a popular map for the <method_12> and extending it to <otherscientificterm_3> . we show that <method_2> can handle efficiently these <otherscientificterm_10> in <task_17> . as an application , we show that <otherscientificterm_13> can be interpreted as a <otherscientificterm_5> , and use this to significantly accelerate <task_17> with this technique . we demonstrate these ideas on <task_14> with <method_8> and <task_15> with <method_6> on the challenging <material_4> , obtaining five to tenfold speed-ups as well as reducing <metric_9> by an order of magnitude .	17 7 16 18 -1 0 1 18 -1 10 11 12 3 19 18 -1 2 23 18 -1 13 5 20 18 -1 21 22 18 -1
Joint linear precoder optimization and base station selection for an uplink MIMO network : A game theoretic approach .	mimo interfering multiple access channel ; weighted sum rate optimization problem ; nash equilibrium ; weighted sum rate optimization ; linear procoders ; bs congestion ; congested bss ; noncooperative game ; user fairness ; stationary solution ; ne	<method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	9 0 1 ; 7 0 3 ; 3 0 0	we consider the <method_3> of <method_3> in a <method_0> . we propose to jointly optimize the users ' <method_4> as well as their base station -lrb- bs -rrb- associations . this approach enables the users to avoid <otherscientificterm_6> and can improve system performance as well as <otherscientificterm_8> . we formulate the <method_3> into a <otherscientificterm_7> , and develop an algorithm that allows the players to distributedly reach the <otherscientificterm_2> of the game . we show that every <otherscientificterm_10> of the game is a <method_9> of the <task_1> , and propose an algorithm to compute the <otherscientificterm_10> of the game . simulation results show that the proposed algorithm performs well in the presence of <otherscientificterm_5> .	3 0 14 11 -1 4 11 -1 6 8 11 -1 7 2 13 11 -1 10 9 1 12 11 -1 11 -1
Elaboration in Object Descriptions through Examples .	instructional or explanatory contexts ; textual descriptions ; object descriptions	<otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 0	examples are often used along with <otherscientificterm_1> to help convey particular ideas-especially in <otherscientificterm_0> . these accompanying examples reflect information in the surrounding text , and in turn , also influence the text . sometimes , examples replace possible -lrb- textual -rrb- elaborations in the description . it is thus clear that if <otherscientificterm_2> are to be generated , the system must incorporate strategies to handle examples . in this work , we shall investigate some of these issues in the generation of <otherscientificterm_2> .	1 0 4 3 -1 3 -1 3 -1 2 3 -1 3 -1
Enabling scalable stochastic gradient-based inference for Gaussian processes by employing the Unbiased LInear System SolvEr -LRB- ULISSE -RRB- .	stochastic gradient langevin dynamics algorithm ; unbiased linear systems solver ; parallelizable covariance matrix-vector products ; unbiased estimation of gradients ; gaussian process regression ; quantification of uncertainty ; posterior distribution ; gaussian processes ; linear systems ; covariance parameters ; marginal likelihood ; negligible bias ; stochastic gradients ; covari-ance	<method> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 0 12 ; 1 0 3 ; 2 0 1	in applications of <method_7> where <otherscientificterm_5> is of primary interest , it is necessary to accurately characterize the <otherscientificterm_6> over <otherscientificterm_9> . this paper proposes an adaptation of the <method_0> to draw samples from the <otherscientificterm_6> over <otherscientificterm_9> with <otherscientificterm_11> and without the need to compute the <otherscientificterm_10> . in <task_4> , this has the enormous advantage that <otherscientificterm_12> can be computed by solving <method_8> only . a novel <method_1> based on <method_2> is developed to accelerate the <task_3> . the results demonstrate the possibility to enable scal-able and exact -lrb- in a monte carlo sense -rrb- quantifi-cation of uncertainty in <method_7> without imposing any special structure on the <otherscientificterm_13> or reducing the number of input vectors .	7 5 6 9 14 -1 0 11 10 14 -1 4 12 8 15 14 -1 1 2 3 16 17 14 -1 14 -1
Expressive Completeness of Existential Rule Languages for Ontology-based Query Answering .	ontology-based conjunctive query answering ; class of disjunc-tive tuple-generating dependencies ; class of embedded dependencies ; disjunctive embedded dependencies ; ontology-based query answering ; built-in linear order ; existential rules ; semantic definition ; ocqa ontologies ; expressive completeness ; data dependencies ; databases	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	10 6 6 ; 7 0 0	existential rules , also known as <otherscientificterm_10> in <material_11> , have been recently rediscovered as a promising family of languages for <task_4> . in this paper , we prove that <otherscientificterm_3> exactly capture the class of recursively enumerable ontologies in <task_0> . our <otherscientificterm_9> result does not rely on any <otherscientificterm_5> on the database . to establish the <otherscientificterm_9> , we introduce a novel <otherscientificterm_7> for <task_0> . we also show that neither the <otherscientificterm_1> nor the <otherscientificterm_2> is expressively complete for recursively enumerable <otherscientificterm_8> .	10 11 4 13 12 -1 3 0 12 -1 9 5 12 -1 7 14 12 -1 1 2 8 6 12 -1
Array processing techniques and shape reconstruction in tomography .	linear antenna array processing ; mathematical inversion problem ; classical ap techniques ; x ray tomography ; bayesian estimation approach ; compact object ; shape reconstruction ; inverse problem ; contour ; polygon	<method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm>	2 0 6 ; 1 0 6 ; 4 0 7	we consider the problem of the <task_6> of a <otherscientificterm_5> in <otherscientificterm_3> when the <otherscientificterm_8> of the object is modeled by a <otherscientificterm_9> . the problem is then to estimate the vertices of that <otherscientificterm_9> from a limited number of projections . the main objectives of this paper are : -lcb- to show how this <task_6> becomes equivalent to a generic <task_1> which arises also in <method_0> ; -lcb- to evaluate the performances of the <method_2> to handle with this <task_6> , and , -lcb- to propose a new method based on <method_4> for the resolution of this <task_7> .	6 5 3 8 9 10 -1 10 -1 1 0 2 4 7 11 12 13 10 -1
Text to 3D Scene Generation with Rich Lexical Grounding .	3d scene generation task ; manually specified object categories ; map descriptions of scenes ; 3d scene generation ; natural language descriptions ; 3d geometric representations ; rule-based methods ; human judgments ; concrete referents ; tex-tual descriptions ; grounding approach ; physical objects ; lexical terms ; art ; robotics ; education	<task> <material> <task> <task> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <material>	13 1 15 ; 7 0 10 ; 6 0 3 ; 10 4 7 ; 15 1 14	the ability to <task_2> to <task_5> has many applications in areas such as <material_13> , <material_15> , and <task_14> . however , prior work on the text to <task_0> has used <material_1> and language that identifies them . we introduce a dataset of 3d scenes annotated with <material_4> and learn from this data how to ground <otherscientificterm_9> to <otherscientificterm_11> . our method successfully grounds a variety of <otherscientificterm_12> to <otherscientificterm_8> , and we show quantitatively that our method improves <task_3> over previous work using purely <method_6> . we evaluate the fidelity and plau-sibility of 3d scenes generated with our <method_10> through <otherscientificterm_7> . to ease evaluation on this task , we also introduce an <method_10> that strongly correlates with <otherscientificterm_7> .	2 5 13 15 14 17 21 16 -1 0 1 16 -1 4 9 11 16 -1 12 8 3 6 19 16 -1 10 18 16 -1 7 20 16 -1
Layered image motion with explicit occlusions , temporal consistency , and depth ordering .	optical flow in layers ; image-dependent hidden field prior ; detected occlusion regions ; meaningful scene segmentations ; robust spatial prior ; static scene segmentation ; probabilistic graphical model ; image motion estimation ; layered models ; smooth deviation ; middlebury benchmark ; optical flow ; smooth surfaces ; natural scenes ; layer segmentation ; non-layered methods ; probabilistic model ; temporal consistency ; parametric model ; disocclusions ; mrf ; accuracy ; occlusions	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <metric> <method> <otherscientificterm> <method> <metric> <otherscientificterm>	9 0 11 ; 10 5 6 ; 18 0 11 ; 8 0 1 ; 22 1 19 ; 8 0 5	layered <method_8> are a powerful way of describing <material_13> containing <otherscientificterm_12> that may overlap and occlude each other . for <task_7> , such <method_8> have a long history but have not achieved the wide use or <metric_21> of <method_15> . we present a new <method_16> of <otherscientificterm_0> that addresses many of the shortcomings of previous approaches . in particular , we define a <method_6> that explicitly captures : 1 -rrb- <otherscientificterm_22> and <otherscientificterm_19> ; 2 -rrb- depth ordering of the layers ; 3 -rrb- <metric_17> of the <method_14> . additionally the <otherscientificterm_11> in each layer is modeled by a combination of a <method_18> and a <otherscientificterm_9> based on an <method_20> with a <otherscientificterm_4> ; the resulting <method_6> allows roughness in layers . finally , a key contribution is the formulation of the layers using an <otherscientificterm_1> based on recent <method_8> for <task_5> . the <method_6> achieves state-of-the-art results on the <material_10> and produces <otherscientificterm_3> as well as <otherscientificterm_2> .	8 13 12 23 -1 7 21 15 23 -1 16 0 23 -1 6 22 19 17 14 28 23 -1 11 24 26 23 -1 18 9 20 4 27 29 23 -1 1 5 25 23 -1
A feature study for classification-based speech separation at very low signal-to-noise ratio .	low signal-to-noise ratios ; temporal trajectories of feature dimensions ; multi-resolution cochleagram ; snr level of-5 db ; low snr condition ; robust speech recognition ; neural network classifier ; classification problem ; background noise ; speech separation ; speech separation ; robust features ; monaural features ; noisy mixture ; post-processing technique ; non-stationary noises ; feature robustness ; local information ; speech ; separation ; classification	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <task> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <task>	14 0 9 ; 16 5 2 ; 13 0 11 ; 5 0 9 ; 16 0 9 ; 7 0 19 ; 14 0 5 ; 2 0 5	speech separation is a challenging problem at <otherscientificterm_0> . <otherscientificterm_19> can be formulated as a <task_7> . in this study , we focus on the <otherscientificterm_3> in which <material_18> is generally dominated by <otherscientificterm_8> . in such a <otherscientificterm_4> , extracting <otherscientificterm_11> from a <otherscientificterm_13> is crucial for successful <task_20> . using a common <method_6> , we systematically compare separation performance of many <otherscientificterm_12> . in addition , we propose a new <otherscientificterm_2> called <otherscientificterm_2> , which is extracted from four cochlea-grams of different resolutions to capture both <otherscientificterm_17> and spectrotemporal context . comparisons using two <otherscientificterm_15> show a range of <metric_16> for <task_9> with the proposed <otherscientificterm_2> performing the best . we also find that <otherscientificterm_2> , a <method_14> previously used for <task_5> , improves <task_9> performance by smoothing the <otherscientificterm_1> .	0 19 21 -1 7 27 21 -1 3 18 8 21 -1 4 11 13 20 24 21 -1 6 12 21 -1 2 17 21 -1 15 23 26 21 -1 16 9 22 25 28 29 21 -1
Recognizing Handwritten Digits Using Mixtures of Linear Models .	pixel-based images of digits ; locally linear generative models ; sample covariance matrices ; tangent vectors ; em-based algorithm ; local deformations ; m-step ; recognition	<material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task>	1 0 7 ; 3 3 2 ; 3 0 5	we construct a mixture of <method_1> of a collection of <material_0> , and use <method_1> for <task_7> . different models of a given digit are used to capture different styles of writing , and new images are classified by evaluating their log-likelihoods under each <method_1> . we use an <method_4> in which the <method_6> is computationally straightforward principal components analysis -lrb- <method_6> -rrb- . incorporating tangent-plane information -lsb- 12 -rsb- about expected <otherscientificterm_5> only requires adding <otherscientificterm_3> into the <otherscientificterm_2> for the <method_6> , and it demonstrably improves performance .	1 0 7 9 8 -1 8 -1 4 6 8 -1 5 3 2 10 11 8 -1
Comparison between CFG Filtering Techniques for LTAG and HPSG .	cfg filtering techniques ; cfg filter ; ltag ; hpsg	<method> <method> <method> <method>	0 0 3 ; 0 0 2 ; 2 4 3	an empirical comparison of <method_0> for <method_2> and <method_3> is presented . we demonstrate that an approximation of <method_3> produces a more effective <method_1> than that of <method_2> . we also investigate the reason for that difference .	0 2 3 5 6 7 4 -1 1 4 -1 4 -1
Some Experiments in Mining Named Entity Transliteration Pairs from Comparable Corpora .	parallel named entity transliteration pairs ; parallel named entity pairs ; training transliteration systems ; well-trained linear classifier ; article-aligned comparable corpora ; mining transliterations pairs ; linguistic tools ; indian language ; transliteration pairs ; mining methodology ; nlp tasks ; tamil ; english	<material> <material> <task> <method> <material> <task> <method> <material> <material> <method> <task> <material> <material>	1 6 10 ; 3 0 8 ; 1 0 2	parallel named entity <material_1> are important resources in several <task_10> , such as , clir and mt systems . further , such <material_1> may also be used for <task_2> , if <material_1> are transliterations of each other . in this paper , we profile the performance of a <method_9> in mining <material_0> in <material_12> and an <material_7> , <material_11> , leveraging <method_6> in <material_12> , and <material_4> in the two languages . we adopt a <method_9> parallel to that of -lsb- klementiev and roth , 2006 -rsb- , but we focus instead on mining <material_0> , using a <method_3> to identify <material_8> . we profile the performance at several operating parameters of our <method_9> and present the results that show the potential of the <method_9> in <task_5> ; in addition , we uncover a host of issues that need to be resolved , for effective mining of <material_0> .	1 10 14 13 -1 2 16 13 -1 9 0 12 7 11 6 4 13 -1 3 15 13 -1 8 13 -1
Fastmap : a fast , approximate maximum a posteriori probability parameter estimator with application to robust matched-field processing .	pos-teriori approach ; computationally-intensive i n tegrations ; approximate map estimator ; matched-eld source localiza-tion ; estimation problems ; unknown parameters ; nuisance parameters ; parameter estimation ; computationally-intensive esti-mator ; bayesian estimation ; monte carlo ; estimation process	<method> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <task> <method> <task> <method> <method>	6 3 11	in many <task_4> , the set of <otherscientificterm_5> can be divided into a subset of desired parameters and a subset of <otherscientificterm_6> . using a maximum a <method_0> to <task_7> , these <otherscientificterm_6> are integrated out in the <method_11> . this can result in an extremely <method_8> . this paper proposes a method by which <method_1> over the <otherscientificterm_6> required in <task_9> may be avoided under certain conditions . the propsed method is an <method_2> which is much more compu-tationally ecient than direct , or even <method_10> , integration of the joint posteriori distribution of the desired and <otherscientificterm_6> . as an example of its eciency , we apply the fast algorithm to <task_3> in an uncertain environment .	4 5 6 12 -1 0 7 11 13 12 -1 8 12 -1 1 9 12 -1 2 10 12 -1 12 -1
Closed-loop feedback cancellation utilizing two microphones and transform domain processing .	real measured feedback paths ; incoming signal estimate ; discrete cosine transform ; undesired signal correlation ; adaptive filter signals ; acoustic feedback cancellation ; convergence rates ; adaptation process ; error signal ; hearing aids ; speech signals ; adaptive filters ; microphones approach ; orthogonal transforms ; canceler	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric> <task> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm>	0 1 10 ; 2 0 4	in this paper we are studying the use of two microphones for <task_5> in <otherscientificterm_9> . with the two <method_12> , an additional microphone is employed to provide added information about the signals which is then utilized to obtain an <otherscientificterm_1> . this <otherscientificterm_1> is removed from the <otherscientificterm_8> prior to adapting the <otherscientificterm_14> , thus removing the <otherscientificterm_3> . in this paper , we propose to use <otherscientificterm_13> with the two <method_12> . the discrete fourier transform and the <otherscientificterm_2> are implemented to transform the <otherscientificterm_4> . also , a bank of <method_11> is employed , each adapting to different portions of the spectrum for a finer control of the <task_7> . simulation results based on <material_0> and <material_10> show improved <metric_6> and stable solutions .	5 9 15 -1 12 1 15 -1 8 14 3 15 -1 13 15 -1 2 4 17 15 -1 11 15 -1 7 16 15 -1
Goal Recognition Design with Stochastic Agent Action Outcomes .	markov decision process based algorithms ; goal recognition design problems ; worst-case distinctiveness measure ; stochastic grd problems ; stochastic action outcomes ; real-world problems ; wheel slippage ; wcd ; stochastic-ity	<method> <task> <metric> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 3	goal recognition design -lrb- grd -rrb- problems involve identifying the best ways to modify the underlying environment that the agents operate in , typically by making a subset of feasible actions infeasible , in such a way that agents are forced to reveal their goals as early as possible . thus far , existing work assumes that the outcomes of the actions of the agents are deterministic , which might be unrealistic in <task_5> . for example , <otherscientificterm_6> in robots cause the outcomes of their movements to be stochastic . in this paper , we generalize the <task_1> to <task_3> , which handle <otherscientificterm_4> . we also generalize the <metric_2> , which measures the goodness of a solution , to take <otherscientificterm_8> into account . finally , we introduce <method_0> to compute the <otherscientificterm_7> and minimize <method_0> by making up to k actions infeasible .	9 -1 5 9 -1 6 9 -1 1 10 9 -1 3 4 9 -1 2 8 9 -1
SDG Cut : 3D Reconstruction of Non-lambertian Objects Using Graph Cuts on Surface Distance Grid .	surface distance grid ; iterative graph cuts based algorithm ; 3d reconstruction of non-lambertian objects ; signed distance transform ; volumetric graph cuts ; non-lambertian photo-consistency measure ; minimal surface bias ; surface extrusions ; cost function ; discretization bias ; object surface ; 3d reconstruction ; 3d space ; surface smoothness	<method> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <metric>	6 1 9 ; 2 5 1 ; 0 0 1 ; 0 0 6	we show that the approaches to <task_11> that use <otherscientificterm_4> to minimize a <otherscientificterm_8> over the <otherscientificterm_10> have two types of biases , the <otherscientificterm_6> and the <otherscientificterm_9> . these biases make it difficult to recover <otherscientificterm_7> and other details , especially when a <metric_5> is used . to reduce these biases , we propose a new <method_1> that operates on the <method_0> , which is a special discretization of the <otherscientificterm_12> , constructed using a <otherscientificterm_3> of the current surface estimate . it can be shown that <method_0> significantly reduces the <otherscientificterm_6> , and transforms the <otherscientificterm_9> into a controllable degree of <metric_13> . experiments on <task_2> confirm the effectiveness of our <method_1> over previous methods .	11 4 8 10 6 9 15 14 -1 7 5 14 -1 1 0 12 3 17 14 -1 18 14 -1 13 16 14 -1
Co-Simmate : Quick Retrieving All Pairwise Co-Simrank Scores .	simrank-like measure of similarity ; matrix decomposition based method ; graph structure ; co-simrank score ; singular graphs ; pagerank vectors ; graph ; co-simrank	<otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	7 6 0 ; 4 0 1 ; 2 0 0 ; 2 0 7	co-simrank is a useful <otherscientificterm_0> based on <otherscientificterm_2> . the existing method iteratively computes each pair of <metric_3> from a dot product of two <otherscientificterm_5> , entailing o -lrb- log -lrb- 1 / ǫ -rrb- n 3 -rrb- time to compute all pairs of <metric_3> in a <otherscientificterm_6> with n nodes , to attain a desired accuracy ǫ . in this study , we devise a model , <method_7> , to speed up the retrieval of all pairs of <metric_3> to o -lrb- log 2 -lrb- log -lrb- 1 / ǫ -rrb- -rrb- n 3 -rrb- time . moreover , we show the optimality of <method_7> among other hop - -lrb- u k -rrb- variations , and integrate it with a <method_1> on <otherscientificterm_4> to attain higher efficiency . the viable experiments verify the superiority of <method_7> to others .	0 2 9 11 12 8 -1 3 5 6 8 -1 7 8 -1 10 8 -1 1 4 8 -1
Modeling Form for On-line Following of Musical Performances .	automated musical accompaniment of human performers ; melodic corpus of 98 jazz melodies ; large-scale structural variation ; sequence-based score followers ; on-line algorithm ; markov model ; written score ; human performer ; score form ; branching structure	<task> <material> <otherscientificterm> <otherscientificterm> <method> <method> <material> <material> <otherscientificterm> <otherscientificterm>	6 0 5 ; 6 0 8 ; 1 5 3	automated musical accompaniment of human performers often requires an agent be able to follow a musical score with similar facility to that of a <material_7> . systems described in the literature represent musical scores in a way that assumes no <otherscientificterm_2> of the piece during performance . if the performer deviates from the expected path by skipping or repeating a section , the system may become lost . we describe a way to automatically generate a <method_5> from a <material_6> that models the <otherscientificterm_8> , and an <method_4> to align a performance to a score . the resulting system can follow performances that take alternate paths through the score without losing its place . we compare the performance of our system to that of <otherscientificterm_3> on a <material_1> . results show that explicitly representing the <otherscientificterm_9> of a score significantly improves score following when the branch a performer may take is unknown beforehand .	7 10 -1 2 10 -1 10 -1 5 6 8 4 11 12 10 -1 10 -1 13 10 -1 3 1 10 -1
Rao-Blackwellised Gibbs sampling for switching linear dynamical systems .	rao-blackwellised gibbs sampling ; hidden markov models ; switching linear dy-namical systems ; assumption of independent segments ; arpa resource management task ; stochastic segment model ; discrete state sequence ; linear dynamical systems ; intractable model ; proposal mechanism ; speech recognition ; inference ; speech	<method> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <method> <task> <task> <material>	0 0 0 ; 4 5 11 ; 4 5 0 ; 0 0 10 ; 0 0 11 ; 1 1 7 ; 0 0 3	this paper describes the application of <method_0> to <task_10> using <method_2> -lrb- <method_0> -rrb- . the <method_0> is a hybrid of standard <method_1> and <method_7> . <method_0> is an extension of the <method_5> as <method_0> relaxes the <otherscientificterm_3> . <method_0> explicitly take into account the strong co-articulation present in <material_12> . unfortunately , <task_11> in <method_0> is intractable unless the <otherscientificterm_6> is known . <method_0> is one approach that may be applied for both improved training and decoding for this form of <method_8> . the theory of <method_0> and <method_0> is described , along with an efficient <method_9> . the performance of the <method_0> using <method_0> for training and <task_11> is evaluated on the <material_4> .	0 10 2 17 13 -1 1 7 19 13 -1 5 3 20 13 -1 12 13 -1 11 6 13 -1 8 13 -1 9 13 -1 14 15 16 18 13 -1
Matched filtering assisted energy detection for sensing weak primary user signals .	secondary users ; energy detector ; energy detection ; spectrum sensing ; energy detection ; su signals ; su interference ; cognitive radios ; sus ; delay	<otherscientificterm> <method> <task> <task> <task> <material> <otherscientificterm> <method> <method> <metric>	7 0 4 ; 4 6 7 ; 7 0 3 ; 4 0 3	energy detection is widely used by <method_7> for <task_3> . during a silent period , <otherscientificterm_0> are kept silent so that the <method_1> does not confuse <material_5> for primary user -lrb- pu -rrb- signals . due to imperfect coordination , an <otherscientificterm_0> may transmit during a silent period and cause possible false alarms . we propose to leverage matched filters that already exist in many <method_8> to alleviate the impact of such <otherscientificterm_6> by combining the matched filtering result and the <task_2> result . the analysis shows that for practical purposes , our algorithm virtually eliminates all of the negative impact of <otherscientificterm_6> with only negligible penalty in <metric_9> and energy consumption .	7 3 11 12 13 14 10 -1 0 1 5 10 -1 10 -1 8 6 2 10 -1 10 -1
Block and Group Regularized Sparse Modeling for Dictionary Learning .	reconstructed block/group sparse coding schemes ; dictionary learning methods ; dictionary learning framework ; learning process ; well-known datasets ; intra-block coherence ; optimization problems ; dictionary blocks ; group structure ; dictionary learning ; input data ; block-gradient descent ; block structure ; optimization algorithms ; sparse coding	<method> <method> <method> <task> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <method> <task>	8 1 12 ; 9 1 14 ; 11 0 6 ; 6 0 9 ; 6 0 14	this paper proposes a <method_2> that combines the proposed block/group -lrb- bgsc -rrb- or <method_0> with the novel intra-block coherence suppression dictionary learning -lrb- ics-dl -rrb- algorithm . an important and distinguishing <otherscientificterm_7> of the proposed <method_2> is that all <otherscientificterm_7> are trained simultaneously with respect to each data group while the <otherscientificterm_5> being explicitly minimized as an important objective . we provide both empirical evidence and heuristic support for this <otherscientificterm_7> that can be considered as a direct consequence of incorporating both the <otherscientificterm_8> for the <material_10> and the <otherscientificterm_12> for the dictionary in the <task_3> . the <task_6> for both the <task_9> and <task_14> can be solved efficiently using <otherscientificterm_11> , and the details of the <method_13> are presented . we evaluate the proposed methods using <material_4> , and favorable comparisons with state-of-the-art <method_1> demonstrate the viability and validity of the proposed <method_2> .	2 0 15 -1 7 5 15 -1 8 10 12 3 16 15 -1 6 17 18 19 20 15 -1 9 14 11 13 15 -1
Single-link diffusion strategies over adaptive networks .	adaptive diffusion strategy ; limited communication overhead ; steady-state mean-square-deviation ; communication overhead ; maximal-ratio-combining rule ; combination coefficients ; interacting nodes ; node	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 2 0 ; 5 0 6	we propose an <method_0> with <otherscientificterm_1> by cutting off all links but one for each <otherscientificterm_7> in the network . we keep the '' best '' neighbor that has the smallest estimated variance-product measure and ignore the other neighbors . the <otherscientificterm_5> for the <otherscientificterm_6> are calculated via a <otherscientificterm_4> to minimize the <otherscientificterm_2> . simulation results illustrate that , with less <otherscientificterm_3> and less computations , the proposed <method_0> performs well and outperforms other related methods with similar overheads .	0 1 7 9 8 -1 8 -1 5 6 4 2 10 8 -1 3 8 -1
Space-Time Video Montage .	the3rst-jt und graph cut optimization techniques ; spatial and temporal injbrmation distribution ; space-time video summarization method ; smull ouzput video volume ; video summarization methods ; space-time video montage ; time axis ; empty spuce ; video trailer ; movie trailer ; volumetric la.yers ; packing process ; visual information ; video volume ; video sequence ; layers	<method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	0 0 2	conventional <method_4> j2 -rrb- cus predominantly on summarizing videos along the <otherscientificterm_6> , such as building a <method_9> : the resulting <method_8> tends to retain much <otherscientificterm_7> in the background of the video ji-ames while discarding much informulive video content due lo size limit . in this pupes we propose a novel <method_2> which we call <method_5> . the <method_2> simultaneously analyzes both the <otherscientificterm_1> in a <material_14> , and exlructs the visually informative space-time portions of the input videos . the informative video porlions are represented in <method_10> . the <otherscientificterm_15> are then puckrd together in a <otherscientificterm_3> such tlzar the total amount of <otherscientificterm_12> in the <otherscientificterm_13> is maximized . to achieve the <method_11> , we develop a new <method_2> based upon <method_0> . since our <method_2> is uble to cul qfr spatially und temporally less informative portions , it is uble to generute much more compuct yet highly informative output videos . the effecliveness -lrb- $ our <method_2> is validated by extensive experiments over a wide variety c ~ videos .	4 6 9 8 7 16 -1 2 5 16 -1 1 14 16 -1 10 16 -1 15 3 16 -1 12 13 17 16 -1 11 0 16 -1 16 -1
Efficient Search for Transformation-based Inference .	local-lookahead node expansion method ; gradient-style evaluation function ; search algorithms ; inference-preserving transformations ; textual inference ; proof quality ; open-source system ; algorithmic components ; search problem ; biutee	<method> <method> <method> <otherscientificterm> <task> <metric> <method> <method> <task> <method>	7 0 4 ; 0 6 7 ; 1 6 7	this paper addresses the <task_8> in <task_4> , where systems need to infer one piece of text from another . a prominent approach to this <task_8> is attempts to transform one text into the other through a sequence of <otherscientificterm_3> , a.k.a. a proof , while estimating the proof 's validity . this raises a search challenge of finding the best possible proof . we explore this challenge through a comprehensive investigation of prominent <method_2> and propose two novel <method_7> specifically designed for <task_4> : a <method_1> , and a <method_0> . evaluations , using the <method_6> , <method_9> , show the contribution of these ideas to search efficiency and <metric_5> .	8 4 10 -1 3 10 -1 10 -1 2 7 1 0 11 12 13 10 -1 6 9 10 -1
A new analytical model for the NLMS algorithm .	stochastic differential equation approach ; steady-state weight-error correlations ; monte carlo simulations ; analytical model ; numerical simulations	<method> <otherscientificterm> <method> <method> <method>	0 0 3 ; 3 4 3	this paper presents a new <method_3> for the normalized least mean square -lrb- nlms -rrb- adaptive algorithm . the new <method_3> is derived using a <method_0> . an accurate estimate of the <otherscientificterm_1> is also derived , which leads to an improved <method_3> performance for medium and large step sizes . <method_4> compare the new <method_3> with existing <method_3> and show better agreement with <method_2> .	3 5 -1 0 6 5 -1 1 4 5 -1 2 7 5 -1
Ultrafast Monte Carlo for Statistical Summations .	multi-stage stratified monte carlo method ; probabilistic relative error control ; nested summations over datasets ; theoretical sample complexity ; dataset size ; machine learning ; multi-tree methods ; scalability techniques ; error control ; computational bottlenecks ; speedups	<method> <otherscientificterm> <material> <metric> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 6 7 ; 0 0 5 ; 9 3 5 ; 1 0 0	machine learning contains many <otherscientificterm_9> in the form of <material_2> . computation of these <task_5> is typically o -lrb- n 2 -rrb- or higher , which severely limits application to large datasets . we present a <method_0> for approximating such <task_5> with <otherscientificterm_1> . the essential idea is fast approximation by sampling in trees . this <method_0> differs from many previous <method_7> -lrb- such as <method_6> -rrb- in that its error is stochastic , but we derive conditions for <otherscientificterm_8> and demonstrate that they work . further , we give a <metric_3> for the <method_0> that is independent of <otherscientificterm_4> , and show that this appears to hold in experiments , where <otherscientificterm_10> reach as high as 10 14 , many orders of magnitude beyond the previous state of the art .	9 2 14 11 -1 5 11 -1 0 1 13 15 11 -1 11 -1 7 6 8 12 11 -1 3 4 11 -1
Contractive Auto-Encoders : Explicit Invariance During Feature Extraction .	deterministic and non-deterministic auto-encoders ; local directions of variation ; classical reconstruction cost function ; localized space contraction ; lower-dimensional non-linear manifold ; deterministic auto-encoders ; denoising auto-encoders ; frobenius norm ; jacobian matrix ; encoder activations ; regularized auto-encoders ; activation layer ; features ; mlp ; pre-training ; manifold	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	12 0 13 ; 10 1 6	we present in this paper a novel approach for training <method_5> . we show that by adding a well chosen penalty term to the <otherscientificterm_2> , we can achieve results that equal or surpass those attained by other <method_10> as well as <method_6> on a range of datasets . this penalty term corresponds to the <otherscientificterm_7> of the <otherscientificterm_8> of the <otherscientificterm_9> with respect to the input . we show that this penalty term results in a <otherscientificterm_3> which in turn yields robust <otherscientificterm_12> on the <otherscientificterm_11> . furthermore , we show how this penalty term is related to both <method_10> and <method_6> and how it can be seen as a link between <method_0> . we find empirically that this penalty helps to carve a representation that better captures the <otherscientificterm_1> dictated by the data , corresponding to a <otherscientificterm_4> , while being more invariant to the vast majority of directions orthogonal to the <otherscientificterm_15> . finally , we show that by using the learned <otherscientificterm_12> to initialize a <method_13> , we achieve state of the art classification error on a range of datasets , surpassing other methods of <method_14> .	5 16 -1 2 10 6 16 -1 7 8 9 16 -1 3 12 11 16 -1 18 16 -1 0 16 -1 1 4 15 17 16 -1
Eye Movements and Spoken Language Comprehension .	rapid mental processes ; spoken language comprehension ; syntactic ambiguity resolution ; saccadic eye-movements ; reference resolution ; eye movements ; linguistic input ; word recognition ; linguistic processing ; non-linguistic information ; visual workspace ; spoken instructions ; window	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 1 7 ; 7 1 2	we present an overview of recent work in which <otherscientificterm_5> are monitored as people follow <otherscientificterm_11> to move objects or pictures in a <otherscientificterm_10> . subjects naturally make <otherscientificterm_3> to objects that are closely time-locked to relevant information in the instruction . thus the eye-movements provide a <otherscientificterm_12> into the <otherscientificterm_0> that underlie <otherscientificterm_1> . we review studies of <task_4> , <task_7> , and pragmatic effects on <task_2> . our studies show that people seek to establish reference with respect to their behavioral goals during the earliest moments of <task_8> . moreover , referentially relevant <otherscientificterm_9> immediately affects how the <otherscientificterm_6> is initially structured .	5 11 10 13 -1 3 13 -1 12 0 1 13 -1 4 7 2 14 15 13 -1 8 13 -1 9 13 -1
Locality Preserving Nonnegative Matrix Factorization .	non-negative matrix factorization ; geodesics of the data manifold ; high dimensional ambient space ; low dimensional manifold ; intrinsic geometric structure ; information processing tasks ; matrix factorization techniques ; hidden topics ; human brain ; high-dimensional databases ; feature values ; geometric perspective ; compact representation ; kl-divergence	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <method> <method>	6 0 5 ; 12 0 4	matrix factorization techniques have been frequently applied in <task_5> . among them , <method_0> have received considerable attentions due to its psychological and physiological interpretation of naturally occurring data whose representation may be parts-based in <material_8> . on the other hand , from <otherscientificterm_11> the data is usually sampled from a <otherscientificterm_3> embedded in <otherscientificterm_2> . one hopes then to find a <method_12> which uncovers the <otherscientificterm_7> and simultaneously respects the <otherscientificterm_4> . in this paper , we propose a novel algorithm , called locality preserving non-negative matrix factorization -lrb- lpnmf -rrb- , for this purpose . for two data points , we use <method_13> to evaluate their similarity on the <otherscientificterm_7> . the optimal maps are obtained such that the <otherscientificterm_10> on <otherscientificterm_7> are restricted to be non-negative and vary smoothly along the <otherscientificterm_1> . our empirical study shows the encouraging results of the proposed algorithm in comparisons to the state-of-the-art algorithms on two large <material_9> .	5 15 14 -1 0 8 14 -1 11 3 2 14 -1 12 7 4 16 14 -1 14 -1 14 -1 13 14 -1 10 1 14 -1
On a theory of learning with similarity functions .	natural pairwise similarity functions ; theory of kernels ; natural similarity-based properties ; machine learning ; implicit spaces ; implicit space ; similarity functions ; kernel function ; similarity function ; positive semi-definiteness ; implicit mapping ; learning problem ; kernel functions	<otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method>	2 2 7 ; 12 3 3 ; 7 0 11	kernel functions have become an extremely popular tool in <task_3> , with an attractive theory as well . this theory views a kernel as implicitly mapping data points into a possibly very high dimensional space , and describes a <otherscientificterm_7> as being good for a given <task_11> if data is separable by a large margin in that <otherscientificterm_5> . however , while quite elegant , this theory does not directly correspond to one 's intuition of a good kernel as a good <otherscientificterm_8> . furthermore , it may be difficult for a domain expert to use the theory to help design an appropriate kernel for the <task_11> at hand since the <method_10> may not be easy to calculate . finally , the requirement of <otherscientificterm_9> may rule out the most <otherscientificterm_0> for the given problem domain.in this work we develop an alternative , more general theory of learning with <otherscientificterm_6> -lrb- i.e. , sufficient conditions for a <otherscientificterm_8> to allow one to learn well -rrb- that does not require reference to <otherscientificterm_4> , and does not require the function to be positive semi-definite -lrb- or even symmetric -rrb- . our results also generalize the standard theory in the sense that any good <otherscientificterm_7> under the usual definition can be shown to also be a good <otherscientificterm_8> under our definition -lrb- though with some loss in the parameters -rrb- . in this way , we provide the first steps towards a <otherscientificterm_1> that describes the effectiveness of a given <otherscientificterm_7> in terms of <material_2> .	3 15 13 -1 7 11 5 16 13 -1 8 13 -1 13 -1 10 13 -1 9 0 6 4 13 -1 14 13 -1
Instantaneous frequency estimation using discrete evolutionary transform for jammer excision .	discrete evolutionary transform ; instantaneous frequency ; direct sequence spread spectrum communication ; recursive non-linear correction procedure ; direct sequence spread spectrum ; noiseless and noisy situations ; excision of jammers ; non-stationary signals ; time-dependent spectrum ; evolutionary kernel ; instantaneous phase ; jammer excision ; time-frequency kernel ; instantaneous frequency ; time-frequency analysis ; representation ; masking	<method> <otherscientificterm> <task> <method> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <task> <method> <method>	0 0 7 ; 7 1 12 ; 10 1 1 ; 0 0 12 ; 3 0 1 ; 16 0 1 ; 16 1 3	in this paper , we propose a method -- based on the <method_0> -- to estimate the <otherscientificterm_13> of a signal embedded in noise or noise-like signals . the <method_0> provides a <method_15> for <otherscientificterm_7> and a <method_12> that permit us to obtain the <otherscientificterm_8> of the signal . we will show the <otherscientificterm_10> and the corresponding <otherscientificterm_1> can also be computed from the <method_9> . estimation of <otherscientificterm_13> is of general interest in <task_14> , and of special interest in the <task_6> in <material_4> . implementation of the <otherscientificterm_1> is done by <method_16> and a <method_3> . the proposed <otherscientificterm_1> is valid for monocompo-nent as well as multicomponent signals in the <otherscientificterm_5> . its application to <task_11> in <task_2> is considered as an important application . the <otherscientificterm_1> procedure is illustrated with several examples .	0 13 17 -1 15 7 12 8 18 19 21 17 -1 10 1 9 20 17 -1 14 6 4 17 -1 16 3 22 23 24 17 -1 17 -1 5 17 -1 11 2 17 -1
Tensor Decomposition for Fast Parsing with Latent-Variable PCFGs .	real-world natural language parsing data ; probability distribution over trees ; tensor decomposition algorithm ; multilinear algebra literature ; natural language parsing ; tensor formulation ; speed-up inference ; latent-variable pcfgs ; pcfgs ; parsing	<material> <otherscientificterm> <method> <material> <task> <method> <task> <otherscientificterm> <method> <task>	3 0 2	we describe an approach to <task_6> with <otherscientificterm_7> , which have been shown to be highly effective for <task_4> . our approach is based on a <method_5> recently introduced for spectral estimation of <otherscientificterm_7> coupled with a <method_2> well-known in the <material_3> . we also describe an error bound for this approximation , which gives guarantees showing that if the underlying tensors are well approximated , then the <otherscientificterm_1> will also be well approximated . empirical evaluation on <material_0> demonstrates a significant speed-up at minimal cost for <task_9> performance .	6 7 4 10 -1 5 2 3 11 10 -1 1 10 -1 0 9 8 10 -1
Sparse probabilistic regression for activity-independent human pose inference .	real pose databases ; monotonically decreasing co-variance functions ; online probabilistic regression scheme ; mapping visual observations ; articulated body configurations ; human pose inference ; appearance and pose ; local neighborhoods ; local regression ; probabilistic approaches ; pose space ; discriminative approaches ; global regression ; mapping hyperparameters ; gaussian processes ; inference ; pruning ; locality	<material> <task> <method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method> <method> <task> <task> <otherscientificterm>	12 0 1 ; 3 0 4 ; 11 0 5 ; 14 0 2 ; 9 0 3	discriminative approaches to <task_5> involve <task_3> to <otherscientificterm_4> . current <method_9> to learn this <task_3> have been limited in their ability to handle domains with a large number of activities that require very large training sets . we propose an <method_2> for efficient <task_15> of complex , high-dimensional , and multimodal mappings . our <method_2> is based on a local mixture of <method_14> , where <otherscientificterm_17> is defined based on both <otherscientificterm_6> , and where the <method_13> can vary across <otherscientificterm_7> to better adapt to specific regions in the <otherscientificterm_10> . the <method_13> are defined online in very small neighborhoods , so learning and <task_15> is extremely efficient . when the <task_3> is one-to-one , we derive a bound on the approximation error of <method_8> -lrb- vs. <method_12> -rrb- for <task_1> . our <method_2> can determine when training examples are redundant given the rest of the database , and use this criteria for <task_16> . we report results on synthetic -lrb- poser -rrb- and <material_0> , obtaining fast and accurate pose estimates using training set sizes up to 10 5 .	5 3 4 20 21 18 -1 9 23 18 -1 2 15 18 -1 14 17 6 13 7 10 22 18 -1 18 -1 19 18 -1 8 12 1 18 -1 16 18 -1
Global Optimisation of Neural Network Models via Sequential Sampling .	sequential sampling-importance resampling algorithms ; probability distribution ; neural networks ; network weights ; sequential framework	<method> <otherscientificterm> <method> <otherscientificterm> <method>	0 0 2	we propose a novel strategy for training <method_2> using <method_0> . this global optimisation strategy allows us to learn the <otherscientificterm_1> of the <otherscientificterm_3> in a <method_4> . it is well suited to applications involving on-line , nonlinear , non-gaussian or non-stationary signal processing .	2 0 6 5 -1 1 3 4 5 -1 5 -1
Hierarchical Incremental Adaptation for Statistical Machine Translation .	flexible hierarchical domain structure ; stream of post-edits ; multi-level domain hierarchy ; statistical machine translation ; incremental adaptation approach ; local context ; translation quality ; consistent model ; rules ; granularity	<otherscientificterm> <material> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm>	6 5 4 ; 4 0 3 ; 4 0 0	we present an <method_4> for <task_3> that maintains a <otherscientificterm_0> within a single <method_7> . both weights and <otherscientificterm_8> are updated incrementally on a <material_1> . our <otherscientificterm_2> allows the <method_4> to adapt simultaneously towards <otherscientificterm_5> at different levels of <otherscientificterm_9> , including genres and individual documents . our experiments show consistent improvements in <metric_6> from all components of our <method_4> .	4 3 0 7 12 13 10 -1 8 1 10 -1 2 5 9 10 -1 6 11 10 -1
A Principled Deep Random Field Model for Image Segmentation .	pairwise random field based approaches ; cooperative cuts model ; coupling graph edges ; multi-layered hidden units ; image seg-mentation methods ; image segmentation ; random field ; map inference ; exact inference ; segmentation instances ; short-boundary bias	<method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 0 ; 3 0 6	we discuss a model for <task_5> that is able to overcome the <otherscientificterm_10> observed in standard <method_0> . to wit , we show that a <otherscientificterm_6> with <otherscientificterm_3> can encode boundary preserving higher order potentials such as the ones used in the <method_1> of -lsb- 12 -rsb- while still allowing for fast and exact <task_7> . <otherscientificterm_8> allows our model to outperform previous <method_4> , and to see the true effect of <otherscientificterm_2> . finally , our model can be easily extended to handle <otherscientificterm_9> with multiple labels , for which it yields promising results .	5 10 0 12 11 -1 6 3 1 7 8 13 11 -1 4 2 11 -1 9 11 -1
Particle Filters for Infinite -LRB- or Large -RRB- Dimensional State Spaces-Part 2 .	particle filtering -lrb- monte carlo sampling -rrb- ; large dimensional system noise distribution ; asymptotically stable adaptive particle filter ; particle filtering algorithms ; basis change detection ; weaker assumptions ; re-estimation steps ; pf algorithm ; tracking	<method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <task>	4 1 6 ; 6 0 7 ; 4 0 7 ; 1 0 0 ; 3 0 8	we study <method_3> for <task_8> on infinite -lrb- in practice , large -rrb- dimensional state spaces . <method_0> from a <method_1> is computationally expensive . but , in most large dim <task_8> applications , it is fair to assume that '' most of the state change '' occurs in a small dimensional basis and the basis itself may be slowly time varying -lrb- approximated as piecewise constant -rrb- . we have proposed a <method_7> with <method_4> and <method_6> that uses this idea . the implicit assumptions in defining this <method_7> are very strong . we study here the implications of <otherscientificterm_5> and how to handle them . we propose to use a simple modification of the <method_2> to handle errors in estimating the basis dimension .	3 8 0 14 9 -1 1 13 9 -1 9 -1 7 4 6 10 11 12 9 -1 9 -1 9 -1 5 9 -1
Spectral and temporal modulation features for phonetic recognition .	discrete cosine transform analysis ; spectral and modulation information ; automatic speech recognition ; log magnitude spectrum ; frequency resolution ; modulation spectrum ; speech information ; phonetic recognition ; modulation features ; time resolution ; spectral features ; dct/dcs features ; features ; timit ; mfccs	<method> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	12 4 14 ; 8 4 10 ; 13 1 13 ; 4 1 9 ; 13 0 11 ; 10 0 2 ; 0 0 3 ; 13 0 7	recently , the <otherscientificterm_5> has been proposed and found to be a useful source of <otherscientificterm_6> . the <otherscientificterm_5> represents longer term variations in the spectrum and thus implicitly requires <otherscientificterm_12> extracted from much longer speech segments compared to <method_14> and their delta terms . in this paper , a <method_0> of the <otherscientificterm_3> combined with a discrete cosine series -lrb- dcs -rrb- expansion of dct coefficients over time is proposed as a method for capturing both the <otherscientificterm_1> . these <otherscientificterm_11> can be computed so as to emphasize <task_4> or <task_9> or a combination of the two factors . several variations of the <otherscientificterm_11> were evaluated with <task_7> experiments using <method_13> and its telephone version -lrb- <method_13> -rrb- . best results obtained with a combined feature set are 73.85 % for <method_13> and 62.5 % for <method_13> . the <otherscientificterm_8> are shown to be far more important than the <otherscientificterm_10> for <task_2> and far more noise robust .	5 6 15 -1 12 14 16 15 -1 0 3 1 22 15 -1 11 4 9 19 15 -1 20 23 15 -1 7 13 18 15 -1 17 21 15 -1
Active Inference for Dynamic Bayesian Networks .	dynamic bayesian networks ; optimizing training phase ; temporal systems ; selective collection ; active inference ; supervised learning ; unobserved variables ; active inference ; prediction	<method> <task> <method> <method> <task> <task> <otherscientificterm> <task> <task>	0 0 2	in <task_5> , many techniques focus on <task_1> to increase <task_8> performance . <task_7> , a relatively novel paradigm , aims to decrease overall <task_8> error via <method_3> of some labels based on relations among instances . in this research , we use <method_0> to model <method_2> and we apply <task_4> to dynamically choose variables for observation so as to improve <task_8> on <otherscientificterm_6> .	5 1 8 7 9 -1 3 9 -1 0 2 4 6 10 9 -1
An instantaneous vector representation of delta pitch for speaker-change prediction in conversational dialogue systems .	instantaneous vector representation of pitch variation ; human-like dialogue flow control ; acoustic modeling techniques ; recall of locations ; spoken dialogue systems ; naturalness of interaction ; real human-human conversations ; automatically labeled data ; predicting speaker changes ; system responsiveness ; pause-only systems ; hand-crafted baseline ; precision	<method> <task> <method> <metric> <method> <metric> <material> <material> <task> <task> <method> <material> <metric>	9 0 1 ; 12 1 3 ; 5 5 4 ; 6 0 8 ; 4 0 2	as <method_4> become deployed in increasingly complex domains , <method_4> face rising demands on the <metric_5> . we focus on <task_9> , aiming to mimic <task_1> by <task_8> as observed in <material_6> . we derive an <method_0> and show that <method_4> is amenable to standard <method_2> . using a small amount of <material_7> , we train models which significantly outperform current state-of-the-art <method_10> , and replicate to within 1 % absolute the performance of our previously published <material_11> . the new system additionally offers scope for run-time control over the <metric_12> or <metric_3> at which to speak .	4 5 16 13 -1 9 1 8 6 14 17 13 -1 0 2 18 13 -1 7 10 11 13 -1 12 3 15 13 -1
On-line Simultaneous Learning and Tracking of Visual Feature Graphs .	uninformative components ; graphical model ; computer vision ; model learning ; tracking	<method> <method> <task> <task> <task>	4 0 1 ; 1 0 4 ; 4 3 2	model learning and <task_4> are two important topics in <task_2> . while there are many applications where one of them is used to support the other , there are currently only few where both aid each other simultaneously . in this work , we seek to incrementally learn a <method_1> from <task_4> and to simultaneously use whatever has been learned to improve the <task_4> in the next frames . the main problem encountered in this situation is that the current <method_1> may be inconsistent with future observations , creating a bias in the <task_4> results . we propose an uncertain model that explicitly accounts for such uncertainties by representing relations by an appropriately weighted sum of informative -lrb- parametric -rrb- and <method_0> . the method is completely unsupervised and operates in real time .	4 2 8 5 -1 5 -1 1 6 7 5 -1 5 -1 5 -1 0 5 -1
Optimizing Binary MRFs with Higher Order Cliques .	pairwise markov random field models ; gibbs energy of signal interaction ; computer vision problems ; pairwise mrf models ; asymmetric potts prior ; energy minimization tools ; higher order counterparts ; order polynomial ; quadratic function ; image segmentation ; binary mrfs ; polynomial function	<method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	5 0 3 ; 7 0 8 ; 0 0 2 ; 10 0 1 ; 5 0 6 ; 3 0 6	widespread use of efficient and successful solutions of <task_2> based on <method_0> raises a question : does any link exist between the pairwise and higher order mrfs such that the like solutions can be applied to the latter models ? this work explores such a link for <method_10> that allow us to represent <otherscientificterm_1> with a <otherscientificterm_11> . we show how a higher <otherscientificterm_7> can be efficiently transformed into a <otherscientificterm_8> . then <method_5> for the <method_3> can be easily applied to the <otherscientificterm_6> . also , we propose a method to analytically estimate the potential parameter of the <otherscientificterm_4> . the proposed framework demonstrates very promising experimental results of <task_9> and can be used to solve other <task_2> .	2 0 10 1 11 15 12 -1 7 8 16 12 -1 5 3 6 14 12 -1 4 13 17 18 12 -1 12 -1 9 12 -1
Improving Pivot-Based Statistical Machine Translation Using Random Walk .	pivot-based statistical machine translation ; spoken language data ; european parliament data ; machine learning method ; markov random walks ; pivot phrases ; source-target translation ; source-target translations ; web data ; pivot-based smt ; bilingual data	<task> <material> <material> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <method> <material>	9 0 6 ; 3 0 0 ; 1 1 8	this paper proposes a novel approach that utilizes a <method_3> to improve <task_0> . for language pairs with few <material_10> , a possible solution in <method_9> using another language as a `` bridge '' to generate <task_6> . however , one of the weaknesses is that some useful <otherscientificterm_7> can not be generated if the corresponding source phrase and target phrase connect to different <otherscientificterm_5> . to alleviate the problem , we utilize <otherscientificterm_4> to connect possible translation phrases between source and target language . experimental results on <material_2> , <material_1> and <material_8> show that our method leads to significant improvements on all the tasks over the baseline system .	3 0 13 11 -1 10 9 6 12 11 -1 7 5 11 -1 4 11 -1 2 1 8 14 11 -1
Gap Filling in the Plant Kingdom - Trait Prediction Using Hierarchical Probabilistic Matrix Factorization .	hierarchical probabilistic matrix factorization ; factorization based matrix completion techniques ; joint trait analysis ; hierarchical phylogenetic structure ; adaptation of ecosystems ; matrix factorization methods ; hierarchical phylogenetic information ; missing data problem ; plant traits ; missing data ; global database ; trait prediction ; ecological community ; plant traits ; trait data ; phylogenetic structure ; trait correlation ; hierarchical structure	<method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <material> <material> <task> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 7 ; 0 0 16 ; 9 0 2 ; 10 0 12 ; 6 0 11 ; 5 0 15 ; 5 0 7 ; 10 0 8 ; 6 0 0	plant traits are a key to understanding and predicting the <task_4> to environmental changes , which motivates the try project aiming at constructing a <material_10> for <otherscientificterm_8> and becoming a standard resource for the <task_12> . despite its unprecedented coverage , a large percentage of <material_9> substantially constrains <method_2> . meanwhile , the <material_14> is characterized by the <otherscientificterm_3> of the plant kingdom . while <method_1> have been widely used to address the <task_7> , traditional <method_5> are unable to leverage the <otherscientificterm_15> . we propose <method_0> , which effectively uses <otherscientificterm_6> for <task_11> . we demonstrate <method_0> 's high accuracy , effectiveness of incorporating <otherscientificterm_17> and ability to capture <otherscientificterm_16> through experiments .	4 10 8 12 22 26 18 -1 9 2 21 18 -1 14 3 18 -1 1 7 5 15 19 24 25 18 -1 0 6 11 23 27 18 -1 20 18 -1
Towards Intelligent Mission Profiles of Micro Air Vehicles : Multiscale Viterbi Classification .	multiscale viterbi classification algorithm ; micro air vehicles ; tree-structured belief networks ; complex wavelet transform ; multi-scale bayesian classification ; statistical models of object appearances ; relative poverty of scene detail ; complexity of object appearances ; adaptive feature selection algorithm ; tree-structured belief networks ; hsi color space ; context-based object recognition ; real-world test images ; visual contexts ; aerial images ; feature set ; discriminating features ; design choices ; flight images ; video noise ; object recognition ; msbc paradigm ; real-time constraints ; vision system ; feature ; robustness	<method> <task> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <task> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <task> <method> <otherscientificterm> <method> <otherscientificterm> <metric>	19 1 7 ; 22 1 25 ; 10 1 3 ; 8 0 15 ; 0 0 20 ; 12 5 21 ; 8 0 2 ; 12 5 23 ; 2 0 15 ; 22 1 19	in this paper , we present a <method_23> for <task_20> in <material_14> , which enables broader mission profiles for <task_1> . the most important factors that inform our <otherscientificterm_17> are : <otherscientificterm_22> , <metric_25> to <material_19> , and <otherscientificterm_7> . as such , we first propose the <otherscientificterm_10> and the <method_3> as a set of sufficiently <otherscientificterm_16> . for each <otherscientificterm_24> , we then build <method_2> as our underlying <method_5> . to perform <task_20> , we develop the novel <method_0> , as an improvement to <task_4> . next , we show how to globally optimize <method_2> with respect to the <otherscientificterm_15> , using an <method_8> . finally , we discuss <task_11> , where <otherscientificterm_13> help to disambiguate the identity of an object despite the <otherscientificterm_6> in <material_18> , and obviate the need for an exhaustive search of objects over various scales and locations in the image . experimental results show that the proposed <method_23> achieves smaller classification error and fewer false positives than systems using the <method_21> on challenging <material_12> .	23 20 14 1 26 -1 17 22 25 19 7 27 28 36 26 -1 10 3 16 29 26 -1 24 2 5 26 -1 0 4 31 26 -1 30 33 35 26 -1 15 8 26 -1 11 13 6 18 32 34 26 -1
Multi-timbre chord classification using wavelet transform and self-organized map neural networks .	self-organized map neural network ; model of human perception ; information of timbres ; musical chord recognition ; human ears ; wavelet-based transform	<method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	5 0 0	this paper presents a new method for <task_3> based on a <method_1> . we classify the chords directly from the sound without the <otherscientificterm_2> and notes . a <otherscientificterm_5> as well as a <method_0> is adopted to imitate <otherscientificterm_4> and cerebra , respectively . the resultant system can classify chords very well even in a noisy environment .	3 1 6 -1 2 6 -1 5 0 4 7 6 -1 6 -1
Decision tree usage for incremental parametric speech synthesis .	parametric speech synthesis voices ; para-metric speech synthesizers ; hmm state selection ; determing hmm states ; incremental speech synthesis ; vocoding parameters ; full-utterance context ; incremental use-cases ; phonetic details ; prosody modelling ; features	<otherscientificterm> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	6 0 1 ; 10 0 0 ; 2 1 9 ; 5 0 1 ; 2 0 4 ; 9 0 4	human speakers plan and deliver their utterances incremen-tally , piece-by-piece , and it is obvious that their choice regarding <otherscientificterm_8> -lrb- and the details ' peculiarities -rrb- is rarely determined by globally optimal solutions . in contrast , <otherscientificterm_1> use a <otherscientificterm_6> when optimizing <otherscientificterm_5> and when <task_3> . apart from being cognitively implausible , this impedes <otherscientificterm_7> , where the future context is often at least partially unavailable . this paper investigates the ` locality ' of <otherscientificterm_10> in <otherscientificterm_0> and takes some missing steps towards better <method_2> and <task_9> for <task_4> .	8 11 -1 1 6 5 3 12 15 11 -1 7 11 -1 10 0 2 9 4 13 14 16 17 11 -1
Temporal and Social Context Based Burst Detection from Folksonomies .	robust state based model ; temporal stream analysis ; social media content ; pervasive collaborative context ; resource lifetime ; textual features ; collaborative context ; topic coverage ; burst detection ; user attractiveness ; learning method ; burst pulses ; burst detection ; burst extraction ; metadata frequency	<method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm>	5 1 3 ; 7 1 9 ; 12 6 1 ; 14 1 7 ; 5 0 8 ; 4 6 3	burst detection is an important topic in <task_1> . usually , only the <otherscientificterm_5> are used in <task_8> . in the theme extraction from current prevailing <material_2> , it is necessary to consider not only <otherscientificterm_5> but also the <otherscientificterm_3> , e.g. , <otherscientificterm_4> and user activity . this paper explores novel approaches to combine multiple sources of such indication for better <task_13> . we systematically investigate the characters of <otherscientificterm_6> , i.e. , <otherscientificterm_14> , <otherscientificterm_7> and <otherscientificterm_9> . first , a <method_0> is utilized to detect bursts from individual streams . we then propose a <method_10> to combine these <otherscientificterm_11> . experiments on a large real dataset demonstrate the remarkable improvements over the traditional methods .	1 18 15 -1 5 8 20 15 -1 2 3 4 16 21 15 -1 13 15 -1 6 14 7 9 17 19 15 -1 0 15 -1 10 15 -1 11 15 -1
Learning Cellular Automation Dynamics with Neural Networks .	complex or chaotic behaviour ; asymptotic dynamical behaviour ; e-ii units ; cellular automata ; short-range connections ; automaton rule ; weight sharing ; learning	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	4 0 3 ; 4 2 2	we have trained networks of <method_2> with <otherscientificterm_4> to simulate simple <method_3> that exhibit <otherscientificterm_0> . three levels of <task_7> are possible -lrb- in decreasing order of difficulty -rrb- : <task_7> the underlying <otherscientificterm_5> , learning <otherscientificterm_1> , and <task_7> to extrapolate the training history . the levels of <task_7> achieved with and without <otherscientificterm_6> for different automata provide new insight into their dynamics .	2 4 3 0 9 10 8 -1 7 5 1 8 -1 6 8 -1
LDA/SVM Driven Nearest Neighbor Classification .	locally adaptive neighborhood morphing classification method ; nearest neighbor classification ; local support vector machine learning ; class conditional probabilities ; discriminant feature dimensions ; curse of dimensionality ; finite samples ; severe bias ; bias	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 8	nearest neighbor -lrb- nn -rrb- classification relies on the assumption that <otherscientificterm_3> are locally constant . this assumption becomes false in high dimensions with <otherscientificterm_6> due to the <otherscientificterm_5> . the <method_1> introduces <otherscientificterm_7> under these conditions . we propose a <method_0> to try to minimize <otherscientificterm_8> . we use <method_2> to estimate an effective metric for producing neighborhoods that are elongated along less <otherscientificterm_4> and constricted along most discriminant ones . as a result , the <otherscientificterm_3> can be expected to be approximately constant in the modified neighborhoods , whereby better classification performance can be achieved . the efficacy of our <method_0> is validated and compared against other competing techniques using a number of datasets .	3 9 -1 6 5 9 -1 1 7 9 -1 0 8 10 9 -1 2 4 9 -1 9 -1 9 -1
A recursive total least squares algorithm for deconvolution problems .	re-cursive total least squares algorithm ; total least squares based approach ; noise corrupted fir channels ; least squares estimation ; constant computational cost ; non-recursive tls algorithm ; unknown input signal ; signal processing applications ; recursive implementation ; blind algorithms ; deconvolution problems ; computational cost ; fir channels ; kalman filter	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <task> <metric> <otherscientificterm> <method>	4 2 8 ; 13 0 8 ; 10 0 7	deconvolution problems are encountered in <task_7> where an <otherscientificterm_6> can only be observed after propagation through one or more <otherscientificterm_2> . the first step in recovering the input usually entails an estimation of the <otherscientificterm_12> through training based or <method_9> . the ` standard ' procedure then uses <method_3> to recover the input . a <method_8> with <otherscientificterm_4> is based on the <method_13> . in this paper we focus on a <method_1> , which is more appropriate if errors are expected both on the output samples and the estimates of the <otherscientificterm_12> . we will develop a <method_0> which closely approximates the performance of the <method_5> and this at a much lower <metric_11> .	7 6 2 17 14 -1 12 9 14 -1 3 14 -1 8 4 13 15 16 14 -1 1 14 -1 0 14 -1
Generalized filter-bank equalizer for noise reduction with reduced signal delay .	analysis-synthesis filter-bank -lrb- as fb -rrb- ; generalized filter-bank equalizer ; low signal delay ; non-uniform frequency resolution ; low delay filter-bank ; noise reduction ; algorithmic complexity ; parameter configurations ; allpass transformation ; signal reconstruction ; filter-bank structure ; time-domain filter ; frequency-domain ; coefficients	<method> <method> <otherscientificterm> <task> <method> <task> <metric> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 1 1 ; 6 0 7 ; 10 0 9 ; 8 0 3 ; 1 4 11 ; 1 4 1 ; 1 6 4	an efficient realization of a <method_4> , termed as <method_1> , will be proposed for <task_5> with <otherscientificterm_2> . the <method_1> is equivalent to a <method_11> with <otherscientificterm_13> adapted in the <otherscientificterm_12> . this <otherscientificterm_10> ensures perfect <task_9> for a variety of spectral transforms with less restrictions than for an <method_0> . a <task_3> can be achieved by an <method_8> . in this case , the <method_1> has not only a lower signal delay than the <method_1> , but also a lower <metric_6> for most <otherscientificterm_7> . another advantage of the <method_1> is the lower number of required delay elements -lrb- memory -rrb- compared to the <method_1> . the <task_5> achieved by means of the <method_1> and the <method_1> is approximately equal .	4 1 5 2 21 14 -1 11 13 12 19 14 -1 10 9 0 17 14 -1 3 8 18 14 -1 6 7 16 20 14 -1 14 -1 15 14 -1
Detection of speech embedded in real acoustic background based on amplitude modulation spectrogram features .	itu g729.b voice activity detection ; detection of speech ; amplitude modulation spectrogram ; modulation frequency range ; feature selection techniques ; false positive rates ; detection of speech ; real acoustic background ; classification task ; classification method ; modulation components ; modulation features ; signal-to-noise level ; non-speech sounds ; non-speech signals ; test-data accuracy ; classification ; features	<task> <task> <method> <otherscientificterm> <method> <metric> <task> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <material> <material> <metric> <task> <otherscientificterm>	11 0 1 ; 17 0 16 ; 0 5 9 ; 5 5 9 ; 15 5 6 ; 10 0 8 ; 2 0 10 ; 17 0 10 ; 4 0 10	a <method_9> is presented that detects the presence of speech embedded in a <otherscientificterm_7> of <material_13> . <otherscientificterm_17> used for <task_16> are <method_10> extracted by computation of the <method_2> . <method_4> and support vector <task_16> are employed to identify <method_10> most salient for the <task_8> and therefore considered as highly characteristic for speech . results show that reliable <task_1> can be performed with less than 10 optimally selected <otherscientificterm_11> , the most important ones are located in the <otherscientificterm_3> below 10 hz . <task_6> in a background of <material_14> is performed with about 90 % <metric_15> at a <otherscientificterm_12> of 0 db . compared to standard <task_0> , the proposed <method_9> results in increased true positive and reduced <metric_5> induced by a <otherscientificterm_7> .	9 7 13 17 18 -1 16 10 2 4 20 25 26 18 -1 8 24 27 18 -1 1 11 3 6 19 18 -1 14 15 12 23 18 -1 21 22 18 -1
Simple Training of Dependency Parsers via Structured Boosting .	maximum margin markov networks ; annotated natural language corpora ; specialized training algorithms ; coordinated training algorithms ; predicting dependency links ; support vector machines ; structured prediction accuracy ; dependency parsing model ; supervised training methods ; conditional random fields ; boosting-like procedure ; local predictor ; logistic regression ; structured predictors ; structured classification ; misclassified components ; structured boosting ; base classifier ; dependency parsers ; chinese ; features	<method> <material> <method> <method> <task> <method> <metric> <method> <method> <otherscientificterm> <method> <method> <method> <method> <task> <method> <method> <method> <method> <material> <otherscientificterm>	9 6 3 ; 0 6 3 ; 12 0 7 ; 17 0 7 ; 3 0 13 ; 9 1 0 ; 12 1 5 ; 16 0 7 ; 10 0 8 ; 12 0 17	recently , significant progress has been made on learning <method_13> via <method_3> such as <otherscientificterm_9> and <method_0> . unfortunately , these techniques are based on <method_2> , are complex to implement , and expensive to run . we present a much simpler approach to training <method_13> by applying a <method_10> to standard <method_8> . the idea is to learn a <method_11> using standard methods , such as <method_12> or <method_5> , but then achieve improved <task_14> by '' boosting '' the influence of <method_15> after <task_14> , retraining the <method_11> , and repeating . further improvement in <metric_6> can be achieved by incorporating '' dynamic '' <otherscientificterm_20> -- i.e. an extension whereby the <otherscientificterm_20> for one predicted component can depend on the predictions already made for some other components . we apply our techniques to the problem of learning <method_18> from <material_1> . by using <method_12> as an efficient <method_17> -lrb- for <task_4> between word pairs -rrb- , we are able to efficiently train a <method_7> , via <method_16> , that achieves state of the art results in en-glish , and surpasses state of the art in <material_19> .	13 3 9 0 22 23 26 27 21 -1 2 21 -1 10 8 30 21 -1 11 12 5 14 15 28 21 -1 6 21 -1 20 21 -1 18 1 24 25 29 31 21 -1
Annealed Importance Sampling for Structure Learning in Bayesian Networks .	markov chain monte carlo method ; annealed importance sampling ; bayesian network structure ; sampling methods ; sampling approach ; order-based sampling ; linear orders ; probabilistic guarantees ; partial order ; nodes ; posterior ; parallelization ; bias	<method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	4 0 2 ; 0 4 0	we present a new <method_4> to bayesian learning of the <method_2> . like some earlier <method_3> , we sample <otherscientificterm_6> on <otherscientificterm_9> rather than directed acyclic graphs -lrb- dags -rrb- . the key difference is that we replace the usual <method_0> by the <method_4> of <method_1> . we show that <method_0> is not only competitive to <method_0> in exploring the <otherscientificterm_10> , but also superior to <method_0> in two ways : <method_0> enables easy and efficient <task_11> , due to the independence of the samples , and lower-bounding of the marginal likelihood of the <method_4> with good <otherscientificterm_7> . we also provide a principled way to correct the <otherscientificterm_12> due to <method_5> , by implementing a fast algorithm for counting the linear extensions of a given <otherscientificterm_8> .	4 2 14 13 -1 3 6 9 13 -1 0 1 13 -1 10 11 7 15 13 -1 13 -1
Probabilistic concept verification for language understanding in spoken dialogue systems .	concept-based probabilistic verification model ; error reduction rate ; acoustic confidence measure ; contextual confidence information ; confidence tag ; confidence measure ; confidence measures ; neighboring concepts ; error rate ; word/phrase	<method> <metric> <metric> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <metric> <otherscientificterm>	0 0 3 ; 0 4 0 ; 6 0 0 ; 4 0 9	in the past researches , several kinds of information have been explored to assess the <metric_5> or to select the <otherscientificterm_4> for a <otherscientificterm_9> . however , the <otherscientificterm_3> is little touched . in this paper , we propose a <method_0> to integrate the <otherscientificterm_3> . in this <method_0> , a concept is verified not only according to its <metric_2> but also according to <otherscientificterm_7> and their confidence levels . experimental results show that the proposed <method_0> significantly outperforms the <method_0> using only <method_6> . the <metric_8> of <otherscientificterm_4> is reduced from 17.7 % to 15.12 % , which corresponds to an <metric_1> of 14.5 % .	5 4 9 14 10 -1 3 10 -1 0 11 10 -1 2 7 10 -1 6 12 13 10 -1 8 10 -1
Linear Programming Boosting for Uneven Datasets .	text classification problem ; linear programming boosting ; boosting strategies ; uneven datasets	<task> <method> <method> <material>	1 0 3	the paper extends the notion of <method_1> to handle <material_3> . extensive experiments with <task_0> compare the performance of a number of different <method_2> , concentrating on the problems posed by <material_3> .	1 3 5 4 -1 0 2 4 -1
Lexical Co-occurrence , Statistical Significance , and Word Association .	span distributions of associated words ; benchmark data sets ; global unigram frequencies ; detecting word associations ; unigram frequencies ; lexical co-occurrence ; lexical co-occurrences ; co-occurrence measures ; lexical co-occurrence ; ttest ; biases ; ochiai	<otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method>	8 0 3 ; 1 5 7	lexical co-occurrence is an important cue for <task_3> . we present a theoretical framework for discovering statistically significant <otherscientificterm_6> from a given corpus . in contrast with the prevalent practice of giving weightage to <otherscientificterm_4> , we focus only on the documents containing both the terms -lrb- of a candidate bi-gram -rrb- . we detect <otherscientificterm_10> in <otherscientificterm_0> , while being agnostic to variations in <otherscientificterm_2> . our framework has the fidelity to distinguish different classes of <otherscientificterm_6> , based on strengths of the document and corpus-level cues of co-occurrence in the data . we perform extensive experiments on <material_1> to study the performance of various <metric_7> that are currently known in literature . we find that a relatively obscure measure called <method_11> , and a newly introduced measure csa capture the notion of <otherscientificterm_5> best , followed next by llr , dice , and <method_9> , while another popular measure , pmi , suprisingly , performs poorly in the context of <otherscientificterm_5> .	3 13 12 -1 6 12 -1 4 12 -1 10 0 2 12 -1 12 -1 1 14 12 -1 7 12 -1
Session Variability Subspace Projection Based Model Compensation for Speaker Verification .	session variability subspace projection svspbased model compensation method ; relative equal error rate reduction ; compensated speaker models ; gmm-ubm system ; speaker verification ; speaker models ; session variability ; ubm	<method> <metric> <method> <method> <task> <method> <otherscientificterm> <material>	1 5 0 ; 0 0 4 ; 6 0 5 ; 2 1 7	in this paper , a <method_0> for <task_4> is proposed . during the training phase the <otherscientificterm_6> is removed from <method_5> by projection , while during the testing phase the <otherscientificterm_6> in a test utterance is used to compensate <method_5> . finally , the <method_2> and <material_7> are used to recognize the identity of the test utterance . compared with the conventional <method_3> , the <metric_1> of <method_0> is 16.2 % on the nist 2006 single-side one conversation training , single-side one conversation test .	0 4 10 8 -1 6 5 11 8 -1 2 7 12 8 -1 3 1 9 8 -1
A Divide-and-Conquer Approach to 3D Object Reconstruction from Line Drawings .	3d reconstruction of complex manifold objects ; 3d reconstruction of more complex objects ; single 2d line drawings ; 3d object reconstruction ; 2d line drawing ; computer vision ; 3d object ; line drawing ; geometric structure ; 3d shapes ; divide-and-conquer strategy ; face identification	<task> <task> <material> <task> <task> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task>	10 0 0 ; 4 0 3	3d object reconstruction from a single <task_4> is an important problem in both <task_5> and graphics . many methods have been put forward to solve this problem , but they usually fail when the <otherscientificterm_8> of a <otherscientificterm_6> becomes complex . in this paper , a novel approach based on a <method_10> is proposed to handle <task_0> from <material_2> . the approach consists of three steps : 1 -rrb- dividing a complex <method_7> into multiple simpler line drawings based on the result of <task_11> ; 2 -rrb- reconstructing the <otherscientificterm_9> from these simpler line drawings ; and 3 -rrb- merging the <otherscientificterm_9> into one complete object represented by the original <method_7> . a number of examples are given to show that our approach can handle <task_1> than previous methods .	4 5 14 12 -1 8 6 12 -1 10 0 2 13 12 -1 7 11 9 12 -1 12 -1
A tapered SVD without rank determination for estimation of multipulse input time series from noisy output .	deterministic input multipulse time series ; estimatiug multipulse time series ; au optimnm tapering window ; ihe transfer system ; resonant transfer system ; andard svd-based estimator ; tapering window ; uew method ; sharp truucabion ; snr ; singular-value-decomposit	<otherscientificterm> <task> <task> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	7 0 2 ; 2 0 1	oue of -lrb- . he key questions to be addressed in t , liis paper is how 1.0 estimate the <otherscientificterm_0> from a noisy respouse of the <method_4> iii -lrb- . lie case where t.he <otherscientificterm_9> is low aud the system q -lrb- quality laci.or -rrb- of <method_3> is high . by generaliziug the <otherscientificterm_8> employed in the standard <method_10> . ion -lrb- svd -rrb- , a <otherscientificterm_6> is iutroduced to t ruucat.e high order non-significant singular values obtained by t.lie svd , t , lie mea : l squared error of the estimat.es due to the st , <method_5> is reduced to a miui-mum . this paper also preseuts a <method_7> to design <task_2> for <task_1> .	11 -1 0 4 11 -1 9 3 11 -1 8 10 11 -1 6 5 11 -1 12 13 11 -1
Robust optical flow estimation in MPEG sequences .	multiresolution robust regularization technique ; mpeg consistency constraint ; mpeg motion field ; memory consuming decompression ; video analysis tasks ; optical flow field ; motion information ; dc coefficients ; compressed stream ; motion discontinuities ; computer vision ; motion scenarios ; mathematical constraints ; surveillance applications ; objective function ; event analysis ; velocity fields ; mpeg sequences ; temporal continuity ; mpeg	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <task> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <method>	15 1 13 ; 18 1 1 ; 2 6 16	motion information is essential in many <task_10> and <task_4> . since <method_19> is still one of the most prevalent formats for representing , transferring and storing video data , the analysis of its motion field is important for real time video indexing and segmentation , <task_15> and <task_13> . our work considers the problem of improving the <task_5> in <material_17> . we address the issues of robust , incremental , dense optical flow estimation by combining information from two different <otherscientificterm_16> : the available <otherscientificterm_2> and the one inferred by a <method_0> applied on the <otherscientificterm_7> . thus , the <method_0> is based only on information that is directly available in the <material_8> avoiding therefore the time and <otherscientificterm_3> . we extend standard techniques by adding a <otherscientificterm_18> and an <otherscientificterm_1> , both as <otherscientificterm_12> in the <otherscientificterm_14> and as hypothesis tests for the presence of <otherscientificterm_9> . our approach is shown to perform well over a range of different <otherscientificterm_11> and can serve as a basis for efficient <task_4> .	10 4 20 -1 19 15 13 21 20 -1 5 17 20 -1 16 2 0 7 23 20 -1 20 -1 8 3 22 20 -1 18 1 12 14 9 20 -1
A fractional Gabor transform .	flexible , non-rectangular time-frequency lattice ; general , non-rectangular time-frequency lattice ; fractional fourier basis ; fractional gabor expansion ; basis functions ; gabor logons ; bi-orthogonality conditions ; constant-bandwidth analysis ; non-rectangular tiling ; compact representation	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	4 0 3	we present a <method_3> on a <otherscientificterm_1> . the traditional <method_3> represents a signal in terms of time and frequency shifted <otherscientificterm_4> , called <otherscientificterm_5> . this <method_7> results in a fixed , rectangular time frequency plane tiling . many of the practical signals require a more <otherscientificterm_0> for a <method_9> . the proposed <method_3> uses a set of <otherscientificterm_4> that are related to the <otherscientificterm_2> and generate a <otherscientificterm_8> . the completeness and <otherscientificterm_6> of the new <otherscientificterm_5> are discussed .	3 1 10 -1 4 5 10 -1 7 10 -1 0 9 10 -1 2 8 11 10 -1 6 10 -1
Fingerprint matching based on distance metric learning .	distance metric learning ; audio fingerprinting system ; cost function ; convex optimization ; global minimum ; mahalanobis distance ; query content ; fingerprinting system ; distance metric ; identification	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <method> <task>	3 0 4 ; 0 0 1 ; 7 0 6	this paper considers a method for learning a <method_8> in a <method_7> which identifies a <material_6> by measuring the distance between its fingerprint and a fingerprint stored in a database . a metric having a general form of the <otherscientificterm_5> is learned with the goal that the distance between fingerprints extracted from perceptually similar contents should be smaller than the distance between fingerprints extracted from perceptually dissimilar contents . the metric is learned by minimizing a <otherscientificterm_2> designed to achieve the goal . the <otherscientificterm_2> is convex , and the <otherscientificterm_4> can be obtained using <method_3> . in our experiment , the <method_0> is applied in an <method_1> , and it is experimentally shown that the learned <method_8> improves the <task_9> performance .	8 7 6 13 10 -1 5 10 -1 2 10 -1 4 3 11 10 -1 12 10 -1
Learning trajectory patterns by clustering : Experimental studies and comparative evaluation .	trajectory learning problem ; automatic activity analysis ; motion characteristics ; similarity measures ; clustering rate ; clustering methodologies ; clustering	<task> <task> <otherscientificterm> <method> <metric> <method> <task>	4 5 6	recently a large amount of research has been devoted to <task_1> . typically , activities have been defined by their <otherscientificterm_2> and represented by trajectories . these trajectories are collected and clustered to determine typical behaviors . this paper evaluates different <method_3> and <method_5> to catalog their strengths and weaknesses when utilized for the <task_0> . the <task_6> performance is measured by evaluating the correct <metric_4> on different datasets with varying characteristics .	1 7 -1 2 7 -1 7 -1 3 5 0 7 -1 6 4 8 7 -1
Towards Multiagent Meta-level Control .	multiagent meta-level control ; multiagent tornado tracking application ; reinforcement learning based approach ; decentralized meta-control policies ; global optimization algorithm ; action plan ; embedded systems ; coordinating agents ; adaptation process ; collaborating agents ; 3-agent network ; netrads	<method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <task> <method> <method> <method>	2 0 4 ; 2 0 3 ; 11 6 1 ; 9 3 6	embedded <method_6> consisting of <method_9> capable of interacting with their environment are becoming ubiquitous . it is crucial for these <method_6> to be able to adapt to the dynamic and uncertain characteristics of an open environment . in this paper , we argue that <method_0> is an effective way to determine when this <task_8> should be done and how much effort should be invested in adaptation as opposed to continuing with the current <otherscientificterm_5> . we describe a <method_2> to learn <method_3> offline . we then propose to use the learned <method_2> as input to a <method_4> to avoid conflicting meta-level decisions between <method_7> . our initial experiments in the context of <method_11> , a <method_1> show that <method_11> significantly improves performance in a <method_10> .	6 9 16 12 -1 12 -1 0 8 5 12 -1 2 3 14 12 -1 4 13 12 -1 7 15 12 -1
Fusing short term and long term features for improved speaker diarization .	short-term features ; prosodic and long-term features ; top-ranked long-term features ; speaker di-arization system ; diarization error rate ; diarization-independent speaker-discriminability study ; short-term features ; speaker discriminability ; nist evaluation ; speaker diarization ; long-term features ; features ; prosodic ; accuracy	<method> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <method> <metric>	0 3 3 ; 6 0 2 ; 5 0 1 ; 6 0 9 ; 4 5 3	the following article shows how a state-of-the-art <method_3> can be improved by combining traditional <method_0> with <method_12> and other <otherscientificterm_10> . first , we present a framework to study the <otherscientificterm_7> of 70 different <otherscientificterm_10> . then , we show how the <otherscientificterm_2> can be combined with <otherscientificterm_6> to increase the <metric_13> of <task_9> . the results were measured on standardized data sets -lrb- nist rt -rrb- and show a consistent improvement of about 30 % relative in <metric_4> compared to the best <method_3> presented at the <metric_8> in 2007 . this result was also verified on a wide set of meetings , which we call combdev , that contains 21 meetings from previous evaluations . since the <otherscientificterm_1> were selected using a <method_5> , we are confident that the same <otherscientificterm_11> are able to improve other systems that perform similar tasks	3 0 12 10 15 14 -1 7 14 -1 2 6 13 9 16 18 14 -1 4 8 19 14 -1 14 -1 17 14 -1
Performance bounds for channel tracking algorithms For MIMO systems .	additive white gaussian noise ; frequency-domain tracking scheme ; known channel statistics ; channel tracking schemes ; channel impulse response ; filter coefficients ; performance bounds	<method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm>	2 0 3	in this paper we derive <otherscientificterm_6> for tracking time-varying ofdm multiple-input multiple-output -lrb- mimo -rrb- communication channel in the presence of <method_0> . we discuss two <method_3> . the first tracks the <otherscientificterm_5> directly in time-domain , while the second separately tracks each tone in the frequency-domain . the <method_3> , with <material_2> , is utilized for evaluating the <otherscientificterm_6> . it is shown that the <method_3> , which exploits the sparseness of the <method_4> , outperforms the compu-tationally more efficient , <method_1> , which does not exploit the smooth frequency response of the channel .	6 0 7 -1 3 7 -1 5 7 -1 2 8 7 -1 4 1 7 -1
Video event detection and summarization using audio , visual and text saliency .	detection of perceptually important video events ; unimodal or audiovisual-based skimming ; bottom-up video summarization algorithm ; multimodal saliency curve ; multifrequency waveform modulations ; spatiotemporal attention model ; part-of-speech tagging ; attention curve ; video stream ; visual saliency ; nonlinear operators ; energy tracking ; movie distributions ; saliency models ; modality curves ; audio saliency ; text saliency ; video summarization ; color ; reſnes ; cues	<task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <material> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <task> <task> <otherscientificterm> <material> <otherscientificterm>	3 6 2 ; 10 1 11 ; 13 0 0 ; 20 0 15 ; 6 0 16 ; 2 0 17 ; 5 0 9 ; 20 0 4 ; 1 0 19	detection of perceptually important video events is formulated here on the basis of <method_13> for the audio , visual and textual information conveyed in a <material_8> . <task_15> is assessed by <otherscientificterm_20> that quantify <otherscientificterm_4> , extracted through <method_10> and <method_11> . <task_9> is measured through a <method_5> driven by intensity , <otherscientificterm_18> and motion . <task_16> is extracted from <task_6> on the subtitles information available with most <otherscientificterm_12> . the various <otherscientificterm_14> are integrated in a single <otherscientificterm_7> , where the presence of an event may be signiſed in one or multiple domains . this <otherscientificterm_3> is the basis of a <method_2> , that <material_19> results from <method_1> . the <method_2> performs favorably for <task_17> in terms of informativeness and enjoyability .	13 8 15 24 21 -1 20 4 10 11 9 23 25 29 21 -1 5 18 16 28 21 -1 6 12 26 21 -1 14 7 21 -1 3 22 30 21 -1 2 19 1 27 21 -1
Optimal Efficient Learning Equilibrium : Imperfect Monitoring in Symmetric Games .	efficient learning equilibrium ; natural solution concept ; learning algorithms ; incomplete information ; ele deviations ; multi-agent encounters ; polynomial time	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	0 6 1 ; 1 0 5	efficient learning equilibrium -lrb- <method_0> -rrb- is a <method_1> for <task_5> with <otherscientificterm_3> . it requires the <method_2> themselves to be in equilibrium for any game selected from a set of -lrb- initially unknown -rrb- games . in an optimal <method_0> , the <method_2> would efficiently obtain the surplus the agents would obtain in an optimal nash equilibrium of the initially unknown game which is played . the crucial part is that in an <otherscientificterm_4> from the <method_2> would become non-beneficial after <otherscientificterm_6> , although the game played is initially unknown . while appealing conceptually , the main challenge for establishing <method_2> based on this concept is to isolate general classes of games where an <method_0> exists . unfortunately , it has been shown that while an <method_0> exists for the setting in which each agent can observe all other agents ' actions and payoffs , an <method_0> does not exist in general when the other agents ' payoffs can not be observed . in this paper we provide the first positive results on this problem , constructively proving the existence of an optimal <method_0> for the class of symmetric games where an agent can not observe other agents ' payoffs .	0 1 5 3 8 9 7 -1 2 7 -1 7 -1 4 6 7 -1 7 -1 7 -1 7 -1
Skip-Thought Vectors .	generic , distributed sentence encoder ; semantic and syntactic properties ; vocabulary expansion method ; generic sentence representations ; encoded passage ; encoder-decoder model ; linear models ; question-type classification ; image-sentence ranking ; unsupervised learning ; semantic relatedness ; vector representations ; paraphrase detection	<otherscientificterm> <otherscientificterm> <method> <method> <material> <method> <method> <task> <task> <task> <task> <method> <task>	0 0 9 ; 12 1 7 ; 1 0 11 ; 8 1 7 ; 12 1 8 ; 10 1 8 ; 10 1 12	we describe an approach for <task_9> of a <otherscientificterm_0> . using the continuity of text from books , we train an <method_5> that tries to reconstruct the surrounding sentences of an <material_4> . sentences that share <otherscientificterm_1> are thus mapped to similar <method_11> . we next introduce a simple <method_2> to encode words that were not seen as part of training , allowing us to expand our vocabulary to a million words . after training our model , we extract and evaluate our vectors with <method_6> on 8 tasks : <task_10> , <task_12> , <task_8> , <task_7> and 4 benchmark sentiment and subjectivity datasets . the end result is an off-the-shelf encoder that can produce highly <method_3> that are robust and perform well in practice . we will make our encoder publicly available .	9 0 14 13 -1 5 4 13 -1 1 11 16 13 -1 2 13 -1 6 10 12 8 7 15 17 18 19 20 13 -1 13 -1 3 13 -1
An improved parser for data-oriented lexical-functional analysis .	verbmobil and homecentre corpora ; discounted frequency estimator ; relative frequency estimator ; monte carlo search ; lfg-annotated sentences ; fragment size ; parse accuracy ; dop hypothesis ; tree structures ; lfg-dop parser ; lfg-dop ; tree-dop ; accuracy	<material> <method> <metric> <method> <material> <otherscientificterm> <metric> <method> <otherscientificterm> <method> <method> <metric> <metric>	10 4 11 ; 0 5 3 ; 4 0 9	we present an <method_9> which uses fragments from <material_4> to parse new sentences . experiments with the <material_0> show that -lrb- 1 -rrb- viterbi n best search performs about 100 times faster than <method_3> while both achieve the same <metric_12> ; -lrb- 2 -rrb- the <method_7> which states that <metric_6> increases with increasing <otherscientificterm_5> is confirmed for <method_10> ; -lrb- 3 -rrb- <method_10> 's <metric_2> performs worse than a <method_1> ; and -lrb- 4 -rrb- <method_10> significantly outperforms <metric_11> if evaluated on <otherscientificterm_8> only .	9 4 16 13 -1 0 3 12 7 6 5 10 2 1 11 8 14 15 13 -1
Model-based speech enhancement using SNR dependent MMSE estimation .	temporal correlation of successive frames ; snr dependent mmse estimator ; speech prediction error signal ; modified kalman filter approach ; single channel speech enhancement ; prediction error signal ; temporal correlation ; objective measurements ; frequency domain ; snr ; estima-tors	<otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <material> <otherscientificterm> <method>	3 0 4 ; 7 5 10	this contribution presents a <method_3> for <task_4> which is operating in the <material_8> . in the first step , <otherscientificterm_0> is exploited yielding estimates of the current speech and noise dft coefficients . this first prediction is updated in the second step applying an <method_1> which is adapted to the -lrb- measured -rrb- statistics of the <otherscientificterm_2> . <metric_7> show consistent improvements compared to <method_10> which do not take into account the <otherscientificterm_6> or the influence of the input <otherscientificterm_9> on the statistics of the <otherscientificterm_5> .	3 4 8 12 11 -1 0 11 -1 1 2 7 11 -1 10 6 9 5 13 11 -1
Detection of TV commercials .	commercial or program shots ; viterbi decoder ; shot labeling ; shot duration ; logo presence ; real video ; tv shots ; hmm	<otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material> <material> <method>	7 1 1 ; 4 1 3 ; 1 0 2	this paper presents a system that labels <material_6> either as <otherscientificterm_0> . the system uses two observations : <otherscientificterm_4> and <otherscientificterm_3> . this observations are modeled using <method_7> and the <method_1> is finally used for <task_2> . the system has been tested on several hours of <material_5> achieving more than 99 % of correct labeling .	6 0 8 -1 4 3 10 8 -1 7 1 2 9 11 8 -1 5 8 -1
Discriminative Classifiers for Deterministic Dependency Parsing .	support vector machines ; deterministic dependency parsing ; classifier-based deterministic parsing ; deterministic parsing ; treebank-induced classifiers ; parsing accuracy ; feature models ; parsing models ; data-driven parsing ; chinese ; swedish ; accuracy ; classifiers ; english	<method> <task> <method> <method> <method> <metric> <method> <method> <task> <material> <material> <metric> <method> <material>	5 5 2 ; 12 0 1 ; 13 1 10 ; 4 0 3 ; 11 5 0 ; 0 0 12 ; 5 5 7 ; 2 0 7 ; 0 0 1 ; 9 1 13	deterministic parsing guided by <method_4> has emerged as a simple and efficient alternative to more complex models for <task_8> . we present a systematic comparison of memory-based learning -lrb- mbl -rrb- and <method_0> for inducing <method_12> for <task_1> , using data from <material_9> , <material_13> and <material_10> , together with a variety of different <method_6> . the comparison shows that <method_0> gives higher <metric_11> for richly articulated <method_6> across all languages , albeit with considerably longer training times . the results also confirm that <method_2> can achieve <metric_5> very close to the best results reported for more complex <method_7> .	4 8 18 14 -1 0 12 1 9 13 10 6 16 17 20 23 24 14 -1 11 19 14 -1 2 5 7 15 21 22 14 -1
Boosting Statistical Word Alignment Using Labeled and Unlabeled Data .	limited labeled data ; relative error reductions ; pseudo reference set ; semi-supervised boosting methods ; statistical word alignment ; semi-supervised boosting approach ; supervised boosting algorithm ; semi-supervised learning algorithm ; supervised boosting ; labeled data ; word aligner ; semi-supervised boosting ; unsupervised boosting ; boosting methods ; unlabeled data ; error rate	<material> <metric> <otherscientificterm> <method> <task> <method> <method> <method> <method> <material> <otherscientificterm> <method> <method> <method> <material> <metric>	8 1 12 ; 0 1 14 ; 9 1 14 ; 13 0 4 ; 5 0 4 ; 11 0 4 ; 2 0 14 ; 5 0 7 ; 5 0 10 ; 5 0 6 ; 1 5 11	this paper proposes a <method_5> to improve <task_4> with <material_0> and large amounts of <material_14> . the proposed <method_5> modifies the <method_6> to a <method_7> by incorporating the <material_14> . in this <method_5> , we build a <otherscientificterm_10> by using both the <material_9> and the <material_14> . then we build a <otherscientificterm_2> for the <material_14> , and calculate the <metric_15> of each <otherscientificterm_10> using only the <material_9> . based on this <method_6> , we investigate two <method_13> for <task_4> . in addition , we improve the <task_4> results by combining the results of the two <method_3> . experimental results on <task_4> indicate that <method_11> achieves <metric_1> of 28.29 % and 19.52 % as compared with <method_8> and <method_12> , respectively .	5 4 0 14 18 21 16 -1 6 7 24 26 16 -1 10 9 19 25 16 -1 2 15 23 16 -1 13 20 16 -1 3 16 -1 17 22 27 16 -1
An Efficient Monte-Carlo Algorithm for Pricing Combinatorial Prediction Markets for Tournaments .	conjunctive normal form ; disjunctive normal form ; dnf formulas of polynomial size ; combinatorial prediction market game ; multiplicative error factor ; combinatorial prediction market ; additive error bounds ; time polynomial ; importance sampling ; monte-carlo technique ; #p	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	2 0 0 ; 4 2 1 ; 8 0 9 ; 0 6 3	computing the market maker price of a security in a <method_5> is <otherscientificterm_10> - hard . we devise a fully polynomial randomized approximation scheme -lrb- fpras -rrb- that computes the price of any security in <otherscientificterm_1> within an <metric_4> in <otherscientificterm_7> in 1 / / and the size of the input , with high probability and under reasonable assumptions . our algorithm is a <method_9> based on <method_8> . the algorithm can also approximately price securities represented in <otherscientificterm_0> with <otherscientificterm_6> . to illustrate the applicability of our algorithm , we show that many securities in yahoo! 's popular <method_3> called <otherscientificterm_0> can be represented by <otherscientificterm_2> .	5 10 11 -1 1 4 7 13 11 -1 9 8 14 11 -1 0 6 11 -1 3 12 15 11 -1
Applying a Naive Bayes Similarity Measure to Word Sense Disambiguation .	word sense disambiguation tasks ; general-purpose naive bayes model ; probability estimates ; overlap mechanism ; maximum likelihood ; lexical knowledge ; random variables ; many-to-many association ; lesk algorithm ; word-net	<task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material>	1 0 7 ; 0 5 8 ; 1 4 8 ; 1 0 0 ; 8 0 0 ; 0 5 1	we replace the <method_3> of the <method_8> with a simple , <method_1> that measures <otherscientificterm_7> between two sets of <otherscientificterm_6> . even with simple <method_2> such as <otherscientificterm_4> , the <method_1> gains significant improvement over the <method_8> on <task_0> . with additional <otherscientificterm_5> from <material_9> , performance is further improved to surpass the state-of-the-art results .	3 8 1 7 6 11 10 -1 2 4 0 12 13 14 15 16 10 -1 5 9 10 -1
A Knowledge Compilation Map for Ordered Real-Valued Decision Diagrams .	valued decision diagrams ; non-negative real numbers ; knowledge compilation map ; real-valued functions ; vdd languages ; data structures ; cost functions ; utility functions ; probability distributions ; cuts ; complexity ; csps ; marginalizations	<method> <material> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm>	7 1 8 ; 12 1 10 ; 9 1 12 ; 2 0 3 ; 6 1 7	valued decision diagrams -lrb- <material_4> -rrb- are <otherscientificterm_5> that represent functions mapping variable-value assignments to <material_1> . they prove useful to compile <otherscientificterm_6> , <otherscientificterm_7> , or <otherscientificterm_8> . while the <metric_10> of some queries -lrb- notably optimization -rrb- and transformations -lrb- notably conditioning -rrb- on <material_4> has been known for some time , there remain many significant queries and transformations , such as the various kinds of <otherscientificterm_9> , <otherscientificterm_12> , and combinations , the <metric_10> of which has not been identified so far . this paper contributes to filling this gap and completing previous results about the time and space efficiency of <material_4> , thus leading to a <method_2> for <otherscientificterm_3> . our results show that many tasks that are hard on valued <method_11> are actually tractable on <material_4> .	4 5 1 13 -1 6 7 8 14 18 13 -1 10 9 12 15 16 13 -1 17 13 -1 2 3 13 -1
Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation .	conversational spoken language translation ; causal constraint of spoken conversations ; monolingual lda topic model ; translation model adaptation approach ; english-to-iraqi cslt task ; topic distribution ; up-front knowledge ; non-incremental oracle ; incremental nature ; similarity measure ; bleu ; nist ; ter	<task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <metric> <metric> <method>	3 4 7 ; 12 1 11 ; 2 0 9 ; 3 0 1 ; 4 5 3 ; 2 0 3 ; 10 1 12 ; 3 0 0	we describe a <method_3> for <task_0> , which encourages the use of contextually appropriate translation options from relevant training conversations . our <method_3> employs a <method_2> to derive a <metric_9> between the test conversation and the set of training conversations , which is used to bias translation choices towards the current context . a significant novelty of our <method_3> is its <otherscientificterm_8> ; we continuously update the <otherscientificterm_5> on the evolving test conversation as new utterances become available . thus , our <method_3> is well-suited to the <otherscientificterm_1> . on an <task_4> , the proposed <method_3> gives significant improvements over a baseline system as measured by <metric_10> , <method_12> , and <metric_11> . interestingly , the <method_3> outperforms a <method_7> that has <otherscientificterm_6> of the whole conversation .	3 0 21 13 -1 2 9 16 19 13 -1 8 5 13 -1 1 17 13 -1 4 15 18 20 13 -1 10 12 11 14 13 -1
Jointly Optimal Signature Sequences and Power Allocation for CDMA .	designing signature sequences ; sum power constraint ; power allocation policy ; correlated signals ; information-theoretic capacity ; user capacity ; colored noise ; signature sequences ; power allocation ; design problems	<task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task>	5 1 4 ; 3 1 6	the problems of <task_0> and <method_2> for code-division multiple access -lrb- cdma -rrb- are important and have been the subject of intensive research in recent years . two different criteria adopted in such <task_9> are the <otherscientificterm_5> and the <otherscientificterm_4> . regarding the maxi-mization of the <otherscientificterm_4> , most of the previous works only consider the optimizations of <material_7> and <otherscientificterm_8> separately . in contrast , this paper presents a jointly optimal design of <material_7> and <otherscientificterm_8> under the <otherscientificterm_1> . the proposed design is of closed-form and applicable for the general case of <material_3> and <otherscientificterm_6> . numerical results verify the superiority of the proposed design over the existing ones .	0 2 10 -1 9 5 4 11 10 -1 7 8 10 -1 1 10 -1 3 6 12 10 -1 10 -1
ForgetMeNot : Memory-Aware Forensic Facial Sketch Matching .	automated facial forensic sketch matching ; forensic facial sketch recognition ; well-studied sketch-photo modality gap ; 10,030 mugshot database ; forensic sketch recognition ; domain gap ; forensic sketches ; forgetting process ; memory problem ; law enforcement	<task> <task> <otherscientificterm> <material> <task> <otherscientificterm> <material> <method> <task> <task>	1 0 9	we investigate whether it is possible to improve the performance of <task_0> by learning from examples of facial forgetting over time . <task_1> is a key capability for <task_9> , but remains an unsolved problem . it is extremely challenging because there are three distinct contributors to the <otherscientificterm_5> between <material_6> and photos : the <otherscientificterm_2> , and the less studied gaps due to -lrb- i -rrb- the <method_7> of the eye-witness and -lrb- ii -rrb- their inability to elucidate their memory . in this paper , we address the <task_8> head on by introducing a database of 400 <material_6> created at different time-delays . based on this database we build a model to reverse the <method_7> . surprisingly , we show that it is possible to systematically '' un-forget '' facial details . moreover , it is possible to apply this model to dramatically improve <task_4> in practice : we achieve the state of the art results when matching 195 benchmark <material_6> against corresponding photos and a <material_3> .	0 1 10 -1 9 11 10 -1 5 6 2 7 10 -1 8 10 -1 10 -1 10 -1 10 -1
Convex Neural Networks .	multi-layer artificial neural networks ; machine learning community ; convex optimization problem ; learning algorithms ; hidden unit ; linear classifier ; convexity ; convexity	<method> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method>	2 0 0 ; 0 6 3	convexity has recently received a lot of attention in the <task_1> , and the lack of <otherscientificterm_6> has been seen as a major disadvantage of many <method_3> , such as <method_0> . we show that training <method_0> in which the number of hidden units is learned can be viewed as a <task_2> . this <task_2> involves an infinite number of variables , but can be solved by incrementally inserting a <otherscientificterm_4> at a time , each time finding a <method_5> that minimizes a weighted sum of errors .	1 6 3 0 10 8 -1 2 9 8 -1 4 5 7 8 -1
Path Integral Control by Reproducing Kernel Hilbert Space Embedding .	invariant and task dependent component ; stochastic optimal control problems ; model-free , non-parametric approach ; sample based approaches ; path integral form ; sample re-use ; sample efficiency ; sample data ; control problem ; embedding	<method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <material> <task> <otherscientificterm>	9 0 2 ; 2 0 8 ; 4 6 1 ; 7 5 3	we present an <otherscientificterm_9> of <otherscientificterm_1> , of the so called <otherscientificterm_4> , into reproducing kernel hilbert spaces . using consistent , sample based estimates of the <otherscientificterm_9> leads to a <method_2> for calculation of an approximate solution to the <task_8> . this <method_2> admits a decomposition of the problem into an <method_0> . consequently , we make much more efficient use of the <material_7> compared to previous <method_3> in this domain , e.g. , by allowing <otherscientificterm_5> across tasks . numerical examples on test problems , which illustrate the <metric_6> , are provided .	9 1 4 13 10 -1 2 8 11 12 10 -1 0 10 -1 7 3 5 14 10 -1 6 10 -1
Automatic Image Colorization Via Multimodal Predictions .	human perception of distances ; dataset of colored examples ; non-uniform spatial coherency criterion ; l-a-b color space ; machine learning tools ; user-provided color landmarks ; multimodality and estimate ; graph cuts ; one-to-one correspondence ; probability distribution ; local level ; color proposition ; colored image ; global level ; local texture ; texture noise ; manual intervention ; greyscale images ; automatic col-orization ; pixel	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm>	5 0 11	we aim to color <material_17> automatically , without any <otherscientificterm_16> . the <otherscientificterm_11> could then be interactively corrected by <otherscientificterm_5> if necessary . <task_18> is nontrivial since there is usually no <otherscientificterm_8> between color and <otherscientificterm_14> . the contribution of our framework is that we deal directly with <task_6> , for each <otherscientificterm_19> of the image to be colored , the <otherscientificterm_9> of all possible colors , instead of choosing the most probable color at the <otherscientificterm_10> . we also predict the expected variation of color at each <otherscientificterm_19> , thus defining a <otherscientificterm_2> . we then use <method_7> to maximize the probability of the whole <material_12> at the <otherscientificterm_13> . we work in the <otherscientificterm_3> in order to approximate the <otherscientificterm_0> between colors , and we use <method_4> to extract as much information as possible from a <material_1> . the resulting algorithm is fast , designed to be more robust to <otherscientificterm_15> , and is above all able to deal with ambiguity , in contrary to previous approaches .	17 16 20 -1 11 5 18 21 20 -1 8 14 20 -1 6 19 9 10 20 -1 2 20 -1 7 20 -1 12 13 20 -1 3 0 4 1 20 -1
Weighted Likelihood Ratio -LRB- WLR -RRB- Hidden Markov Model for Noisy Speech Recognition .	natural resonances of vocal track ; mfcc trained gmm baseline system ; human perception of speech formants ; output probability density function ; aurora2 connected digits database ; dynamic cepstral features ; broad-band noise interferences ; speech spectra ; speech recognition ; multiple-stream wlr-hmm ; spectral peaks ; exponential kernels ; hmm framework ; valleys ; wlr-hmm	<material> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	11 0 3 ; 12 0 3 ; 11 0 12 ; 0 0 6	in this paper we present a weighted likelihood ratio -lrb- wlr -rrb- based hidden markov model and apply it to <task_8> in noise . the wlr measure emphasizes <otherscientificterm_10> than <otherscientificterm_13> in comparing two given <otherscientificterm_7> . the measure is more consistent with <otherscientificterm_2> where <material_0> are and tends to be more robust to <otherscientificterm_6> than other measures . a complete <method_12> of this measure is derived and a mixture of <otherscientificterm_11> is used to model the <otherscientificterm_3> . the new <method_14> is tested on the <material_4> in noise . it shows more robust performance than the <method_1> . when combined with the <otherscientificterm_5> , the <method_9> shows a 39 % relative improvement over the baseline system .	8 15 -1 10 13 7 15 -1 2 0 6 19 15 -1 12 11 3 16 17 18 15 -1 14 4 15 -1 1 15 -1 15 -1
RWTH LVCSR systems for quaero and EU-bridge : German , Polish , Spanish and Portuguese .	language model adaptation ; minimum phone error trained acoustic models ; quaero and eu-bridge project evaluations ; confusion-network based system combination ; multilingual bottleneck features ; open vocabulary approach ; broadcast news ; audio data ; lecture domain ; spontaneous speech ; acoustic conditions ; lm adaptation ; morphemic units ; german lvcsr ; lvcsr systems ; podcasts	<method> <method> <task> <method> <otherscientificterm> <method> <material> <material> <material> <material> <otherscientificterm> <method> <otherscientificterm> <material> <method> <material>	4 1 1 ; 12 0 5 ; 15 1 8 ; 1 1 0 ; 9 3 7 ; 6 1 15 ; 0 1 3	in this paper , german , polish , spanish , and portuguese large vocabulary continuous speech recognition -lrb- lvcsr -rrb- systems developed by the rwth aachen university are presented . all the above mentioned systems for the aforementioned languages are used for the <task_2> . the <method_14> developed for these competitive evaluations focus on various domains like <material_6> , <material_15> and <material_8> . transcription of the speech for these tasks is challenging due to huge variability in the <otherscientificterm_10> and a significant portion of <material_7> includes <material_9> . good improvements are obtained using state-of-the-art <otherscientificterm_4> , <method_1> , <method_0> and <method_3> . in addition , an <method_5> using <otherscientificterm_12> is investigated along with the <method_11> for the <material_13> .	16 -1 2 16 -1 14 6 15 8 19 22 16 -1 10 7 9 21 16 -1 4 1 0 17 20 23 16 -1 3 18 16 -1
Testing the consistency assumption : Pronunciation variant forced alignment in read and spontaneous speech synthesis .	lattice-based forced alignment system ; front-end text processing system ; phoneme identity accuracy ; hmm-based voices ; acoustic models ; phoneme sequence ; spontaneous models ; spontaneous speech ; consistency assumption ; pronunciation variation ; speech synthesis ; forced alignment ; read prompts	<method> <method> <metric> <material> <method> <otherscientificterm> <method> <material> <otherscientificterm> <task> <task> <method> <material>	0 0 9 ; 11 0 10 ; 1 0 5	forced alignment for <task_10> traditionally aligns a <otherscientificterm_5> predetermined by the <method_1> . this sequence is not altered during alignment , i.e. , it is forced , despite possibly being faulty . the <otherscientificterm_8> is the assumption that these mistakes do not degrade models , as long as the mistakes are consistent across training and synthesis . we present evidence that in the alignment of both standard <material_12> and <material_7> this <otherscientificterm_5> is often wrong , and that this is likely to have a negative impact on <method_4> . a <method_0> allowing for <task_9> is implemented , resulting in improved <metric_2> for both types of speech . a perceptual evaluation of <material_3> showed that <method_6> trained on this improved alignment also improved standard synthesis , despite breaking the <otherscientificterm_8> .	10 5 1 15 16 13 -1 13 -1 8 13 -1 12 7 4 13 -1 0 9 14 13 -1 2 13 -1
Image registration based on both feature and intensity matching .	smooth spatially varying illumination variation ; parametric projective model ; projective transformation parameters ; projective model parameters ; intensity-based matching ; polynomial coefficients ; geometrical variation ; feature-based matching ; image processing ; polynomial model ; image registration ; illumination model ; intensity matching ; feature-based approach ; accuracy ; robustness	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <task> <method> <task> <method> <task> <method> <metric> <metric>	13 0 3 ; 2 0 11 ; 5 0 9 ; 10 3 8 ; 7 1 4	image registration is one of the most important tasks in <task_8> . the algorithms of <task_10> are classified into two categories : the <task_7> and <task_4> . each of them has its strength and weakness . in this paper , by combining these two techniques together , we developed a new algorithm for <task_10> . the algorithm utilises a <method_1> accounting for <otherscientificterm_6> and a <method_9> with a small number of <otherscientificterm_5> explicating the <otherscientificterm_0> . the initial <otherscientificterm_3> are first estimated by using <method_13> . subsequently , the coefficients of the <method_11> are determined simultaneously with the <otherscientificterm_2> through the process of <task_12> . the experimental results demonstrated the algorithm is of <metric_15> , efficiency and <metric_14> .	8 20 16 -1 10 7 4 21 16 -1 16 -1 16 -1 1 6 9 5 0 19 16 -1 3 13 17 16 -1 11 2 18 16 -1 12 16 -1
Mean Field Approach to a Probabilistic Model in Information Retrieval .	information retrieval ; approximate leave-one-out cross-validation procedure ; explicit parametric model ; cavity method ; rel-evancy assessment ; mean-field methods ; documents ; queries ; ir ; hyperparameters	<task> <method> <method> <method> <task> <method> <material> <otherscientificterm> <task> <otherscientificterm>	3 0 9 ; 3 0 1 ; 4 0 0 ; 7 1 4 ; 6 1 7 ; 1 0 9	we study an <method_2> of <material_6> , <otherscientificterm_7> , and <task_4> for <task_0> . <method_5> are applied to analyze the model and derive efficient practical algorithms to estimate the parameters in the problem . the <otherscientificterm_9> are estimated by a fast <method_1> based on the <method_3> . the <method_1> is further evaluated on several benchmark databases by comparing with standard algorithms in <task_8> .	2 6 7 4 0 5 13 14 15 10 -1 10 -1 9 1 3 11 12 16 10 -1 8 10 -1
Lowresource speech recognition with automatically learned sparse inverse covariance matrices .	maximum likelihood estimation.the graphic lasso method ; sparse inverse co-variance matrices ; sparse inverse covariance matrix ; sparse inverse covariance gaus-sians ; full covariance acoustic models ; sparse inverse covariance methods ; expectation maximization algorithm ; full co-variance gaussians ; unseen test data ; limited training data ; full covari-ance methods ; inverse covariance matrices ; limited data ; objective function ; l1 reg-ularization ; free parameters ; hmm	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <method> <material> <material> <method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <method>	12 0 7 ; 14 0 0 ; 0 0 2 ; 9 0 4 ; 5 4 10 ; 14 0 13	full covariance acoustic models trained with <material_9> generalize poorly to <material_8> due to a large number of <otherscientificterm_15> . we propose to use <otherscientificterm_1> to address this problem . previous <method_5> never outperformed <method_10> . we propose a method to automatically drive the structure of <otherscientificterm_11> to sparse during training . we use a new <otherscientificterm_13> by adding <method_14> to the traditional <otherscientificterm_13> for <method_0> for the estimation of a <otherscientificterm_2> is incorporated into the <method_6> to learn parameters of <method_16> using the new <otherscientificterm_13> . experimental results show that we only need about 25 % of the parameters of the <otherscientificterm_11> to be nonzero in order to achieve the same performance of a full covariance system . our proposed system using <method_3> also significantly outperforms a system using <method_7> trained on <material_12> .	9 8 15 21 17 -1 1 17 -1 5 10 22 17 -1 11 17 -1 13 14 0 2 6 16 19 20 23 17 -1 17 -1 18 17 -1
Motion-based object segmentation using local background sprites .	global motion estimation and/or background sprite generation techniques ; local background sprite generation ; segmenting foreground objects ; background modeling technique ; background subtraction techniques ; segmentation of sequences ; object segmentation ; static background ; moving background ; video material ; preprocessing	<method> <method> <task> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <material> <method>	7 0 9 ; 10 0 5 ; 8 0 5 ; 3 0 6 ; 4 0 2 ; 5 0 7 ; 1 0 3 ; 10 0 7 ; 8 0 7	it is well known that <material_9> with a <otherscientificterm_7> allows easier segmentation than that with a <otherscientificterm_8> . one approach to <task_5> with a <otherscientificterm_8> is to use <method_10> to create a <otherscientificterm_7> , after which conventional <method_4> can be used for <task_2> . it has been recently shown that <method_0> are reliable . we propose a new <method_3> for <task_6> using <method_1> . experimental results show the excellent performance of this new <method_3> compared to recent algorithms proposed .	9 7 8 12 11 -1 5 10 4 2 13 14 16 17 19 20 11 -1 0 11 -1 3 6 1 15 18 11 -1 11 -1
Opinion dynamics with bounded confidence in the Bayes risk error divergence sense .	bounded confidence opinion dynamic models ; bayes risk error divergence ; bayesian decision makers ; localized distributed averaging ; intermediate signal-to-noise ratios ; hypothesis testing task ; social networks ; signal detection ; bounded confidence ; decision-making system ; opinion dynamics ; prior probabilities ; limiting values ; hypothesis testing ; information propagation ; signal-to-noise ratio ; priors ; clusters	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <metric> <otherscientificterm> <otherscientificterm>	6 1 3 ; 2 0 13 ; 15 5 5 ; 2 0 7 ; 13 1 7 ; 2 0 10	bounded confidence opinion dynamic models have received much recent interest as models of <task_14> in <method_6> and <otherscientificterm_3> . however in the existing literature , opinions are only viewed as abstract quantities rather than as part of a <method_9> . in this work , <otherscientificterm_10> are examined when agents are <method_2> that perform <task_13> or <task_7> . <otherscientificterm_8> is defined on <otherscientificterm_11> of hypotheses through <otherscientificterm_1> , the appropriate measure between <otherscientificterm_16> in <task_13> . this definition contrasts with the measure used between opinions in the standard model : absolute error . it is shown that the rapid convergence of <otherscientificterm_11> to a small number of <otherscientificterm_12> is similar to that seen in the standard model . the most interesting finding in this work is that the number of these <otherscientificterm_12> changes with the <metric_15> in the <task_5> . the number of final values or <otherscientificterm_17> is maximal at <otherscientificterm_4> , suggesting that the most contentious issues lead to the largest number of factions .	14 6 3 19 18 -1 9 18 -1 10 2 13 7 8 20 22 23 24 18 -1 11 1 16 18 -1 18 -1 18 -1 12 21 18 -1 15 5 18 -1
Learning Kernels with Random Features .	machine learning tasks ; class of estimators ; supervised manner ; generalization bounds ; kernel machines ; user-defined kernel ; optimization problem ; training cost ; randomized features ; random features ; randomized-feature approach	<task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <method>	2 0 6 ; 8 0 4 ; 3 0 1 ; 4 0 0 ; 8 0 0	randomized features provide a computationally efficient way to approximate <method_4> in <task_0> . however , such methods require a <method_5> as input . we extend the <method_10> to the task of learning a kernel -lrb- via its associated <otherscientificterm_9> -rrb- . specifically , we present an efficient <task_6> that learns a kernel in a <method_2> . we prove the consistency of the estimated kernel as well as <otherscientificterm_3> for the <otherscientificterm_1> induced by the optimized kernel , and we experimentally evaluate our technique on several datasets . our approach is efficient and highly scalable , and we attain competitive results with a fraction of the <metric_7> of other techniques .	4 0 13 15 16 11 -1 5 11 -1 10 9 11 -1 6 2 12 11 -1 3 1 14 11 -1 11 -1
An Implementation of Combined Partial Parser and Morphosyntactic Disambiguator .	ipi pan corpus of polish ; simultaneous rule-based morphosyntactic tagging ; tree-bank of partial parses ; partial parsing formalism	<material> <task> <otherscientificterm> <task>	1 1 3	the aim of this paper is to present a simple yet efficient implementation of a tool for <task_1> and <task_3> . the parser is currently used for creating a <otherscientificterm_2> in a valency acquisition project over the <material_0> .	1 3 5 4 -1 2 0 4 -1
Minimax Probability Machine .	misclassification of future data ; nonlinear decision boundaries ; optimization problem ; mercer kernels ; convex optimization ; classifier	<task> <otherscientificterm> <task> <method> <method> <method>	3 0 1 ; 5 0 2	when constructing a <method_5> , the probability of correct classification of future data points should be maximized . in the current paper this <method_5> is translated in a very direct way into an <task_2> , which is solved using methods from <method_4> . we also show how to exploit <method_3> in this setting to obtain <otherscientificterm_1> . a worst-case bound on the probability of <task_0> is obtained explicitly .	5 6 -1 2 4 8 6 -1 3 1 7 6 -1 0 6 -1
CHAT : a conversational helper for automotive tasks .	task completion rate ; spoken dialogue interfaces ; computing platforms ; user experience ; automotive tasks ; dialog efficiency ; dialog systems ; conversational helper ; chat	<metric> <otherscientificterm> <method> <otherscientificterm> <task> <metric> <method> <method> <method>	5 1 3 ; 7 0 4 ; 0 1 5	spoken dialogue interfaces , mostly command-and-control , become more visible in applications where attention needs to be shared with other tasks , such as driving a car . the deployment of the simple <method_6> , instead of more sophisticated ones , is partly because the <method_2> used for such tasks have been less powerful and partly because certain issues from these cognitively challenging tasks have not been well addressed even in the most advanced <method_6> . this paper reports the progress of our research effort in developing a robust , wide-coverage , and cognitive load-sensitive spoken dialog interface called <method_8> : <method_7> for <task_4> . our research in the past few years has led to promising results , including high <metric_0> , <metric_5> , and improved <otherscientificterm_3> .	9 -1 6 2 9 -1 8 11 9 -1 7 4 10 12 9 -1
Topic and Stylistic Adaptation for Speech Summarisation .	ted corpus of eurospeech conference presentations ; linguistic model component ; speech recogniser transcriptions ; lim topic and stylistic adaptation ; cnn broadcast news data ; automatic lim adaptation ; automatic speech summarisation ; automatically generated summaries ; news stories ; language model ; summarised text ; human summaries ; summari-sation accuracy ; contemporary approaches ; recognition process ; adaptation data ; lims	<material> <method> <material> <task> <material> <method> <task> <material> <material> <method> <material> <material> <metric> <method> <task> <material> <method>	9 0 14 ; 15 0 16 ; 4 0 8	contemporary approaches to <task_6> comprise several components , among them a <method_1> , which is unrelated to the <method_9> used during the <task_14> . this <method_1> assigns a probability to word sequences from the source text according to their likelihood of appearing in the <material_10> . in this paper we investigate <task_3> using combinations of <method_16> each trained on different <material_15> . experiments are performed on 9 talks from the <material_0> , as well as 5 <material_8> from <material_4> , for all of which human -lrb- trs -rrb- and <material_2> along with <material_11> were used . in all asr cases , <metric_12> -lrb- sumaccy -rrb- of <material_7> was significantly improved by <method_5> , with relative improvements of at least 2.5 % in all experiments .	6 1 9 14 18 17 -1 10 17 -1 3 16 15 19 17 -1 0 8 4 2 11 20 17 -1 17 -1
On Stochastic and Worst-case Models for Investing .	geometric brownian motion ; universal portfolio management ; online convex optimization ; exp-concave loss functions ; stock price returns ; investment strategy ; probabilistic model ; regret bounds ; worst-case approach	<method> <method> <task> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <method>	7 0 2 ; 8 0 1 ; 7 0 5	in practice , most investing is done assuming a <method_6> of <metric_4> known as the <method_0> . while often an acceptable approximation , the <method_0> is not always valid empirically . this motivates a <method_8> to investing , called <method_1> , where the objective is to maximize wealth relative to the wealth earned by the best fixed portfolio in hindsight . in this paper we tie the two approaches , and design an <method_5> which is universal in the worst-case , and yet capable of exploiting the mostly valid <method_0> . our <method_5> is based on new and improved <otherscientificterm_7> for <task_2> with <otherscientificterm_3> .	6 4 0 9 -1 9 -1 8 1 11 9 -1 5 9 -1 7 10 12 9 -1
Approximate Gaussian process inference for the drift function in stochastic differential equations .	sparse observations of the state vector ; unobserved , latent dynamics ; sparse gaussian process regression ; approximate em algorithm ; stochastic differential equations ; piecewise linearized process ; estimating drift functions ; posterior over states ; state vector ; gaussian process ; ornstein-uhlenbeck type ; nonparametric approach ; map estimation	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method>	11 0 6	we introduce a <method_11> for <task_6> in systems of <otherscientificterm_4> from <otherscientificterm_0> . using a <method_9> prior over the drift as a function of the <otherscientificterm_8> , we develop an <method_3> to deal with the <otherscientificterm_1> between observations . the <otherscientificterm_7> is approximated by a <method_5> of the <otherscientificterm_10> and the <method_12> of the drift is facilitated by a <method_2> .	11 6 4 0 14 13 -1 9 8 3 1 13 -1 7 5 10 12 2 13 -1
Computational Complexity of Multi-way , Dataflow Constraint Problems .	multi-way dataflow constraints ; multi-way constraint problems ; local propagation algorithms ; interactive applications ; computational complexity ; restriction ; skyblue	<otherscientificterm> <task> <method> <task> <metric> <otherscientificterm> <method>	0 0 3	although it is acknowledged that <otherscientificterm_0> are useful in <task_3> , concerns about their tractability have hindered their acceptance . certain <method_2> that solve these constraints are polynomial , others -lrb- such as sky-blue -rrb- are exponential . every system handles a specific problem and the influence of any particular <otherscientificterm_5> on the <metric_4> is not yet precisely determined . in this paper , we present three theoretical results that allow us to classify existing <task_1> . especially , we prove that the problem handled by <method_6> is np-hard .	0 3 8 7 -1 2 7 -1 5 4 7 -1 1 7 -1 6 7 -1
Lattice structure for two-band perfect reconstruction filter banks using Pade approximation .	two-channel bi-orthogonal pr lter banks ; pad e table ; lter bank ; parameter space ; pr property ; scalar quantity ; complementary lters ; lattice structure ; end-to-end delay ; lter ; lattice	<method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	1 0 7	we show how the <otherscientificterm_1> can be utilized to develop a new <otherscientificterm_7> for general two-channel bi-orthogonal perfect reconstruction -lrb- pr -rrb- <method_9> banks . this is achieved through characterization of all <method_0> . the <otherscientificterm_3> found using this method is unique for each <material_2> . similarly to any other <otherscientificterm_7> , the <otherscientificterm_4> is achieved structurally and quantization of the parameters of the <otherscientificterm_10> does not eeect this property . furthermore , we demonstrate that for a given <method_9> , the set of all <otherscientificterm_6> can be uniquely speciied by two parameters , namely the <otherscientificterm_8> of the system and a <otherscientificterm_5> .	1 7 9 12 11 -1 0 11 -1 3 2 11 -1 4 10 11 -1 6 8 11 -1
A Functional Approach to Generation with TAG .	tree adjoining grammar ; sentence generation system ; tag-based generation systems ; syntactic choice ; generation system ; sentence generation ; syntactic possibilities ; features ; grammar ; mumble-86	<method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method>	0 0 5 ; 4 0 3 ; 0 0 1	it has been hypothesized that <method_0> is particularly well suited for <task_5> . it is unclear , however , how a <method_1> based on <method_0> should choose among the <otherscientificterm_6> made available in the <method_8> . in this paper we consider the question of what needs to be done to generate with <method_0> and explain a <method_4> that provides the necessary <otherscientificterm_7> . this approach is compared with other <method_2> . particular attention is given to <method_9> which , like our <method_4> , makes <otherscientificterm_3> on sophisticated functional grounds .	0 5 11 10 -1 1 6 8 13 10 -1 4 7 10 -1 2 10 -1 9 3 12 10 -1
On the influence of frame-asynchronous grammar scoring in a CSR system .	tree-based vocabulary search strategy ; continuous speech recognition system ; language models ; acoustic probabilities ; grammar scoring ; theoretical explanation ; grammar probabilities ; searching procedure ; grammarprobabilities ; bigrams ; unigrams	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	6 1 3 ; 6 3 1 ; 3 3 1 ; 4 3 7	it is usually assumed that <otherscientificterm_6> and <otherscientificterm_3> in a <method_1> have to be incorporated to the general score with dierent w eights . this is an experimental fact and there is no generally accepted <otherscientificterm_5> . in this paper we propose an explanation to this fact , related to the way <method_4> is incorporated in the <method_7> . accordingly to this explanation , we perform a set of experiments to test our hypothesis . we are also proposing a new way o f i n troducing <otherscientificterm_8> in a <method_0> , where systems are usually bound to use the worst strategy . to apply our ideas to <otherscientificterm_10> is rather simple . for more complex <method_2> like <method_9> we h a v e t o implement a new procedure .	6 3 1 12 13 14 11 -1 5 11 -1 4 7 15 11 -1 11 -1 8 0 11 -1 11 -1 10 11 -1
Effect of Colorspace Transformation , the Illuminance Component , and Color Modeling on Skin Detection .	receiver operating characteristic curve ; colorspace and color modeling testing methodology ; illuminance component of skin color ; sct or hsi colorspaces ; manual ground truth ; human motion analysis ; skin color distribution ; color model-ing approaches ; skin color modeling ; pixel color ; non-rgb col-orspace ; colorspace transformations ; skin detection ; colorspace transformation ; histogram approach ; illuminance component ; classifying	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <method> <method> <method>	8 4 13 ; 12 6 5 ; 1 0 12	skin detection is an important preliminary process in <task_5> . it is commonly performed in three steps : transforming the <otherscientificterm_9> to a <otherscientificterm_10> , dropping the <otherscientificterm_2> , and <method_16> by modeling the <otherscientificterm_6> . in this paper , we evaluate the effect of these three steps on the <task_12> performance . the importance of this study is a new comprehensive <method_1> that would allow for making the best choices for <task_12> . combinations of nine colorspaces , the presence of the absence of the <method_15> , and the two <method_7> are compared . the performance is measured by using a <otherscientificterm_0> on a large dataset of 805 images with <material_4> . the results reveal that -lrb- 1 -rrb- <otherscientificterm_11> can improve performance in certain instances , -lrb- 2 -rrb- the absence of the <method_15> decreases performance , and -lrb- 3 -rrb- <method_8> has a greater impact than <task_13> . we found that the best performance was obtained by transforming the <otherscientificterm_9> to the <otherscientificterm_3> , keeping the <method_15> , and modeling the color with the <method_14> .	5 19 17 -1 9 10 2 16 6 17 -1 12 17 -1 1 20 17 -1 15 7 17 -1 17 -1 0 4 18 17 -1 11 8 13 17 -1
Exploring Key Concept Paraphrasing Based on Pivot Language Translation for Question Retrieval .	community-based question answering services ; pivot language translation based approach ; unified question retrieval model ; paraphrases of key concepts ; concept level enrichment ; word level ; word mismatch ; query question ; question retrieval ; paraphrases	<task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm>	8 3 0 ; 1 0 3 ; 9 0 7	question retrieval in current <task_0> does not , in general , work well for long and complex queries . one of the main difficulties lies in the <otherscientificterm_6> between queries and candidate questions . existing solutions try to expand the queries at <otherscientificterm_5> , but they usually fail to consider <method_4> . in this paper , we explore a <method_1> to derive the <otherscientificterm_3> . we further propose a <method_2> which integrates the key concepts and their <otherscientificterm_9> for the <task_7> . experimental results demonstrate that the <method_1> significantly outperforms the state-of-the-art models in <task_8> .	0 11 10 -1 6 10 -1 5 4 10 -1 1 3 12 10 -1 2 9 7 13 10 -1 8 10 -1
Kernel density-based acoustic model with cross-lingual bottleneck features for resource limited LVCSR .	deep neural networks ; gaussian mixture models ; emission probability of hmm states ; non-parametric kernel density estimation method ; limited training data case ; wall street journal task ; gmm and dnn models ; speech recognition task ; speech class posteriors ; cross-lingual bottleneck features ; speech training data ; discriminative score calibrator ; kernel density ; acoustic models	<method> <method> <otherscientificterm> <method> <material> <material> <method> <task> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method>	1 6 13 ; 11 0 8 ; 12 0 8 ; 12 0 7 ; 6 0 4 ; 5 5 13 ; 3 0 2 ; 1 1 0 ; 0 6 13 ; 9 0 13	conventional <method_13> , such as <method_1> or <method_0> , can not be reliably estimated when there are very little <material_10> , e.g. less than 1 hour . in this paper , we investigate the use of a <method_3> to predict the <otherscientificterm_2> . in addition , we introduce a <method_11> to improve the <otherscientificterm_8> generated by the <otherscientificterm_12> for <task_7> . experimental results on the <material_5> show that the proposed <method_13> using <otherscientificterm_9> significantly outperforms <method_6> for <material_4> .	13 1 0 10 15 22 23 14 -1 3 2 21 14 -1 11 8 12 7 16 17 18 14 -1 5 9 6 4 19 20 24 14 -1
Collective Opinion Target Extraction in Chinese Microblogs .	unsupervised label propagation algorithm ; sentiment analysis techniques ; fine-grained word-level task ; informal writing style ; chinese microblog messages ; opinion targets ; chinese microblogs ; microblog messages ; length limit ; clustering algorithms ; hashtags	<method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm>	8 1 3 ; 7 0 1 ; 6 5 0	microblog messages pose severe challenges for current <method_1> due to some inherent characteristics such as the <otherscientificterm_8> and <otherscientificterm_3> . in this paper , we study the problem of extracting <otherscientificterm_5> of <material_4> . such <task_2> has not been well investigated in <otherscientificterm_6> yet . we propose an <method_0> to address the problem . the <otherscientificterm_5> of all messages in a topic are collectively extracted based on the assumption that similar messages may focus on similar <otherscientificterm_5> . topics in <otherscientificterm_6> are identified by <otherscientificterm_10> or using <method_9> . experimental results on <otherscientificterm_6> show the effectiveness of our <method_0> and algorithms .	1 8 3 12 13 11 -1 5 4 11 -1 2 6 11 -1 0 11 -1 11 -1 10 9 11 -1 14 11 -1
Mapping Sparse Representation to State Likelihoods in Noise-Robust Automatic Speech Recognition .	partial least squares regression ; automatic speech recognition system ; chime noisy speech database ; at-6 db snr ; binary labeling system ; speech state likelihoods ; learning-based methods ; state likelihoods ; recognition ; exemplars ; mapping ; recognition ; speech	<method> <method> <material> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task> <task> <material>	6 0 10 ; 2 0 8 ; 7 3 1	this paper proposes <method_6> for <task_10> a sparse representation of noisy <material_12> to <otherscientificterm_7> in an <method_1> . we represent <material_12> as a sparse linear combination of <otherscientificterm_9> extracted from training data . the weights of <otherscientificterm_9> are mapped to <otherscientificterm_5> using ordinary least squares -lrb- ols -rrb- and <method_0> . <task_8> experiments are conducted using the <material_2> . according to the results , both <method_6> can be successfully used for training the <task_10> . we achieve improvements over the previous <method_4> , and <task_11> scores close to 70 % <metric_3> .	6 10 12 7 1 16 13 -1 9 13 -1 5 0 8 13 -1 2 15 13 -1 14 13 -1 4 11 3 13 -1
Recursive estimation of generative models of video .	generative model and learning procedure ; clustering of gaussian mixtures ; computationally intensive learning ; video browsing tool ; kl approximation methods ; recursive model estimation ; unsupervised video clustering ; fast inference ; on-line learning ; kl divergence ; gaussians ; efficiency ; clustering	<method> <task> <task> <method> <method> <method> <task> <task> <task> <otherscientificterm> <method> <metric> <method>	12 1 4 ; 7 1 8 ; 11 1 12 ; 2 0 0 ; 0 0 3 ; 5 1 7 ; 0 0 6	in this paper we present a <method_0> for <task_6> into scenes . the work addresses two important problems : realistic mod-eling of the sources of variability in the video and fast transformation invariant frame <method_12> . we suggest a solution to the problem of <task_2> in this <method_0> by combining the <method_5> , <task_7> , and <task_8> . thus , we achieve real time frame <method_12> performance . novel aspects of this <method_0> include an algorithm for the <task_1> , and the fast computation of the <otherscientificterm_9> between two mixtures of <method_10> . the <metric_11> and the performance of <method_12> and <method_4> are demonstrated . we also present novel <method_3> based on the visualization of the variables in the <method_0> .	0 6 20 13 -1 12 13 -1 2 5 7 8 15 17 19 13 -1 13 -1 1 9 10 13 -1 11 14 16 13 -1 4 18 13 -1
A game theoretical algorithm for joint power and topology control in distributed WSN .	game theory concepts ; fully distributed algorithm ; network topology control ; non-cooperative game ; connected network ; wireless networks	<method> <method> <task> <otherscientificterm> <method> <method>	2 0 2 ; 0 0 3 ; 1 0 3 ; 0 0 1 ; 2 0 5	in this paper , the issue of <task_2> in <method_5> using a <method_1> is considered . whereas the proposed <method_1> is designed applying <method_0> to design a <otherscientificterm_3> , <task_2> is guaranteed based on asymp-totic results of <task_2> . simulations show that for a relatively low node density , the probability that the proposed <method_1> leads to a <method_4> is close to one .	2 5 1 11 6 -1 0 3 7 8 9 10 6 -1 4 6 -1
Unsupervised lattice-based acoustic model adaptation for speaker-dependent conversational telephone speech transcription .	iterative and cascaded adaptation ; conversational telephone speech transcription ; iterative cascaded lattice system ; thresholding frame posteriors ; lattice adaptation techniques ; local best-confidence path ; unsupervised/supervised adaptation gap ; lattice adaptation ; transcript-based adaptation ; speaker-dependent models	<task> <task> <method> <task> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <method>	6 5 7 ; 4 0 1 ; 9 0 1 ; 2 0 7 ; 4 0 9	this paper examines the application of <method_4> to <method_9> for the purpose of <task_1> . given sufficient training data per speaker , it is feasible to build adapted <method_9> using lattice mllr and lattice map . experiments on <task_0> are presented . additionally various strategies for <task_3> are investigated , and it is shown that accumulating statistics from the <otherscientificterm_5> is sufficient to achieve optimal adaptation . overall , an <method_2> was able to reduce <metric_7> by 7.0 % abs. , which was a 0.8 % abs . gain over <method_8> . <metric_7> reduced the <otherscientificterm_6> from 2.5 % to 1.7 % .	4 9 1 12 13 15 10 -1 10 -1 0 10 -1 3 5 10 -1 2 7 14 10 -1 8 10 -1 6 11 10 -1
Gaussian mixture sigma-point particle filters for sequential probabilistic inference in dynamic state-space models .	time-update and proposal distribution generation ; recursive bayesian estimation algorithm ; posterior state density ; weighted em algorithm ; gaussian mixture model ; nonlinear non-gaussian systems ; sigma-point kalman filters ; sequential probabilistic inference ; weighted particle set ; measurement update step ; resampling stage ; particle filters ; computational complexity	<task> <method> <otherscientificterm> <method> <method> <method> <method> <task> <material> <otherscientificterm> <otherscientificterm> <method> <metric>	12 5 1 ; 3 0 9 ; 4 0 2	for <task_7> in <method_5> approximate solutions must be used . we present a novel <method_1> that combines an importance sampling based <otherscientificterm_9> with a bank of <method_6> for the <task_0> . the <otherscientificterm_2> is represented by a <method_4> that is recovered from the <material_8> of the <otherscientificterm_9> by means of a <method_3> . this <method_1> replaces the <otherscientificterm_10> needed by most <method_11> and mitigates the '' sample depletion '' problem . we show that this new <method_1> has an improved estimation performance and reduced <metric_12> compared to other related algorithms .	7 5 13 -1 1 9 6 0 13 -1 2 4 8 3 15 16 13 -1 10 11 13 -1 12 14 13 -1
Gender in everyday speech and language : a corpus-based study .	spontaneous telephone and face-to-face conversations ; everyday male and female speech ; spontaneous speech phenomena ; spoken language corpora ; data-mining '' approach ; phoneme substitutions ; gender-specific characteristics ; pronunciation variation ; articulation rate ; filled pauses ; insertions ; repetitions ; disfluencies ; deletions	<material> <material> <material> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 1 10 ; 12 1 10 ; 5 1 12 ; 5 1 13 ; 9 1 5 ; 4 0 6 ; 12 1 13 ; 9 1 12 ; 9 1 13	this paper presents an exploratory study on the relations between gender and everyday parlance . a '' <method_4> is used to explore <otherscientificterm_6> in a large number of <material_0> . our study focuses on speech rate -lrb- speaking rate and <metric_8> -rrb- , <otherscientificterm_12> -lrb- <otherscientificterm_9> and <otherscientificterm_11> -rrb- , <otherscientificterm_7> -lrb- <otherscientificterm_5> , <otherscientificterm_13> and <otherscientificterm_10> -rrb- , and preferences for particular parts of speech . our study reveals interesting similarities and differences in <material_1> , and proves that data-mining on large <material_3> is a promising approach for obtaining information on <material_2> and for generating new hypotheses for research .	14 -1 4 6 0 20 14 -1 8 12 9 11 7 5 13 10 15 16 17 18 19 21 22 23 14 -1 1 3 2 14 -1
Joint maximum sum-rate receiver design and power allocation strategy for multihop wireless sensor networks .	constrained maximum sum-rate expressions ; multihop wireless sensor network ; amplify-and-forward scheme ; equal power allocation ; power allocation parameters ; alternating optimization approach ; complex amplification coefficients ; linear receiver ; relay node ; sum-rate	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	5 0 4 ; 9 0 1 ; 7 1 4	in this paper , we consider a <method_1> with multiple relay nodes for each hop where the <method_2> is employed . we present a strategy to jointly design the <method_7> and the <otherscientificterm_4> via an <method_5> that maximizes the <otherscientificterm_9> of the <method_1> . we derive <otherscientificterm_0> along with an algorithm to compute the <method_7> and the <otherscientificterm_4> with the optimal <otherscientificterm_6> for each <otherscientificterm_8> . computer simulations show good performance of our proposed methods in terms of <otherscientificterm_9> compared to the method with <otherscientificterm_3> .	1 2 10 -1 7 4 5 9 11 12 13 10 -1 0 6 8 10 -1 3 10 -1
Gaussian dynamic warping -LRB- GDW -RRB- method applied to text-dependent speaker detection and verification .	temporal structure information component ; gaussian dynamic warping ; voice-based entrance door security systems ; acoustic variability of speech ; hierarchical statistical framework ; acoustic modeling method ; real world applications ; temporal constraints ; acoustic modeling ; specialization	<method> <method> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <task> <metric>	2 6 6 ; 4 0 5 ; 1 6 5 ; 1 0 3 ; 5 0 6 ; 9 2 4 ; 4 0 8	this paper introduces a new <method_5> called <method_1> . <method_5> is targeting <task_6> such as <method_2> , the example presented in this paper . the proposed <method_5> uses a <method_4> with three levels of <metric_9> for the <task_8> . the highest level of <metric_9> is in addition responsible for the modeling of the <otherscientificterm_7> via a specific <method_0> . the preliminary results show the ability of the <method_1> to elegantly take into account the <otherscientificterm_3> while capturing important <otherscientificterm_7> .	5 1 13 10 -1 6 2 11 15 10 -1 4 9 8 12 16 17 10 -1 7 0 10 -1 3 14 10 -1
Concept-based Summarization using Integer Linear Programming : From Concept Pruning to Multiple Optimal Solutions .	budgeted maximum coverage problem ; sentence selection ; approximation algorithm ; low-weight concepts ; concept pruning ; concept-based summarization ; inference ; solver ; np-hard	<task> <task> <method> <otherscientificterm> <task> <task> <task> <method> <method>	3 0 7 ; 2 0 4 ; 2 0 6	in <task_5> , <task_1> is modelled as a <task_0> . as this problem is <method_8> , pruning <otherscientificterm_3> is required for the <method_7> to find optimal solutions efficiently . this work shows that reducing the number of concepts in the model leads to lower rouge scores , and more importantly to the presence of multiple optimal solutions . we address these issues by extending the model to provide a single optimal solution , and eliminate the need for <task_4> using an <method_2> that achieves comparable performance to exact <task_6> .	5 1 0 9 -1 8 3 7 10 9 -1 9 -1 4 2 6 11 12 9 -1
Multi-resolution cepstral features for phoneme recognition across speech sub-bands .	full bandwith cepstral features ; multi-resolution sub-band cepstral features ; signal to noise ratio ; independent multi-resoltuion sub-band models ; log likelihood probabilities ; narrow band noise ; partial recognition scores ; non linear recombination ; linearly weighted recombination ; sub-band cepstral features ; mult-iresolution feature vectors ; subband cepstral features ; sub-band approach ; mfcc features ; timit database ; discriminative cues ; sub-band variations ; broadband noise ; phoneme recognition ; localised regions ; sub-band decomposition	<otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	13 0 18 ; 20 0 9 ; 13 0 14 ; 0 1 9 ; 18 0 8 ; 1 0 15 ; 14 0 18 ; 7 0 12 ; 17 2 18	multi-resolution <otherscientificterm_9> strive to exploit <otherscientificterm_15> in <otherscientificterm_19> of the spectral domain by supplementing the <otherscientificterm_0> with <otherscientificterm_9> derived from several levels of <otherscientificterm_20> . <otherscientificterm_10> , formed by concatenation of the <otherscientificterm_11> into an extended feature vector , are shown to yield better performance than conventional <method_13> for <task_18> on the <material_14> . possible strategies for the recombination of <metric_6> from <method_3> are explored . by exploiting the <otherscientificterm_16> in <metric_2> for <task_8> of the <otherscientificterm_4> we obtained improved <task_18> performance in <otherscientificterm_17> compared to <method_13> . this is an advantage over a purely <method_12> using <method_7> which is robust only to <otherscientificterm_5> .	9 15 19 0 20 10 23 25 27 21 -1 11 13 18 14 22 24 28 21 -1 6 3 21 -1 16 2 8 4 17 26 30 21 -1 12 7 29 21 -1
Speech recognition using neural networks with forward-backward probability generated targets .	continuous digits recognition task ; forward-backward probabilities ; training pattern ; speech recognition ; error rate ; continuous targets	<task> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm>	1 0 5	neural network training targets for <task_3> are estimated using a novel method . rather than use zero and one , <otherscientificterm_5> are generated using <otherscientificterm_1> . each <otherscientificterm_2> has more than one class active . experiments showed that the new method eectively decreased the <metric_4> by 15 % in a <task_0> .	3 6 -1 5 1 7 6 -1 2 6 -1 4 0 6 -1
Improving pronunciation modeling for non-native speech recognition .	n-best rescoring approach ; n-best list rescoring ; speaker clustering approach ; latent pronunciation analysis ; pronunciation modeling approaches ; pronunciation dictionary approach ; pronunciation modeling ; non-native speech ; pronunciation habits ; speaker clustering	<method> <method> <method> <method> <method> <method> <task> <material> <otherscientificterm> <task>	0 6 4 ; 2 0 6 ; 3 0 9 ; 6 4 1 ; 6 1 0 ; 6 0 9 ; 6 6 4	in this paper , three different approaches to <task_6> are investigated . two existing <method_4> , namely the <task_6> and <method_0> are modified to work with little amount of <material_7> . we also propose a <method_2> , which capable of grouping the speakers based on their <otherscientificterm_8> . given some speech , the <method_2> can also be used for <task_6> . this <method_2> is called <method_3> . the results show that conventional <task_6> perform slightly better than <method_1> , while the <method_3> has shown to be beneficial for <task_9> , and <method_2> can produce nearly the same improvement as the <method_5> , without the need to know the origin of the speaker .	6 10 -1 4 0 7 11 15 17 10 -1 2 8 10 -1 12 10 -1 3 10 -1 1 9 13 14 16 10 -1
Unsupervised Learning of Mixtures of Multiple Causes in Binary Data .	unsupervised learning of clusters ; images of printed characters ; noisy test data ; multiple cause model ; binary data ; sigmoid squashing ; data reconstructions ; mixture model ; weighted sum ; observed data ; nonlinearity ; cluster-centers ; recognition ; learning	<task> <material> <material> <method> <material> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <task>	3 0 9 ; 12 1 13	this paper presents a formulation for <task_0> reflecting multiple causal structure in <material_4> . unlike the standard <method_7> , a <method_3> accounts for <material_9> by combining assertions from many hidden causes , each of which can pertain to varying degree to any subset of the observable dimensions . a crucial issue is the mixing-function for combining beliefs from different <otherscientificterm_11> in order to generate <task_6> whose errors are minimized both during <task_12> and <task_13> . we demonstrate a weakness inherent to the popular <otherscientificterm_8> followed by <method_5> , and offer an alternative form of the <otherscientificterm_10> . results are presented demonstrating the algorithm 's ability successfully to discover coherent multiple causal representat.ions of <material_2> and in <material_1> .	0 4 14 -1 7 3 9 15 14 -1 11 6 12 13 16 14 -1 8 5 10 14 -1 14 -1
Full-Angle Quaternions for Robustly Matching Vectors of 3D Rotations .	online subspace learning ; 2d object tracking ; 3d shape recognition ; color video ; faq representation ; point clouds ; hashing scheme ; public dataset ; euclidean	<method> <task> <task> <material> <method> <otherscientificterm> <method> <material> <otherscientificterm>	3 0 2 ; 5 0 2 ; 5 1 1	in this paper we introduce a new distance for robustly matching vectors of 3d rotations . a special representation of 3d rotations , which we coin full-angle quaternion -lrb- faq -rrb- , allows us to express this distance as <otherscientificterm_8> . we apply the distance to the problems of <task_2> from <otherscientificterm_5> and <task_1> in <material_3> . for the former , we introduce a <method_6> for scale and translation which outperforms the previous state-of-the-art approach on a <material_7> . for the latter , we incorporate <method_0> with the proposed <method_4> to highlight the benefits of the new representation .	9 -1 8 9 -1 2 5 1 3 10 11 12 9 -1 6 7 9 -1 0 4 9 -1
Feature extraction methods for consistent spatio-temporal image sequence classification using hidden Markov models .	hidden markov models ; diierent low level image features ; classiica-tion of dynamic hand gestures ; geometry of the image ; probability density values ; image density functions ; image intensities	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 3 0	in this paper a general and eecient approach for representing and classifying image sequences by <method_0> is presented . a consistent modeling of spatial and temporal information is achieved by extracting <otherscientificterm_1> . these implicitly convert the <otherscientificterm_6> into <otherscientificterm_4> , while preserving the <otherscientificterm_3> . the resulting so called <otherscientificterm_5> are contained in the states of the <method_0> . first results of applying the approach to the <otherscientificterm_2> demonstrate the performance of the modeling .	0 7 -1 1 7 -1 6 4 3 7 -1 5 8 7 -1 2 7 -1
Extracting Causes of Emotions from Text .	detection of the linguistic relations ; automatic extraction of phrases ; syntactic and dependency parser ; emotion-cause linguistic relations ; corpus of emotion ; emotion keywords ; rules ; accuracy ; emotion	<task> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	2 1 6	this paper focuses on the novel task of <task_1> related to causes of emotions . the analysis of emotional causes in sentences , where emotions are explicitly indicated through <otherscientificterm_5> can provide the foundation for research on challenging task of recognition of implicit affect from text . we developed a <material_4> causes specific for 22 emotions . based on the analysis of this corpus we introduce a method for the <task_0> between an <otherscientificterm_8> and its cause and the extraction of the phrases describing the <otherscientificterm_8> causes . the method employs <method_2> and <otherscientificterm_6> for the analysis of eight types of the <otherscientificterm_3> . the results of evaluation showed that our method performed with high level of <metric_7> -lrb- 82 % -rrb- .	1 9 -1 5 9 -1 4 9 -1 0 8 9 -1 2 6 10 9 -1 3 9 -1
Geometric min-Hashing : Finding a -LRB- thick -RRB- needle in a haystack .	spatial extent of image features ; recall -lrb- probability of collision ; large scale image clustering problem ; visual appearance -lrb- visual words ; small object discovery ; repeatable hash keys ; geometric min-hashing approach ; semi-local geometric information ; false positive rates ; automatic object discovery ; image retrieval ; hash key ; geometric information ; random collisions ; min-hash ; viewpoint ; images ; clustering ; hashes	<otherscientificterm> <metric> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <metric> <task> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task> <otherscientificterm>	12 0 5 ; 17 1 9 ; 3 3 11 ; 7 0 11 ; 6 0 17 ; 6 0 9 ; 10 1 9 ; 1 5 14 ; 6 0 10 ; 1 5 6 ; 10 1 17	we propose a novel <method_6> for <task_10> , <task_17> and <task_9> . unlike commonly used bag-of-words approaches , the <otherscientificterm_0> is exploited in our <method_6> . the <otherscientificterm_12> is used both to construct <otherscientificterm_5> and to increase the discriminability of the description . each <method_11> combines <otherscientificterm_3> -rrb- with <otherscientificterm_7> . compared with the state-of-the-art <method_14> , the proposed <method_6> has both higher <metric_1> for <otherscientificterm_18> on the same object -rrb- and lower <metric_8> -lrb- <otherscientificterm_13> -rrb- . the advantages of <method_6> are most pronounced in the presence of <otherscientificterm_15> and scale change , significant occlusion or small physical overlap of the viewing fields . we demonstrate the power of the proposed <method_6> on <task_4> in a large unordered collection of <material_16> and on a <task_2> .	6 10 17 9 21 24 25 26 28 30 19 -1 0 19 -1 12 5 20 19 -1 11 3 7 22 23 19 -1 14 1 18 8 13 27 29 19 -1 15 19 -1 19 -1
Exploiting order-preserving perfect hashing to speedup n-gram language model lookahead .	language model lookahead time ; minimum perfect hashing ; op mph and subtree cache structure ; order-preserving property ; string-key based mph function ; lm lookahead time ; lvcsr decoding ; subtree structure ; hashing operation ; order-preserving mph ; switchboard data ; structure design ; lm lookahead ; subtrees ; trigrams	<metric> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <material> <method> <method> <otherscientificterm> <method>	9 0 11 ; 3 0 4 ; 0 0 6 ; 1 0 0 ; 12 1 9 ; 7 0 12 ; 4 0 8	minimum perfect hashing -lrb- <method_1> -rrb- has recently been shown successful in reducing <metric_0> in <task_6> . in this paper we propose to exploit the <method_3> of a <method_4> to further reduce <task_8> and speed up <method_12> . a <otherscientificterm_7> is proposed for <method_12> and an <method_9> is integrated into the <method_11> . <otherscientificterm_13> are generated on demand and stored in caches . experiments were performed on <material_10> . by using the proposed method of <otherscientificterm_2> for both <method_14> and backoff bigrams , the <otherscientificterm_5> was reduced by a factor of 2.9 in comparison with the baseline case of using <method_1> alone .	1 0 6 18 19 15 -1 3 4 8 12 17 22 15 -1 7 9 11 13 16 20 21 15 -1 15 -1 10 15 -1 2 14 5 15 -1
Non-convex Statistical Optimization for Sparse Tensor Graphical Model .	statistical rate of convergence ; penalized maximum likelihood estimation ; high-dimensional tensor-valued data ; alternating minimization algorithm ; tensor normal distribution ; sparse precision matrix ; consistent graph recovery ; non-convex objective function ; sparse graphical models ; kronecker product structure ; dependency structure ; estimation problem ; estimation consistency ; precision matrix ; tensor sample ; numerical studies ; estimator	<metric> <task> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm> <method> <method>	3 0 5 ; 14 5 16 ; 0 2 16 ; 10 2 2 ; 9 2 4 ; 12 5 16	we consider the estimation of <method_8> that characterize the <otherscientificterm_10> of <material_2> . to facilitate the estimation of the <otherscientificterm_13> corresponding to each way of the tensor , we assume the data follow a <method_4> whose covariance has a <otherscientificterm_9> . the <task_1> of this model involves minimizing a <otherscientificterm_7> . in spite of the non-convexity of this <task_11> , we prove that an <method_3> , which iteratively estimates each <otherscientificterm_5> while fixing the others , attains an <method_16> with the optimal <metric_0> as well as <method_6> . notably , such an <method_16> achieves <metric_12> with only one <otherscientificterm_14> , which is unobserved in previous work . our theoretical results are backed by thorough <method_15> .	8 10 2 21 17 -1 13 4 9 22 17 -1 1 7 17 -1 11 3 5 16 0 6 18 20 17 -1 12 14 19 23 17 -1 17 -1
Robust Visual Tracking Based on Incremental Tensor Subspace Learning .	online tensor subspace learning algorithm ; low-order tensor eigenspace representation ; representation of image ensembles ; tensor reconstruction error norm ; subspace analysis-based tracking algorithms ; computational and memory cost ; tensor subspace model ; state inference ; theoretic analysis ; flattened vector ; multilin-ear framework ; likelihood function ; spatio-temporal redundancies ; subspace analysis ; high-order tensors ; particle filter ; tracking	<method> <method> <method> <method> <method> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method>	14 0 10 ; 7 0 16 ; 13 3 10 ; 3 0 11 ; 9 0 4	most existing <method_4> utilize a <otherscientificterm_9> to represent a target , resulting in a high dimensional data learning problem . recently , <method_13> is incorporated into the <method_10> which offline constructs a <method_2> using <otherscientificterm_14> . this reduces <otherscientificterm_12> substantially , whereas the <metric_5> is high . in this paper , we present an effective <method_0> which models the appearance changes of a target by incrementally learning a <method_1> through adaptively updating the sample mean and eigenbasis . <method_16> then is led by the <otherscientificterm_7> within the framework in which a <method_15> is used for propagating sample distributions over the time . a novel <otherscientificterm_11> , based on the <method_3> , is developed to measure the similarity between the test image and the learned <method_6> during the <method_16> . <method_8> and experimental evaluations against a state-of-the-art method demonstrate the promise and effectiveness of this <method_0> .	4 9 22 17 -1 13 10 2 14 18 20 17 -1 12 5 17 -1 0 1 16 17 -1 7 15 19 17 -1 21 17 -1 11 3 6 8 17 -1
Potential relevance of audio-visual integration in mammals for computational modeling .	early word learning ; arbitrary geometrical objects ; audiovisual video sequences ; repetitions of exposure-test-phases ; speech recognition systems ; neural networks ; non-human animals ; audiovisual integration ; robotics	<task> <otherscientificterm> <material> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm>	7 2 6 ; 4 1 5 ; 5 1 8	the purpose of this study was to examine typically developing infants ' integration of audiovisual sensory information as a fundamental process involved in <task_0> . one hundred sixty pre-linguistic children were randomly assigned to watch one of four counterbalanced versions of <material_2> . the infants ' eye-movements were recorded and their looking behavior was analyzed throughout three <otherscientificterm_3> . the results indicate that the infants were able to learn covariance between shapes and colors of <otherscientificterm_1> and to them corresponding nonsense words . implications of <task_7> in infants and in <otherscientificterm_6> for modeling within <method_4> , <method_5> and <otherscientificterm_8> are discussed .	0 9 -1 2 9 -1 3 9 -1 1 9 -1 7 6 4 5 8 10 11 12 9 -1
Online unsupervised pattern discovery in speech using parallelization .	segmental dynamic time warping ; online unsupervised pattern discovery ; static or dynamic way ; offline manner ; speech utterances ; segmental dtw ; 8-processor cluster ; multi-core servers ; computational requirements ; 32-processor system	<method> <task> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 0 1	segmental dynamic time warping -lrb- dtw -rrb- has been demonstrated to be a useful technique for finding acoustic similarity scores between segments of two <material_4> . due to its high <otherscientificterm_8> , it had to be computed in an <otherscientificterm_3> , limiting the applications of the technique . in this paper , we present results of parallelization of this task by distributing the workload in either a <otherscientificterm_2> on an <otherscientificterm_6> and discuss the trade-offs among different distribution schemes . we show that <task_1> using <method_5> is plausible with as low as 8 processors . this brings the task within reach of today 's general purpose <otherscientificterm_7> . we also show results on a <method_9> , and discuss factors affecting scalability of our methods .	4 10 -1 8 3 10 -1 2 6 10 -1 1 5 11 10 -1 10 -1 7 10 -1
Improved Regret Bounds for Oracle-Based Adversarial Contextual Bandits .	o -lrb- t 3 4 -rrb- barrier ; adversarial contextual bandit problem ; relaxation based approach ; offline optimization oracle ; oracle-based algorithm ; baseline policies ; priori ; iterations	<otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 1	we give an <method_4> for the <task_1> , where either contexts are drawn i.i.d. or the sequence of contexts is known a <otherscientificterm_6> , but where the losses are picked adversarially . our <method_4> is computationally efficient , assuming access to an <method_3> , and enjoys a regret of order o -lrb- -lrb- kt -rrb- 2 3 -lrb- log n -rrb- 1 3 -rrb- , where k is the number of actions , t is the number of <otherscientificterm_7> and n is the number of <otherscientificterm_5> . our result is the first to break the <otherscientificterm_0> that is achieved by recently introduced algorithms . breaking this barrier was left as a major open problem . our analysis is based on the recent <method_2> of rakhlin and sridharan -lsb- 7 -rsb- .	4 1 6 9 8 -1 3 7 5 8 -1 0 8 -1 8 -1 8 -1
Robust binary least squares : Relaxations and algorithms .	semideſnite relaxation ; worst-case robust optimization problem ; vector of binary variables ; binary ls problems ; coefſcient matrix h ; lagrangian duality ; uncertainty ellipsoid ; sdr approaches ; problem reformulation ; relaxation step ; np-hard problem ; np-hard	<otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <method>	7 0 3 ; 9 4 7 ; 5 0 9	finding the least squares -lrb- ls -rrb- solution s to a system of linear equations hs = y where h , y are given and s is a <otherscientificterm_2> , is a well known <task_10> . in this paper , we consider <task_3> under the assumption that the <otherscientificterm_4> is also unknown , and lies in a given <otherscientificterm_6> . we show that the corresponding <task_1> , although <method_11> , is still amenable to <otherscientificterm_0> - based approximations . however , the <otherscientificterm_9> is not obvious , and requires a certain <method_8> to be efſcient . the proposed <otherscientificterm_9> is motivated using <method_5> and simulations suggest that <otherscientificterm_9> performs well , offering a robust alternative over the traditional <method_7> for <task_3> .	2 10 12 -1 3 4 6 12 -1 1 11 0 12 -1 9 8 12 -1 13 14 15 12 -1
Cancelling and Overshadowing : Two Types of Defeasibility in Defeasible Deontic Logic .	chisholm and for-rester ` paradoxes ; defeasible deontic logic ; dyadic deontic logics ; factual defeasibility ; conditional obligations ; deontic reasoning ; deontic logic ; subideal behavior ; decision theories ; non-monotonic logics ; overridden defeasi-bility ; defeasibility	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 5	in this paper we give a general analysis of <otherscientificterm_2> that were introduced in the early seventies to formalize <method_5> about <otherscientificterm_7> . recently it was observed that <otherscientificterm_2> are closely related to <otherscientificterm_9> , theories of diagnosis and <method_8> . in particular , we argue that two types of <otherscientificterm_11> must be distinguished in a <otherscientificterm_1> : <otherscientificterm_10> that formalizes cancelling of an obligation by other <otherscientificterm_4> and <otherscientificterm_3> that formalizes overshadowing of an obligation by a violating fact . we also show that this distinction is essential for an adequate analysis of notorious ` paradoxes ' of <otherscientificterm_6> such as the <otherscientificterm_0> ' .	2 5 7 13 12 -1 9 8 12 -1 11 1 10 4 3 12 -1 6 12 -1
Efficiently Creating 3D Training Data for Fine Hand Pose Estimation .	spatial , temporal , and appearance constraints ; hand pose estimation method ; hand pose estimation methods ; at/projects/hand _ detection ; sub-modular loss function ; hand depth video ; semi-automated method ; 3d locations ; reference frames ; labeling ; accuracy	<otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric>	6 0 5 ; 4 0 9	while many recent <method_2> critically rely on a training set of labelled frames , the creation of such a dataset is a challenging task that has been overlooked so far . as a result , existing datasets are limited to a few sequences and individuals , with limited <metric_10> , and this prevents these methods from delivering their full potential . we propose a <method_6> for efficiently and accurately <task_9> each frame of a <otherscientificterm_5> with the corresponding <otherscientificterm_7> of the joints : the user is asked to provide only an estimate of the 2d reprojec-tions of the visible joints in some <otherscientificterm_8> , which are automatically selected to minimize the <task_9> work by efficiently optimizing a <otherscientificterm_4> . we then exploit <otherscientificterm_0> to retrieve the full 3d poses of the hand over the complete sequence . we show that this data can be used to train a recent state-of-the-art <method_1> , leading to increased <metric_10> . the <method_1> and dataset can be found on our website https://cvarlab.icg.tugraz . <task_3> / .	2 11 -1 10 11 -1 6 9 5 7 12 13 11 -1 8 4 11 -1 0 11 -1 1 11 -1 3 11 -1
Learning from Demonstration .	linear quadratic regulator problems ; model-based reinforcement learning ; real signal processing ; nonlinear learning problems ; human instructor ; reinforcement learning ; value function ; prior knowledge ; pole balancing ; initial biases ; learning problem ; policy ; q-function ; demonstrations ; learning ; robustness	<task> <method> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric>	1 0 3 ; 1 0 0	by now it is widely accepted that <task_14> a task from scratch , i.e. , without any <otherscientificterm_7> , is a daunting undertaking . humans , however , rarely attempt to learn from scratch . they extract <otherscientificterm_9> as well as strategies how to approach a <task_10> from instructions and/or <otherscientificterm_13> of other humans . for <task_10> , this paper investigates how <task_14> from demonstration can be applied in the context of <task_5> . we consider priming the <otherscientificterm_12> , the <otherscientificterm_6> , the <otherscientificterm_11> , and the model of the task dynamics as possible areas where <otherscientificterm_13> can speed up <task_14> . in general <task_3> , only <method_1> shows significant speed-up after a demonstration , while in the special case of <task_0> , all methods profit from the demonstration . in an implementation of <task_8> on a complex anthropomorphic robot arm , we demonstrate that , when facing the complexities of <task_2> , <method_1> offers the most <metric_15> for <task_0> . using the suggested methods , the robot learns <task_8> in just a single trial after a 30 second long demonstration of the <method_4> .	14 7 16 -1 16 -1 9 10 13 16 -1 5 16 -1 12 6 11 16 -1 17 16 -1 3 1 0 18 16 -1 8 2 15 16 -1
Why Initialization Matters for IBM Model 1 : Multiple Optima and Non-Strict Convexity .	test set log-likelihood ; linear programming approach ; optimal model parameters ; alignment error rate ; ibm model 1 ; random trials	<metric> <method> <otherscientificterm> <metric> <task> <otherscientificterm>	0 5 4 ; 3 5 4 ; 1 0 2 ; 0 1 3	contrary to popular belief , we show that the optimal parameters for <task_4> are not unique . we demonstrate that , for a large class of words , <task_4> is indifferent among a continuum of ways to allocate probability mass to their translations . we study the magnitude of the variance in <otherscientificterm_2> using a <method_1> as well as multiple <otherscientificterm_5> , and demonstrate that <task_4> results in variance in <metric_0> and <metric_3> .	4 6 -1 6 -1 2 1 5 0 3 7 8 9 10 6 -1
Blind source separation in a distributed microphone meeting environment for improved teleconferencing .	adaptive noise cancellation solution ; simulated and real data ; least-squares post-processing scheme ; convolutive bss ; teleconferencing technology ; audio perspective ; depermutation scheme ; speaker overlap ; sirs	<method> <material> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method>	1 5 2 ; 2 0 8	from an <otherscientificterm_5> , the present state of <method_4> leaves something to be desired ; <otherscientificterm_7> is one of the causes of this inadequate performance . to that end , this paper presents a frequency-domain implementation of <method_3> specifically designed for the nature of the teleconferencing environment . in addition to presenting a novel <method_6> , this paper presents a <method_2> , which exploits segments during which only a subset of all speakers are active . experiments with <material_1> demonstrate the ability of the proposed <method_2> to provide <method_8> at or near that of the <method_0> which is obtained under idealistic assumptions that the <method_0> are adapted with one source being on at a time .	5 4 7 9 -1 3 9 -1 6 2 9 -1 1 8 0 10 11 9 -1
Invited Talk : Processes that Shape Conversation and their Implications for Computational Linguistics .	communication media shape conversations ; cognitive and interpersonal processes ; interactive language use ; interactive processes ; metalinguistic displays ; computational linguistics ; spontaneous speech ; referring expressions ; hedges	<otherscientificterm> <task> <task> <method> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm>	8 6 4	experimental studies of <task_2> have shed light on the <task_1> that shape conversation ; corpora are the emergent products of these processes . i will survey studies that focus on under-modelled aspects of <task_2> , including the processing of <material_6> and disfluencies ; <otherscientificterm_4> such as <otherscientificterm_8> ; <method_3> that affect choices of <otherscientificterm_7> ; and how <otherscientificterm_0> . the findings suggest some agendas for <task_5> .	2 1 9 -1 6 4 8 3 7 0 10 9 -1 5 9 -1
Homeostatic plasticity in Bayesian spiking networks as Expectation Maximization with posterior constraints .	` balancing ' posterior constraint ; recurrent network archi-tectures ; neuronal activation functions ; synaptic plasticity rules ; spiking network models ; neural implementation ; expectation maximization ; synaptic plasticity ; theoretical limitations ; variational inference ; mathematical treatment ; probabilis-tic inference ; spiking networks ; homeostatic dynamics ; homeostatic processes ; nontrivial terms ; probabilistic inference ; cortical microcircuits ; unsupervised learning ; bayesian inference ; homeostatic plasticity ; learning ; inference ; homeostasis	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <method> <task> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <task> <otherscientificterm>	2 1 3 ; 23 0 22 ; 19 1 18 ; 14 1 7 ; 7 2 17 ; 14 2 17 ; 22 1 21	recent <method_4> of <task_19> and <method_18> frequently assume either inputs to arrive in a special format or employ complex computations in <otherscientificterm_2> and <otherscientificterm_3> . here we show in a rigorous <method_10> how <method_14> , which have previously received little attention in this context , can overcome common <otherscientificterm_8> and facilitate the <task_5> and performance of existing models . in particular , we show that <otherscientificterm_20> can be understood as the enforcement of a <otherscientificterm_0> during <task_11> and <task_21> with <method_6> . we link <otherscientificterm_13> to the theory of <task_9> , and show that <otherscientificterm_15> , which typically appear during <otherscientificterm_16> in a large class of models , drop out . we demonstrate the feasibility of our approach in a spiking winner-take-all architecture of <task_19> and <task_21> . finally , we sketch how the <method_10> can be extended to richer <method_1> . altogether , our theory provides a novel perspective on the interplay of <method_14> and <otherscientificterm_7> in <otherscientificterm_17> , and points to an essential role of <otherscientificterm_23> during <task_22> and <task_21> in <task_12> .	4 19 18 2 3 25 27 24 -1 10 14 8 5 24 -1 20 0 11 21 6 24 -1 13 9 15 24 -1 16 24 -1 24 -1 1 26 28 29 30 31 24 -1
The effect of language factors for robust speaker recognition .	joint factor analysis model ; nist speaker recognition evaluation ; eigenchannels session variability compensation ; speaker recognition systems ; language gap problem ; language factor compensation ; english training data ; english trails ; language factors ; eer	<method> <task> <method> <method> <task> <method> <material> <material> <otherscientificterm> <metric>	6 0 3	from the results of the <task_1> in resent years , <method_3> which are mainly developed based on <material_6> suffer the <task_4> , namely , the performance of non-english trails is much worse than that of <material_7> . this problem is addressed in this paper . based on the conventional <method_0> , we enrolled in the <otherscientificterm_8> which are mean to capture the language character of each testing and training speech utterance , and compensation was carried out by removing the <otherscientificterm_8> in order to shrink the difference between languages . experiments on 2006 nist sre data show that , the <method_5> alone can reduce the gap between the performance of english and non-english trails , and the score level combination with eigenchannels can further improve the performance of non-english trails , e.g. , for female part , we observed about 19 % relatively reduction in <metric_9> , when compared with <method_2> alone .	1 3 6 4 7 11 10 -1 10 -1 0 8 10 -1 10 -1
An Eye Fixation Database for Saliency Detection in Images .	semantics-driven human understanding of images ; active image segmentation application ; saliency computation algorithms ; characteristic fixation seeds ; eye fixation database ; visual attention ; salient object ; fixation clusters ; image content ; salient objects ; image understanding ; semantic categories ; feature-driven approaches ; fixation seeds ; fixation patterns ; eye fixations ; eye-tracker ; segmentation	<task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	16 0 14 ; 4 0 1 ; 7 0 10 ; 6 0 13 ; 2 0 12 ; 15 0 0 ; 3 0 17 ; 16 0 4	to learn the preferential <otherscientificterm_5> given by humans to specific <material_8> , we present an <method_4> compiled from a pool of 758 images and 75 subjects . <otherscientificterm_15> are an excellent modality to learn <task_0> , which is vastly different from <method_12> employed by <method_2> . the <method_4> comprises <otherscientificterm_14> acquired using an <method_16> , as subjects free-viewed images corresponding to many <otherscientificterm_11> such as faces -lrb- human and mammal -rrb- , nudes and actions -lrb- look , read and shoot -rrb- . the consistent presence of <otherscientificterm_7> around specific image regions confirms that <otherscientificterm_5> is not subjective , but is directed towards <otherscientificterm_9> and object-interactions . we then show how the <otherscientificterm_7> can be exploited for enhancing <task_10> , by using our <method_4> in an <task_1> . apart from proposing a mechanism to automatically determine <otherscientificterm_3> for <task_17> , we show that the use of <otherscientificterm_13> generated from multiple <otherscientificterm_7> on the <otherscientificterm_6> can lead to a 10 % improvement in segmen-tation performance over the state-of-the-art .	5 8 4 15 18 -1 0 12 2 23 24 18 -1 14 16 11 19 26 18 -1 7 18 -1 9 20 21 18 -1 10 1 22 25 18 -1
System-driven metrics for the design and adaptation of analog to digital converters .	forward error correction ; intersymbol interference links ; adc design methods ; fixed uniform quantization ; application meaningful criteria ; system-driven metrics ; communication link ; mutual information ; bit-error rate ; information rate ; communication ; adcs	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric> <task> <method>	7 6 5 ; 5 0 11 ; 3 0 2 ; 11 0 11 ; 11 0 4 ; 8 6 5 ; 8 0 10	-- in this paper , we review some recent advances in the design of <method_11> that exploit <otherscientificterm_5> , such as the <metric_8> in a <otherscientificterm_6> , or <otherscientificterm_7> in a scheme employing <otherscientificterm_0> . we show , for example , that <method_11> can be designed that maximize the <metric_9> between the quantized output of the channel and the input to the channel for <task_10> links with intersymbol-interference and additive noise . these <method_11> dramatically outper-form -lrb- in terms of achievable information rates -rrb- traditional <method_2> that are based on <otherscientificterm_3> . architectures are also developed for <method_11> such that <method_11> can be used to dynamically adapt the structure of the <method_11> to optimize <metric_4> , such as <metric_8> for <task_10> over <otherscientificterm_1> .	11 5 8 6 7 0 13 14 18 12 -1 9 10 12 -1 2 3 15 12 -1 16 17 19 12 -1
Symmetrical Dense Optical Flow Estimation with Occlusions Detection .	dense optical flow field map ; synthetic and real images ; dense optical flow estimation ; euler -- lagrange equations ; multi-resolution technique ; images i1 ; displacements vectors ; symmetrical solutions ; images i2 ; flow field ; energy functional ; optical flow ; gradient flow ; focusing strategy ; variational problem ; i2 ; images ; i1	<otherscientificterm> <material> <task> <otherscientificterm> <method> <material> <method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <task> <otherscientificterm> <material> <otherscientificterm>	3 0 12 ; 17 1 15 ; 17 0 6 ; 4 0 13 ; 5 1 17 ; 8 1 17 ; 15 1 15 ; 8 1 15 ; 5 1 15 ; 15 1 17 ; 12 0 14	traditional techniques of <task_2> do n't generally yield <method_7> : the results will differ if <method_7> are applied between <material_5> and <otherscientificterm_15> or between <material_8> and <otherscientificterm_17> . in this work , we present a method to recover a <otherscientificterm_0> from two <material_16> , while explicitely taking into account the symmetry across the <material_16> as well as possible occlusions and discontinuities in the <otherscientificterm_9> . the idea is to consider both <method_6> from <otherscientificterm_17> to <otherscientificterm_15> and <otherscientificterm_15> to <otherscientificterm_17> and to minimise an <otherscientificterm_10> that explicitely encodes all those properties . this <task_14> is then solved using the <otherscientificterm_12> defined by the <otherscientificterm_3> associated to the energy . in order to reduce the risk to be trapped within some irrelevant minimum , a <method_13> based on a <method_4> is used to converge toward the solution . promising experimental results on both <material_1> are presented to illustrate the capabilities of this symmetrical variational approach to recover accurate <material_11> .	2 7 5 15 8 17 23 24 26 27 28 18 -1 0 16 9 18 -1 6 10 20 21 25 18 -1 14 12 19 29 18 -1 3 22 18 -1 13 4 18 -1
On Linear Structure from Motion for Light Field Cameras .	relative pose of the light field cameras ; point cloud reconstruction of the scene ; hand-held consumer light field cameras ; 4d light field cameras ; direct linear pose estimation ; light field cameras ; 3d point clouds ; plücker ray coordinates ; light field structure ; light field projection ; ray space correspondences ; relative pose estimation ; generalized cameras ; refocus-able panoramas ; light fields ; linear constraints ; pose estimates ; scene geometry ; ray-to-ray correspondence	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material>	2 3 13 ; 16 0 14 ; 15 2 10 ; 11 0 3	we present a novel approach to <task_11> which is tailored to <otherscientificterm_3> . from the relationships between <otherscientificterm_17> and <otherscientificterm_8> and an analysis of the <otherscientificterm_9> in terms of <otherscientificterm_7> , we deduce a set of <otherscientificterm_15> on <otherscientificterm_10> between a pair of <otherscientificterm_5> . these can be applied to infer <otherscientificterm_0> and thus obtain a <task_1> . while the proposed method has interesting relationships to pose estimation for <task_12> based on <material_18> , our experiments demonstrate that our approach is both more accurate and computationally more efficient . it also compares favorably to <task_4> based on aligning the <otherscientificterm_6> obtained by reconstructing depth for each individual light field . to further validate the method , we employ the <method_16> to merge <otherscientificterm_14> captured with <otherscientificterm_2> into <otherscientificterm_13> .	11 3 23 19 -1 17 8 9 7 15 10 5 22 19 -1 0 1 19 -1 12 18 19 -1 4 6 19 -1 20 21 19 -1
On the relationship between the Karhunen-Loeve transform and the prolate spheroidal wave functions .	discrete prolate spheroidal wave functions ; discrete karhunen-loeve transform ; discrete prolate spheroidal wave functions ; medium order solution ; signal spectrum ; approximate solutions ; frequency domain ; principal eigenfunc-tion ; center frequency ; approximation	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm>	6 2 1 ; 1 1 0	we find a close relationship between the <otherscientificterm_1> and the <method_0> . we show that the <method_0> form a natural basis for an expansion of the eigenfunctions of the <otherscientificterm_1> in the <material_6> , and then determine more general conditions that any set of functions must obey to be a valid basis . we also present <method_5> for small , medium , and large filter orders . the <method_3> suggests that the <method_7> is , to a high degree of <otherscientificterm_9> , the principal <method_0> modulated so that its <otherscientificterm_8> coincides with the peak of maximum energy in the <otherscientificterm_4> . we then use this result to propose a new basis .	1 0 12 10 -1 6 11 10 -1 5 10 -1 3 7 9 8 4 10 -1 10 -1
A Growing Neural Gas Network Learns Topologies .	`` neural gas '' method ; hebb-like learning rule ; incremental network model ; vector quantization ; performance criterion ; topological relations ; clustering ; interpolation	<method> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <method> <method>	6 3 0 ; 3 3 0 ; 3 1 6 ; 6 1 7 ; 2 0 5	an <method_2> is introduced which is able to learn the important <otherscientificterm_5> in a given set of input vectors by means of a simple <otherscientificterm_1> . in contrast to previous approaches like the <method_0> of martinetz and schulten -lrb- 1991 , 1994 -rrb- , this <method_0> has no parameters which change over time and is able to continue learning , adding units and connections , until a <metric_4> has been met . applications of the <method_0> include <method_3> , <method_6> , and <method_7> .	2 5 1 13 8 -1 0 4 8 -1 3 6 7 9 10 11 12 8 -1
Factorial Markov Random Fields .	markov random field model ; hidden markov models -lrb- hmm 's -rrb- ; factorial mrf ; real and synthetic images ; wide inference step ; factorial mrf 's ; factorial hmm 's ; graph cuts ; em-based algorithm ; wide inference ; binary segmentation ; deep inference ; observable image ; layers ; inference	<method> <method> <method> <material> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <task>	0 0 13 ; 8 0 14 ; 7 0 10	in this paper we propose an extension to the standard <method_0> in order to handle <otherscientificterm_13> . our extension , which we call a <method_2> , is analogous to the extension from <method_1> to <method_6> . we present an efficient <method_8> for <task_14> on <material_5> . our <method_8> makes use of the fact that <otherscientificterm_13> are a priori independent , and that <otherscientificterm_13> only interact through the <material_12> . the <method_8> iterates between <otherscientificterm_9> , i.e. , <task_14> within each layer for the entire set of pixels , and <otherscientificterm_11> , i.e. , <task_14> through the <otherscientificterm_13> for each single pixel . the efficiency of our <method_8> is partly due to the use of <method_7> for <task_10> , which is part of the <otherscientificterm_4> . we show experimental results for both <material_3> .	0 13 16 15 -1 2 1 6 15 -1 8 14 5 17 15 -1 12 15 -1 9 11 15 -1 18 15 -1 7 10 4 15 -1
Real-Time Shape Analysis of a Human Body in Clothing Using Time-Series Part-Labeled Volumes .	3d reconstruction algorithm ; time-series sample volumes ; input visual hull ; hierarchical search ; real-time method ; time-series volumes ; body-part labels ; loose-fitting clothing ; eigenspace ; pca	<method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	7 0 4 ; 9 0 1	we propose a <method_4> for simultaneously refining the reconstructed volume of a human body with <otherscientificterm_7> and identifying body-parts in it . <otherscientificterm_5> , which are acquired by a slow but sophisticated <method_0> , with <otherscientificterm_6> are obtained offline . the <otherscientificterm_1> are represented by trajectories in the eigenspaces using <method_9> . an <otherscientificterm_2> reconstructed online is projected into the <otherscientificterm_8> and compared with the trajectories in order to find similar high-precision samples with <otherscientificterm_6> . the <method_3> taking into account 3d reconstruction errors can achieve robust and fast matching . experimental results demonstrate that our <method_4> can refine the <otherscientificterm_2> including <otherscientificterm_7> and identify its body-parts in real time .	4 7 5 11 10 -1 0 6 10 -1 1 9 12 10 -1 2 8 10 -1 3 10 -1 10 -1
Deep neural networks for single channel source separation .	single channel source separation ; deep neural network architecture ; nonnegative matrix factorization ; single channel source separation problem ; mixed signal spectrum ; classifying time-frequency bins ; energy scale differences ; energy minimization problem ; estimated source spectra ; training stage ; separation stage ; source separation ; training data ; classifiers	<task> <method> <method> <task> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <task> <material> <method>	13 0 5 ; 12 0 1 ; 1 1 13 ; 1 0 11 ; 7 0 3 ; 2 0 1	in this paper , a novel approach for <task_0> using a <method_1> is introduced . unlike previous studies in which <method_1> and other <method_13> were used for <task_5> to obtain hard masks for each source , we use the <method_1> to classify <otherscientificterm_8> to check for their validity during separation . in the <task_9> , the <material_12> for the source signals are used to train a <method_1> . in the <otherscientificterm_10> , the trained <method_1> is utilized to aid in estimation of each source in the mixed signal . <task_3> is formulated as an <task_7> where each source spectra estimate is encouraged to fit the trained <method_1> and the <otherscientificterm_4> is encouraged to be written as a weighted sum of the <otherscientificterm_8> . the proposed approach works regardless of the <otherscientificterm_6> between the source signals in the training and separation stages . <method_2> is used to initialize the <method_1> for each source . the experimental results show that using <method_1> initialized by <method_1> for <task_11> improves the quality of the separated signal compared with using <method_1> for <task_11> .	0 1 14 -1 13 5 8 15 17 14 -1 9 12 16 14 -1 10 3 14 -1 7 19 14 -1 4 14 -1 6 2 20 14 -1 18 14 -1
Spectral efficiency of CDMA uplink cellular networks .	wireless flat fading channels ; uplink cdma system ; base station coverage ; receiver structures ; optimum filter ; random spreading ; network capacity ; multi-cell interference ; matched filter ; asymptotic arguments ; wiener filter ; spectral efficiency	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <metric>	8 1 10 ; 8 6 3 ; 2 0 0 ; 10 6 3 ; 4 6 3 ; 10 1 4	in this contribution , the performance of an <method_1> with <otherscientificterm_5> and <otherscientificterm_7> is analyzed . a useful framework is provided in order to determine the <otherscientificterm_2> for <otherscientificterm_0> with very dense networks -lrb- in the number of users per meter -rrb- considering different <otherscientificterm_3> at the base station , namely the <method_8> , the <method_10> and the <method_4> . using <otherscientificterm_9> , analytical expressions of the <metric_11> are obtained and provide a simple expression of the <otherscientificterm_6> based only on a few meaningful parameters .	1 5 7 12 -1 2 0 3 8 10 4 13 14 15 16 17 18 12 -1 9 11 6 12 -1
Local learning projections .	<i> principal component analysis </i> ; minimal <i> global </i> estimation error ; minimal <i> local </i> estimation error ; linear dimensionality reduction ; dimensionality reduction algorithm ; projection values ; classification tasks ; local information ; projection value ; projection	<method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task>	4 0 9	this paper presents a <i> local learning projection </i> -lrb- llp -rrb- approach for <task_3> . we first point out that the well known <method_0> essentially seeks the <task_9> that has the <otherscientificterm_1> . then we propose a <method_4> that leads to the <task_9> with the <otherscientificterm_2> , and elucidate its advantages for <task_6> . we also indicate that llp keeps the <otherscientificterm_7> in the sense that the <otherscientificterm_8> of each point can be well estimated based on its neighbors and their <otherscientificterm_5> . experimental results are provided to validate the effectiveness of the proposed <method_4> .	3 10 -1 0 9 1 10 -1 4 2 6 11 10 -1 7 8 5 10 -1 10 -1
Adaptive channel equalization using context trees .	gradient based adaptation ; inter-symbol interference channel ; crudely quantized training sequence ; maximum likelihood sequence estimator ; variable order markov model ; linear isi channel ; additive white noise ; decoding binary symbols ; decision feedback equalization ; gaussian based algorithms ; heavy-tailed noise ; receiver performance ; receiver	<method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <metric> <method>	8 6 9 ; 6 2 5 ; 12 0 1 ; 0 6 9 ; 3 0 1 ; 2 0 4 ; 5 0 7 ; 8 1 0 ; 4 0 12	the <method_3> is the optimal <method_12> for the <method_1> with <otherscientificterm_6> . a <method_12> is demonstrated that estimates sequence likelihood using a <method_4> constructed from a <material_2> . <metric_11> is relatively unaffected by <otherscientificterm_10> that can undermine the performance of <method_9> such as <method_8> with <method_0> . we consider the problem of <task_7> across a <otherscientificterm_5> contaminated with <otherscientificterm_6> . given discrete-time observations of the channel output r n	3 12 1 6 16 18 13 -1 4 2 11 19 22 13 -1 10 9 8 0 14 17 21 13 -1 7 5 15 20 13 -1 13 -1
Outcomes of the Equivalence of Adaptive Ridge with Least Absolute Shrinkage .	series ofpossi-ble extensions oflasso ; fixed point algorithm ; neural net training ; quadratic penalization ; model complexity ; ridge regression ; kernel smoothing ; quadratic penalizer ; sparse regression ; additive modeling ; adaptive ridge ; lasso solution ; lasso ; hyper-parameter	<method> <method> <task> <method> <metric> <method> <task> <method> <otherscientificterm> <task> <method> <method> <method> <method>	6 2 8 ; 7 2 12 ; 13 0 4 ; 1 0 11 ; 6 1 9 ; 10 6 5 ; 9 1 2	adaptive ridge is a special form of <method_5> , balancing the <method_3> on each parameter of the model . it was shown to be equivalent to <method_12> -lrb- least absolute shrinkage and selection operator -rrb- , in the sense that both procedures produce the same estimate . <method_12> can thus be viewed as a particular <method_7> . from this observation , we derive a <method_1> to compute the <method_11> . the analogy provides also a new <method_13> for tuning effectively the <metric_4> . we finally present a <method_0> performing <otherscientificterm_8> in <task_6> , <task_9> and <task_2> .	5 3 20 14 -1 12 14 -1 7 16 14 -1 1 11 18 14 -1 13 4 17 14 -1 0 8 6 9 2 10 15 19 21 14 -1
Natural Language Processing for Less Privileged Languages : Where do we come from ? Where are we going ? .	natural language processing ; less privileged languages	<task> <material>	0 0 1	in the context of the ijcnlp workshop on <task_0> for <material_1> , we discuss the obstacles to research on such languages . we also briefly discuss the ways to make progress in removing these obstacles . we mention some previous work and comment on the papers selected for the workshop .	0 1 3 2 -1 2 -1 2 -1
Behaviosites : Manipulation of Multiagent System Behavior through Parasitic Infection .	distributed swarm control mechanism ; behavior manipulation properties ; distributed control ; distributed system ; biological parasites ; behavioral changes ; social norms ; sensory activity ; behaviosite paradigm ; code modules ; multiagent system ; infection rate ; distributed agents ; swarm ; herders	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <metric> <method> <otherscientificterm> <method>	1 0 4 ; 14 1 6	in this paper we present the <method_8> , a new approach to coordination and control of <method_12> in a <method_10> , inspired by <otherscientificterm_4> with <otherscientificterm_1> . <method_8> are <method_9> that '' infect '' a <method_10> , attaching themselves to agents and altering the <otherscientificterm_7> and actions of those agents . these <otherscientificterm_5> can be used to achieve altered , potentially improved , performance of the overall <method_10> ; thus , <method_8> provide a mechanism for <otherscientificterm_2> over a <method_3> . <method_8> need to be designed so that <method_8> are intimately familiar with the internal workings of the environment and of the agents operating within it . to demonstrate our approach , we use behaviosites to control the behavior of a <otherscientificterm_13> of simple agents . with a relatively low <metric_11> , a few behaviosites can engender desired behavior over the <otherscientificterm_13> as a whole : keeping it in one place , leading it through checkpoints , or moving the <otherscientificterm_13> from one stable equilibrium to another . we contrast behaviosites as a <method_0> with alternatives , such as the use of group leaders , <method_14> , or <otherscientificterm_6> .	8 12 10 4 1 16 15 -1 9 7 15 -1 5 2 3 15 -1 15 -1 15 -1 13 15 -1 11 17 15 -1
Generalization Analysis for Game-Theoretic Machine Learning .	parametric and non-parametric behavior learning methods ; non-asymptotic error bounds ; behavior learning error ; markov behavior model ; generalization analysis techniques ; sponsored search ; machine learning ; behavior data ; generalization analysis ; self-interested agents ; uniform convergence ; mechanism space ; generalization error ; internet applications ; data distribution	<method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	5 6 13 ; 1 0 2 ; 6 0 13 ; 10 0 2 ; 12 0 2 ; 4 0 10	for <task_13> like <task_5> , cautions need to be taken when using <method_6> to optimize their mechanisms -lrb- e.g. , auction -rrb- since <otherscientificterm_9> in these applications may change their behaviors -lrb- and thus the <otherscientificterm_14> -rrb- in response to the mechanisms . to tackle this problem , a framework called game-theoretic <method_6> -lrb- gtml -rrb- was recently proposed , which first learns a <method_3> to characterize agents behaviors , and then learns the optimal <method_3> by simulating agents ' behavior changes in response to the <method_3> . while gtml has demonstrated practical success , its <method_8> is challenging because the <material_7> are non-i.i.d. and dependent on the <method_3> . to address this challenge , first , we decompose the <otherscientificterm_12> for gtml into the <otherscientificterm_2> and the <otherscientificterm_2> ; second , for the <otherscientificterm_2> , we obtain novel <otherscientificterm_1> for both <method_0> ; third , for the <otherscientificterm_2> , we derive a <otherscientificterm_10> bound based on a new concept called nested covering number of the <otherscientificterm_11> and the <method_4> developed for mixing sequences .	13 5 6 9 14 16 18 15 -1 3 15 -1 8 15 -1 7 17 19 20 21 15 -1
Characterizing physical-layer secrecy with unknown eavesdropper locations and channels .	poisson point process ; physical layer secrecy ; rayleigh fading ; probabilistic framework ; path loss ; secure communications ; beamforming	<method> <task> <otherscientificterm> <method> <otherscientificterm> <task> <method>	4 1 2 ; 3 0 1	-- we present a <method_3> for <task_1> when the locations and channels of the eavesdrop-pers are unknown . the locations are modeled by a <method_0> . the channels include <otherscientificterm_4> and <otherscientificterm_2> . <method_6> and frequency-selectivity of the fading channels are shown to greatly increase the probability of <task_5> .	3 1 9 7 -1 0 7 -1 4 2 6 8 7 -1 5 7 -1
Directly modeling voiced and unvoiced components in speech waveforms by neural networks .	stochastic components ; mean and covariance functions ; non-zero mean gaussian process ; statistical parametric speech synthesis ; natural speech waveforms ; probability density function ; neural networks ; unvoiced component ; speech waveforms ; gaussian process ; linguistic features ; acoustic model ; speech waveform	<method> <otherscientificterm> <method> <task> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	11 0 3 ; 0 3 12 ; 10 0 5 ; 6 0 3 ; 10 0 12 ; 6 0 2 ; 5 2 12 ; 6 0 11	this paper proposes a novel <method_11> based on <method_6> for <task_3> . the <method_6> outputs parameters of a <method_2> , which defines a <otherscientificterm_5> of a <otherscientificterm_12> given <otherscientificterm_10> . the <otherscientificterm_1> of the <method_9> represent deterministic -lrb- voiced -rrb- and <method_0> of a <otherscientificterm_12> , whereas the previous approach considered the <method_7> only . experimental results show that the proposed approach can generate <otherscientificterm_8> approximating <material_4> .	11 6 3 14 17 21 13 -1 2 5 12 10 16 18 19 20 13 -1 1 9 0 7 15 13 -1 8 4 13 -1
An Agent-Based Model Studying the Acquisition of a Language System of Logical Constructions .	logical combinations of categories ; logical constructions ; language system ; agent-based model ; boolean functions ; grammatical constructions ; adoption ; induction ; adaptation ; invention	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <task> <task>	9 1 7 ; 9 1 6 ; 7 1 8 ; 6 1 7 ; 6 1 8	this paper presents an <method_3> that studies the emergence and evolution of a <method_2> of <otherscientificterm_1> , i.e. a vocabulary and a set of <otherscientificterm_5> that allows the expression of <otherscientificterm_0> . the <method_3> assumes the agents have a common vocabulary for basic categories , the ability to construct <otherscientificterm_0> using <otherscientificterm_4> , and some general purpose cognitive capacities for <task_9> , <task_6> , <task_7> and <task_8> . but it does not assume the agents have a vocabulary for <otherscientificterm_4> nor <otherscientificterm_5> for expressing such <otherscientificterm_0> through language . the results of the experiments we have performed show that a <method_2> of <otherscientificterm_1> emerges as a result of a process of self-organisation of the individual agents ' interactions when these agents adapt their preferences for vocabulary and <otherscientificterm_5> to those they observe are used more often by the rest of the population , and that such a <method_2> is transmitted from one generation to the next .	3 2 1 5 0 10 -1 4 9 6 7 8 11 12 13 14 15 10 -1 10 -1 10 -1
Hyperplane margin classifiers on the multinomial manifold .	margin-based hyperplane models ; generalized margin concept ; hyperplane classifiers ; multinomial manifold ; classification framework ; multinomial family ; linear classifiers ; categorical data ; multinomial geometry ; multinomial models ; fisher information ; text classification ; categorical structure ; riemannian structure	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	1 0 2 ; 6 0 7 ; 10 0 13 ; 4 0 11 ; 0 0 8 ; 3 0 6	the assumptions behind <method_6> for <material_7> are examined and reformulated in the context of the <otherscientificterm_3> , the simplex of <method_9> furnished with the <otherscientificterm_13> induced by the <otherscientificterm_10> . this leads to a new view of <method_2> which , together with a <method_1> , shows how to adapt existing <method_0> to <otherscientificterm_8> . experiments show the new <method_4> to be effective for <task_11> , where the <otherscientificterm_12> of the data is modeled naturally within the <otherscientificterm_5> .	6 7 3 9 13 10 16 17 20 14 -1 2 1 0 8 15 19 14 -1 4 11 12 5 18 14 -1
Trellis-based parallel stereo matching .	discrete representation of stereo correspondence ; sparsely connected trellis ; d p methods ; natural constraints ; occlu-sion nodes ; parallel solution ; center-referenced basis ; map context ; disparity estirna-tion ; computational complexity	<task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <metric>	9 4 2 ; 6 0 0	we present a <method_6> for <task_0> that includes new <otherscientificterm_4> . this basis improves the inclusion of constraints and the parallelism of the final algorithm . <method_8> is formulated in a <otherscientificterm_7> and <otherscientificterm_3> are incorporated , resulting in an optimal path problem in a <otherscientificterm_1> . like other <method_2> , the <metric_9> is low at -lrb- 3 -lrb- m n 2 -rrb- for m x n pixel images . however , this method is better suited to <method_5> , scaling up to -lrb- 3 -lrb- m n -rrb- processors . experimental results confirm the performance of this method .	6 0 4 12 10 -1 8 10 -1 7 3 1 10 -1 2 9 11 10 -1 5 10 -1 10 -1
A Bayesian approach to spectrum sensing , denoising and anomaly detection .	soft decision detector ; spectrum sensing ; cognitive radio ; bayesian approach ; signal denoising ; anomaly detection ; ieee ; complexity ; noise ; abstract	<method> <task> <material> <method> <task> <task> <material> <metric> <otherscientificterm> <method>	1 0 2 ; 0 0 4 ; 5 1 1 ; 4 1 5 ; 5 1 2 ; 0 0 1	sion to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the <material_6> . '' <method_9> this paper deals with the problem of discriminating samples that contain only <otherscientificterm_8> from samples that contain a signal embedded in <otherscientificterm_8> . the focus is on the case when the variance of the <otherscientificterm_8> is unknown . we derive the optimal <method_0> using a <method_3> . the <metric_7> of this optimal <method_0> grows exponentially with the number of observations and as a remedy , we propose a number of approximations to <method_0> . the problem under study is a fundamental one and <method_0> has applications in <task_4> , <task_5> , and <task_1> for <material_2> . we illustrate the results in the context of the latter .	6 10 -1 9 8 10 -1 10 -1 0 3 10 -1 7 10 -1 11 12 13 14 15 16 10 -1 4 5 1 2 10 -1
Competition-based score analysis for utterance verification in name recognition .	sequence of sorted likelihood ratios ; sorted likelihood ratios ; competition-based measurement framework ; n-best hmm scores ; n-best uv approach ; utterance verification ; selective components ; asr system ; hypothesis testing ; measurement score	<method> <task> <method> <metric> <method> <task> <method> <task> <method> <metric>	6 3 1 ; 3 0 5 ; 2 0 4 ; 1 0 0 ; 9 0 5 ; 5 0 7 ; 6 0 0	utterance <task_5> based on <metric_3> has been widely used in <task_7> . there are a number of ways to calculate a <metric_9> for <task_5> from n-best scores . most of proposed methods are based on the <method_4> of the <method_8> . this has lead to use the second best score or an overall average of available n-best scores for normalisation . in this study we examine <method_4> from a <method_2> . with this <method_4> different competitive measurements can be derived from a <method_0> . the evaluation results demonstrate that oov performance can be improved by using some <method_6> in <task_1> . in our experiments by using the first four components oov rejection errors can be reduced about 30 % in comparison with the baseline results .	5 3 7 12 16 10 -1 9 15 10 -1 4 8 10 -1 10 -1 2 13 10 -1 0 10 -1 6 1 11 14 17 10 -1 10 -1
Bird-phrase segmentation and verification : A noise-robust template-based approach .	energy or entropy-based birdsong segmentation algorithms ; noise-robust , dynamic-time-warping ; support vector machine ; birdsong-phrase segmentation and verification algorithm ; cassin 's vireo recordings ; limited training data ; segmenting continuous recordings ; outlier rejection ; additive noise ; discriminative classifier ; noise-robust template ; manual annotations ; spectrogram amplitudes ; segment boundaries ; class variability ; features ; noise	<method> <method> <method> <method> <material> <material> <task> <task> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 7 ; 3 0 10 ; 3 4 0 ; 4 5 3 ; 14 1 16 ; 1 3 3 ; 5 1 14 ; 1 1 9 ; 3 0 6	in this paper , we present a <method_3> that is robust to <material_5> , <otherscientificterm_14> , and <otherscientificterm_16> . the <method_3> comprises a <method_1> - based segmentation and a <method_9> for <task_7> . the <method_3> utilizes <method_1> and prominent -lrb- high energy -rrb- time-frequency regions of training spectrograms to derive a reliable <otherscientificterm_10> for each phrase class . the resulting <method_3> is then used for <task_6> to obtain segment candidates whose <otherscientificterm_12> in the prominent regions are used as <otherscientificterm_15> to a <method_2> . the <method_3> is evaluated on the <material_4> ; our proposed <method_3> yields low equal error rates -lrb- eer -rrb- and <otherscientificterm_13> that are close to those obtained from <material_11> and , is better than <method_0> . in the presence of <otherscientificterm_8> -lrb- -10 to 10 db snr -rrb- , the proposed <method_3> does not degrade as significantly as the other algorithms do .	3 5 14 16 22 24 17 -1 1 9 7 18 23 25 17 -1 10 19 17 -1 6 12 15 2 26 17 -1 4 20 21 17 -1 13 11 0 17 -1
Recovering planar homographies between 2D shapes .	matching of traffic signs ; hip prosthesis x-ray images ; linearly independent functions ; nonlinear equations ; planar object ; computer vision ; real images ; planar homography ; established correspondences ; segmentation errors ; binary images ; deformation ; homography ; images	<task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <material>	13 3 5 ; 10 2 12 ; 2 0 3	images taken from different views of a <otherscientificterm_4> are related by <method_7> . recovering the parameters of such <material_13> is a fundamental problem in <task_5> with various applications . this paper proposes a novel method to estimate the parameters of a <method_12> that aligns two <material_10> . it is obtained by solving a system of <otherscientificterm_3> generated by integrating <otherscientificterm_2> over the domains determined by the shapes . the advantage of the proposed solution is that it is easy to implement , less sensitive to the strength of the <otherscientificterm_11> , works without <otherscientificterm_8> and robust against <otherscientificterm_9> . the method has been tested on synthetic as well as on <material_6> and its efficiency has been demonstrated in the context of two different applications : alignment of <material_1> and <task_0> .	4 7 14 -1 13 5 15 14 -1 12 10 16 14 -1 3 2 17 14 -1 11 8 9 14 -1 14 -1
A subspace decomposition method for point source localization in blurred images .	redving blurred point sources ; 2-d generalization uf techniques ; 2-d frequency domain ; blurred point sources ; signal space ; image restoration ; array smoothing ; rank enhanrmient ; intensity images ; covariance mutrir ; regularization operator ; music	<task> <method> <material> <material> <otherscientificterm> <task> <method> <otherscientificterm> <material> <method> <method> <method>	8 2 0 ; 7 3 9 ; 10 0 6	in this paper we address the problem of <task_0> in <material_8> . a new approach to <task_5> is introduced which is a <method_1> originating from the field of direction of arrival estimation -lrb- doa -rrb- . i n the <material_2> . algorithms , such as <method_11> . may be adapted to search for these <material_3> . a generalization of <method_6> bused on a <method_10> is introduced for 2-11 arrays in order to achieve <otherscientificterm_7> in the <otherscientificterm_4> of the <method_9> .	0 8 13 12 -1 5 1 12 -1 2 12 -1 11 12 -1 3 12 -1 6 10 7 4 9 14 15 12 -1
Query Answering in the Horn Fragments of the Description Logics SHOIQ and SROIQ .	non-trivial generalization of plain conjunctive queries ; expressive description logics ; decidability of plain conjunctive queries ; data complexity ; dls shoiq ; horn fragments ; owl standard ; full shoiq ; query answering ; computational complexity ; 2exptime-complete ; sroiq ; complexity ; nominals	<otherscientificterm> <method> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <material> <task> <metric> <material> <method> <metric> <otherscientificterm>	11 1 10 ; 4 1 11 ; 9 5 1 ; 7 1 11 ; 1 0 8 ; 10 5 11 ; 11 1 11	the high <metric_9> of the <method_1> that underlie the <otherscientificterm_6> has motivated the study of their <method_5> , which are usually tractable in <metric_3> and can also have lower combined <metric_12> , particularly for <task_8> . in this paper we provide algorithms for answering conjunc-tive 2-way regular path queries -lrb- 2crpqs -rrb- , a <otherscientificterm_0> , in the <method_5> of the <method_4> and <method_11> underlying owl 1 and owl 2 . we show that the combined <metric_12> of the problem is ex-ptime-complete for <method_11> and <material_10> for the more expressive <method_11> , but is ptime-complete in <metric_3> for both . in contrast , even <otherscientificterm_2> is still open for <material_7> and <method_11> . these are the first completeness results for <task_8> in <method_1> with inverses , <otherscientificterm_13> , and counting , and show that for the considered logics the problem is not more expensive than standard reasoning .	9 1 6 5 3 12 8 17 14 -1 0 4 11 16 14 -1 10 15 20 21 14 -1 18 14 -1 2 7 19 14 -1
Mining Wikipedia Revision Histories for Improving Sentence Compression .	gram-maticality and compression rate criteria ; lexical-ized noisy channel model ; supervised sentence compression ; ziff-davis corpus ; wikipedia data ; sentence compressions ; sentence compression ; training data ; expansions	<metric> <method> <task> <material> <material> <task> <task> <material> <task>	1 0 6 ; 5 1 8	a well-recognized limitation of research on <task_2> is the dearth of available <material_7> . we propose a new and bountiful resource for such <material_7> , which we obtain by mining the revision history of wikipedia for <task_5> and <task_8> . using only a fraction of the available <material_4> , we have collected a training corpus of over 380,000 sentence pairs , two orders of magnitude larger than the standardly used <material_3> . using this newfound data , we propose a novel <method_1> for <task_6> , achieving improved results in <metric_0> with a slight decrease in importance .	2 7 9 -1 5 8 11 9 -1 4 3 9 -1 1 6 0 10 9 -1
A Nonparametric Bayesian Approach toward Stacked Convolutional Independent Component Analysis .	independent components analysis ; deep unsupervised hierarchical feature extractors ; unsupervised feature learning algorithms ; hybrid variational inference algorithm ; action recognition benchmarks ; indian buffet process ; tedious parameter tuning ; overcomplete feature learning ; successive model layers ; tedious cross-validation procedures ; latent components ; unsupervised manner ; latent features ; con-volutional formulations ; high-dimensional data ; inference	<method> <otherscientificterm> <method> <method> <metric> <method> <method> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <material> <task>	13 0 2 ; 0 0 2	unsupervised feature learning algorithms based on <method_13> of <method_0> have been demonstrated to yield state-of-the-art results in several <metric_4> . however , existing approaches do not allow for the number of <method_10> -lrb- features -rrb- to be automatically inferred from the data in an <method_11> . this is a significant disadvantage of the state-of-the-art , as it results in considerable burden imposed on researchers and practitioners , who must resort to <method_9> to obtain the optimal number of <otherscientificterm_12> . to resolve these issues , in this paper we introduce a convolutional nonpara-metric bayesian sparse ica architecture for <task_7> from <material_14> . our method utilizes an <method_5> prior to facilitate <task_15> of the appropriate number of <otherscientificterm_12> under a <method_3> , scalable to massive datasets . as we show , our model can be naturally used to obtain <otherscientificterm_1> , by greedily stacking <otherscientificterm_8> , similar to existing approaches . in addition , <task_15> for this model is completely heuristics-free ; thus , it obviates the need of <method_6> , which is a major challenge most deep learning approaches are faced with . we evaluate our method on several <metric_4> , and exhibit its advantages over the state-of-the-art .	13 0 4 17 18 16 -1 10 11 16 -1 9 12 16 -1 7 16 -1 14 16 -1 5 15 3 16 -1 1 8 16 -1 6 16 -1
Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser .	pcfg-la berkeley parser ; lattice parsing methodology ; unseg-mented hebrew text ; uncertain inputs ; syntactic model ; error reduction ; lattice parsing ; f-score ; parsing ; parser	<method> <method> <material> <otherscientificterm> <method> <metric> <task> <metric> <task> <method>	9 0 2 ; 1 0 8 ; 0 6 4 ; 0 0 6	we experiment with extending a <method_1> for <task_8> hebrew -lrb- gold-berg and tsarfaty , 2008 ; golderg et al. , 2009 -rrb- to make use of a stronger <method_4> : the <method_0> . we show that the <method_1> is very effective : using a small training set of about 5500 trees , we construct a <method_9> which parses and segments <material_2> with an <metric_7> of almost 80 % , an <metric_5> of over 20 % over the best previous result for this task . this result indicates that <task_6> with the <method_0> is an effective <method_1> for <task_8> over <otherscientificterm_3> .	1 8 4 0 13 10 -1 9 2 7 5 11 10 -1 6 3 12 14 10 -1
Auditory visual speech processing .	auditory visual speech processing ; human-machine interaction ; speech science ; hearing-impaired communication ; psycholinguistics ; animation ; eurospeech ; psychology	<task> <task> <material> <task> <material> <material> <material> <material>	5 1 3 ; 4 1 1 ; 2 1 1 ; 4 1 3 ; 5 1 1 ; 2 1 5 ; 2 1 4 ; 1 1 3 ; 7 1 2 ; 5 1 4 ; 7 1 5	this paper provides an overview of the developments in <task_0> , a special interest group within <material_6> . i hope that this discussion will be informative and useful to readers in a variety of fields , including <material_7> , <material_2> , <material_5> , <material_4> , <task_1> , <task_3> , and numerous other fields which also share in this fruitful intersection .	0 6 8 -1 7 2 5 4 1 3 9 10 11 12 13 14 15 16 17 18 19 8 -1
Acoustic class specific VTLN-warping using regression class trees .	phonetic knowledge based regression class tree definitions ; vocal tract length normalization ; physiological differences in vocal tract ; linear-transformation ; acoustic class specific warp-factor ; regression class tree ; vtln method ; wsj database ; gaussian components ; mfcc features ; frequency warp-factors ; acoustic model ; data-driven approach ; phonetic knowledge ; cmllr adaptation ; acoustic classes ; frequency-warp ; recognition ; warp-factor	<otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <method> <material> <method> <method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <method>	7 0 4 ; 6 0 1 ; 6 4 18 ; 1 0 15 ; 5 0 1 ; 5 0 18 ; 10 0 15 ; 8 3 11 ; 12 0 15 ; 10 0 1 ; 13 0 12 ; 3 0 6	in this paper , we study the use of different <method_10> for different <otherscientificterm_15> in a computationally efficient framework of <task_1> . this is motivated by the fact that all <otherscientificterm_15> do not exhibit similar spectral variations as a result of <otherscientificterm_2> , and therefore , the use of a single <otherscientificterm_16> for the entire utterance may not be appropriate . we have recently proposed a <method_6> that implements <task_1> through a <method_3> of the conventional <method_9> and efficiently estimates the <method_18> using the same sufficient statistics as that are used in <task_14> . in this paper we have shown that , in this framework of <task_1> , and using the idea of <method_5> , we can obtain separate <task_1> for different <otherscientificterm_15> . the use of <method_5> ensures that <method_18> is estimated for each class even when there is very little data available for that class . the <otherscientificterm_15> , in general , can be any collection of the <method_8> in the <method_11> . we have built <otherscientificterm_15> by using <method_12> and by using <otherscientificterm_13> . using <material_7> we have shown the <task_17> performance of the proposed <method_4> both for the data driven and the <otherscientificterm_0> and compare <method_6> with the case of the single <method_18> .	10 15 1 26 29 19 -1 2 16 19 -1 6 3 9 18 14 21 31 19 -1 23 24 19 -1 5 25 19 -1 27 19 -1 8 11 28 30 19 -1 12 13 20 22 19 -1
Packet-loss concealment technology advances in EVS .	enhanced voice services ; packet loss concealment ; jitter buffer management ; standardized codec ; mobile services ; error resilience ; technical features ; reference codecs ; evs ; volte ; robustness	<task> <task> <method> <otherscientificterm> <task> <metric> <otherscientificterm> <method> <method> <method> <metric>	9 6 4 ; 0 0 4 ; 5 6 4 ; 10 5 0	evs , the newly standardized 3gpp codec for <task_0> was developed for <task_4> such as <method_9> , where <metric_5> is highly essential . the presented paper outlines all aspects of the advances brought during the <method_8> development on <task_1> , by presenting a high level description of all <otherscientificterm_6> present in the final <otherscientificterm_3> . coupled with <method_2> , the <task_0> provides <metric_10> against late or lost packets . the advantages of the new <task_0> over <method_7> are further discussed based on listening test results .	0 4 9 5 12 13 14 11 -1 8 1 6 3 11 -1 2 10 15 11 -1 7 11 -1
Extraction of detailed image regions for content-based image retrieval .	perceptually modified distance measure ; direcional detail histogram technique ; natural color images ; histogram thresholding techniques ; image database indexing ; directional detail ; color activity ; database indices ; sum-of-angles criterion ; edges ; texture ; edge ; retrieval	<metric> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	1 0 7 ; 9 1 10 ; 10 6 5 ; 8 0 0 ; 9 6 5	we present a technique for coarsely extracting the regions of <material_2> which contain <otherscientificterm_5> , e.g. , <otherscientificterm_9> , <otherscientificterm_10> , etc. , which we then use for <task_4> . as a measure of <otherscientificterm_6> , we use a <metric_0> based on the <otherscientificterm_8> . we then apply <method_3> to separate the image into smooth color regions and busy regions where <otherscientificterm_11> , <otherscientificterm_10> and colour activity exists . <material_7> are then created from the busy regions using the <method_1> and <task_12> is performed using these .	2 5 9 10 4 15 16 18 13 -1 6 0 8 17 13 -1 3 11 7 13 -1 1 12 14 13 -1
Scene Parsing by Integrating Function , Geometry and Appearance Models .	posteriori solution ; function-geometry-appearance hierarchy ; simulated annealing mcmc algorithm ; geometry -lrb- 3d shape ; indoor scene parsing algorithm ; indoor functional objects ; stochastic grammar model ; 3d geometric shapes ; metropolis-hastings acceptance probability ; 3d primitive shapes ; appearance-based classification paradigm ; 2d segmentation maps ; functional object recognition ; fga space ; object function ; 3d recovery ; data-driven steps ; missing objects/parts ; functional labels ; scene category ; indoor object ; indoor images ; functional groups ; functional parts ; indoor datasets ; line segments ; functional objects ; parse tree ; joint distribution ; chair ; segmentation	<method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	22 1 26 ; 19 3 28 ; 8 0 27 ; 23 3 28 ; 24 5 4 ; 22 3 28 ; 11 0 27 ; 28 3 1 ; 19 1 22 ; 26 3 28 ; 22 1 23 ; 6 0 14 ; 30 1 15 ; 23 1 7 ; 26 1 23 ; 26 1 7	indoor <otherscientificterm_26> exhibit large view and appearance variations , thus are difficult to be recognized by the traditional <method_10> . in this paper , we present an algorithm to parse <material_21> based on two observations : i -rrb- the functionality is the most essential property to define an <otherscientificterm_20> , e.g. '' a <otherscientificterm_29> to sit on '' ; ii -rrb- the <otherscientificterm_3> -rrb- of an object is designed to serve its function . we formulate the nature of the <otherscientificterm_14> into a <method_6> . this model characterizes a <otherscientificterm_28> over the <otherscientificterm_1> . the <otherscientificterm_28> includes a <otherscientificterm_19> , <otherscientificterm_22> , <otherscientificterm_26> , <otherscientificterm_23> and <otherscientificterm_7> . we use a <method_2> to find the maximum a <method_0> , i.e. a <otherscientificterm_27> . we design four <method_16> to accelerate the search in the <otherscientificterm_13> : i -rrb- group the <otherscientificterm_25> into <otherscientificterm_9> , ii -rrb- assign <otherscientificterm_18> to these <otherscientificterm_9> , iii -rrb- fill in <otherscientificterm_17> according to the <otherscientificterm_18> , and iv -rrb- synthesize <method_11> and verify the current <otherscientificterm_27> by the <otherscientificterm_8> . the experimental results on several challenging <material_24> demonstrate the proposed approach not only significantly widens the scope of <method_4> from the <task_30> and the <task_15> to the <task_12> , but also yields improved overall performance .	26 10 31 -1 21 20 29 3 31 -1 14 6 43 31 -1 28 1 39 31 -1 19 32 33 35 37 40 41 42 45 46 47 31 -1 22 23 7 31 -1 2 0 27 34 38 31 -1 16 13 25 9 18 17 11 8 36 44 31 -1
Improving music auto-tagging by intra-song instance bagging .	temporal information of music signals ; bootstrapping -lrb- random sampling ; machine learning literature ; intra-song instance bagging ; ensemble learning techniques ; inter-song instance bagging ; bootstraps song-level features ; meta algorithm ; short-time features ; music auto-tagging ; bagging methods ; mir systems ; temporal signal ; accuracies ; bagging	<otherscientificterm> <method> <task> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method>	10 0 0 ; 10 0 11 ; 14 6 4 ; 10 0 9 ; 4 3 2	bagging is one the most classic <method_4> in the <task_2> . the idea is to generate multiple subsets of the training data via <method_1> with replacement -rrb- , and then aggregate the output of the models trained from each subset via voting or averaging . as music is a <otherscientificterm_12> , we propose and study two <method_10> in this paper : the <method_5> that <otherscientificterm_6> , and the <method_3> that draws bootstrapping samples directly from <otherscientificterm_8> for each training song . in particular , we focus on the latter method , as <method_10> better exploits the <otherscientificterm_0> . the <method_10> result in surprisingly effective models for <task_9> : incorporating the idea to a simple linear support vector machine -lrb- svm -rrb- based system yields <otherscientificterm_13> that are comparable or even superior to state-of-the-art , possibly more sophisticated methods for three different datasets . as the <method_10> is a <method_7> , <method_10> holds the promise of improving other <method_11> .	4 2 18 20 15 -1 1 15 -1 12 10 5 6 3 8 15 -1 0 16 15 -1 19 15 -1 9 13 17 15 -1
A Novel Embedding Method For An Anti-Collusion Fingerprinting By Embedding Both A Code And An Orthogonal Fingerprint .	linear combination collusion attack ; and anti-collusion code ; code modulation embedding method ; fingerprint embedding method ; basis vectors ; embedding method ; fingerprinting system ; code modulation ; orthogonal fingerprint ; code ; and-acc ; detection	<method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task>	2 0 6 ; 9 1 8 ; 3 0 1 ; 5 0 0 ; 11 0 5 ; 7 0 6 ; 2 0 1 ; 5 0 6 ; 0 0 6	in this paper , a <method_3> better-suited for the <method_1> is proposed . the proposed <method_3> embeds both a <otherscientificterm_9> and an <otherscientificterm_8> using different <otherscientificterm_4> depending on the bit . although the <task_11> for the <method_5> is complex , the performance of the <method_6> using proposed <method_5> with the <method_10> against average attack is improved compared with the <method_1> using <method_2> . the <method_6> using the proposed <method_5> is robust against the <method_0> whereas the <method_6> using the <method_7> is not .	3 1 15 12 -1 9 8 4 14 12 -1 11 5 6 10 2 13 17 19 12 -1 0 7 16 18 20 21 12 -1
Narrative Prose Generation .	poor writing quality ; natural language generation ; narrative prose generator ; prose quality ; writing quality ; narrative theory ; story generation ; plot design ; corpora analyses ; author architecture ; story grammars ; complexity	<metric> <task> <method> <metric> <metric> <method> <task> <task> <method> <method> <method> <metric>	10 0 7 ; 8 0 5	story generation is experiencing a revival , despite disappointing preliminary results from the preceding three decades . one of the principle reasons for previous inadequacies was the low level of <metric_4> , which resulted from the excessive focus of <method_10> on <task_7> . although these systems leveraged <method_5> via <method_8> , they failed to thoroughly extend those analyses to all relevant linguistic levels . the end result was narratives that were recognizable as stories , but whose <metric_3> was unsatisfactory . however , the blame for <metric_0> can not be laid squarely at the feet of <method_10> , as <task_1> has to-date not fielded systems capable of faithfully reproducing either the variety or <metric_11> of naturally occurring stories . this paper presents the <method_9> for accomplishing precisely that task , the storybook implementation of a <method_2> , and a brief description of a formal evaluation of the stories it produces .	12 -1 4 10 7 13 12 -1 5 8 14 12 -1 3 12 -1 0 1 12 -1 11 12 -1
Robust adaptive beamforming and steering vector estimation in partly calibrated sensor arrays : A structured uncertainty approach .	gain-and-phase and phase-only intersubarray distortions ; intersubarray gain and/or phase mismatches ; structured ellipsoidal uncertainty model ; sparse subarray-based sensor arrays ; minimum variance beamformer ; worst-case beamformer design ; signal steering vector ; worst-case designs ; adaptive beamforming	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method> <task>	2 0 6	two new approaches to <task_8> in <otherscientificterm_3> are proposed . each subarray is assumed to be well calibrated but the <otherscientificterm_1> are assumed to remain unknown or imperfectly known . our first approach is based on a <method_5> that , unlike the existing <method_7> , exploits a <method_2> for the <method_6> . our second approach exploits the idea of estimating the <method_6> by maximizing the output power of the <method_4> . several modifications of our second approach are developed for the cases of <otherscientificterm_0> .	8 3 9 -1 1 9 -1 5 7 2 6 10 9 -1 4 9 -1 0 9 -1
CrowdMR : Integrating Crowdsourcing with MapReduce for AI-Hard Problems .	captcha -lrb- completely automated public turing test ; incremental scheduling method ; large-scale distributed computing ; human-machine solution ; ai-hard problems ; crowdsourcing ; crowdmr ; mapreduce ; accuracy	<material> <method> <method> <method> <task> <method> <method> <method> <metric>	3 0 4 ; 5 0 3 ; 7 0 3	large-scale distributed computing has made available the resources necessary to solve '' ai-hard '' problems . as a result , it becomes feasible to automate the processing of such problems , but <metric_8> is not very high due to the conceptual difficulty of these problems . in this paper , we integrated <method_5> with <method_7> to provide a scalable innovative <method_3> to <task_4> , which is called <method_6> . in <method_6> , the majority of problem instances are automatically processed by machine while the troublesome instances are redirected to human via <method_5> . the results returned from <method_5> are validated in the form of <material_0> to tell computers and humans apart -rrb- before adding to the output . an <method_1> was brought forward to combine the results from machine and human in a '' pay-as-you-go '' way .	9 -1 8 9 -1 5 7 3 4 6 10 11 12 9 -1 9 -1 9 -1 0 9 -1
Non-Linear Domain Adaptation with Boosting .	parameter-free domain adaptation approach ; multi-task learning algorithm ; shared feature space ; global analytical form ; task-specific decision boundaries ; non-linear mapping ; labeled data ; 3d data ; bio-medical datasets ; machine vision ; domain adaptation ; decision boundary ; bio-medical applications ; distribution ; annotation ; boosting ; boosting-trick	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <material> <material> <task> <task> <otherscientificterm> <task> <otherscientificterm> <task> <method> <method>	7 0 9 ; 1 0 11 ; 1 0 10 ; 8 5 1 ; 2 2 11 ; 15 0 1	a common assumption in <task_9> is that the training and test samples are drawn from the same <otherscientificterm_13> . however , there are many problems when this assumption is grossly violated , as in <task_12> where different acquisitions can generate drastic variations in the appearance of the data due to changing experimental conditions . this <task_9> is accentuated with <material_7> , for which <task_14> is very time-consuming , limiting the amount of data that can be labeled in new acquisitions for training . in this paper we present a <method_1> for <task_10> based on <method_15> . unlike previous approaches that learn <otherscientificterm_4> , our <method_1> learns a single <otherscientificterm_11> in a <otherscientificterm_2> , common to all tasks . we use the <method_16> to learn a <method_5> of the observations in each task , with no need for specific a-priori knowledge of its <otherscientificterm_3> . this yields a more <method_0> that successfully leverages learning on new tasks where <material_6> is scarce . we evaluate our <method_1> on two challenging <material_8> and achieve a significant improvement over the state of the art .	9 13 17 -1 12 17 -1 7 14 18 17 -1 1 10 15 20 23 17 -1 19 22 17 -1 4 11 2 17 -1 16 5 3 17 -1 0 6 21 17 -1
Memory-Efficient Dynamic Programming for Learning Optimal Bayesian Networks .	dynamic programming graphs ; dynamic programming algorithm ; bayesian network ; layered structure ; re-cursive decomposition ; binomial coefficient ; memory requirements	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	3 0 4 ; 0 0 4 ; 3 0 1 ; 3 2 0 ; 4 2 0	we describe a memory-efficient implementation of a <method_1> for learning the optimal structure of a <method_2> from training data . the <method_1> leverages the <otherscientificterm_3> of the <method_0> representing the <method_4> of the problem to reduce the <otherscientificterm_6> of the <method_1> from o -lrb- n2 n -rrb- to o -lrb- c -lrb- n , n/2 -rrb- -rrb- , where c -lrb- n , n/2 -rrb- is the <otherscientificterm_5> . experimental results show that the <method_1> runs up to an order of magnitude faster and scales to datasets with more variables than previous approaches .	1 2 7 -1 3 0 4 6 5 8 9 10 11 12 7 -1 7 -1
Creaseness from Level Set Extrinsic Curvature .	extrema of the level set curvatures ; mean curvature of the level surfaces ; curvature of the level curves ; anisotropic grey -lcb- level shapes ; discon-tinuous creaseness measure ; level curve curvature ; creaseness measures ; creaseness measure ; local conditions ; crease deenitions ; image landscape ; creases ; creases ; medialness ; creaseness ; discontinuities	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <metric> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	15 2 5	creases are a type of ridge/valley -lcb- like structures of a d dimensional image , characterized by <otherscientificterm_8> . as <otherscientificterm_12> tend to be at the center of <otherscientificterm_3> , <otherscientificterm_14> can be considered as a type of <otherscientificterm_13> . among the several <otherscientificterm_9> , one of the most important is based on the <otherscientificterm_0> . in 2 -lcb- d it is used the <otherscientificterm_2> of the <otherscientificterm_10> , however , the way it is usually computed produces a <metric_4> . the same problem arises in 3 -lcb- d with its straightforward extension and with other related <metric_6> . in this paper , we rst present an alternative method of computing the <otherscientificterm_5> that avoids the <otherscientificterm_15> . next , we propose the <otherscientificterm_1> as <metric_7> of 3 -lcb- d images , computed by the same method . finally , we propose a natural extension of our rst alternative method in order to enhance the <metric_7> .	8 16 -1 12 3 14 13 16 -1 9 0 16 -1 2 10 4 16 -1 6 16 -1 17 16 -1 5 15 16 -1 1 7 16 -1
Acquisition of second language intonation .	second language production ; phonological properties of intonation ; phonetic properties of intonation ; english speakers of korean ; segmental and prosodic features ; surface tonal realizations ; american english speakers ; native-like intonation patterns ; prosodic structure ; korean speakers ; foreign accents ; phonological system ; segmental data ; segment-tone interaction ; seoul korean ; l2 speakers	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <material> <otherscientificterm> <material> <material>	10 0 0 ; 7 1 8 ; 12 4 15 ; 15 0 5 ; 15 0 8 ; 1 4 2 ; 15 0 7	foreign accents in <otherscientificterm_0> are caused by interference from the <method_11> and phonetic realization of the speaker 's first language -lrb- l1 -rrb- , including both <otherscientificterm_4> . this paper examines the intonation structure of <material_14> and its realization by <material_6> . four <material_3> , differing in fluency , and two <material_9> participated in the experiment . forty sentences were designed to test the realization of intonation patterns by varying the number of syllables within a word and a sentence , and by varying the conditions for the <otherscientificterm_13> . results show that , as with <material_12> , more advanced <material_15> produce more <otherscientificterm_7> and <otherscientificterm_8> than less advanced speakers . however , although advanced <material_15> are better at grouping words into phrases , <material_15> are not better at producing <otherscientificterm_5> of an accentual phrase than less advanced speakers . this suggests that <otherscientificterm_1> are acquired earlier than <otherscientificterm_2> .	0 11 4 17 16 -1 14 6 16 -1 3 9 16 -1 13 16 -1 12 18 19 21 23 16 -1 15 7 8 20 16 -1 5 22 16 -1
A polyphase IIR adaptive filter : error surface analysis and application .	direct form iir adaptive ¯ lters ; local and global convergence properties ; polyphase iir adaptive ¯ lter ; adverse e ® ects ; underdamped low-frequency poles ; local convergence speed ; constant gain algorithms ; global convergence speed ; reduced error surface ; modelled system ; unit circle ; real axis ; complex poles ; direct form ; computational complexity	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	6 0 0	an analysis of the <metric_5> of <method_6> for <otherscientificterm_0> is initially presented , showing the <otherscientificterm_3> that result from the proximity of the poles of the <method_9> to the <otherscientificterm_10> and , for <otherscientificterm_12> , to the <otherscientificterm_11> . a global analysis of the <otherscientificterm_8> in these cases is also presented , which shows that , away from the global minimum , there will be regions with an almost constant error , where the convergence of <method_6> tends to be slow . a <method_2> is then proposed and its <otherscientificterm_1> are investigated , showing <method_2> to be specially well suited for applications with <otherscientificterm_4> . the <method_2> is tested with di ® erent <method_6> in an echo-cancellation example , attaining a gain of 14 to 70 times in <metric_7> over the <otherscientificterm_13> , at the price of a relatively modest increase in <metric_14> . a theorem concerning the existence of stationary points for the <method_2> is also presented .	5 6 0 3 9 10 12 11 16 15 -1 8 15 -1 2 1 15 -1 4 15 -1 7 13 14 15 -1
Localization of multiple sound sources based on a CSP analysis with a microphone array .	csp -lrb- cross-power spectrum phase analysis -rrb- method ; microphone array-based high quality sound capture ; single sound source localization ; dier-ent microphone pairs ; sound source ; un-desired cross-correlation ; localization accuracy ; synchronous addition ; csp coecients	<method> <task> <task> <otherscientificterm> <material> <otherscientificterm> <metric> <otherscientificterm> <method>	0 0 2 ; 0 0 4	accurate localization of multiple sound sources is indispensable for the <task_1> . for <task_2> , the <method_0> has been proposed . the <method_0> localizes a <material_4> as a crossing point of sound directions estimated using <otherscientificterm_3> . however , when localizing multiple sound sources , the <method_0> has a problem that the <metric_6> is degraded due to cross-correlation among dierent sound sources . to solve this problem , this paper proposes a new method which suppresses the <otherscientificterm_5> by <otherscientificterm_7> of <method_8> derived from multiple microphone pairs . experiment results in a real room showed that the proposed method improves the <metric_6> when increasing the number of the <otherscientificterm_7> .	1 9 -1 2 0 10 9 -1 4 3 11 9 -1 6 9 -1 5 7 8 9 -1 9 -1
Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics .	time-varying linear dynamics models ; simulated robotic manipulation tasks ; guided policy search ; policy search method ; local linear models ; neural network policies ; model-free methods ; global model ; nonsmooth dynamics ; model-based techniques ; trajectory distributions ; contact discontinuities ; arbitrary parameterization ; policies ; learning ; underactuation	<method> <task> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	3 0 14 ; 3 0 5 ; 2 0 13 ; 10 0 13 ; 3 0 1 ; 11 1 15 ; 0 0 14 ; 3 0 10 ; 2 0 10	we present a <method_3> that uses iteratively refitted <method_4> to optimize <otherscientificterm_10> for large , continuous problems . these <otherscientificterm_10> can be used within the framework of <method_2> to learn <otherscientificterm_13> with an <otherscientificterm_12> . our <method_3> fits <method_0> to speed up <task_14> , but does not rely on <task_14> a <method_7> , which can be difficult when the dynamics are complex and discontinuous . we show that this <method_3> requires many fewer samples than <method_6> , and can handle complex , <otherscientificterm_8> that can pose a challenge for <method_9> . we present experiments showing that our <method_3> can be used to learn complex <method_5> that successfully execute <task_1> in partially observed environments with numerous <otherscientificterm_11> and <otherscientificterm_15> .	3 4 10 24 16 -1 2 13 12 19 20 25 16 -1 0 14 7 17 23 16 -1 6 8 9 16 -1 18 21 22 16 -1
Conditioned Hidden Markov Model Fusion for Multimodal Classification .	hidden markov models ; naturalistic mul-tiparty dialogue ; late fusion approaches ; fusion strategies ; conditioned hmm ; classical hmm ; class decision ; class label ; model likelihoods ; affec-tive computing ; processing unit ; hmm ; classification ; classification	<method> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <task>	0 0 12	classification using <method_0> is in general done by comparing the <otherscientificterm_8> and choosing the class more likely to have generated the data . this work investigates a <method_4> which additionally provides a probability for a <otherscientificterm_7> and compares different <method_3> . the notion is twofold : on the one hand applications in <task_9> might pass their uncertainty of the <task_13> to the next <method_10> , on the other hand different streams might be fused to increase the performance . the data set studied incorporates two modalities and is based on a <material_1> . the goal is to discriminate between laughter and utterances . it turned out that the <method_4> out-performs <method_5> using different <method_2> while additionally providing a certainty about <otherscientificterm_6> .	0 8 15 14 -1 4 7 3 14 -1 9 13 10 14 -1 1 14 -1 14 -1 14 -1
An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector .	spatio-temporal interest point detectors ; spatio-temporal interest points ; approximative box-filter operations ; integral video structure ; scale-invariant features ; user-defined scales ; video content ; action recognition ; scale-space theory ; saliency measure ; features ; hessian ; speed ; accuracy	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <method> <metric> <otherscientificterm> <otherscientificterm> <metric> <metric>	13 1 12 ; 11 0 10	over the years , several <method_0> have been proposed . while some detectors can only extract a sparse set of <otherscientificterm_4> , others allow for the detection of a larger amount of <otherscientificterm_10> at <otherscientificterm_5> . this paper presents for the first time <otherscientificterm_1> that are at the same time scale-invariant -lrb- both spatially and temporally -rrb- and densely cover the <material_6> . moreover , as opposed to earlier work , the <otherscientificterm_10> can be computed efficiently . applying <method_8> , we show that <otherscientificterm_10> can be achieved by using the determinant of the <otherscientificterm_11> as the <metric_9> . computations are speeded-up further through the use of <method_2> on an <otherscientificterm_3> . a quantitative evaluation and experimental results on <task_7> show the strengths of the proposed detector in terms of repeatability , <metric_13> and <metric_12> , in comparison with previously proposed detectors .	0 14 -1 4 10 5 14 -1 1 6 14 -1 14 -1 8 11 9 16 14 -1 14 -1 2 3 15 14 -1
Modelling Reflections via Multiperspective Imaging .	perspective and multiperspective camera types ; caustic surfaces of reflections ; locally model reflections ; irregular mirror surfaces ; catadioptric imaging systems ; multiper-spective camera models ; general linear cameras ; multiperspective cameras ; mirror design ; imaging models ; cata-dioptric mirrors ; analytical framework ; image distortions ; arbitrary surfaces	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	11 0 2 ; 11 0 8 ; 5 1 1	we present a novel method for analyzing reflections on <otherscientificterm_13> . we model reflections using a broader than usual class of <method_9> , which include both <otherscientificterm_0> . we provide an <method_11> to <otherscientificterm_2> as specific <otherscientificterm_7> around every ray based on a new theory of <otherscientificterm_6> . our <method_11> better characterizes the complicated <otherscientificterm_12> seen on <otherscientificterm_3> as well as the conventional <otherscientificterm_10> . we show the connection between <method_5> and <otherscientificterm_1> and demonstrate how <method_5> reveal important surface rulings of the caustics . finally , we show how to use our <method_11> to assist <task_8> and characterize distortions seen in <method_4> .	13 14 -1 9 0 14 -1 11 2 7 6 15 14 -1 12 3 10 14 -1 5 1 17 14 -1 8 16 14 -1
A realtime software MPEG transcoder using a novel motion vector reuse and a SIMD optimization techniques .	mean absolute error approximation criteria ; realtime software mpeg transcoder ; pentium ii 266mhz ; scaled motion vectors ; simd optimization techniques ; motion vector reuse ; quality degradation ; reuse technique ; mpeg-1 bitstream ; realtime	<metric> <method> <method> <otherscientificterm> <method> <method> <metric> <method> <otherscientificterm> <otherscientificterm>	5 1 4 ; 7 0 3	a <method_1> has been developed . a novel <method_5> and a <method_4> are introduced to accelerate the transcoder without any <metric_6> . <metric_0> are employed in the <method_7> to refine <otherscientificterm_3> . the developed transcoder on <method_2> runs 2.5 times as fast as <otherscientificterm_9> , when scaling an <otherscientificterm_8> to half size .	1 10 -1 5 4 6 0 11 10 -1 7 3 12 10 -1 2 9 8 10 -1
Analysis and modeling of next speaking start timing based on gaze behavior in multi-party meetings .	natural multi-party meetings ; gaze transition patterns ; conversational interface ; prediction models ; agent system ; prediction model ; multi-party meetings ; start timing ; features	<material> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <task> <otherscientificterm>	5 0 7 ; 1 0 5 ; 8 0 5	to realize a <otherscientificterm_2> where an <method_4> can smoothly communicate with multiple persons , it is imperative to know how the <task_7> of speaking is decided . in this research , we demonstrate a relationship between <otherscientificterm_1> and the <task_7> of next speaking against the end of the last speaking in <material_6> . then , we construct a <method_5> for the <task_7> using <otherscientificterm_1> near the end of an utterance . an analysis of data collected from <material_0> reveals a strong relationship between <otherscientificterm_1> of the speaker , next speaker , and listener and the <task_7> of the next speaker . on the basis of the results , we used <otherscientificterm_1> of the speaker , next speaker , and listener and mutual gaze as variables , and devised several <method_3> . a <method_5> using all <otherscientificterm_8> performed the best and was able to predict the <task_7> well .	2 4 7 9 -1 1 6 9 -1 5 11 9 -1 0 9 -1 9 -1 3 10 12 9 -1
Bayesian Tensor Inference for Sketch-Based Facial Photo Hallucination .	sketch images of human faces ; sketch-based facial photo hallucination ; patch-based tensor model ; facial sketch synthesis ; photo patch space ; face hallucination scenario ; common variation space ; statistical inference approach ; sketch patch space ; image content ; tensor model ; cooperative factors ; image appearance ; bidirectional mapping/inferring ; style transformation ; image style ; statistical inference ; bayesian approach ; photo images	<material> <task> <method> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <material>	4 1 8 ; 15 6 11 ; 5 0 3 ; 17 0 3 ; 17 0 16 ; 7 6 7 ; 9 1 15 ; 1 6 5 ; 7 0 14 ; 11 0 12 ; 9 6 11	this paper develops a <method_7> , <method_7> , for <task_14> between <material_18> and <material_0> . motivated by the rationale that <otherscientificterm_12> is determined by two <otherscientificterm_11> : <material_9> and <otherscientificterm_15> , we first model the interaction between these factors through learning a <method_2> . second , by introducing a <otherscientificterm_6> , we capture the inherent connection between <otherscientificterm_4> and <otherscientificterm_8> , thus building <otherscientificterm_13> between the two spaces . subsequently , we formulate a <method_17> accounting for the <otherscientificterm_16> from sketches to their corresponding photos in terms of the learned <method_10> . comparative experiments are conducted to contrast the proposed <method_17> with state-of-the-art algorithms for <task_3> in a novel <task_5> : <task_1> . the encouraging results obtained convincingly validate the effectiveness of our <method_17> .	7 14 18 0 25 28 19 -1 12 11 9 15 2 21 26 29 30 19 -1 6 4 8 13 20 19 -1 17 16 10 24 19 -1 22 23 27 19 -1 3 5 1 19 -1
Sub-band feedback cancellation with variable step sizes for music signals in hearing aids .	distortion artifacts ; adaptive feedback cancellation algorithms ; general adaptive filter algorithms ; sub-band feedback cancellation system ; prediction error filtering ; variable step sizes ; biased adaptation ; tonal signals ; hearing aids ; frequency shifting ; feedback cancellation ; control concepts ; computational complexity ; adaptation control ; bias ; setup	<method> <method> <method> <method> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <task> <method> <metric> <method> <otherscientificterm> <otherscientificterm>	4 6 14 ; 1 0 8 ; 4 1 9 ; 11 0 5 ; 9 6 14 ; 6 0 8 ; 15 0 10	standard <method_1> in <otherscientificterm_8> suffer from a <task_6> if the input signal is spectrally colored , as it is for <material_7> , like music . due to that , <method_0> are generated . in this paper , a <method_3> is presented combined with an <method_13> to deal with those signals . two <method_11> for determining the <otherscientificterm_5> -lsb- 1 , 2 -rsb- , known from <method_2> , are theoretically and practically analyzed and evaluated for an application to <task_10> . for <task_10> the control is combined with known methods to reduce the <otherscientificterm_14> , such as <task_4> or <otherscientificterm_9> . based on this combination , a completely new <otherscientificterm_15> for <task_10> is proposed . <otherscientificterm_15> relies entirely on signals accessible in real systems , shows a low <metric_12> , and therefore has a strong practical relevance .	1 8 6 7 18 22 16 -1 0 16 -1 3 13 16 -1 11 5 2 10 20 16 -1 14 4 9 17 19 21 16 -1 23 16 -1 15 16 -1
Wasserstein Training of Restricted Boltzmann Machines .	kullback-leibler divergence ; boltzmann machine training ; data completion ; generative models ; wasserstein distance ; boltzmann machines ; statistical properties ; model parameters ; gradient ; denoising	<otherscientificterm> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	6 2 3	boltzmann machines are able to learn highly complex , multimodal , structured and multiscale real-world data distributions . parameters of the model are usually learned by minimizing the <otherscientificterm_0> from training samples to the learned model . we propose in this work a novel approach for <task_1> which assumes that a meaningful metric between observations is given . this metric can be represented by the <otherscientificterm_4> between distributions , for which we derive a <otherscientificterm_8> with respect to the <otherscientificterm_7> . minimization of this new objective leads to <method_3> with different <otherscientificterm_6> . we demonstrate their practical potential on <task_2> and <task_9> , for which the metric between observations plays a crucial role .	10 -1 0 10 -1 1 10 -1 4 8 7 10 -1 3 6 11 10 -1 2 10 -1
Cross-lingual Opinion Analysis via Negative Transfer Detection .	nlp&cc 2013 cross-lingual opinion analysis dataset ; detection of negative transfers ; transductive transfer learning ; cumulative class noise ; monotonic increase trend ; language resources ; transfer learning ; opinion analysis ; transfer learning ; noises	<material> <task> <task> <otherscientificterm> <otherscientificterm> <material> <method> <task> <task> <otherscientificterm>	3 0 8 ; 6 0 7	transfer learning has been used in <task_7> to make use of available <material_5> for other resource scarce languages . however , the <otherscientificterm_3> in <task_8> adversely affects performance when more training data is used . in this paper , we propose a novel method in <task_2> to identify <otherscientificterm_9> through the <task_1> . evaluation on <material_0> shows that our approach outperforms the state-of-the-art systems . more significantly , our system shows a <otherscientificterm_4> in performance improvement when more training data are used .	7 5 12 10 -1 3 8 11 10 -1 2 9 1 10 -1 0 10 -1 4 6 10 -1
Adaptive prediction of time-varying channels for coded OFDM systems .	orthogonal frequency division multiplexing communications ; recursive least-squares algorithms ; normalized least-mean-square ; adaptive channel pre-dictors ; adaptive channel predictors ; time-varying channels ; delay-free equalization	<task> <method> <method> <method> <method> <otherscientificterm> <task>	2 1 1 ; 4 0 0 ; 3 0 6	we propose <method_4> for <task_0> over <otherscientificterm_5> . successful application of the <method_2> and <method_1> is demonstrated . we also consider the use of <method_3> for <task_6> , thereby avoiding the need for regular transmission of pilot symbols . simulation results demonstrate the good performance of the proposed techniques .	4 0 5 9 7 -1 2 1 8 7 -1 3 6 10 7 -1 7 -1
Using Personal Traits For Brand Preference Prediction .	indi-vidual 's personal traits ; ground truth character traits ; automated social media analytics ; his/her brand preferences ; brand preference prediction ; personal traits ; personal values ; character traits ; psychometric survey ; social media ; personality	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	10 1 6 ; 10 6 7 ; 2 0 7 ; 6 6 7 ; 0 1 3 ; 8 1 2 ; 8 0 7	in this paper , we present a comprehensive study of the relationship between an <otherscientificterm_0> and <otherscientificterm_3> . in our analysis , we included a large number of <otherscientificterm_7> such as <otherscientificterm_10> , <otherscientificterm_6> and individual needs . these <otherscientificterm_7> were obtained from both a <method_8> and <method_2> . we also included an extensive set of brand names from diverse product categories . from this analysis , we want to shed some light on -lrb- 1 -rrb- whether it is possible to use <otherscientificterm_5> to infer an individual 's brand preferences -lrb- 2 -rrb- whether the <otherscientificterm_7> automatically inferred from <material_9> are good proxies for the <otherscientificterm_1> in <task_4> .	0 3 16 11 -1 7 10 6 12 13 15 11 -1 8 2 14 17 18 11 -1 11 -1 5 11 -1
Motor Simulation via Coupled Internal Models Using Sequential Monte Carlo .	reenactment of internal model pairs ; perceptual prediction and action understanding ; sequential monte carlo methods ; inverse-forward internal model pairs ; approximate inference mechanism ; generative bayesian model ; inverse-forward models ; motor simulation ; internal models ; real-world scenarios ; action recognition ; computational resources ; ` hypotheses ; prediction error ; action understanding	<task> <task> <method> <otherscientificterm> <method> <method> <method> <task> <method> <task> <task> <material> <otherscientificterm> <otherscientificterm> <task>	11 0 8 ; 5 0 11 ; 5 0 14 ; 2 0 4 ; 5 0 8 ; 9 5 5	we describe a <method_5> for <task_14> in which <otherscientificterm_3> are considered <otherscientificterm_12> ' of plausible action goals that are explored in parallel via an <method_4> based on <method_2> . the <task_0> can be considered a form of <task_7> , which supports both <task_1> at the goal level . however , this <method_5> is generally considered to be computationally inefficient . we present a <method_5> that dynamically reallocates <material_11> to more accurate <method_8> depending on both the available prior information and the <otherscientificterm_13> of the <method_6> , and which leads to successful <task_10> . we present experimental results that test the robustness and efficiency of our <method_5> in <task_9> .	5 14 3 12 4 2 18 19 15 -1 0 7 1 15 -1 15 -1 11 8 13 6 10 16 17 20 15 -1 21 15 -1
Multi-View Discriminant Transfer Learning .	multi-view discriminant transfer learning approach ; within-view and/or between-view conflicts ; transfer learning framework ; multi-view learning approaches ; discriminant weight vectors ; two-view projected data ; transfer learning algorithm ; discriminant analysis perspective ; view-based problems ; domain adaptation ; single-or cross-domain ; domain discrepancy ; learning problem ; view disagreement	<method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <task> <task> <material> <otherscientificterm> <task> <otherscientificterm>	0 0 9 ; 7 0 0 ; 0 4 3 ; 6 0 8 ; 11 1 13	we study to incorporate multiple views of data in a perceptive <method_2> and propose a <method_0> for <task_9> . the main idea is to find the optimal <otherscientificterm_4> for each view such that the correlation between the <material_5> is maximized , while both the <otherscientificterm_11> and the <otherscientificterm_13> are minimized simultaneously . furthermore , we analyze <method_0> theoretically from <otherscientificterm_7> to explain the condition and reason , under which the proposed <method_0> is not applicable . the analytical results allow us to investigate whether there exist <otherscientificterm_1> , and thus provides a deep insight into whether the <method_6> work properly or not in the <task_8> and the combined <task_12> . experiments show that <method_0> significantly outperforms the state-of-the-art baselines including some typical <method_3> in <material_10> .	2 0 9 15 14 -1 4 5 11 13 19 14 -1 7 16 14 -1 1 6 18 14 -1 8 12 17 14 -1
Shape reconstruction from unorganized points with a data-driven level set method .	noisy and unorganized point data ; data-driven level set method ; constrained energy minimization problem ; observed point set ; signed distance function ; level set formalism ; local minima ; smoothness prior ; optimization problem ; reconstructed shape ; topologi-cal nature ; shape reconstruction ; shape ; noise ; clutter	<material> <method> <task> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 1 14 ; 1 0 8 ; 2 0 11 ; 3 0 2 ; 14 1 13 ; 4 0 11	we propose a new method for <task_11> from <material_0> . we represent a <otherscientificterm_12> through its <otherscientificterm_4> and formulate <task_11> as a <task_2> directly based on the <material_3> . the associated energy function includes both the likelihood of the observed data points and a <otherscientificterm_7> on the <otherscientificterm_9> . to solve this <task_8> , an efficient <method_1> is developed . our method is robust to <otherscientificterm_6> , <otherscientificterm_14> , and <otherscientificterm_13> . it is also applicable to situations where the data are sparse . the <otherscientificterm_10> of the underlying <otherscientificterm_12> is handled automatically through the <method_5> .	11 0 15 -1 12 4 2 3 18 19 21 15 -1 7 9 15 -1 8 1 17 15 -1 6 14 13 16 20 15 -1 15 -1 10 5 15 -1
Combining perceptually-motivated spectral shaping with loudness and duration modification for intelligibility enhancement of HMM-based synthetic speech in noise .	duration and excitation lombard-adapted changes ; lombard excitation and duration patterns ; speech-in-noise intelligibility enhancement evaluation ; perceptually-motivated spectral shaper ; unmodified synthetic speech ; dynamic range compression ; glimpse proportion measure ; speech-shaped noise ; spectral shaper ; hurricane challenge ; snr conditions ; text-to-speech voice ; enhancement strategies ; compressor	<otherscientificterm> <otherscientificterm> <task> <method> <material> <method> <metric> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <method>	5 0 3 ; 6 0 3 ; 6 1 5 ; 9 6 2 ; 6 0 11 ; 8 1 13	this paper presents our entry to a <task_2> : the <material_9> . the system consists of a <otherscientificterm_11> manipulated through a combination of <method_12> , each of which is known to be individually successful : a <method_3> based on the <metric_6> , <method_5> , and adaptation to <otherscientificterm_1> . we achieved substantial intelligibility improvements relative to <material_4> : 4.9 db in competing speaker and 4.1 db in <otherscientificterm_7> . an analysis conducted across this and other two similar evaluations shows that the <method_8> and the <method_13> -lrb- both of which are loudness boosters -rrb- contribute most under higher <otherscientificterm_10> , particularly for <otherscientificterm_7> . <otherscientificterm_0> are more beneficial in lower <otherscientificterm_10> , and for competing speaker noise .	2 9 18 14 -1 11 12 3 6 5 1 15 16 17 19 14 -1 4 7 14 -1 8 13 10 20 14 -1 0 14 -1
Motion estimation using ordinal measures .	sum-of squared-difference -lrb- s s d -rrb- ; relative ordering of intensity values ; normalized correlation ; linear-ity between corresponding intensity values ; rotating ring phantom image sequence ; real heart image sequence ; tagged magnetic resonance images ; motion estimation ; rank permutation ; ordinal measures ; image region ; temporal monotonicity ; rank permutations ; ordinal measures ; imaging equation ; tagging	<method> <otherscientificterm> <method> <otherscientificterm> <material> <material> <material> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <task>	14 0 15 ; 1 0 13 ; 6 0 7	we present a method for <task_7> using <method_9> . <metric_13> are based on <otherscientificterm_1> in a <otherscientificterm_10> called <otherscientificterm_8> . while popular measures like the <method_0> and <method_2> rely on <otherscientificterm_3> , <method_9> only require them to be monotonically related so that <otherscientificterm_12> between corresponding regions are preserved . this property turns out to be usefil for <task_7> in <material_6> . we study the <task_14> involved in two methods of <task_15> and observe <otherscientificterm_11> in intensity under certain conditions though the tags themselves fade . we compare our method to s s d and <method_2> in a <material_4> . we present an experiment on a <material_5> which suggests the suitability of our method .	7 9 13 16 -1 1 10 8 18 16 -1 0 2 3 12 16 -1 6 19 16 -1 14 15 11 17 16 -1 4 16 -1 16 -1
Model-lite Planning for the Web Age Masses : The Challenges of Planning with Incomplete and Evolving Domain Models .	automated planning community ; model-lite planning technology ; domain theory ; richer models ; domain model ; domain-modeling burden ; planning technology	<task> <method> <method> <method> <method> <otherscientificterm> <method>	1 0 5	the <task_0> has traditionally focused on the efficient synthesis of plans given a complete <method_2> . in the past several years , this line of work met with significant successes , and the future course of the community seems to be set on efficient planning with even <method_3> . while this line of research has its applications , there are also many domains and scenarios where the first bottleneck is getting the <method_4> at any level of completeness . in these scenarios , the <method_4> automatically renders the <method_6> unusable . to counter this , i will motivate <method_1> aimed at reducing the <otherscientificterm_5> -lrb- possibly at the expense of reduced functionality -rrb- , and outline the research challenges that need to be addressed to realize <method_1> .	0 2 7 -1 3 7 -1 4 7 -1 6 7 -1 1 8 7 -1
Separation of overlapping RFID signals by antenna arrays .	radio frequency identi ¿ cation ; zero constant modulus signals ; synthetic and measured data sets ; long-range systems ; blind source separation techniques ; identity of tagged objects ; binary tree algorithms ; tag replies ; collision avoidance ; mac protocols ; zcm algorithms ; slotted aloha ; antenna array	<method> <material> <material> <method> <method> <task> <method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm>	11 1 6 ; 9 0 8 ; 6 0 8 ; 2 5 10 ; 0 0 5	-- <method_0> is a technology to wirelessly transmit the <task_5> . for <method_3> with multiple tags , the <otherscientificterm_7> may overlap . current solutions are based on <method_8> using <method_9> -lrb- e.g. <method_11> and <method_6> -rrb- . this can be a time-consuming process . in this paper , it is shown how an <otherscientificterm_12> in combination with <method_4> can be used to separate multiple overlapping tag signals . the source signals are modeled as <material_1> , and the corresponding <method_10> are tested on <material_2> .	0 5 18 13 -1 3 7 13 -1 8 9 11 6 14 15 16 13 -1 13 -1 12 4 13 -1 1 10 2 17 13 -1
Joint power allocation based on link reliability for MIMO systems assisted by relay .	joint optimal power allocation ; convex optimization methods ; error probability ; cost function ; convex problem ; power parameters ; mimo systems ; optimization criterion ; pa scheme	<method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method>	7 0 2 ; 7 0 0 ; 7 0 6 ; 0 0 6	a new <method_7> is proposed to minimize <otherscientificterm_2> for the proposed <method_0> of the <method_6> enhanced by relay in this paper . it is proved that the <otherscientificterm_3> obtained is only convex with respect to -lrb- w.r.t. -rrb- the <otherscientificterm_5> of the source or those of the relay separately , but not convex w.r.t. the whole parameters . in order to use <method_1> with high efficiency to solve this complicated problem , a tight upper bound of the sum mse -lrb- mean squared error -rrb- is derived , and employed to modify the <otherscientificterm_3> in order to obtain a <task_4> . it is verified through simulation results that the proposed <method_8> outperforms the existing one .	7 2 0 6 10 11 12 13 9 -1 3 5 9 -1 1 4 9 -1 9 -1
Generalization Bounds for Learning Kernels .	convex combination of p base kernels ; non-negative combination of p base kernels ; l 2 regularization ; generalization bounds ; rademacher complexity ; learning kernels ; combinatorial analysis ; generalization error ; complexity	<method> <method> <method> <otherscientificterm> <metric> <task> <method> <otherscientificterm> <metric>	0 0 5 ; 3 0 5 ; 2 2 1	this paper presents several novel <otherscientificterm_3> for the problem of <task_5> based on a <method_6> of the <metric_4> of the corresponding hypothesis sets . our bound for <task_5> with a <method_0> using l 1 regular-ization admits only a √ log p dependency on the number of kernels , which is tight and considerably more favorable than the previous best bound given for the same problem . we also give a novel bound for learning with a <method_1> with an <method_2> whose dependency on p is also tight and only in p 1/4 . we present similar results for l q regular-ization with other values of q , and outline the relevance of our proof techniques to the analysis of the <metric_8> of the class of linear functions . experiments with a large number of kernels further validate the behavior of the <otherscientificterm_7> as a function of p predicted by our bounds .	3 5 6 4 11 9 -1 0 10 9 -1 1 2 12 9 -1 9 -1 8 9 -1
Experimental Support for a Categorical Compositional Distributional Model of Meaning .	unsupervised learning of matrices ; modelling compositional meaning ; abstract categorical model ; word disambiguation task ; empirical distributional methods ; intransitive sentences ; syntactic complexity ; computational linguists ; transitive sentences ; relational words ; bnc	<method> <task> <method> <task> <method> <material> <metric> <task> <material> <otherscientificterm> <material>	0 0 9 ; 4 0 1	modelling compositional meaning for sentences using <method_4> has been a challenge for <task_7> . we implement the <method_2> of coecke et al. -lrb- 2010 -rrb- using data from the <material_10> and evaluate <method_2> . the implementation is based on <method_0> for <otherscientificterm_9> and applying <method_0> to the vectors of their arguments . the evaluation is based on the <task_3> developed by mitchell and lapata -lrb- 2008 -rrb- for <material_5> , and on a similar new experiment designed for <material_8> . our model matches the results of its competitors in the first experiment , and betters <method_0> in the second . the general improvement in results with increase in <metric_6> show-cases the compositional power of our model .	4 7 13 11 -1 2 10 11 -1 0 9 12 11 -1 3 5 8 11 -1 11 -1 11 -1
Exploring the use of ENF for multimedia synchronization .	electric network frequency signal ; detecting forgery of enf-containing mul-timedia signals ; automatic synchronization of audio and video ; enf based synchronization approach ; multi-view video synchronization ; time-varying random process ; embedded enf signals ; multimedia recordings ; multimedia signals ; power grid ; forensic applications ; electromagnetic influences ; enf signals	<method> <task> <task> <method> <task> <method> <otherscientificterm> <material> <material> <otherscientificterm> <task> <otherscientificterm> <material>	12 0 2 ; 12 0 10	the <method_0> can be captured in <material_7> due to <otherscientificterm_11> from the <otherscientificterm_9> at the time of recording . recent work has exploited the <material_12> for <task_10> , such as authenticating and <task_1> , and inferring their time and location of creation . in this paper , we explore a new potential of <material_12> for <task_2> . the <material_12> as a <method_5> can be used as a timing fingerprint of <material_8> . synchronization of audio and video recordings can be achieved by aligning their <otherscientificterm_6> . we demonstrate the proposed scheme with two applications : <task_4> and synchronization of historical audio recordings . the experimental results show the <method_3> is effective , and has the potential to solve problems that are intractable by other existing methods .	0 7 11 9 13 -1 12 10 1 15 13 -1 2 14 13 -1 5 8 13 -1 6 13 -1 4 13 -1 13 -1
Error-Tolerant Scribbles Based Interactive Image Segmentation .	iterated graph cut algorithm ; foreground scribble pixels ; ratio energy function ; mobile touch-screen devices ; user input information ; scribble-based interactive segmentation ; user input ; graph-cut energy ; synthetic scribbles ; grabcut dataset ; manual scribbles ; image ; robustness ; scribbles ; graph-cut ; segmentation	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <material> <material> <material> <metric> <otherscientificterm> <otherscientificterm> <task>	8 1 10 ; 14 6 5 ; 8 5 2 ; 2 0 7 ; 0 0 2 ; 10 5 2 ; 12 5 2 ; 9 5 2	scribbles in <task_5> such as <otherscientificterm_14> are usually assumed to be perfectly accurate , i.e. , <otherscientificterm_1> will never be segmented as background in the final <task_15> . however , it can be hard to draw perfectly accurate <otherscientificterm_13> , especially on fine structures of the <material_11> or on <otherscientificterm_3> . in this paper , we propose a novel <method_2> that tolerates errors in the <otherscientificterm_6> while encouraging maximum use of the <otherscientificterm_4> . more specifically , the <method_2> aims to minimize the <otherscientificterm_7> while maximizing the <otherscientificterm_6> respected in the <task_15> . the <method_2> can be exactly optimized using an efficient <method_0> . the <metric_12> of the proposed <method_2> is validated on the <material_9> using both <material_8> and <material_10> . the experimental results show that the proposed <method_2> is robust to the errors in the <otherscientificterm_6> and preserves the '' anchoring '' capability of the <otherscientificterm_6> .	5 14 1 15 18 16 -1 13 11 3 16 -1 2 6 4 16 -1 7 20 16 -1 21 16 -1 0 17 19 22 23 24 16 -1 12 9 8 10 16 -1
Statistical Mapping Between Articulatory and Acoustic Data for an Ultrasound-Based Silent Speech Interface .	joint modeling of visual and spectral features ; artificial neural network ; gaussian mixture models ; hidden markov models ; tongue and lip motions ; continuous speech database ; visual articulatory data ; unit selection approach ; statistical mapping techniques ; video sequences ; voiced/unvoiced parameter ; video imaging ; audible speech ; speech sound ; mapping	<method> <method> <method> <method> <otherscientificterm> <material> <material> <method> <method> <material> <otherscientificterm> <task> <material> <material> <task>	2 1 3 ; 7 0 13 ; 5 0 8 ; 6 0 10	this paper presents recent developments on our '' silent speech interface '' that converts <otherscientificterm_4> , captured by ultrasound and <task_11> , into <material_12> . in our previous studies , the <task_14> between the observed articulatory movements and the resulting <material_13> was achieved using a <method_7> . we investigate here the use of <method_8> , based on the <method_0> , using respectively <method_2> and <method_3> . the prediction of the <otherscientificterm_10> from <material_6> is also investigated using an <method_1> . a <material_5> consisting of one-hour of high-speed ultrasound and <material_9> was specifically recorded to evaluate the proposed <method_8> .	4 11 12 15 -1 14 13 7 17 15 -1 8 0 2 3 16 15 -1 10 6 1 19 15 -1 5 9 18 15 -1
Analysis of Mixed Natural and Symbolic Input in Mathematical Dialogs .	deep syntactic and semantic analysis ; corpus of dialogs ; telegraphic natural language ; embedded -lrb- semi ; simulated tutorial system ; language phenomena ; formal domains ; discourse ; verbaliza-tion ; mathematics	<task> <material> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material>	4 0 5 ; 4 0 0 ; 9 6 6	discourse in <material_6> , such as <material_9> , is characterized by a mixture of <material_2> and <otherscientificterm_3> - -rrb- formal symbolic mathematical expressions . we present <otherscientificterm_5> observed in a <material_1> with a <method_4> for proving theorems as evidence for the need for <task_0> . we propose an approach to input understanding in this setting . our goal is a uniform analysis of inputs of different degree of <otherscientificterm_8> : ranging from symbolic alone to fully worded mathematical expressions .	6 9 2 3 13 10 -1 5 1 4 0 11 12 10 -1 10 -1 8 7 10 -1
Estimation of Talker 's Head Orientation Based on Discrimination of the Shape of Cross-power Spectrum Phase Coefficients .	csp -lrb- cross-power spectrum phase -rrb- coefficients ; talker 's head orientation estimation method ; talker 's head orientation ; microphone array network systems ; network of microphone arrays ; talker 's position ; head orientation estimation ; 2-channel microphones ; microphone array ; sub-microphone arrays ; sound amplitude ; csp coefficients ; peak value ; head orientation ; talker localization ; microphone arrays ; feature vectors ; csp vector ; reverberation	<otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	7 0 1 ; 5 1 13 ; 10 0 2 ; 14 0 1 ; 0 0 2 ; 14 1 6 ; 10 1 12 ; 15 0 3	this paper presents a <method_1> using <otherscientificterm_7> . in recent research , some approaches based on a <method_4> have been proposed in order to estimate the <otherscientificterm_2> . in those methods , the <otherscientificterm_2> is estimated using the <otherscientificterm_10> or <otherscientificterm_12> of <otherscientificterm_0> obtained from each <otherscientificterm_8> . however , <method_3> need many <otherscientificterm_15> to be set along the walls of a given room so that <otherscientificterm_9> surround the user . in this paper , we focus on the shape of the <otherscientificterm_11> affected by the <otherscientificterm_18> , which depends on the <otherscientificterm_5> and the <otherscientificterm_13> . in our proposed <method_1> , we use not only the <otherscientificterm_12> but also the other values of the <otherscientificterm_11> as <otherscientificterm_16> , and the <otherscientificterm_5> and the <otherscientificterm_13> are estimated by discriminating the <method_17> . the effectiveness of this <method_1> has been confirmed by <method_14> and <task_6> experiments performed in a real environment .	1 7 20 19 -1 4 2 19 -1 10 12 0 8 22 24 26 19 -1 3 15 9 27 19 -1 11 18 5 13 19 -1 21 19 -1 16 17 23 25 19 -1
Kernel Fukunaga-Koontz Transform Subspaces For Enhanced Face Recognition .	higher dimensional subspaces ; linear fukunaga-koontz transform ; discriminative subspaces building approach ; face recognition applications ; domain specific problems ; kernel fukunaga-koontz transform ; multi-class problem ; discrimination ability ; small-sample-size	<otherscientificterm> <method> <method> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm>	3 5 5 ; 5 0 4 ; 1 0 8 ; 1 6 2 ; 6 1 0	traditional <method_1> -lsb- 1 -rsb- is a powerful <method_2> . previous work has successfully extended <method_1> to be able to deal with <otherscientificterm_8> . in this paper , we extend traditional <method_1> to enable it to work in <task_6> and also in <otherscientificterm_0> and therefore provide enhanced <otherscientificterm_7> . we verify the effectiveness of the proposed <method_5> by demonstrating its effectiveness in <task_3> ; however the proposed <method_5> can be applied to any other <task_4> .	1 2 13 9 -1 8 12 9 -1 6 0 7 14 9 -1 5 3 4 10 11 9 -1
Data-specific concept correlation estimation for video annotation refinement .	data-specific concept correlation estimation procedure ; probability-calculation based video annotation refinement ; high-level concept correlation bases ; visual and high-level characteristics ; concept correlation basis estimation ; data-specific concept correlation calculation ; trecvid 2006 dataset ; video annotation refinement ; feature-level sparse coefficients ; generic concept correlation ; concept correlation representation ; concept distribution ; data-specific characteristics ; sparse representation ; correlation bases	<method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	8 1 14 ; 6 0 1 ; 2 0 13 ; 4 3 0 ; 2 0 11 ; 4 1 5 ; 10 0 7	for <task_7> , a reasonable <method_10> is crucial . in this paper , we present a <method_0> for this task , where the resulting correlation with respect to each data encodes both its <otherscientificterm_3> . specifically , this <method_0> comprises two major modules : <method_4> and <method_5> . under the framework of <method_13> , the <method_0> introduces a set of <otherscientificterm_2> to represent the <otherscientificterm_11> of each feature-level basis , while the latter constructs the concept correlation of a specific data by combining its <otherscientificterm_8> and <otherscientificterm_14> together . in the end , given this new correlation , a <method_1> is performed on <material_6> . the experiments show that such a representation capturing <otherscientificterm_12> could achieve better performance , than the <otherscientificterm_9> applied to all data .	7 10 22 15 -1 0 3 15 -1 4 5 19 21 15 -1 13 2 11 8 14 16 18 20 15 -1 1 17 15 -1 6 15 -1
Fast Trust Region for Segmentation .	fast trust region approach ; non-linear -lrb- more accurate -rrb- approximation model ; optimization of segmentation energies ; constrained optimization algorithm ; target appearance distributions ; shape prior constraint ; non-linear regional terms ; nonlinear approximation models ; gradient descent techniques ; approximation model ; volume constraint ; segment size ; bhattacharyya distance ; global optimum ; trust region ; kl divergence ; iterative approach ; optimization	<method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	0 0 2 ; 16 4 8 ; 3 0 1 ; 6 2 2	trust region is a well-known general <method_16> to <task_17> which offers many advantages over standard <method_8> . in particular , it allows more accurate <method_7> . in each iteration this approach computes a <otherscientificterm_13> of a suitable <method_9> within a fixed radius around the current solution , a.k.a. trust region . in general , this approach can be used only when some efficient <method_3> is available for the selected <method_1> . in this paper we propose a <method_0> for <task_2> with <otherscientificterm_6> , which are known to be challenging for existing algorithms . these <otherscientificterm_6> include , but are not limited to , <otherscientificterm_15> and <otherscientificterm_12> between the observed and the <otherscientificterm_4> , <otherscientificterm_10> on <otherscientificterm_11> , and <otherscientificterm_5> in a form of l 2 distance from target shape moments . our method is 1-2 orders of magnitude faster than the existing state-of-the-art methods while converging to comparable or better solutions .	16 17 8 20 18 -1 7 18 -1 13 9 18 -1 3 1 21 18 -1 0 2 6 19 22 18 -1 18 -1 15 12 4 10 11 5 18 -1
Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators .	kernel cross-spectral density operator ; stationary time-series of arbitrary objects ; electrophysiological neural time series ; arbitrary input domains ; positive definite kernels ; complex data structures ; independence test ; dynamical systems ; detection errors ; random variables ; hsic test ; similarity measure ; coupling ; graphs	<method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <metric> <otherscientificterm> <material> <metric> <task> <otherscientificterm>	11 0 2 ; 11 0 12 ; 4 0 0	many applications require the analysis of complex interactions between time series . these interactions can be non-linear and involve vector valued as well as <otherscientificterm_5> such as <otherscientificterm_13> or strings . here we provide a general framework for the statistical analysis of these dependencies when <otherscientificterm_9> are sampled from <otherscientificterm_1> . to achieve this goal , we study the properties of the <method_0> induced by <otherscientificterm_4> on <otherscientificterm_3> . this framework enables us to develop an <metric_6> between time series , as well as a <metric_11> to compare different types of <task_12> . the performance of our test is compared to the <material_10> using i.i.d. assumptions , showing strong improvements in terms of <metric_8> , as well as the suitability of this approach for testing dependency in complex <method_7> . this <metric_11> enables us to identify different types of interactions in <task_2> .	14 -1 5 13 14 -1 9 1 14 -1 0 4 3 17 14 -1 6 11 12 16 14 -1 14 -1 10 8 7 15 14 -1
Connotation Lexicon : A Dash of Sentiment Beneath the Surface Meaning .	semantic parallelism of coordination ; nuanced , connotative sentiments ; connotation of words ; broad-coverage connotation lexicon ; semantic prosody ; distri-butional similarity ; induction algorithms ; lexical resources ; prior knowledge	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	4 1 5 ; 5 1 0 ; 5 1 5 ; 0 1 8	understanding the <otherscientificterm_2> plays an important role in interpreting subtle shades of sentiment beyond denotative or surface meaning of text , as seemingly objective statements often allude nuanced sentiment of the writer , and even purposefully conjure emotion from the readers ' minds . the focus of this paper is drawing <otherscientificterm_1> from even those words that are objective on the surface , such as '' intelligence '' , '' human '' , and '' cheesecake '' . we propose <method_6> encoding a diverse set of linguistic insights -lrb- <otherscientificterm_4> , <otherscientificterm_5> , <otherscientificterm_0> -rrb- and <otherscientificterm_8> drawn from <material_7> , resulting in the first <material_3> .	2 9 -1 1 9 -1 6 4 5 0 8 7 10 11 12 13 9 -1
MPMA : Mixture Probabilistic Matrix Approximation for Collaborative Filtering .	mixture probabilistic matrix approximation method ; collaborative filtering ; matrix approximation ; locally optimized user/item feature vectors ; movielens and netflix datasets ; ma based cf methods ; global latent factors ; user-item rating matrix ; gaus-sian mixture model ; user/item latent factors ; recommendation accuracy ; local predictions ; global predictions ; latent factors ; ma methods ; rating matrix ; user/item ratings ; users/items ; user/item	<method> <task> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	14 0 9 ; 7 0 9 ; 12 1 11 ; 4 5 0 ; 6 0 17 ; 0 4 5 ; 4 5 5 ; 10 5 5 ; 10 5 0 ; 7 0 14	matrix approximation -lrb- ma -rrb- is one of the most popular techniques for <task_1> . most existing <method_14> train <otherscientificterm_9> based on a <otherscientificterm_7> and then use the <otherscientificterm_6> to model all <otherscientificterm_17> . however , globally optimized <otherscientificterm_13> may not reflect the unique interests shared among only subsets of <otherscientificterm_17> , without which unique interests of users may not be accurately modelled . as a result , existing <method_14> , which can not capture the uniqueness of different <otherscientificterm_18> , can not provide optimal recommendation . in this paper , a <method_0> is proposed , which unifies globally optimized <otherscientificterm_18> feature vectors -lrb- on the entire <method_15> -rrb- and <otherscientificterm_3> -lrb- on subsets of <otherscientificterm_16> -rrb- to improve <metric_10> . more specifically , in <method_0> , a method is developed to find both globally and <otherscientificterm_3> . then , a <method_8> is adopted to combine <otherscientificterm_12> and <otherscientificterm_11> to produce accurate rating predictions . experimental study using <material_4> demonstrates that <method_0> outperforms five state-of-the-art <method_5> in <metric_10> with good scalability .	1 19 -1 14 9 7 6 17 20 21 24 29 19 -1 13 19 -1 18 19 -1 0 19 -1 15 3 16 10 19 -1 22 19 -1 8 12 11 23 25 26 27 28 19 -1
Sequential Spectral Learning to Hash with Multiple Representations .	approximate k-nn graph construction method ; α-averaging view-specific distance matrices ; similarity-preserving low-dimensional hamming space ; sequential spectral learning approach ; recursive spectral bisection ; single-view spectral hashing ; multi-view local variances ; averaged distance matrix ; multi-view hashing methods ; view-specific distance matrices ; high-dimensional visual descriptors ; visual descriptors ; small partitions ; α-averaged distances ; hash function ; multi-view hashing ; local variances ; hash functions ; decorrelation constraints ; nus-wide datasets ; binary codes ; learning ; sift ; images ; gist	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <method> <material> <method>	11 0 20 ; 22 6 11 ; 3 4 8 ; 24 6 11 ; 22 1 24 ; 19 5 3 ; 1 0 6 ; 7 0 6 ; 4 0 13 ; 5 1 8 ; 11 0 14 ; 3 0 15 ; 23 0 17 ; 23 0 10 ; 4 0 12	learning to hash involves learning <otherscientificterm_17> from a set of <material_23> for embedding <otherscientificterm_10> into a <otherscientificterm_2> . most of existing methods resort to a single representation of <material_23> , that is , only one type of <otherscientificterm_11> is used to learn a <otherscientificterm_14> to assign <otherscientificterm_20> to <material_23> . however , <material_23> are often described by multiple different <otherscientificterm_11> -lrb- such as <method_22> , <method_24> , hog -rrb- , so it is desirable to incorporate these multiple representations into learning a <otherscientificterm_14> , leading to <task_15> . in this paper we present a <method_3> to <task_15> where a <otherscientificterm_14> is sequentially determined by solving the successive maximiza-tion of <otherscientificterm_16> subject to <otherscientificterm_18> . we compute <otherscientificterm_6> by <otherscientificterm_1> such that the best <otherscientificterm_7> is determined by minimizing its α-divergence from <otherscientificterm_9> . we also present a scalable implementation , exploiting a fast <method_0> , in which <otherscientificterm_13> computed in <otherscientificterm_12> determined by <otherscientificterm_4> are gradually merged in conquer steps until whole examples are used . numerical experiments on caltech-256 , cifar-20 , and <material_19> confirm the high performance of our <method_3> , in comparison to <task_5> as well as existing <method_8> .	17 23 10 2 38 39 25 -1 11 14 20 26 36 25 -1 22 24 15 27 29 30 25 -1 3 37 25 -1 16 18 32 33 25 -1 6 1 7 9 34 40 25 -1 0 13 12 4 28 31 35 25 -1
Transform-invariant Image Decomposition with Similarity Templates .	class-specific image set ; pixel-wise similarities ; similarity templates ; transform-invariant modeling ; object class ; pedestrian images ; clustering	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method>	3 1 6	recent work has shown impressive <method_3> and <method_6> for sets of images of objects with similar appearance . we seek to expand these capabilities to sets of images of an <otherscientificterm_4> that show considerable variation across individual instances -lrb- e.g. <material_5> -rrb- using a representation based on <otherscientificterm_1> , <otherscientificterm_2> . because of its invariance to the colors of particular components of an object , this representation enables detection of instances of an <otherscientificterm_4> and enables alignment of those instances . further , this model implicitly represents the regions of color regularity in the <otherscientificterm_0> enabling a decomposition of that <otherscientificterm_4> into component regions .	3 6 8 7 -1 4 5 1 2 7 -1 7 -1 0 7 -1
On the Optimality of Classifier Chain for Multi-label Classification .	greedy classifier chain algorithm ; classifier chain ; deterministic high-order markov chain model ; real-world multi-label data sets ; globally optimal label order ; random label order ; optimal label order ; multi-label classification problems ; cc-dp algorithm ; generalization error ; cc-dp	<method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method>	6 0 1 ; 3 5 8 ; 9 0 2 ; 5 0 1 ; 8 4 8 ; 10 5 8	to capture the interdependencies between labels in <task_7> , <method_1> tries to take the multiple labels of each instance into account under a <method_2> . since its performance is sensitive to the choice of label order , the key issue is how to determine the <otherscientificterm_6> for <method_1> . in this work , we first generalize the <method_1> over a <otherscientificterm_5> . then , we present a theoretical analysis of the <otherscientificterm_9> for the proposed <method_2> . based on our results , we propose a dynamic programming based classifier chain -lrb- <method_10> -rrb- algorithm to search the <otherscientificterm_4> for <method_1> and a <method_0> to find a locally optimal <method_1> . comprehensive experiments on a number of <material_3> from various domains demonstrate that our proposed <method_8> outperforms state-of-the-art approaches and the <method_8> achieves comparable prediction performance with <method_10> .	7 1 2 11 -1 6 12 11 -1 5 15 11 -1 9 14 11 -1 10 4 11 -1 0 13 16 17 11 -1
Self-taught clustering .	co-clustering based self-taught clustering algorithm ; <i> unsupervised transfer learning </i> ; <i> auxiliary </i> unlabeled data ; irrelevant unlabeled auxiliary data ; target and auxiliary data ; <i> self-taught clustering </i> ; topic distribution ; auxiliary data ; clustering task ; self-taught clustering ; image clustering ; feature representation ; clustering methods ; features ; clustering	<method> <method> <material> <material> <material> <method> <task> <material> <task> <method> <task> <method> <method> <otherscientificterm> <method>	0 4 12 ; 5 6 8 ; 4 0 11	this paper focuses on a new <task_8> , called <method_5> . <method_9> is an instance of <method_1> , which aims at <method_14> a small collection of target unlabeled data with the help of a large amount of <material_2> . the <material_4> can be different in <task_6> . we show that even when the target data are not sufficient to allow effective learning of a high quality <method_11> , it is possible to learn the useful <otherscientificterm_13> with the help of the <material_7> on which the target data can be clustered effectively . we propose a <method_0> to tackle this problem , by <method_14> the <material_4> simultaneously to allow the <method_11> from the <material_7> to influence the target data through a common set of <otherscientificterm_13> . under the new <method_11> , <method_14> on the target data can be improved . our experiments on <task_10> show that our <method_0> can greatly outperform several state-of-the-art <method_12> when utilizing <material_3> .	8 5 9 17 15 -1 1 14 2 15 -1 4 6 15 -1 11 13 7 15 -1 0 18 15 -1 15 -1 16 15 -1
A Machine Learning Approach to the Automatic Evaluation of Machine Translation .	human reference translations ; machine translation system ; machine learning approach ; machine translations ; failure analysis ; classifiers	<task> <method> <method> <otherscientificterm> <method> <method>	0 0 3 ; 2 0 1 ; 5 0 0	we present a <method_2> to evaluating the well-formedness of output of a <method_1> , using <method_5> that learn to distinguish <task_0> from <otherscientificterm_3> . this <method_2> can be used to evaluate an <method_1> , tracking improvements over time ; to aid in the kind of <method_4> that can help guide system development ; and to select among alternative output strings . the <method_2> presented is fully automated and independent of source language , target language and domain .	2 1 5 0 3 7 9 6 -1 4 8 6 -1 6 -1
Adaptive listening room equalization using a scalable filtering structure in thewave domain .	wave field synthesis ; wave-domain adaptive filtering ; listening room equalization ; massive multichannel reproduction systems ; computational and algorithmic reasons ; adap-tive filtering tasks ; listener positions ; reproduction channels ; reproduction scenarios ; filtering structures ; adaptive lre ; robustness	<method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <material> <task> <task> <method> <metric>	1 0 5 ; 0 6 3 ; 1 0 8 ; 2 0 3 ; 10 0 8 ; 10 0 9	massive multichannel reproduction systems like <method_0> are potentially well suited to be complemented by <method_2> . however , their typically large number of <material_7> makes this task challenging for both <otherscientificterm_4> . <method_1> was proposed earlier and is especially well-suited to <task_5> in the context of <method_0> . in this paper , we propose to generalize the model originally used for <method_1> to allow an <method_10> for a broader range of <task_8> , while maintaining the advantages of the original <method_10> . the proposed <method_10> is evaluated for <task_9> of varying complexity along with considering the <metric_11> to varying <otherscientificterm_6> .	0 2 14 16 12 -1 7 4 1 12 -1 5 13 12 -1 10 8 15 17 12 -1 9 11 6 18 12 -1
Reflection methods for user-friendly submodular optimization .	de-composability of submodular functions ; discrete submodular minimization problem ; continuous best approximation problem ; image segmentation tasks ; parameter tuning ; machine learning ; computer vision ; optimization procedures ; submodu-lar functions ; minimization problems ; signal processing ; reconstruction ; inference ; learning ; submodularity	<otherscientificterm> <task> <task> <task> <method> <task> <task> <method> <otherscientificterm> <task> <task> <task> <task> <task> <otherscientificterm>	10 1 6 ; 7 0 9 ; 12 1 11 ; 13 1 12 ; 14 0 10 ; 7 0 8 ; 5 1 10 ; 14 0 5	recently , it has become evident that <otherscientificterm_14> naturally captures widely occurring concepts in <task_5> , <task_10> and <task_6> . consequently , there is need for efficient <method_7> for <otherscientificterm_8> , especially for <task_9> . while general submodular minimization is challenging , we propose a new method that exploits existing <otherscientificterm_0> . in contrast to previous approaches , our method is neither approximate , nor impractical , nor does it need any cumbersome <method_4> . moreover , it is easy to implement and parallelize . a key component of our method is a formulation of the <task_1> as a <task_2> that is solved through a sequence of reflections , and its solution can be easily thresholded to obtain an optimal discrete solution . this method solves both the continuous and discrete formulations of the <task_1> , and therefore has applications in <task_13> , <task_12> , and <task_11> . in our experiments , we illustrate the benefits of our method on two <task_3> .	14 5 10 6 16 20 22 23 15 -1 7 8 9 17 21 15 -1 0 15 -1 4 15 -1 15 -1 1 2 15 -1 18 19 15 -1 13 12 11 15 -1
On the relevance of bandwidth extension for speaker verification .	covariance matrix based verification systems ; microphone and isdn speech databases ; detection error trade-off curves ; short-time spectral parameterizations ; short-time spectral parameterization ; mel-frequency cepstral coefficients ; speaker verification task ; bandwidth-extended speech ; narrow-band speech ; speaker verification ; bandwidth-extension algorithm ; model order ; verification system	<method> <material> <otherscientificterm> <method> <task> <otherscientificterm> <task> <material> <material> <task> <method> <otherscientificterm> <method>	12 0 8 ; 2 1 0 ; 5 0 4 ; 12 0 6 ; 5 0 8 ; 1 0 3	in this paper , we consider the effect of a bandwidth extension of <material_8> signals -lrb- 0.3-3 .4 khz -rrb- to 0.3-8 khz on <task_9> . using <method_0> together with <otherscientificterm_2> , we compare the performance between systems operating on narrow-band , wide-band -lrb- 0-8 khz -rrb- , and <material_7> . the experiments were conducted using different <method_3> derived from <material_1> . the studied <method_10> did not introduce artifacts that affected the <task_6> , and we achieved improvements between 1 and 10 percent -lrb- depending on the <otherscientificterm_11> -rrb- over the <method_12> designed for <material_8> when <otherscientificterm_5> for the <task_4> were used .	8 9 13 -1 0 2 7 15 13 -1 3 1 19 13 -1 10 6 11 12 5 4 14 16 17 18 13 -1
A sparse representation approach for perceptual quality improvement of separated speech .	perceptual evaluation of speech quality ; short-time fourier transform magnitudes ; intelligibility of speech signals ; clean speech dictionary ; binary-masked noisy speech ; speech quality measure ; binary mask ; speech separation ; separated speech ; time-frequency masking ; reconstruction approaches ; speech separation ; perceptual quality ; sparse-representation approach ; separated signal ; speech quality ; speech signal ; binary masking ; overlap-and-add synthesis	<method> <otherscientificterm> <task> <material> <material> <metric> <otherscientificterm> <task> <material> <method> <method> <task> <metric> <method> <otherscientificterm> <metric> <otherscientificterm> <task> <method>	4 1 10 ; 9 0 7 ; 13 0 14 ; 6 0 11 ; 7 0 2 ; 15 5 4 ; 15 5 10	speech separation based on <method_9> has been shown to improve <task_2> corrupted by noise . a perceived weakness of <task_17> is the quality of <material_8> . in this paper , an approach for improving the <metric_12> of <material_8> from <task_17> is proposed . our approach consists of two stages , where a <otherscientificterm_6> is generated in the first stage that effectively performs <task_11> . in the second stage , a <method_13> is used to represent the <otherscientificterm_14> by a linear combination of <otherscientificterm_1> that are generated from a <material_3> . <method_18> is then used to generate an estimate of the <otherscientificterm_16> . the performance of the proposed approach is evaluated with the <method_0> , which is a standard objective <metric_5> . the proposed algorithm offers considerable improvements in <metric_15> over <material_4> and other <method_10> .	9 2 21 24 19 -1 17 8 19 -1 12 19 -1 6 11 23 19 -1 13 14 1 3 18 22 19 -1 19 -1 16 19 -1 0 5 20 25 26 19 -1
It Makes Sense : A Wide-Coverage Word Sense Disambiguation System for Free Text .	word sense disambiguation systems ; supervised english all-words wsd system ; sense-val and semeval workshops ; senseval and semeval tasks ; linear support vector machines ; knowledge-based features ; supervised learning ; preprocessing tools ; features ; ims ; classifier ; classifiers	<method> <method> <material> <material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method>	2 5 0 ; 9 0 7 ; 3 5 9 ; 7 3 9 ; 4 0 10 ; 8 1 11 ; 5 0 10 ; 9 6 1 ; 6 0 0	word sense disambiguation -lrb- <method_0> -rrb- systems based on <method_6> achieved the best performance in <material_2> . however , there are few publicly available <method_1> . this limits the use of <method_0> in other applications , especially for researchers whose research interests are not in <method_0> . in this paper , we present <method_9> , a <method_1> . the flexible framework of <method_9> allows users to integrate different <method_7> , additional <otherscientificterm_8> , and different <method_11> . by default , we use <method_4> as the <method_10> with multiple <otherscientificterm_5> . in our implementation , <method_9> achieves state-of-the-art results on several <material_3> .	0 6 2 13 21 12 -1 1 12 -1 12 -1 9 20 12 -1 7 8 11 14 16 18 12 -1 4 10 5 17 19 12 -1 15 12 -1
Shape classification through structured learning of matching measures .	structured prediction setting ; shape similarity scores ; shape databases ; point correspondences ; classification loss ; similarity measures ; shape classification ; learning techniques ; max-margin formulation ; classifier	<method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <method>	8 0 0 ; 5 0 6	many traditional methods for <task_6> involve establishing <otherscientificterm_3> between shapes to produce matching scores , which are in turn used as <method_5> for <task_6> . <method_7> have been applied only in the second stage of this process , after the matching scores have been obtained . in this paper , instead of simply taking for granted the scores obtained by matching and then learning a <method_9> , we learn the matching scores themselves so as to produce <otherscientificterm_1> that minimize the <otherscientificterm_4> . the solution is based on a <method_8> in the <method_0> . experiments in <material_2> reveal that such an integrated learning algorithm substantially improves on existing methods .	6 3 5 7 12 10 -1 10 -1 9 1 4 10 -1 8 0 11 10 -1 2 10 -1
Distributed principal component analysis on networks via directed graphical models .	distributed principal component analysis ; inverse covariance matrix ; directed gaussian graphical models ; online principal subspace estimation ; global principal subspace estimation ; real-world computer networks ; distributed anomaly detection ; structured sparsity ; message passing ; local computation ; cholesky factor	<task> <method> <method> <task> <task> <method> <task> <otherscientificterm> <material> <otherscientificterm> <method>	9 1 8 ; 7 0 1 ; 7 0 10	we introduce an efficient algorithm for performing <task_0> on <method_2> . by exploiting <otherscientificterm_7> in the <method_10> of the <method_1> , our proposed ddpca algorithm computes <task_4> through <otherscientificterm_9> and <material_8> . we show significant performance and computation/communication advantages of ddpca for <task_3> and <task_6> in <method_5> .	0 2 11 -1 7 10 1 4 9 8 12 13 14 11 -1 3 6 5 11 -1
Panel : Good Spelling of Vietnamese Texts , One Aspect of Computational Linguistics in Vietnam .	vietnamese language processing ; telex code ; spelling correction ; spelling database ; vietools	<task> <otherscientificterm> <task> <method> <method>	1 0 3 ; 4 0 0	there are many challenging problems for <task_0> . it will be a long time before these challenges are met . even some apparently simple problems such as <task_2> are quite difficult and have not been approached systematically yet . in this paper , we will discuss one aspect of this type of work : designing the so-called <method_4> to detect and correct spelling of vietnamese texts by using a <method_3> based on <otherscientificterm_1> . <method_4> is also extended to serve many purposes in <task_0> .	0 5 -1 5 -1 2 5 -1 4 3 1 6 5 -1 7 5 -1
Tables for practical Wyner-Ziv coding of Laplacian sources .	source and channel coding ; wyner-ziv coding problem ; general encoding model ; multi-level coset codes ; transform coefficients ; rate-distortion trade-offs ; encoding parameters ; correlated side-information ; quantizer family ; regular codec ; side-information ; laplacians ; decoder	<method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method>	7 0 12 ; 7 0 1	many practical coding scenarios deal with sources with <otherscientificterm_4> that are well modeled as <method_11> . for the <task_1> for such sources when <otherscientificterm_7> is available at the <method_12> , the <otherscientificterm_10> is modeled as obtained by independent additive laplacian or gaussian innovation on the source . this paper deals with the optimal choice of <otherscientificterm_6> for practical wyner-ziv coding in such scenarios , using the same <method_8> as in the <otherscientificterm_9> to cover a range of <otherscientificterm_5> , given the variances of the source and innovation . using our prior analysis of a <method_2> based on <otherscientificterm_3> combining <method_0> , we present comprehensive tables with optimal <otherscientificterm_6> . these tables can be readily incorporated into a practical codec to read off the <otherscientificterm_6> .	4 11 13 -1 1 7 12 10 14 15 13 -1 6 8 9 5 13 -1 2 3 0 13 -1 13 -1
Personalized Tag Recommendation through Nonlinear Tensor Factorization Using Gaussian Kernel .	nonlinear extension of canonical decomposition ; gaus-sian radial basis function ; personalized tag recommendation systems ; linear tensor factorization ; personal-ized tag recommendation ; tensor factorization techniques ; canonical decomposition ; computation power ; linear time ; tucker decomposition ; tag recommendation ; online recommendation ; real datasets ; features	<method> <otherscientificterm> <method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <material> <otherscientificterm>	1 0 2 ; 8 2 6	personalized <otherscientificterm_10> systems recommend a list of tags to a user when he is about to annotate an item . it exploits the individual preference and the characteristic of the items . <method_5> have been applied to many applications , such as <otherscientificterm_10> . models based on <method_9> can achieve good performance but require a lot of <otherscientificterm_7> . on the other hand , models based on <method_6> can run in <otherscientificterm_8> and are more feasible for <task_11> . in this paper , we propose a novel method for <task_4> , which can be considered as a <method_0> . different from <method_3> , we exploit <otherscientificterm_1> to increase the <method_2> 's capacity . the experimental results show that our proposed method outperforms the state-of-the-art methods for <otherscientificterm_10> on <material_12> and perform well even with a small number of <otherscientificterm_13> , which verifies that our models can make better use of <otherscientificterm_13> .	10 14 -1 5 14 -1 14 -1 9 7 14 -1 6 8 11 16 14 -1 4 0 14 -1 15 14 -1 3 1 2 14 -1
Highlight Removal by Illumination-Constrained Inpainting .	estimation of the underlying diffuse color ; recovery of shading and textures ; single-image highlight removal method ; illumination color uniformity ; highlight color analysis ; occluded image regions ; highlight pixels ; illumination-based constraints ; pixel colors ; image in-painting ; illumination constraints	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	9 0 1 ; 7 3 9 ; 2 0 9 ; 4 1 3 ; 10 0 2 ; 2 0 0 ; 8 1 4 ; 10 0 1	we present a <method_2> that incorporates <otherscientificterm_7> into <task_9> . unlike <otherscientificterm_5> filled by traditional <task_9> , <otherscientificterm_6> contain some useful information for guiding the <task_9> . <otherscientificterm_10> provided by observed <otherscientificterm_8> , <otherscientificterm_4> and <otherscientificterm_3> are employed in our <method_2> to improve <otherscientificterm_0> . the inclusion of these <otherscientificterm_10> allows for better <otherscientificterm_1> by <task_9> . experimental results are given to demonstrate the performance of our <method_2> .	2 7 9 13 14 11 -1 5 6 10 11 -1 8 4 3 0 15 16 17 18 11 -1 1 12 19 11 -1 11 -1
An adaptive lighting correction method for matched-texture coding .	side-matching algorithm ; adaptive poisson lighting correction ; adaptive lighting correction method ; structural texture similarity metric ; structurally lossless compression ; incomplete boundary conditions ; matched-texture coding ; image coder ; natural images ; encoded blocks ; illumination artifacts ; poisson equation ; textures	<method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 2 11 ; 11 0 2 ; 0 1 3 ; 6 6 7	matched-texture coding is a novel <method_7> that utilizes the self-similarity of <material_8> that include <otherscientificterm_12> , in order to achieve <otherscientificterm_4> . the key to a high compression ratio is replacing large image blocks with previously <otherscientificterm_9> with similar structure . adjusting the lighting of the replaced block is critical for eliminating <otherscientificterm_10> and increasing the number of matches . we propose a new <method_2> that is based on the <otherscientificterm_11> with <otherscientificterm_5> . in order to fully exploit the benefits of the <method_1> , we also propose modifications of the <method_0> and <metric_3> . we show that the resulting <method_2> achieves better coding performance .	7 8 12 4 17 13 -1 9 13 -1 10 13 -1 2 11 5 14 15 13 -1 1 0 3 16 13 -1 13 -1
Toward robust learning of the Gaussian mixture state emission densities for hidden Markov models .	hidden markov model ; gaussian mixture state emission densities ; gaussian mixture densities ; gradient descent search ; state emission densities ; insufficient training data ; boosting baum-welch algorithm ; probability density estimation ; baum-welch algorithm ; ensemble framework ; function space ; learning algorithm ; emotion recognition ; free parameters	<method> <otherscientificterm> <otherscientificterm> <method> <metric> <material> <method> <task> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm>	8 0 2 ; 10 2 3 ; 9 0 7	one important class of <metric_4> of the <method_0> is the <otherscientificterm_2> . the classical <method_8> often fails to reliably learn the <otherscientificterm_2> when there is <material_5> , due to the large number of <otherscientificterm_13> present in the model . in this paper , we propose a novel strategy for robustly and accurately learning the <otherscientificterm_1> of the <method_0> . the strategy is based on an <method_9> for <task_7> in which the learning of the <otherscientificterm_2> is formulated as a <method_3> in a <otherscientificterm_10> . the resulting <method_11> is called '' the <method_6> . '' our preliminary experiment results on <task_12> from speech show that the proposed algorithm outperforms the original <method_8> on this task .	4 0 2 14 -1 8 5 13 15 14 -1 1 14 -1 9 7 3 10 16 17 14 -1 11 6 14 -1 12 14 -1
In Defence of RANSAC for Outlier Rejection in Deformable Registration .	robust estimation of non-rigid deformations ; optimisation of fully deformable models ; ransac-driven deformable registration technique ; synthetic and real data ; accurate outlier rejection ; error bounds ; physical deformations ; feature correspondences ; low-dimensional hy-perplane ; manifold	<task> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 0 0 ; 1 0 2 ; 8 0 9	this paper concerns the <task_0> from <otherscientificterm_7> . we advance the surprising view that for many realistic <otherscientificterm_6> , the error of the mismatches -lrb- outliers -rrb- usually dwarfs the effects of the curvature of the <otherscientificterm_9> on which the correct matches -lrb- inliers -rrb- lie , to the extent that one can tightly enclose the <otherscientificterm_9> within the <otherscientificterm_5> of a <otherscientificterm_8> for <task_4> . this justifies a simple <method_2> that is at least as accurate as other methods based on the <method_1> . we support our ideas with comprehensive experiments on <material_3> typical of the deformations examined in the literature .	0 7 11 10 -1 6 9 5 8 4 13 10 -1 2 1 12 10 -1 3 10 -1
Robust talking face video verification using joint factor analysis and sparse representation on GMM mean shifted supervectors .	universal background model ; gaussian mixture models ; posteriori adapted model ; banca talking face video database ; video based talking face verification ; block wise local features ; gmm mean shifted supervector ; gmm mean shifted su-pervectors ; joint factor analysis ; gmm-ztnorm baseline system ; relative error reduction ; l 1-minimization ; quadratic constraints ; facial expressions ; sparse representation ; recording devices ; lighting conditions ; error rate ; gmm-ztnorm baseline ; session variabilities ; over-complete dictionary ; p protocol ; complexity ; robustness	<method> <method> <method> <material> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <material> <otherscientificterm> <material> <method> <metric> <metric>	16 1 13 ; 12 2 11 ; 8 0 19 ; 5 1 1 ; 21 2 3 ; 23 5 9 ; 22 1 23 ; 1 0 4 ; 15 1 16 ; 11 0 14 ; 10 5 18 ; 20 0 6	it has been previously demonstrated that systems based on <otherscientificterm_5> and <method_1> are suitable for <task_4> due to the best trade-off in terms of <metric_22> , <metric_23> and performance . in this paper , we propose two methods to enhance the <metric_23> and performance of the <method_9> . first , <method_8> is performed to compensate the <otherscientificterm_19> due to different <otherscientificterm_15> , <otherscientificterm_16> , <otherscientificterm_13> , etc. . second , the difference between the <method_0> and the maximum a <method_2> is mapped into the <method_6> whose <material_20> becomes more incoherent . then , for verification purpose , the <method_14> computed by <method_11> with <otherscientificterm_12> is employed to model these <otherscientificterm_7> . experimental results show that the proposed system achieved 8.4 % -lrb- group 1 -rrb- and 10.5 % -lrb- group 2 -rrb- equal <metric_17> on the <material_3> following the <method_21> and outperformed the <material_18> by yielding more than 20 % <metric_10> .	5 1 4 22 23 28 31 32 24 -1 9 30 24 -1 8 19 15 16 13 25 27 33 24 -1 0 2 6 20 36 24 -1 14 26 34 24 -1 11 12 7 29 35 24 -1
Manifold Identification of Dual Averaging Methods for Regularized Stochastic Online Learning .	large or streaming data sets ; regularized dual averaging algorithm ; approximate subgradient directions ; nonsmooth regularization term ; stochastic learning problems ; near-optimal manifold ; low-dimensional manifold ; algorith-mic strategy ; loss function ; full space ; near-optimal point ; intrinsic dimension ; iterative methods ; manifold	<material> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	5 0 7 ; 1 0 13 ; 2 0 12 ; 12 0 4	iterative methods that take steps in <otherscientificterm_2> have proved to be useful for <task_4> over <material_0> . when the objective consists of a <otherscientificterm_8> plus a <otherscientificterm_3> , whose purpose is to induce structure -lrb- for example , spar-sity -rrb- in the solution , the solution often lies on a <otherscientificterm_6> along which the regularizer is smooth . this paper shows that a <method_1> can identify this <otherscientificterm_13> with high probability . this observation motivates an <method_7> in which , once a <otherscientificterm_5> is identified , we switch to an <method_1> that searches only in this <otherscientificterm_13> , which typically has much lower <otherscientificterm_11> than the <otherscientificterm_9> , thus converging quickly to a <otherscientificterm_10> with the desired structure . computational results are presented to illustrate these claims .	2 4 0 17 18 14 -1 8 3 6 14 -1 1 13 14 -1 7 5 15 16 14 -1 11 9 10 14 -1
A statistical segment-based approach for spoken language understanding .	corpus of unaligned pairs of sentences ; decoding of user utterances ; statistical language understanding models ; railway information retrieval ; variable-length word segments ; spoken dialog system ; semantic representation ; understanding component ; semantic units ; corpus-based approaches ; spanish	<material> <otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <material>	0 0 2 ; 5 0 3	in this paper we propose an algorithm to learn <method_2> from a <material_0> and their corresponding <method_6> . specifically , it allows to automatically map <otherscientificterm_4> with their corresponding <otherscientificterm_8> and thus , the <otherscientificterm_1> to their corresponding meanings . in this way we avoid the time consuming work of manually associate semantic labels to words , process which is needed by almost all the <method_9> . we use the algorithm to learn the <method_7> of a <method_5> for <task_3> in <material_10> . experiments show that the results obtained with the proposed method are very promising , whereas the effort employed to obtain the models is not comparable with this of manually segment the training corpus .	2 0 6 12 11 -1 4 8 1 11 -1 9 11 -1 7 5 3 10 13 11 -1 11 -1
Multi-cue Visual Tracking Using Robust Feature-Level Fusion Based on Joint Sparse Representation .	joint sparse representation model ; multi-cue visual tracking ; robust feature-level fusion ; fusion-based trackers ; sparse representation ; unreliable features ; video sequence ; tracking ; pose ; illumination ; feature ; occlusion	<method> <task> <task> <method> <method> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 7 ; 11 1 8 ; 0 0 2 ; 0 0 1 ; 9 1 11	the use of multiple features for <task_7> has been proved as an effective approach because limitation of each <otherscientificterm_10> could be compensated . since different types of variations such as <otherscientificterm_9> , <otherscientificterm_11> and <otherscientificterm_8> may happen in a <material_6> , especially long sequence videos , how to dynamically select the appropriate features is one of the key problems in this approach . to address this issue in <task_1> , this paper proposes a new <method_0> for <task_2> . the proposed <method_0> dynamically removes <otherscientificterm_5> to be fused for <task_7> by using the advantages of <method_4> . as a result , robust <task_7> performance is obtained . experimental results on publicly available videos show that the proposed <method_0> outperforms both existing <method_4> based and <method_3> .	7 10 12 -1 9 11 8 6 14 17 12 -1 1 0 2 15 16 12 -1 5 4 13 12 -1 12 -1 12 -1
Super-resolution Person re-identification with semi-coupled low-rank discriminant dictionary learning .	intrinsic feature spaces of hr and lr images ; multi-view sld2l approach ; super-resolution person re-identification ; hr and lr training images ; low-resolution ; sr person re-identification task ; publicly available datasets ; type-specific dictionary pair ; low-rank regularization term ; visual appearance features ; converted features ; mapping matrices ; person re-identification ; gallery images ; discriminative capability ; hr features ; discriminant term ; identification scenarios ; probe images ; feature ; features ; illumination ; sld2l	<otherscientificterm> <method> <method> <material> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	1 0 7 ; 16 1 8 ; 20 0 15 ; 18 3 17 ; 8 0 22 ; 7 0 19 ; 22 0 20	person re-identification has been widely studied due to its importance in surveillance and forensics applications . in practice , <material_13> are high-resolution -lrb- hr -rrb- while <material_18> are usually <otherscientificterm_4> in the <task_17> with large variation of <otherscientificterm_21> , weather or quality of cameras . <task_12> in this kind of scenarios , which we call <method_2> , has not been well studied . in this paper , we propose a semi-coupled low-rank discriminant dictionary learning -lrb- <method_22> -rrb- approach for <task_5> . with the hr and lr dictionary pair and <method_11> learned from the <otherscientificterm_20> of <material_3> , <method_22> can convert the <otherscientificterm_20> of lr <material_18> into <otherscientificterm_15> . to ensure that the <otherscientificterm_10> have favorable <otherscientificterm_14> and the learned dictionaries can well characterize <otherscientificterm_0> , we design a <otherscientificterm_16> and a <otherscientificterm_8> for <method_22> . moreover , considering that low resolution results in different degrees of loss for different types of <otherscientificterm_9> , we propose a <method_1> , which can learn the <otherscientificterm_7> and mappings for each type of <otherscientificterm_19> . experimental results on multiple <material_6> demonstrate the effectiveness of our proposed approaches for the <task_5> .	23 -1 13 18 4 17 21 12 27 23 -1 2 23 -1 22 5 23 -1 11 20 3 26 30 23 -1 15 25 28 23 -1 10 14 0 16 8 24 29 23 -1 9 1 7 19 23 -1
Integrating rule and template-based approaches for emotional Malay speech synthesis .	prosody manipulation principle ; malay emotional synthesizer ; prosody parametric manipulation ; manipulation of prosody ; text input ; sentence structure ; synthesizing emotion ; intonation patterns ; prosody templates ; sadness ; duration ; anger	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 7 ; 2 0 1 ; 10 6 3 ; 8 0 1 ; 8 1 2 ; 11 1 9 ; 2 0 5	the <otherscientificterm_3> , including pitch , <otherscientificterm_10> and intensity , is one of the leading approaches in <task_6> . this paper reports work on the development of a <method_1> capable of expressing four basic emotions , namely happiness , <otherscientificterm_11> , <otherscientificterm_9> and fear for any form of <otherscientificterm_4> with various <otherscientificterm_7> using the <method_0> . the <method_1> makes use of <method_8> and <method_2> for different types of <otherscientificterm_5> .	3 10 6 15 12 -1 1 11 9 4 7 0 13 18 12 -1 8 2 5 14 16 17 19 12 -1
Production domain modeling of pronunciation for visual speech recognition .	visual speech recognition ; feature-based and viseme-based units ; phone-based models of speech ; automatic speech recognition community ; modeling inter-feature asynchrony ; articulatory feature models ; dynamic bayes-ian network ; isolated-word vsr task ; svm feature classifiers ; visually-salient features ; feature-based model ; visual modality	<task> <otherscientificterm> <material> <task> <task> <method> <method> <task> <method> <otherscientificterm> <method> <method>	5 3 3 ; 10 0 0 ; 5 0 2 ; 9 0 10	articulatory feature models have been proposed in the <task_3> as an alternative to <material_2> . in this paper , we extend this approach to the <method_11> . specifically , we adapt a recently proposed <method_10> of pronunciation variation to <task_0> using a set of <otherscientificterm_9> . the model uses a <method_6> to represent the evolution of the feature streams . a bank of <method_8> , with outputs converted to likelihoods , provides input to the <task_0> . we present preliminary experiments on an <task_7> , comparing <otherscientificterm_1> and studying the effects of <task_4> .	3 2 13 15 12 -1 11 12 -1 10 0 9 14 16 12 -1 6 12 -1 8 12 -1 7 1 4 5 12 -1
ParaQuery : Making Sense of Paraphrase Collections .	pivoted paraphrase collection ; bilingual parallel corpora ; pivoted paraphrase collections ; lexical similarity resources ; nlp applications ; paraphrase acquisition ; paraphrases ; paraquery	<task> <material> <method> <material> <task> <task> <otherscientificterm> <method>	2 0 4 ; 7 0 0 ; 1 0 5	pivoting on <material_1> is a popular approach for <task_5> . although such <method_2> have been successfully used to improve the performance of several different <task_4> , it is still difficult to get an intrinsic estimate of the quality and coverage of the <otherscientificterm_6> contained in these collections . we present <method_7> , a tool that helps a user interactively explore and characterize a given <task_0> , analyze its utility for a particular domain , and compare it to other popular <material_3> -- all within a single interface .	1 5 11 8 -1 2 4 6 9 8 -1 7 0 3 10 8 -1
Computation of the Dual Frame : Forward and Backward Greville Formulas .	oversampled filter banks ; greville 's formula ; backward greville formula ; transform coefficients ; row deletion ; laplacian pyramid ; robust transmission ; post-filtering structure ; dual frame ; erasure channel ; erasure channels ; ofbs ; row ; subband	<task> <method> <method> <otherscientificterm> <task> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	2 0 4 ; 7 0 8 ; 2 0 11	we study the computation of the <otherscientificterm_8> for <task_0> by exploiting <method_1> , which was derived in 1960 to compute the pseudo inverse of a matrix when a new <otherscientificterm_12> is appended . in this paper , we first develop the <method_2> to handle the case of <task_4> . based on <method_1> , we then study the <otherscientificterm_8> computation of the <material_5> . through the <method_2> , we investigate <method_11> for <task_6> over <material_10> . the necessary and sufficient conditions for <method_11> robust to one <otherscientificterm_9> are derived . a <otherscientificterm_7> is also presented to implement the <otherscientificterm_8> when the <otherscientificterm_3> in one <otherscientificterm_13> are completely lost .	8 0 1 12 14 -1 2 4 15 14 -1 5 14 -1 11 6 10 17 14 -1 9 14 -1 7 16 14 -1
When VLAD Met Hilbert .	vectors of locally aggregated descriptors ; locally aggregated descriptors ; nonlinear vlad descriptors ; visual recognition tasks ; covariance descriptors ; kernel vlad ; image/video representations ; vector form ; local descriptors ; classification schemes ; linear classifiers ; vlad framework ; manifold-valued data ; kernelized version ; approximate formulations ; coding process ; euclidean space ; non-vector descriptors ; tensors	<method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 6 12 ; 14 0 15 ; 16 2 2 ; 4 6 3	vectors of <method_1> have emerged as powerful <method_6> that compete with or even outperform state-of-the-art approaches on many challenging <task_3> . in this paper , we address two fundamental limitations of <method_0> : its requirement for the <otherscientificterm_8> to have <otherscientificterm_7> and its restriction to <method_10> due to its high-dimensionality . to this end , we introduce a <method_13> of <method_0> . this not only lets us inherently exploit more sophisticated <method_9> , but also enables us to efficiently aggregate <otherscientificterm_17> -lrb- e.g. , <otherscientificterm_18> -rrb- in the <method_11> . furthermore , we propose three <method_14> that allow us to accelerate the <method_15> while still benefiting from the properties of <method_5> . our experiments demonstrate the effectiveness of our approach at handling <material_12> , such as <otherscientificterm_4> , on several <task_3> . our results also evidence the benefits of our <otherscientificterm_2> against the linear ones in <otherscientificterm_16> using several standard benchmark datasets .	1 6 3 19 -1 0 8 7 10 19 -1 13 19 -1 9 17 18 11 19 -1 14 21 19 -1 15 5 20 23 19 -1 12 4 22 19 -1
Fast DPP Sampling for Nystrom with Application to Kernel Methods .	determi-nantal point processes ; markov chain dpp sampling ; kernel ridge regression ; discrete probability models ; dpp-based landmark selection ; nyström method ; kernel methods ; landmark selection ; theoretical analysis ; cubic complexity ; linear time ; dpp sampling ; approximation errors ; nyström ; landmarks	<method> <method> <task> <method> <method> <method> <method> <task> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	0 0 7 ; 3 0 13 ; 7 0 13 ; 0 0 14 ; 5 0 6 ; 0 0 13	the <method_5> has long been popular for scaling up <method_6> . its theoretical guarantees and empirical performance rely critically on the quality of the <otherscientificterm_14> selected . we study <task_7> for <method_13> using <method_0> , <method_3> that allow tractable generation of diverse samples . we prove that <otherscientificterm_14> selected via <method_0> guarantee bounds on <otherscientificterm_12> ; subsequently , we analyze implications for <task_2> . contrary to prior reservations due to <metric_9> of <method_11> , we show that -lrb- under certain conditions -rrb- <method_1> requires only <otherscientificterm_10> in the size of the data . we present several empirical results that support our <method_8> , and demonstrate the superior performance of <method_4> compared with existing approaches .	5 6 20 15 -1 14 15 -1 7 13 0 3 16 17 18 21 15 -1 12 2 19 15 -1 9 11 1 10 15 -1 15 -1
Automated Generation of Understandable Contingency Plans .	markov decision processes ; contingency planning ; deriving contingency plans ; anytime algorithm ; optimal plans ; heuristic techniques	<method> <method> <task> <method> <otherscientificterm> <method>	5 0 1 ; 0 1 1	markov decision processes -lrb- <method_0> -rrb- and <method_1> are two widely used approaches to planning under uncertainty . <method_0> are attractive because the model is extremely general and because many algorithms exist for deriving <otherscientificterm_4> . in contrast , <method_1> is normally performed using <method_5> that do not guarantee op-timality , but the resulting plans are more compact and more understandable . the inability to present <method_1> in a clear , intuitive way has limited their applicability in some important domains . we introduce an <method_3> for <task_2> that combines the advantages of the two approaches .	0 1 8 6 -1 4 6 -1 5 7 6 -1 6 -1 3 2 6 -1
Mining Search Engine Clickthrough Log for Matching N-gram Features .	limited user click data ; web search ranking task ; exact match click features ; query-url n-gram features ; nlp community ; web ranking ; user clicks ; unseen words ; urls ; sparsity ; url ; regularities	<material> <task> <otherscientificterm> <method> <method> <task> <material> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	1 5 3 ; 9 0 8	user clicks on a <material_10> in response to a query are extremely useful predictors of the <material_10> 's relevance to that query . <otherscientificterm_2> tend to suffer from severe data <method_9> issues in <task_5> . such <method_9> is particularly pronounced for new <otherscientificterm_8> or long queries where each distinct query-url pair will rarely occur . to remedy this , we present a set of straightforward yet informative <method_3> that allows for generalization of <material_0> to large amounts of unseen query-url pairs . the <method_3> is motivated by techniques leveraged in the <method_4> for dealing with <otherscientificterm_7> . we find that there are interesting <otherscientificterm_11> across queries and their preferred destination <otherscientificterm_8> ; for example , queries containing '' form '' tend to lead to clicks on <otherscientificterm_8> containing '' pdf '' . we evaluate our set of new <method_3> on a <task_1> and obtain improvements that are statistically significant at a p-value < 0.0001 level over a strong baseline with exact match clickthrough features .	10 2 12 -1 9 5 12 -1 8 14 12 -1 3 0 12 -1 4 7 12 -1 12 -1 11 13 12 -1
Making the right moves : Guiding alpha-expansion using local primal-dual gaps .	adaptive graph-cut based move-making algorithm ; image labelling problems ; pre-defined moves spaces ; object segmentation ; move-making algorithms ; energy minimization ; primal-dual gap ; expansion-move algorithm ; expansion ; stereo ; swap	<method> <task> <otherscientificterm> <task> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method>	1 5 0 ; 8 1 10 ; 10 6 4 ; 3 1 9 ; 3 6 1 ; 0 4 7 ; 8 6 4 ; 0 0 5 ; 9 6 1	this paper presents a new <method_0> for <task_5> . traditional <method_4> such as <method_8> and <method_10> operate by searching for better solutions in some <otherscientificterm_2> around the current solution . in contrast , our <method_0> uses the primal-dual interpretation of the <method_7> to adaptively compute the best move-space to search over . at each step , it tries to greedily find the move-space that will lead to biggest decrease in the <otherscientificterm_6> . we test different variants of our <method_0> on a variety of <task_1> such as <task_3> and <otherscientificterm_9> . experimental results show that our <method_0> significantly outper-forms the conventional <method_7> , in some cases cutting the runtime by 50 % .	0 5 19 11 -1 4 8 10 2 13 14 18 11 -1 7 11 -1 6 11 -1 1 3 9 12 15 16 20 11 -1 17 11 -1
Evaluation of Texture Segmentation Algorithms .	region-based and pixel-based performance met-rics ; control scheme of texture segmentation ; gray level co-occurrence matrax ; laws ' texture energy ; unsu-pervised texture segmentation algorithms ; real scene images ; feature extraction methods ; manually-specified ground truth ; gabor multi-channel filtering ; fuzzy c-means clustering ; ground truth ; segmentation algorithms ; modular processes ; square-error clustering ; homogeneous regions ; real images ; feature values ; split-and-merge	<otherscientificterm> <method> <otherscientificterm> <method> <method> <material> <method> <material> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	2 1 3 ; 17 6 11 ; 3 1 8 ; 2 6 6 ; 7 0 5 ; 3 6 6 ; 13 6 11 ; 13 1 17 ; 8 6 6 ; 9 1 13 ; 9 6 11	this paper presents a method of evaluating <method_4> . the <method_1> has been conceptualized as two <method_12> : -lsb- l -rrb- feature computation and -lrb- 2 -rrb- segmentation of <otherscientificterm_14> based on the <otherscientificterm_16> . three <method_6> are considered : <otherscientificterm_2> , <method_3> and <method_8> . three <method_11> are considered : <method_9> , <method_13> and <otherscientificterm_17> . a set of 35 <material_5> with <material_7> was compiled . performance is measured against <otherscientificterm_10> on <material_15> using <otherscientificterm_0> .	4 18 -1 1 12 14 16 18 -1 6 2 3 8 19 21 22 24 27 18 -1 11 9 13 17 20 25 26 28 29 18 -1 5 7 23 18 -1 10 15 0 18 -1
Filtered Variation method for denoising and sparse signal processing .	sparse signal processing applications ; convex sets approach ; total variation recovery ; discrete time filters ; fv problem ; signal processing ; alternating projections ; de-noising ; regularization	<task> <method> <method> <method> <task> <task> <otherscientificterm> <task> <method>	3 0 8 ; 3 0 5	we propose a new framework , called filtered variation -lrb- fv -rrb- , for <task_7> and <task_0> . these problems are inherently ill-posed . hence , we provide <method_8> to overcome this challenge by using <method_3> that are widely used in <task_5> . we mathematically define the <task_4> , and solve it using <otherscientificterm_6> in space and transform domains . we provide a globally convergent algorithm based on the projections onto <method_1> . we apply to our algorithm to real denoising problems and compare it with the <method_2> .	7 0 9 -1 9 -1 8 3 5 10 11 9 -1 4 6 9 -1 1 9 -1 2 9 -1
Canonicalization of feature parameters for automatic speech recognition .	robust automatic speech recognition system ; phonetic feature extractors ; acoustic feature ; acoustic models ; dpf extraction stage ; multilayer neural networks ; acoustic feature vectors ; computation time ; dpf spaces ; speaking rate ; gender type ; hidden variable ; hidden variables ; canonicalization process ; hmm-based classifier ; hmm classifiers ; acoustic environment ; canonicalized dpf ; hmm classifier ; dpf selector ; hmm ; hmms	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method> <method> <method> <method>	16 6 12 ; 2 1 0 ; 7 2 0 ; 13 4 0 ; 21 1 0 ; 20 1 0 ; 2 1 20 ; 17 1 18 ; 10 6 12 ; 9 1 16 ; 2 4 13 ; 10 1 9 ; 6 0 8 ; 12 0 14 ; 3 0 14 ; 9 6 12	acoustic models -lrb- <method_3> -rrb- of an <method_14> include various types of <otherscientificterm_12> such as <otherscientificterm_10> , <otherscientificterm_9> , and <otherscientificterm_16> . if there exists a <method_13> that reduces the influence of the <otherscientificterm_12> from the <method_3> , a <method_0> can be realized . in this paper , we describe the configuration of a <method_13> targeting <otherscientificterm_10> as a <otherscientificterm_11> . the proposed <method_13> is composed of multiple distinctive <otherscientificterm_1> corresponding to the <otherscientificterm_11> and a <method_19> in which the distance between input dpf and <method_3> is compared . in a <otherscientificterm_4> , an input sequence of <otherscientificterm_6> is mapped onto three <otherscientificterm_8> corresponding to male , female , and neutral voice by using three <method_5> -lrb- mlns -rrb- . experiments are carried out by comparing -lrb- a -rrb- the combination of the <method_17> and a single <method_18> , and -lrb- b -rrb- the combination of a single <method_2> and multiple <method_15> . the result shows that the proposed <method_13> outperforms both of the conventional <method_0> with <method_2> and a single <method_20> and the <method_0> with multiple <method_21> in spite of less memories and <otherscientificterm_7> .	3 14 12 10 9 16 23 31 32 34 36 37 38 22 -1 13 0 22 -1 11 22 -1 1 19 22 -1 4 6 35 22 -1 8 5 30 22 -1 17 18 2 15 24 25 26 27 28 29 33 22 -1
Sparse spectral factorization : Unicity and reconstruction algorithms .	one-dimensional sparse signal ; sparse spectral factorization ; spectral factorization ; iterative algorithm ; phase retrieval ; sign change ; x-ray crystallography ; numerical simulations ; signal processing ; classical tool ; communications ; autocorrelation ; time-shift	<otherscientificterm> <task> <task> <method> <task> <otherscientificterm> <task> <method> <task> <method> <task> <otherscientificterm> <otherscientificterm>	8 1 10 ; 9 0 8 ; 2 6 9 ; 5 1 12 ; 2 0 8	spectral factorization is a <method_9> in <task_8> and <task_10> . it also plays a critical role in <task_6> , in the context of <task_4> . in this work , we study the problem of <task_1> , aiming to recover a <otherscientificterm_0> from its <otherscientificterm_11> . we present a sufficient condition for the recovery to be unique , and propose an <method_3> that can obtain the original signal -lrb- up to a <otherscientificterm_5> , <otherscientificterm_12> and time-reversal -rrb- . <method_7> verify the effectiveness of the proposed algorithm .	9 8 10 14 15 16 18 13 -1 6 4 13 -1 1 0 11 13 -1 3 5 12 7 17 13 -1 2 13 -1
Segmental Hidden Markov Models for View-based Sport Video Analysis .	hidden markov model ; segmental hmm ; variability of visual features ; video mining tasks ; statistical inference process ; generative model approach ; view-based shot classification ; two-layer observation model ; intrinsic semantic structures ; american football games ; sport videos ; semantic space ; generative models ; camera view ; semantic structure ; latent states ; camera views ; visual features	<method> <method> <otherscientificterm> <task> <method> <method> <task> <method> <otherscientificterm> <material> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 1 1 ; 5 0 3 ; 0 6 12 ; 11 2 14 ; 1 6 12 ; 13 6 10 ; 1 0 0 ; 5 0 8 ; 5 0 17 ; 7 0 2 ; 5 0 6	we present a <method_5> to explore <otherscientificterm_8> in <material_10> , e.g. , the <otherscientificterm_13> in <material_9> . we will invoke the concept of <otherscientificterm_11> to explicitly define the <otherscientificterm_14> in the video in terms of <otherscientificterm_15> . a <method_5> is used to govern the transition between states , and an <method_5> is developed to characterize <otherscientificterm_17> pertaining to different states . then the problem is formulated as a <method_4> where we want to infer <otherscientificterm_15> -lrb- i.e. , <otherscientificterm_16> -rrb- from observations -lrb- i.e. , <otherscientificterm_17> -rrb- . two <method_12> , the <method_0> and the <method_1> , are involved in this research . in the <method_0> , both <otherscientificterm_15> and <otherscientificterm_17> are shot-based , and in the <method_1> , <otherscientificterm_15> and <otherscientificterm_17> are defined for shots and frames respectively . both <method_5> provide promising performance for <task_6> , and the <method_1> outper-forms the <method_0> by involving a <method_7> to accommodate the <otherscientificterm_2> . this <method_5> is also applicable to other <task_3> .	5 8 10 13 9 24 26 18 -1 11 14 15 22 18 -1 17 27 18 -1 4 16 18 -1 12 0 1 19 21 23 18 -1 18 -1 25 28 29 18 -1 6 7 2 20 18 -1
Sequential acoustic energy based source localization using particle filter in a distributed sensor network .	maximum likelihood source localization algorithm ; sequential source localization method ; non-gaussian probability density function ; wireless distributed sensor network ; state transition equation ; location estimates ; acoustic sensors ; acoustic signal ; particle filter ; parameter perturbation ; observation equation ; multiple-target locations ; positions	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 0 1 ; 1 0 9 ; 10 0 5 ; 1 0 11	a <method_1> using <method_8> is presented to estimate and track <otherscientificterm_11> . this <method_1> is designed to make use of <otherscientificterm_7> measured at multiple <otherscientificterm_6> randomly deployed in a <method_3> . by using the <method_8> , <otherscientificterm_2> of the target locations are represented by a discrete set of '' particles '' . the <otherscientificterm_12> of these particles are propagated sequentially using known <otherscientificterm_4> , and updated using new <method_5> via the <otherscientificterm_10> . compared to a previously proposed <method_0> , this new <method_1> is computationally effective and more robust to <otherscientificterm_9> .	1 8 11 14 17 13 -1 7 6 3 13 -1 2 13 -1 12 4 5 10 16 13 -1 0 9 15 13 -1
Robust kernel density estimation .	robust kernel density estimator ; kernel density estimator ; reproducing kernel hilbert space ; positive semi-definite kernel ; m-estimator objective function ; nonparametric density estimation ; influence function ; global minimizer ; classical m-estimation ; representer theorem ; kernelized irwls ; density estimation ; anomaly detection ; outliers ; m-estimation ; robustness	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <method> <method> <task> <task> <otherscientificterm> <method> <metric>	9 1 6 ; 11 1 12 ; 9 5 1 ; 3 0 1 ; 14 0 1 ; 9 1 15	we propose a method for <task_5> that exhibits <metric_15> to contamination of the training sample . this method achieves <metric_15> by combining a traditional <method_1> with ideas from <material_8> . we interpret the <method_1> based on a <otherscientificterm_3> as a sample mean in the associated <otherscientificterm_2> . since the sample mean is sensitive to <otherscientificterm_13> , we estimate <method_1> robustly via <method_14> , yielding a <method_0> . an <method_1> can be computed efficiently via a kernelized iteratively re-weighted least squares -lrb- irwls -rrb- algorithm . necessary and sufficient conditions are given for <method_10> to converge to the <otherscientificterm_7> of the <otherscientificterm_4> . the <metric_15> of the <method_1> is demonstrated with a <method_9> , the <otherscientificterm_6> , and experimental results for <task_11> and <task_12> .	5 15 16 -1 1 8 16 -1 3 2 20 16 -1 13 14 0 21 16 -1 16 -1 10 7 16 -1 4 17 18 19 22 16 -1
Entity Disambiguation Using a Markov-Logic Network .	textual named entity mention ; markov logic network ; knowledge base entry ; disambiguation formulae/features ; entity ambiguity ; interweaved constraints ; el approaches ; filtering techniques ; el	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	1 0 3 ; 1 0 5 ; 7 0 6	* entity linking -lrb- <otherscientificterm_8> -rrb- is the task of linking a <otherscientificterm_0> to a <otherscientificterm_2> . it is a difficult task involving many challenges , but the most crucial problem is <otherscientificterm_4> . traditional <method_6> usually employ different constraints and <method_7> to improve performance . however , these constraints are executed in several different stages and can not be used interactively . in this paper , we propose several <method_3> and employ a <method_1> to model <otherscientificterm_5> found in one type of <otherscientificterm_8> , gene mention linking . to assess our systems effectiveness in different applications , we adopt two evaluation schemes : article-wide and instance-based precision/recall/f-measure . experimental results show that our system outperforms the baseline systems and state-of-the-art systems under both evaluation schemes .	8 0 2 9 -1 4 9 -1 6 7 12 9 -1 9 -1 3 1 5 10 11 9 -1 9 -1 9 -1
A Novel Burst-based Text Representation Model for Scalable Event Detection .	temporal aspects of documents ; burst-based text representation model ; classic text representation model ; semantic and temporal information ; scalable event detection ; 10-year news archive ; vector space model ; mining retrospective events ; non-zero entries ; text streams ; bursty features ; burstvsm	<otherscientificterm> <method> <method> <otherscientificterm> <task> <material> <method> <task> <otherscientificterm> <material> <otherscientificterm> <method>	5 5 11 ; 11 6 1 ; 4 0 11 ; 9 0 7	mining retrospective events from <material_9> has been an important research topic . <method_2> -lrb- i.e. , <method_6> -rrb- can not model <otherscientificterm_0> . to address <method_11> , we proposed a novel <method_1> , denoted as <method_11> . <method_11> corresponds dimensions to <otherscientificterm_10> instead of terms , which can capture <otherscientificterm_3> . meanwhile , <method_11> significantly reduces the number of <otherscientificterm_8> in the representation . we test <method_11> via <task_4> , and experiments in a <material_5> show that our <method_11> are both effective and efficient .	9 2 16 12 -1 6 0 12 -1 11 1 14 12 -1 10 3 12 -1 8 12 -1 4 5 7 13 15 12 -1
A Convex Solution to Spatially-Regularized Correspondence Problems .	globally optimal solution ; geometric measure theory ; convex minimization problem ; minimal two-dimensional surface ; data consistency ; energy function ; 2-vector fields ; convex formulation ; two-dimensional surfaces ; primal-dual algorithm ; spatial regularity ; correspondence problem	<method> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task>	7 0 2 ; 4 1 10 ; 7 0 11	we propose a <method_7> of the <task_11> between two images with respect to an <otherscientificterm_5> measuring <metric_4> and <otherscientificterm_10> . to this end , we formulate the general <task_11> as the search for a <otherscientificterm_3> in r 4 . we then use tools from <method_1> and introduce <otherscientificterm_6> as a representation of <otherscientificterm_8> in r 4 . we propose a discretization of this <method_7> that gives rise to a <task_2> and compute a <method_0> using an efficient <method_9> .	7 11 5 4 10 14 15 12 -1 3 12 -1 1 6 8 12 -1 2 0 9 13 12 -1
Modeling Negotiation Subdialogues .	robust natural language understanding system ; natural language understanding system ; expressions of doubt ; multi-strength belief model ; discourse actions ; multi-agent activity ; processing strategy ; negotiation subdialogues ; task-oriented interactions ; communicative actions ; process model ; communicated propositions ; knowledge sources ; subdi-alogues ; negotiation	<method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <task>	0 0 7 ; 7 3 7 ; 12 1 3 ; 12 1 10 ; 0 0 8 ; 3 0 4 ; 3 1 10 ; 12 1 6 ; 3 1 6 ; 9 0 0	this paper presents a <method_0> that handles <otherscientificterm_7> by inferring both the <otherscientificterm_9> that people pursue when speaking and the beliefs underlying these actions . we contend that recognizing the complex <otherscientificterm_4> pursued in <otherscientificterm_7> -lrb- e.g. , expressing doubt -rrb- requires both a <method_3> and a <method_10> that combines different <material_12> in a unified framework . we show how our <method_0> identifies the structure of <otherscientificterm_7> , including recognizing <otherscientificterm_2> , implicit acceptance of <otherscientificterm_11> , and <otherscientificterm_7> embedded within other <otherscientificterm_7> . 1 introduction since <task_14> is an integral part of <task_5> , a <method_0> must be able to handle <otherscientificterm_13> in which participants negotiate what has been claimed in order to try to come to some agreement about those claims . to handle such dialogues , the <method_0> must be able to recognize when a dialogue participant has initiated a <task_14> subdialogue and why the participant began the <task_14> -lrb- i.e. , what beliefs led the participant to start the <task_14> -rrb- . this paper presents a <method_0> of <task_8> that assimilates <otherscientificterm_7> by inferring both the <otherscientificterm_9> that people pursue when speaking and the beliefs underlying these actions . we will argue that recognizing the complex <otherscientificterm_4> pursued in <otherscientificterm_7> -lrb- e.g. , expressing doubt -rrb- requires both a <method_3> and a <method_6> that combines different <material_12> in a unified framework , and we will show how our <method_0> incorporates these and recognizes the structure of <otherscientificterm_7> .	0 7 9 25 15 -1 4 3 10 12 19 22 15 -1 2 11 17 15 -1 14 5 15 -1 13 15 -1 16 20 15 -1 8 18 21 23 24 15 -1
Relative Attributes for Large-Scale Abandoned Object Detection .	low-level spatial and temporal features.these attributes ; abnormal events of interest ; people and light artifacts ; large-scale video surveillance ; public data sets ; abandoned object alerts ; linear ranking algorithm ; abandoned object detection ; ranking function ; abandoned objects ; false alarms ; relative attributes ; detection accuracy ; large-scale deployment ; features ; alerts ; abandon-ment ; staticness ; foregroundness	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 0 11 ; 7 6 1 ; 17 6 11 ; 18 6 11 ; 17 1 18 ; 16 6 11 ; 18 1 16 ; 6 0 15	effective reduction of <otherscientificterm_10> in <task_3> is rather challenging , especially for applications where <otherscientificterm_1> rarely occur , such as <task_7> . we develop an approach to prioritize <otherscientificterm_15> by ranking them , and demonstrate its great effectiveness in reducing false positives while keeping good <metric_12> . our approach benefits from a novel representation of <otherscientificterm_5> by <otherscientificterm_11> , namely <otherscientificterm_17> , <otherscientificterm_18> and <otherscientificterm_16> . the relative strengths of these <otherscientificterm_11> are quantified using a <method_8> -lsb- 19 -rsb- learnt on suitably designed <otherscientificterm_0> of varying strengths are not only powerful in distinguishing <otherscientificterm_9> from <otherscientificterm_10> such as <otherscientificterm_2> , but also computationally efficient for <task_13> . with these <otherscientificterm_14> , we apply a <method_6> to sort <otherscientificterm_15> according to their relevance to the end-user . we test the effectiveness of our approach on both <material_4> and large ones collected from the real world .	10 3 1 7 21 19 -1 15 12 19 -1 5 11 17 18 16 22 23 24 25 26 19 -1 8 0 9 2 20 19 -1 13 27 19 -1 14 6 19 -1
Cornering Stationary and Restless Mixing Bandits with Remix-UCB .	restless bandit problem ; stationary ϕ-mixing processes ; regret analysis ; ϕ-mixing coefficients ; i.i.d scenario ; exploration/exploitation/independence trade-off ; suboptimal arm ; waiting arm ; remix-ucb algorithm ; remix-ucb	<task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	2 0 0	we study the <task_0> where arms are associated with <method_1> and where rewards are therefore dependent : the question that arises from this setting is that of carefully recovering some independence by ` ig-noring ' the values of some rewards . as we shall see , the <task_0> we tackle requires us to address the <otherscientificterm_5> , which we do by considering the idea of a <otherscientificterm_7> in the new <method_8> , a generalization of improved-ucb for the problem at hand , that we introduce . we provide a <method_2> for this <task_0> ; two noticeable features of <method_9> are that i -rrb- <method_2> reduces to the regular improved-ucb when the <otherscientificterm_3> are all 0 , i.e. when the <otherscientificterm_4> is recovered , and ii -rrb- when ϕ -lrb- n -rrb- = o -lrb- n − α -rrb- , <method_2> is able to ensure a controlled regret of order θ ∆ -lrb- α − 2 -rrb- / α * log 1 / α t , where ∆ * encodes the distance between the best arm and the best <otherscientificterm_6> , even in the case when α < 1 , i.e. the case when the <otherscientificterm_3> are not summable .	0 1 10 -1 5 7 8 10 -1 2 9 11 10 -1
A coupled HMM for solving the permutation problem in frequency domain BSS .	coupled hidden markov model ; convolutive blind source separation ; hidden markov model ; psychoacoustic characteristics of signals ; cross-power spectrum-based cost function ; non-unitary penalty term ; joint diagonalization algorithm ; frequency bins ; state transitions ; simulation studies ; permutation effect ; frequency domain ; convolutive bss ; hmms	<method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method> <method>	0 0 3 ; 6 0 12 ; 5 2 4 ; 11 2 4	permutation of the outputs at different <otherscientificterm_7> remains as a major problem in the <task_1> . in this work a <method_0> effectively exploits the <otherscientificterm_3> to mitigate such permutation . a <method_6> for <method_12> , which incorporates a <otherscientificterm_5> within the <otherscientificterm_4> in the <material_11> , has been used . the proposed <method_0> couples a number of conventional <method_13> , equivalent to the number of outputs , by making <otherscientificterm_8> in each model dependent not only on its own previous state , but also on some aspects of the state of the other models . using this <method_6> the <otherscientificterm_10> has been substantially reduced , and demonstrated using a number of <method_9> .	7 1 14 -1 0 3 15 14 -1 6 12 5 4 11 16 17 18 14 -1 13 8 14 -1 10 14 -1
Critera for direct blind deconvolution of MIMO FIR systems driven by white source signals .	blind deconvolution of mimo fir systems ; multi-output fir systems ; white non-gaussian source signals ; so-called i.i.d. condition ; adaptive algorithms ; source signals ; blind deconvolution ; maximization criteria	<task> <method> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric>	2 0 1 ; 7 0 0 ; 4 0 7	this paper addresses the <otherscientificterm_6> of multi-input -- <method_1> driven by <material_2> . first , we present a weaker condition on <otherscientificterm_5> than the <otherscientificterm_3> so that <otherscientificterm_6> is possible . then , under this condition , we provide a necessary and sufficient condition for <task_0> . finally , based on this result , we propose two <metric_7> for <task_0> . these <metric_7> are simple enough to be implemented by <method_4> .	6 1 2 9 8 -1 5 3 8 -1 0 8 -1 7 10 8 -1 4 11 8 -1
Attribute2Image : Conditional Image Generation from Visual Attributes .	composite of foreground and background ; posterior inference of latent variables ; natural images of faces ; disentangled latent representations ; disentangled latent variables ; layered generative model ; attribute-conditioned image reconstruction ; energy minimization algorithm ; visual attributes ; generative models ; variational auto-encoder ; generating images ; completion	<otherscientificterm> <task> <material> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <method> <task> <task>	8 0 11 ; 7 0 1 ; 4 0 5 ; 6 1 12 ; 10 0 5 ; 10 0 4	this paper investigates a novel problem of <task_11> from <otherscientificterm_8> . we model the image as a <otherscientificterm_0> and develop a <method_5> with <otherscientificterm_4> that can be learned end-to-end using a <method_10> . we experiment with <material_2> and birds and demonstrate that the proposed <method_5> are capable of generating realistic and diverse samples with <method_3> . we use a general <method_7> for <task_1> given novel images . therefore , the learned <method_9> show excellent quantitative and visual results in the tasks of <task_6> and <task_12> .	11 8 14 13 -1 0 5 4 10 16 18 19 13 -1 2 3 13 -1 7 1 15 13 -1 9 6 12 17 13 -1
Adaptation-Guided Case Base Maintenance .	adaptation-guided case-base maintenance ; case-based reasoning ; static case adaptation knowledge ; case base densities ; compacting case bases ; numerical prediction tasks ; case retention decisions ; case difference heuristic ; competence-based deletion strategies ; case-base maintenance approach ; case-base maintenance ; adaptation knowledge ; system competence ; adaptation rules	<method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <task> <method> <method> <method> <task> <otherscientificterm> <metric> <otherscientificterm>	9 0 11 ; 0 6 9 ; 8 0 12 ; 2 0 12 ; 7 0 13 ; 2 0 8	in <method_1> , problems are solved by retrieving prior cases and adapting their solutions to fit ; learning occurs as new cases are stored . controlling the growth of the case base is a fundamental problem , and research on <task_10> has developed methods for <task_4> while maintaining <metric_12> , primarily by <method_8> assuming <otherscientificterm_2> . this paper proposes <method_0> , a <method_9> exploiting the ability to dynamically generate new <otherscientificterm_11> from cases . in <method_0> , <task_6> are based both on cases ' value as base cases for solving problems and on their value for generating new <otherscientificterm_13> . the paper illustrates the method for <task_5> -lrb- case-based regression -rrb- in which <otherscientificterm_13> are generated automatically using the <method_7> . in comparisons of <method_0> to five alternative methods in four domains , for varying <otherscientificterm_3> , <method_0> outperformed the alternatives in all domains , with greatest benefit at high compression .	1 14 -1 10 4 12 8 2 17 18 20 14 -1 0 9 11 15 16 14 -1 6 13 14 -1 19 14 -1 5 7 14 -1
An estimator for the eigenvalues of the system matrix of a periodic-reference LMS algorithm .	least mean square algorithm ; periodic-reference lms system ; linear time-periodic system ; convergence analysis ; monodromy matrix ; stochastic signals ; estimator	<method> <method> <method> <method> <method> <material> <method>	2 0 1 ; 6 4 4 ; 4 0 2 ; 5 0 0	the <method_3> of the <method_0> has been conventionally based on <material_5> and describes thus only the average behavior of the <method_0> . it has been shown previously that a <method_1> can be regarded as a <method_2> whose stability can be determined from the <method_4> . generally , the <method_4> can only be solved numerically and does not thus reveal the actual factors behind the dynamics of the <method_1> . this paper derives an <method_6> for the eigenvalues of the <method_4> . the <method_6> is easy to calculate , and <method_6> also reveals the underlying reason for the bad convergence of the <method_0> in some special cases . the <method_6> is confirmed by comparing <method_6> to the precise eigenvalues of the <method_4> . the <method_6> is found to be accurate for the eigenvalues close to unity .	3 0 5 11 7 -1 1 2 4 8 10 7 -1 7 -1 6 7 -1 7 -1 9 7 -1 7 -1
An effective perceptual weighting model for videophone coding .	perceptual coding quality of videophone ; perceptual weighting model ; human visual system ; cognition-driven factor ; cognition-driven factors ; luminance adaptation ; skin color ; stimulus-driven factors ; rate control ; videophone application ; videophone-like sequences	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <material>	6 1 3 ; 3 3 9 ; 1 0 8 ; 6 3 9 ; 1 0 0 ; 7 1 4	in this paper , a <method_1> is proposed for effective <task_8> so as to enhance <otherscientificterm_0> , by exploiting two categories of factors affecting the perception of the <method_2> : <otherscientificterm_7> and <otherscientificterm_4> . in order to achieve a simple but effective <method_1> , we use <otherscientificterm_5> and texture masking as the <otherscientificterm_7> , while <otherscientificterm_6> serves as the <otherscientificterm_3> in the <task_9> . both objective and subjective quality evaluations of <material_10> in h. 263 platform validate the effectiveness of our <method_1> .	1 8 0 2 7 4 14 16 17 11 -1 5 6 3 9 12 13 15 11 -1 10 11 -1
An HMM-based singing voice synthesis system .	hidden markov models ; smooth and natural-sounding singing voice ; corpus-based singing voice synthesis system ; hmm-based speech synthesis ; singing voice ; musical information ; context-dependent hmm ; singing style ; voice quality ; durations ; lyrics	<method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <material>	3 0 4 ; 8 5 2 ; 3 0 2 ; 0 0 2 ; 2 0 4 ; 10 6 5 ; 2 0 1 ; 9 6 5	the present paper describes a <method_2> based on <method_0> . this <method_2> employs the <method_3> to synthesize <material_4> . <otherscientificterm_5> such as <material_10> , tones , <otherscientificterm_9> is modeled simultaneously in a unified framework of the <method_6> . <method_2> can mimic the <metric_8> and <otherscientificterm_7> of the original singer . results of a <material_4> synthesis experiment show that the proposed <method_2> can synthesize <otherscientificterm_1> .	2 0 15 11 -1 3 4 5 12 14 16 11 -1 10 9 6 17 19 11 -1 8 7 13 11 -1 1 18 11 -1
Pitch pattern variations in three regional varieties of American English .	southern -lrb- north carolina -rrb- variants ; realization of nuclear pitch accents ; ohio or wisconsin vowels ; flat f0 contours ; voiced syllable coda ; relative location ; regional accent ; f0 contours ; southern vowels ; vowel onset ; central ohio ; spectral dynamics ; american english ; midwestern varieties ; melodic component ; southeastern wisconsin ; dialect-related differences ; unstressed vowels ; vowels	<otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 2 14 ; 10 1 15	this acoustic study explored dialect effects on <task_1> in three regional varieties of <material_12> spoken in <material_10> , <material_15> and western north carolina . fundamental frequency -lrb- f0 -rrb- change from <otherscientificterm_9> to offset in the most prominent syllable in a sentence was examined along four parameters : maximum f0 change , <otherscientificterm_5> of f0 maximum , f0 offset and f0 fall from maximum to offset . a robust finding was that the <otherscientificterm_7> in the <otherscientificterm_0> were significantly distinct from the two <otherscientificterm_13> whose contours did not differ significantly from one another . the <material_8> had an earlier f0 rise , a greater f0 fall and a lower f0 offset than either <material_2> . there was a sharper f0 drop preceding a voiceless than a <otherscientificterm_4> . no significant <otherscientificterm_16> were found for <otherscientificterm_3> in <otherscientificterm_17> , which were also examined in the study . this study contributes the finding that dynamic variations in pitch are greater for <otherscientificterm_18> which also exhibit a greater amount of <otherscientificterm_11> . the interaction of these two sets of cues contributes to the <method_14> associated with a specific <otherscientificterm_6> .	1 12 10 15 21 19 -1 9 5 19 -1 7 0 13 19 -1 8 19 -1 2 19 -1 4 19 -1 16 3 17 19 -1 18 11 20 19 -1
Identifying and attacking the saddle point problem in high-dimensional non-convex optimization .	deep or recurrent neural network training ; high dimensional problems of practical interest ; continuous , high dimensional spaces ; proliferation of saddle points ; high dimensional saddle points ; science and engineering ; non-convex error functions ; neural network theory ; random matrix theory ; local minima ; local minimum ; second-order optimization ; saddle points ; gradient descent ; global minimum ; quasi-newton methods ; statistical physics ; local methods	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method>	13 1 15 ; 16 1 8 ; 8 1 7	a central challenge to many fields of <task_5> involves minimizing <otherscientificterm_6> over <otherscientificterm_2> . gradient descent or <method_15> are almost ubiquitously used to perform such minimizations , and it is often thought that a main source of difficulty for these <method_17> to find the <otherscientificterm_14> is the proliferation of <method_9> with much higher error than the <otherscientificterm_14> . here we argue , based on results from <method_16> , <method_8> , <method_7> , and empirical evidence , that a deeper and more profound difficulty originates from the <otherscientificterm_3> , not <method_9> , especially in <otherscientificterm_1> . such <otherscientificterm_12> are surrounded by high error plateaus that can dramatically slow down learning , and give the illusory impression of the existence of a <otherscientificterm_10> . motivated by these arguments , we propose a new approach to <method_11> , the saddle-free newton method , that can rapidly escape <otherscientificterm_4> , unlike <method_13> and <method_15> . we apply this algorithm to <task_0> , and provide numerical evidence for its superior optimization performance .	5 6 2 18 -1 15 17 14 9 18 -1 16 8 7 3 1 20 21 18 -1 12 18 -1 10 19 18 -1 11 4 13 18 -1
Projection onto the cosparse set is NP-hard .	ternary or bipolar coefficients ; sparse optimization ; matrix ω ; k-sparse vectors ; projection problem ; k-cosparse vectors ; computational complexity ; projection	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <metric> <otherscientificterm>	7 0 3 ; 0 2 2	the <metric_6> of a problem arising in the context of <task_1> is considered , namely , the <otherscientificterm_7> onto the set of <otherscientificterm_5> w.r.t. some given <otherscientificterm_2> . it is shown that this <task_4> is -lrb- strongly -rrb- np-hard , even in the special cases in which the <otherscientificterm_2> contains only <otherscientificterm_0> . interestingly , this is in contrast to the <otherscientificterm_7> onto the set of <otherscientificterm_3> , which is trivially solved by keeping only the k largest coefficients .	6 1 7 5 2 8 -1 4 0 10 8 -1 3 9 8 -1
An Adaptive Learning Rate for Stochastic Variational Inference .	decreasing learning rate ; latent dirichlet allocation ; adaptive learning rate ; large text corpora ; stochastic variational inference ; vari-ational objective ; hand-tuned rates ; stochastic inference ; stochastic optimization ; natural gradient ; probabilistic models ; hand-tuning ; inference ; tuning ; subsample	<metric> <otherscientificterm> <metric> <material> <task> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm>	2 3 12 ; 8 2 5 ; 2 0 7	stochastic variational inference finds good posterior approximations of <method_10> with very large data sets . it optimizes the <otherscientificterm_5> with <method_8> , following noisy estimates of the <otherscientificterm_9> . operationally , <task_7> iteratively subsamples from the data , analyzes the <otherscientificterm_14> , and updates parameters with a <metric_0> . however , the algorithm is sensitive to that rate , which usually requires <method_11> to each application . we solve this problem by developing an <metric_2> for <task_7> . our method requires no <method_13> and is easily implemented with computations already made in the algorithm . we demonstrate our approach with <otherscientificterm_1> applied to three <material_3> . <task_12> with the <metric_2> converges faster and to a better approximation than the best settings of <otherscientificterm_6> .	10 15 -1 5 8 9 17 15 -1 7 14 0 15 -1 11 15 -1 2 18 15 -1 13 15 -1 15 -1 1 3 12 16 15 -1
Investigation of the Empirical Mode Decomposition Based on Genetic Algorithm Optimization Schemes .	empirical mode decomposition ; piecewise interpolating polynomials ; genetic algorithm framework ; performance analysis ; interpolation points	<method> <method> <method> <method> <otherscientificterm>	2 0 1	empirical mode decomposition -lrb- <method_0> -rrb- has lately received much attention due to the many interesting features that exhibits . however it lacks a strong theoretical basis which would allow a <method_3> and hence the enhancement and optimization of the method in a systematic way . in this paper , an investigation of <method_0> is attempted in an alternative way : the <otherscientificterm_4> and the <method_1> for the formation of the upper and lower envelopes of the signal are optimized based on a <method_2> revealing important characteristics of the method which where previously hidden . as a result , novel directions for both the performance enhancement and the theoretical investigation of the method are unveiling .	0 5 -1 3 5 -1 4 1 2 6 5 -1 5 -1
Learning Bayesian Belief Networks with Neural Network Estimators .	discrete and continuous variables ; bayesian belief networks ; artificial neural networks ; probability estimators ; learning accuracy ; learning scheme ; ann estimators ; architectures	<otherscientificterm> <method> <method> <method> <metric> <method> <method> <otherscientificterm>	6 0 5	in this paper we propose a method for learning <method_1> from data . the method uses <method_2> as <method_3> , thus avoiding the need for making prior assumptions on the nature of the probability distributions governing the relationships among the participating variables . this new method has the potential for being applied to domains containing both <otherscientificterm_0> arbitrarily distributed . we compare the learning performance of this new method with the performance of the method proposed by cooper and herskovits in -lsb- 7 -rsb- . the experimental results show that , although the <method_5> based on the use of <method_6> is slower , the <metric_4> of the two methods is comparable . category : algorithms and <otherscientificterm_7> .	1 8 -1 2 3 8 -1 0 8 -1 8 -1 5 6 9 8 -1 4 8 -1
Ranking Human and Machine Summarization Systems .	human and machine evaluation systems ; summarization systems ; average score ; document sets	<task> <method> <metric> <material>	2 5 3	the text analysis conference -lrb- tac -rrb- ranks <method_1> by their <metric_2> over a collection of <material_3> . we investigate the statistical appropriateness of this score and propose an alternative that better distinguishes between <task_0> .	1 2 3 5 4 -1 0 4 -1
An investigation of manifold learning for speech analysis .	classical linear dimensionality reduction method ; high dimensional speech signal ; low dimensional space ; low dimensional structure ; manifold learning algorithms ; low dimensions ; classical methods ; speech apparatus ; manifold structure ; speech data ; speech sounds ; vowels	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm>	4 0 3 ; 4 4 6 ; 2 2 4 ; 2 2 11 ; 4 0 11 ; 4 0 8 ; 9 0 3 ; 4 0 9	due to the physiological constraints of articulatory motion the <otherscientificterm_7> has limited degrees of freedom . as a result , the range of <material_10> a human is capable of producing may lie on a low dimensional submanifold of the high dimensional space of all possible sounds . in this study a number of <method_4> are applied to <material_9> in an effort to extract useful <otherscientificterm_3> from the <otherscientificterm_1> . the ability of these <method_4> to separate <otherscientificterm_11> in a <otherscientificterm_2> is evaluated and compared to a <method_0> . results indicate that <method_4> outperform <method_6> in <otherscientificterm_5> and are capable of discovering useful <otherscientificterm_8> in <material_9> .	7 12 -1 10 12 -1 4 9 3 1 13 19 20 12 -1 11 2 0 15 16 17 12 -1 6 5 14 18 12 -1
PATHS : A System for Accessing Cultural Heritage Collections .	natural language processing ; euro-pean languages ; european library ; europeana content ; cultural heritage ; eu-ropeana ; spanish ; navigation ; english	<task> <material> <material> <material> <material> <material> <material> <task> <material>	0 0 7 ; 8 1 6	this paper describes a system for navigating large collections of information about <material_4> which is applied to <material_5> , the <material_2> . euro-peana contains over 20 million artefacts with meta-data in a wide range of <material_1> . the system currently provides access to <material_3> with meta-data in <material_8> and <material_6> . the paper describes how <task_0> is used to enrich and organise this meta-data to assist <task_7> through <material_5> and shows how this information is used within the system .	4 5 2 9 -1 1 9 -1 3 8 6 11 9 -1 0 7 10 9 -1
Shortest Paths with Curvature and Torsion .	thin , elongated structures ; higher-order curve properties ; globally optimal method ; line graphs ; medical images ; torsion regularization ; multi-view reconstruction ; shortest paths ; small-scale problems ; images ; curvature ; torsion ; regularization ; discretization	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 5 12 ; 4 1 6 ; 10 1 11 ; 10 1 5	this paper describes a method of finding <otherscientificterm_0> in <material_9> and volumes . we use <otherscientificterm_7> to minimize very general functionals of <otherscientificterm_1> , such as <otherscientificterm_10> and <otherscientificterm_11> . our <method_2> uses <otherscientificterm_3> and its runtime is polynomial in the size of the <otherscientificterm_13> , often in the order of seconds on a single computer . to our knowledge , we are the first to perform experiments in three dimensions with <otherscientificterm_10> and <otherscientificterm_5> . the largest graphs we process have almost one hundred billion arcs . experiments on <material_4> and in <task_6> show the significance and practical usefulness of <otherscientificterm_12> based on <otherscientificterm_10> while <otherscientificterm_11> is still only tractable for <task_8> .	0 9 14 -1 7 1 10 11 17 14 -1 2 3 13 14 -1 5 18 14 -1 14 -1 4 6 15 16 14 -1
Image Segmentation with Networks of Variable States .	video images of railroad cars ; segmenting complex images ; digital signal processor ; neural net architecture ; two-dimensional geometrical shapes ; scale variation ; lighting conditions ; software model ; processor board ; workstation	<material> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	9 0 7 ; 3 0 4 ; 3 0 1 ; 2 0 7 ; 8 0 3 ; 9 1 2 ; 3 0 0	jan ben we developed a <method_3> for <task_1> , i.e. , to localize <otherscientificterm_4> in a scene , without prior knowledge of the objects ' positions and sizes . a <otherscientificterm_5> is built into the <method_3> to deal with varying sizes . this <method_3> has been applied to <material_0> , to find their identification numbers . over 95 % of the characlers were located correctly in a data base of 300 images , despile a large variation in <otherscientificterm_6> and often a poor quality of the characters . a part of the <method_3> is executed on a <otherscientificterm_8> containing an analog neural net chip -lrb- graf et ai . 1991 -rrb- . while the rest is implemented as a <method_7> on a <method_9> or a <method_2> .	3 1 4 12 13 10 -1 5 10 -1 0 17 10 -1 6 10 -1 8 15 10 -1 10 -1 11 14 16 10 -1
Normalised constant modulus algorithm with selective partial updates .	soft criterion satisfaction version ; normalised constant mod-ulus algorithm ; block of equaliser parameters ; constrained minimisation problem ; selective partial updating ; block selection criterion ; convergence speed ; fractionally-spaced equalisation ; equaliser parameters ; implementation cost ; full-update counterpart ; computational complexity ; multiplications	<method> <method> <otherscientificterm> <task> <method> <metric> <otherscientificterm> <task> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm>	11 5 0 ; 3 0 5 ; 12 0 8 ; 11 5 1 ; 1 4 0	a reduced complexity realisation for the <method_1> and its <method_0> is proposed based on <method_4> . the <metric_11> of <method_1> and <method_0> is reduced by updating a <otherscientificterm_2> at every iteration rather than the entire equaliser . this results in a smaller number of <otherscientificterm_12> for updating the <otherscientificterm_8> . a simple <metric_5> is derived from the solution of a <task_3> that underpins the development of <method_1> . in <task_7> , the proposed <method_4> is shown to be capable of maintaining comparable <otherscientificterm_6> to its <otherscientificterm_10> . this implies a significant reduction in <metric_9> without necessarily pe-nalising the <otherscientificterm_6> .	1 0 4 13 -1 11 2 14 17 18 13 -1 12 8 16 13 -1 5 3 15 13 -1 7 6 10 13 -1 9 13 -1
An improved consensus-like method for Minimum Bayes Risk decoding and lattice combination .	consensus a.k.a. confusion network decoding ; minimum bayes risk decoding ; lattice of alternative outputs ; word error rate ; confusion network combination ; lattice-based system combination ; lattice rescoring ; speech recognition ; e-m ; consensus ; rover	<method> <method> <otherscientificterm> <metric> <method> <task> <task> <task> <method> <method> <method>	1 0 7 ; 9 1 4 ; 4 1 10 ; 8 0 6 ; 6 1 5 ; 8 0 5	in this paper we describe a method for <method_1> for <task_7> . this is a technique similar to <method_0> , in which we attempt to find the hypothesis that minimizes the bayes ' risk with respect to the <metric_3> , based on a <otherscientificterm_2> . our method is an <method_8> like technique which makes approximations which we believe are less severe than the approximations made in <method_9> , and our experimental results show an improvement in <method_8> both for <task_6> and <task_5> , versus baselines such as <method_9> , <method_4> and <method_10> .	1 7 12 11 -1 0 3 2 11 -1 8 9 6 5 4 10 13 14 15 16 17 11 -1
Analysis and perception of speech under physical task stress .	physical task stress speech ; physical task stress ; physical stress content ; speech system ; fundamental frequency ; utterance duration ; acoustic correlates ; listener tests ; speech features ; glottal waveform ; features ; speech	<material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	0 0 3 ; 1 0 3 ; 4 1 9	it is known that <material_11> under <otherscientificterm_1> degrades <task_3> performance . therefore , an analysis of <material_11> under <otherscientificterm_1> is performed across several parameters to identify <otherscientificterm_6> . formal <otherscientificterm_7> are also performed to determine the relationship between <otherscientificterm_6> and perception . to verify the statistical significance of all results , student-t statistical tests are applied . it was found that <otherscientificterm_4> decreases for many speakers , that <otherscientificterm_5> increases for some speakers and decreases for others , and that the <otherscientificterm_9> is quantifiably different for many speakers . perturbation of two <otherscientificterm_8> , <otherscientificterm_4> and the <otherscientificterm_9> , is applied in <otherscientificterm_7> to quantify the degree to which these <otherscientificterm_10> convey <otherscientificterm_2> in <material_11> . finally , the enhanced understanding of <material_0> provided here is discussed in the context of <task_3> .	11 1 3 14 12 -1 6 12 -1 7 12 -1 12 -1 4 5 9 12 -1 8 15 12 -1 10 2 13 12 -1
Biologically Inspired Defenses Against Computer Viruses .	infected and un-infected programs ; neural network virus detector ; biologically inspired anti-virus techniques ; computer immune system ; computer viruses ; intelligent agents ; anti-virus technology	<material> <method> <method> <method> <otherscientificterm> <method> <method>	1 0 0	today 's <method_6> , based largely on analysis of existing viruses by human experts , is just barely able to keep pace with the more than three new <otherscientificterm_4> that are written daily . in a few years , <method_5> navigating through highly connected networks are likely to form an extremely fertile medium for a new breed of viruses . at ibm , we are developing novel , <method_2> designed to thwart both today 's and tomorrow 's viruses . here we describe two of these : a <method_1> that learns to discriminate between <material_0> , and a <method_3> that identifies new viruses , analyzes them automatically , and uses the results of its analysis to detect and remove all copies of the virus that are present in the <method_3> . the <method_2> has been incorporated into ibm 's commercial anti-virus product ; the <method_3> is in prototype .	6 4 7 -1 5 7 -1 2 7 -1 1 0 3 8 7 -1 7 -1
Mixture models for optical flow computation .	computation of 3d relative motion ; modeling of multiple motions ; optical ow v alues ; component v elocity measurements ; computation of optical ow ; maximum likelihood estimate ; occlusion boundaries ; image patch ; merging process ; motion parameters ; computational vision ; transparency ; em-algorithm ; outliers	<task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm>	13 2 2 ; 12 0 5 ; 7 0 4 ; 0 6 10 ; 5 0 9 ; 13 2 3 ; 6 1 11	the <otherscientificterm_4> relies on merging information available over an <otherscientificterm_7> to form an estimate of 2d image velocity a t a p o i n t . this <method_8> raises a host of issues , which include the treatment of <otherscientificterm_13> in <otherscientificterm_3> and the <task_1> within a patch which arise from <otherscientificterm_6> or <otherscientificterm_11> . w e present a new approach which allows us to deal with these issues within a common framework . our approach is based on the use of a probabilistic mixture m o del to explicitly represent m ultiple motions within a patch . we use a simple extension of the <method_12> to compute a <method_5> for the various <otherscientificterm_9> . preliminary experiments indicate that this approach is computationally eecient and can provide robust estimates of the <otherscientificterm_2> in the presence of <otherscientificterm_13> and multiple motions . the basic approach can also be applied to other problems in <task_10> , such as the <task_0> , which require the integration of several partial constraints to obtain a desired quantity .	4 7 17 14 -1 8 13 3 1 6 11 20 21 14 -1 14 -1 14 -1 16 19 14 -1 12 5 9 15 14 -1 2 18 14 -1
UMRAO : A Chess Endgame Tutor .	prototype chess tutor ; real time tutoring ; strategy graphs ; bishop-pawn endgames ; strategy graph ; knowledge-based approach ; minimax search ; strategic concepts ; chess player ; endgame problem ; knowledge-based chess ; computer chess ; umrao	<method> <task> <material> <otherscientificterm> <method> <method> <method> <otherscientificterm> <material> <task> <task> <material> <method>	5 0 7 ; 2 0 1 ; 12 6 0 ; 12 0 3	most research in <material_11> has focussed on creating an excellent <material_8> , with relatively little concern given to modelling how humans play <material_8> . the research reported in this paper is aimed at investigating <task_10> in the context of building a <method_0> , <method_12> , which helps students learn how to play <otherscientificterm_3> . in tutoring it is essential to take a <method_5> , since students must learn how to manipulate <otherscientificterm_7> , not how to carry out <method_6> . <method_12> uses an extension of michic 's advice language to represent expert and novice <material_8> plans . for any given endgame the <method_12> is able to compile the plans into a <method_4> , which elaborates strategies -lrb- both well-formed and ill-formed -rrb- that students might use as <material_2> solve the <task_9> . <material_2> can be compiled `` off-line '' so that <material_2> can be used in <task_1> . we show that the normally rigid `` model tracing '' tutoring paradigm can be used in a flexible way in this domain .	11 8 13 -1 10 0 12 3 16 17 13 -1 5 7 6 14 13 -1 13 -1 13 -1 4 2 9 15 13 -1 1 13 -1
Regionally optimised kernels for time-frequency distributions .	bilinear time-frequency distributions ; time-frequency plane ; finite mixture model ; time-varying kernels ; functional merging ; regional optimisation ; expectation-maximisation algorithm ; gaussian distributions ; computational burden ; time-frequency plane ; computational expense ; closely-spaced components	<method> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <metric> <method>	5 0 11 ; 6 1 4	ideally , kernels used to generate <method_0> should be signal-dependent , and optimised independently at every location in the <otherscientificterm_1> . this poses an extremely severe <metric_8> . a compromise is proposed in this paper : <method_3> are optimised for specific <method_3> in the <otherscientificterm_9> . the <method_3> , designed to isolate separate components comprising the signal , are determined by modelling the <method_0> using a <method_2> of <otherscientificterm_7> . the parameters of the model are estimated using a combination of the <method_6> and <method_4> . the <method_5> provides improved separation and resolution of <method_11> when compared to methods using a solely time-varying kernel , without incurring an overwhelming <metric_10> .	0 1 12 -1 8 12 -1 3 9 12 -1 2 7 12 -1 6 4 14 12 -1 5 11 13 12 -1
A Multi-Body Factorization Method for Motion Analysis .	mathematical construct of object shapes ; selection of coordinate systems ; shape interaction matrix ; segmenting features ; computer vision ; image level ; object motions ; canonical form ; image features ; structure-from-motion problem ; features ; shape	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	2 6 0 ; 2 0 11 ; 2 0 3 ; 9 3 4 ; 0 0 6	the <task_9> has been extensively studied in the field of <task_4> . yet , the bulk of the existing work assumes that the scene contains only a single moving object . the more realistic case where an unknown number of objects move in the scene has received little attention , especially for its theoretical treatment . in this paper we present a new method for separating and recovering the motion and <otherscientificterm_11> of multiple independently moving objects in a sequence of images . the method does not require prior knowledge of the number of objects , nor is dependent on any grouping of <otherscientificterm_10> into an object at the <otherscientificterm_5> . for this purpose , we introduce a <otherscientificterm_0> , called the <otherscientificterm_2> , which is invariant to both the <otherscientificterm_6> and the <task_1> . this <otherscientificterm_2> is computable solely from the observed trajectories of <otherscientificterm_8> without grouping them into individual objects . once the <otherscientificterm_2> is computed , <otherscientificterm_2> allows for <otherscientificterm_3> into objects by the process of transforming <otherscientificterm_2> into a <otherscientificterm_7> , as well as recovering the <otherscientificterm_11> and motion of each object .	9 4 16 12 -1 12 -1 12 -1 11 12 -1 12 -1 10 5 13 17 12 -1 0 2 6 1 12 -1 8 14 15 12 -1
PQ-WGLOH : A bit-rate scalable local feature descriptor .	visual search standardization ; compact yet discriminative local descrip-tor ; wireless query transmission latency ; matching and retrieval ; mpeg compact de-scriptor ; mobile visual search ; log-polar location grid ; table lookup operations ; product quantization ; image retrieval ; object localization ; 128-byte sift ; descriptor lengths ; low complexity ; image matching ; chog ; sift ; descriptors	<task> <method> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <metric> <task> <method> <method> <otherscientificterm>	9 1 14 ; 16 0 3 ; 2 3 5 ; 14 1 15 ; 4 0 0 ; 16 1 15 ; 15 1 14 ; 14 1 10 ; 15 1 15 ; 8 0 1 ; 1 4 15	in this paper , we propose a <method_1> which tackles the <task_2> in <task_5> . the <method_1> captures gradient statistics of canoni-cal patches over a <otherscientificterm_6> whose parameters are optimized using training samples . we quantize the resulting <method_1> using <otherscientificterm_8> . the <method_1> achieves about 95 % bits reduction compared with <method_11> and allows adaptation of <otherscientificterm_12> to support user required performance . moreover , accurate matching of <otherscientificterm_17> with <metric_13> is allowed within several <otherscientificterm_7> . we perform a comprehensive comparison with <method_16> , <method_15> and <method_15> in the context of <task_9> , <task_14> and <task_10> . we achieve competing <task_3> performance with <method_16> , <method_15> with much fewer bits . in particular , the <method_1> outperforms <method_15> at the same bits on eight data sets contributed to <method_4> for <task_0> .	1 2 5 21 18 -1 6 18 -1 8 28 18 -1 11 12 18 -1 17 13 7 18 -1 16 15 9 14 10 19 22 24 25 26 27 18 -1 20 18 -1 3 23 29 18 -1
Doubly Stochastic Variational Bayes for non-Conjugate Inference .	bayesian inference problems ; gaussian process regression ; variational inference algorithm ; continuous parameter spaces ; model joint density ; bayesian non-conjugate inference ; stochastic optimi-sation ; variable selection ; gradient information ; illustrative examples ; kernel hyperparameters ; stochastic approximation ; logistic regression	<task> <task> <method> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <material> <method> <method> <task>	3 2 5 ; 7 1 12 ; 7 6 0 ; 6 0 2 ; 11 0 2 ; 8 0 2 ; 10 3 1 ; 12 6 0 ; 2 0 5	we propose a simple and effective <method_2> based on <method_6> that can be widely applied for <task_5> in <otherscientificterm_3> . this <method_2> is based on <method_11> and allows for efficient use of <otherscientificterm_8> from the <otherscientificterm_4> . we demonstrate these properties using <material_9> as well as in challenging and diverse <task_0> such as <method_7> in <task_12> and fully bayesian inference over <method_10> in <task_1> .	2 6 5 3 14 17 22 13 -1 11 8 4 18 19 13 -1 9 0 7 12 10 1 15 16 20 21 13 -1
Top-Down Nearly-Context-Sensitive Parsing .	context-free dynamic programming algorithms ; fully-connected parse tree ; cognitive fact ; statistical parsers ; error reduction ; top-down parsers ; syntactic parser ; dynamic programming ; parse hypotheses ; parsers ; constraint	<method> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm>	6 0 1 ; 1 0 8 ; 4 5 9 ; 4 5 6 ; 4 5 5 ; 0 0 3	we present a new <method_6> that works left-to-right and top down , thus maintaining a <otherscientificterm_1> for a few alternative <otherscientificterm_8> . all of the commonly used <method_3> use <method_0> and as such work bottom up on the entire sentence . thus they only find a complete fully connected parse at the very end . in contrast , both subjective and experimental evidence show that people understand a sentence word-to-word as they go along , or close to it . the <otherscientificterm_10> that the <method_6> keeps one or more fully connected syntactic trees is intended to operationalize this <otherscientificterm_2> . our <method_6> achieves a new best result for <method_5> of 89.4 % , a 20 % <metric_4> over the previous single-parser best result for <method_9> of this type of 86.8 % -lrb- roark , 2001 -rrb- . the improved performance is due to embracing the very large feature set available in exchange for giving up <method_7> .	6 1 8 12 13 11 -1 3 0 17 11 -1 11 -1 11 -1 10 2 11 -1 14 15 16 11 -1 5 4 9 11 -1
Semantic Parsing via Paraphrasing .	candidate logical forms ; knowledge base predicates ; vector space model ; knowledge base information ; semantic parsing ; raw text ; association model ; semantic parsers ; question-answer pairs ; canonical realization ; logical form ; knowledge base ; natural language ; paraphrase model ; question-answering datasets ; accuracies	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <method> <material> <metric>	2 6 13 ; 3 0 7 ; 6 6 13	a central challenge in <task_4> is handling the myriad ways in which <otherscientificterm_1> can be expressed . traditionally , <method_7> are trained primarily from text paired with <otherscientificterm_3> . our goal is to exploit the much larger amounts of <material_5> not tied to any <material_11> . in this paper , we turn <task_4> on its head . given an input utterance , we first use a simple method to deterministically generate a set of <otherscientificterm_0> with a <otherscientificterm_9> in <material_12> for each . then , we use a <method_13> to choose the realization that best paraphrases the input , and output the corresponding <otherscientificterm_10> . we present two simple <method_13> , an <method_6> and a <method_2> , and train <method_13> jointly from <otherscientificterm_8> . our system parasempre improves state-of-the-art <metric_15> on two recently released <material_14> .	4 1 16 -1 7 3 18 16 -1 5 11 16 -1 16 -1 0 9 12 16 -1 13 16 -1 10 17 19 16 -1 6 2 8 16 -1
The Effects of Lexical Resource Quality on Preference Violation Detection .	lexical resource-based preference violation detector ; detecting selec-tional preference violations ; as-is lexical resources ; lexical resources ; f 1-measure ; annotated corpora ; nlp task ; parser outputs ; resource quality ; algorithmic improvements ; nlp tasks ; wordnet ; verbnet ; treebanks ; david	<method> <task> <material> <material> <metric> <material> <task> <otherscientificterm> <metric> <method> <task> <material> <material> <material> <method>	13 6 5 ; 11 6 3 ; 11 6 10 ; 11 1 12 ; 12 6 10 ; 1 6 6 ; 5 0 10 ; 13 6 3 ; 13 6 10 ; 3 0 10 ; 8 5 6 ; 12 6 3	lexical resources such as <material_11> and <material_12> are widely used in a multitude of <task_10> , as are <material_5> such as <material_13> . often , the resources are used as-is , without question or examination . this practice risks missing significant performance gains and even entire techniques . this paper addresses the importance of <metric_8> through the lens of a challenging <task_6> : <task_1> . we present <method_14> , a simple , <method_0> . with <material_2> , <method_14> achieves an <metric_4> of just 28.27 % . when the resource entries and <otherscientificterm_7> for a small sample are corrected , however , the <metric_4> on that sample jumps from 40 % to 61.54 % , and performance on other examples rises , suggesting that the algorithm becomes practical given refined resources . more broadly , this paper shows that <metric_8> matters tremendously , sometimes even more than <method_9> .	11 12 10 5 13 16 17 18 19 20 22 23 24 25 27 15 -1 15 -1 15 -1 8 6 1 21 26 15 -1 14 0 15 -1 2 4 15 -1 7 15 -1 15 -1
Detection of vowel on set points in continuous speech using autoassociative neural network models .	detection of vowel onset points ; autoasso-ciative neural network models ; consonant-vowel utterances ; recognition of cv units ; spotting subword units ; cv class ; aann models ; speech signal ; continuous speech ; vop	<task> <method> <material> <task> <task> <otherscientificterm> <method> <otherscientificterm> <material> <method>	9 0 2 ; 8 2 0 ; 6 0 5 ; 6 0 0	detection of vowel onset points -lrb- <task_0> -rrb- is important for <task_4> in <material_8> . for <material_2> , <method_9> is the instant at which the consonant part ends and the vowel part begins . accurate detection of <task_0> is important for <task_3> in <material_8> . in this paper , we propose an approach for detection of <task_0> using <method_1> . a pair of <method_6> are trained for each <otherscientificterm_5> to capture the characteristics of <otherscientificterm_7> in the consonant and vowel regions of that class . the trained <method_6> are then used to detect <task_0> in <material_8> . the results of studies show that the proposed approach leads to significantly less number of spurious hypotheses .	0 4 8 10 -1 2 9 11 10 -1 3 10 -1 1 10 -1 6 5 7 13 10 -1 12 14 10 -1 10 -1
A Well-Founded Semantics for Basic Logic Programs with Arbitrary Abstract Constraint Atoms .	arbitrary abstract constraint atoms ; abstract constraint atoms ; aggregate logic programs ; answer set semantics ; description logic programs ; logic programs ; well-founded semantics ; polynomial time ; rules	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 5 ; 6 0 4	logic programs with <otherscientificterm_1> proposed by marek and truszczynski are very general <method_4> . they are general enough to capture <method_2> as well as recently proposed <method_4> . in this paper , we propose a <otherscientificterm_6> for basic <method_4> with <otherscientificterm_0> , which are sets of <otherscientificterm_8> whose heads have exactly one atom . we show that similar to the <otherscientificterm_6> of normal <method_4> , it has many desirable properties such as that it can be computed in <otherscientificterm_7> , and is always correct with respect to the <otherscientificterm_3> . this paves the way for using our <otherscientificterm_6> to simplify these <method_4> . we also show how our semantics can be applied to <method_2> and <method_4> , and compare it to the <otherscientificterm_6> already proposed for these <method_4> .	1 4 10 9 -1 2 9 -1 6 0 8 9 -1 7 3 9 -1 9 -1 11 9 -1
Training a Feedback Loop for Hand Pose Estimation .	entirely data-driven approach ; convolutional neural network ; 3d pose ; deep networks ; depth image ; feedback loop ; input data ; 3d model ; training data ; gpu	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <material> <otherscientificterm>	5 0 1 ; 8 0 3	we propose an <method_0> to estimating the <otherscientificterm_2> of a hand given a <otherscientificterm_4> . we show that we can correct the mistakes made by a <method_1> trained to predict an estimate of the <otherscientificterm_2> by using a <otherscientificterm_5> . the components of this <otherscientificterm_5> are also <method_3> , optimized using <material_8> . they remove the need for fitting a <method_7> to the <material_6> , which requires both a carefully designed fitting function and algorithm . we show that our <method_0> outperforms state-of-the-art methods , and is efficient as our implementation runs at over 400 fps on a single <otherscientificterm_9> .	0 2 4 10 -1 1 5 11 10 -1 3 8 12 10 -1 7 6 10 -1 9 10 -1
Cluster-based color space optimizations .	conversion of multispectral and multipri-mary data ; multispectral or multiprimary data ; color deficient viewers ; natural '' mapping ; color transformation problems ; tristimulus colors ; tristimulus spaces ; source space ; image optimization ; cluster-based approach ; color spaces ; gamut mapping ; information loss ; natural mapping ; printing ; color ; grayscale ; metamerism ; bijective	<task> <material> <task> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 0 14 ; 0 6 4 ; 11 1 5 ; 5 6 4 ; 11 6 4 ; 0 1 8 ; 11 1 0 ; 5 1 8 ; 8 0 2 ; 9 0 4 ; 15 1 11 ; 15 6 4	transformations between different <otherscientificterm_10> and gamuts are ubiquitous operations performed on images . often , these transformations involve <otherscientificterm_12> , for example when <task_3> from <otherscientificterm_15> to <otherscientificterm_16> for <task_14> , from <material_1> to <otherscientificterm_6> , or from one <otherscientificterm_15> gamut to another . in all these applications , there exists a straightforward '' <task_3> from the <otherscientificterm_7> to the target space , but the <task_3> is not <otherscientificterm_18> , resulting in <otherscientificterm_12> due to <otherscientificterm_17> and similar effects . we propose a <method_9> for optimizing the transformation for individual images in a way that preserves as much of the information as possible from the <otherscientificterm_7> while staying as faithful as possible to the <task_13> . our <method_9> can be applied to a host of <task_4> including <otherscientificterm_15> to gray , <task_11> , <task_0> to <otherscientificterm_5> , and <task_8> for <task_2> .	10 19 -1 12 3 15 16 14 1 6 20 19 -1 7 18 17 19 -1 9 19 -1 13 21 22 23 24 25 26 27 28 29 30 31 19 -1
Evaluation of a singing voice conversion method based on many-to-many eigenvoice conversion .	many-to-many eigenvoice conversion ; voice timbre of singing voice ; singing voice conversion method ; nonparallel singing voice data ; singing-to-singing synthesis system ; singing voice conversion ; parallel data sets ; speaking voice conversion ; voice timbre ; probabilistic model ; training data	<method> <otherscientificterm> <method> <material> <method> <task> <material> <task> <otherscientificterm> <method> <material>	0 0 2 ; 4 0 6 ; 2 0 8 ; 5 1 7 ; 3 0 6	in this paper , we evaluate our proposed <method_2> from various perspectives . to enable singers to freely control their <otherscientificterm_1> , we have proposed a <method_2> based on <method_0> that enables to convert the <otherscientificterm_8> of an arbitrary source singer into that of another arbitrary target singer using a <method_9> . furthermore , to easily develop <material_10> consisting of multiple <material_6> between a single reference singer and many other singers , a technique for efficiently and effectively generating the <material_6> from <material_3> sets of many singers using a <method_4> have been proposed . however , we have never conducted sufficient investigations into the effectiveness of these proposed <method_2> . in this paper , we conduct both objective and subjective evaluations to carefully investigate the effectiveness of proposed <method_2> . moreover , the differences between <task_5> and <task_7> are also analyzed . experimental results show that our proposed <method_2> succeeds in enabling people to control their own <otherscientificterm_8> by using only an extremely small amount of the target singing voice .	2 11 -1 1 0 8 9 12 14 11 -1 10 6 3 4 13 16 11 -1 11 -1 11 -1 15 11 -1 5 7 11 -1
Feasibility of source separation in frequency domain .	l-point discrete fourier transform ; non linear filtering ; gaussianity of signals ; ith identified signal ; convergence speed ; frequency bin ; algorithm efficiency ; spectral kurtosis ; source separation ; frequency domain ; qarma processes ; reconstruction ; gaussianity ; l ; spectra	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <material> <method> <task> <otherscientificterm> <method> <otherscientificterm>	6 0 10 ; 0 0 2 ; 4 2 2 ; 9 2 8	we focus on the feasibility of the <task_8> in the <material_9> . first , it is linked with the <otherscientificterm_4> towards <otherscientificterm_2> after <method_0> . we test here a distance to <otherscientificterm_12> thanks to the <otherscientificterm_7> . we analyse the influence of <method_13> , of the duration of the source tricorrelations and of a <method_1> . we mainly develop the case of <method_10> . the second point consists in the <task_11> of the <otherscientificterm_14> of the estimated sources from the signals identified at each <otherscientificterm_5> . indeed , the source associated to the <otherscientificterm_3> is not necessarily the same from one <otherscientificterm_5> to another . the <metric_6> is then illustrated on <method_10> , including the procedures of separation and <task_11> .	8 9 19 15 -1 4 2 0 17 18 15 -1 12 7 15 -1 13 1 15 -1 10 15 -1 11 14 5 15 -1 3 15 -1 16 15 -1
3D rotation estimation using discrete spherical harmonic oscillator transforms .	spherical harmonics related algorithms ; angle estimation algorithms ; 3d rotation estimation ; rotated signal ; discrete shots ; spherical harmonics ; cartesian grids ; wigner-d matrix ; discrete shots ; precision ; noise ; accuracy ; robustness	<method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <method> <metric> <otherscientificterm> <metric> <metric>	4 4 1 ; 0 0 8	this paper presents an approach to <task_2> using discrete spherical harmonic oscillator transforms -lrb- <method_8> -rrb- . <method_4> not only have simple and fast implementation methods but also are compatible with the existing <method_1> related to <otherscientificterm_5> . <method_4> of the <otherscientificterm_3> follow the same formulation to the <otherscientificterm_7> as <otherscientificterm_5> transforms . thus , the <method_0> could be utilized to <method_8> without modification . furthermore , compared to some existing methods , our approach with <method_8> exhibits higher <metric_11> , higher <metric_9> and improved <metric_12> to <otherscientificterm_10> if the input signal is sampled uniformly on <material_6> . the phenomenon results from no interpolations in <method_8> .	2 8 4 13 -1 1 5 14 13 -1 3 7 13 -1 0 15 13 -1 11 9 12 10 6 13 -1 13 -1
Consistency of ℓ1-regularized maximum-likelihood for compressive Poisson regression .	1-regularized maximum-likelihood esti-mator ; n p setting ; compressive sensing setting ; canonical link function ; variable selection consistency ; asymp-totic sample complexity ; regression analysis ; high-dimensional statistics ; transmission tomography ; estimation consistency ; electrical engineering ; count data ; poisson regression	<method> <otherscientificterm> <method> <method> <metric> <metric> <task> <material> <task> <metric> <task> <material> <method>	3 0 12 ; 12 0 6 ; 8 0 10	we consider <method_12> with the <method_3> . this <method_12> is widely used in <task_6> involving <material_11> ; one important application in <task_10> is <task_8> . in this paper , we establish the <metric_4> and <metric_9> of the <method_0> in this <method_12> , and characterize the <metric_5> that ensures consistency even under the <method_2> -lrb- or the <otherscientificterm_1> in <material_7> -rrb- .	12 3 14 13 -1 6 11 10 8 15 16 13 -1 4 9 0 5 2 1 7 13 -1
Skewing : An Efficient Alternative to Lookahead for Decision Tree Induction .	greedy decision tree induction algorithms ; greedy decision tree learners ; constant run-time penalty ; time complexity ; parity functions ; problematic functions ; lookahead	<method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 6 5	this paper presents a novel , promising approach that allows <method_0> to handle <otherscientificterm_5> such as <otherscientificterm_4> . lookahead is the standard approach to addressing difficult functions for <method_1> . nevertheless , this approach is limited to very small <otherscientificterm_5> or subfunc-tions -lrb- 2 or 3 variables -rrb- , because the <metric_3> grows more than exponentially with the depth of <otherscientificterm_6> . in contrast , the approach presented in this paper carries only a <otherscientificterm_2> . experiments indicate that the approach is effective with only modest amounts of data for <otherscientificterm_5> or subfunctions of up to six or seven variables , where the examples themselves may contain numerous other -lrb- irrelevant -rrb- variables as well .	0 5 4 8 7 -1 1 7 -1 3 6 7 -1 2 7 -1 7 -1
Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation .	deep convolutional neu-ral networks ; conditional random fields ; cnn-based pairwise potential functions ; pascal voc 2012 dataset ; deep convolutional neu-ral networks ; multi-scale image input ; semantic image segmentation ; semantic segmentation datasets ; sliding pyramid pooling ; deep cnns ; patch-background context ; crf inference ; patch-patch context ; semantic segmentation ; intersection-over-union score ; semantic correlations ; network design ; back propagation ; contextual information ; sift-flow ; pascal-context ; nyudv2	<method> <method> <otherscientificterm> <material> <method> <material> <task> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <method> <task> <otherscientificterm> <method> <material> <material>	18 0 13 ; 5 2 16 ; 21 1 20 ; 5 1 8 ; 21 6 7 ; 19 6 7 ; 20 1 19 ; 2 0 1 ; 20 6 7 ; 8 0 16 ; 0 0 6	recent advances in <task_6> have mostly been achieved by training <method_0> for the task . we show how to improve <task_13> through the use of <otherscientificterm_18> . specifically , we explore ` patch-patch ' context and ` patch-background ' context with <method_9> . for learning the <otherscientificterm_12> between image regions , we formulate <method_1> with <otherscientificterm_2> to capture <otherscientificterm_15> between neighboring patches . efficient piecewise training of the proposed <method_0> is then applied to avoid repeated expensive <otherscientificterm_11> for <task_17> . in order to capture the <otherscientificterm_10> , we show that a <method_16> with traditional <material_5> and <method_8> is effective for improving performance . our experiment results set new state-of-the-art performance on a number of popular <material_7> , including <material_21> , pascal voc 2012 , <material_20> , and <method_19> . particularly , we achieve an <metric_14> of 77.8 on the challenging <material_3> .	6 0 33 22 -1 13 18 23 22 -1 9 22 -1 12 1 2 15 30 22 -1 11 17 22 -1 10 16 5 8 24 26 32 22 -1 25 27 28 29 31 22 -1 7 21 20 19 22 -1
Auditory attention decoding with EEG recordings using noisy acoustic reference signals .	electroencephalography recordings ; noisy acoustic reference signals ; spatio-temporal filter design ; acoustic reference signals ; clean speech signals ; cocktail-party scenario ; regularization parameters ; spatio-temporal filter ; decoding accuracy ; least-squares method ; auditory attention ; noise type ; decoding	<material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <task>	3 0 12 ; 12 0 1 ; 0 0 10 ; 7 1 6 ; 1 1 7	to decode <otherscientificterm_10> from <material_0> in a <otherscientificterm_5> with two competing speakers a <method_9> has recently been proposed , showing a promising <metric_8> . this method however requires the <material_4> of both the attended and the unattended speaker to be available as reference signals , which is difficult to achieve from the noisy recorded microphone signals in practice . in addition , optimizing the parameters involved in the <method_2> is of crucial importance in order to reach the largest possible <task_12> performance . in this paper , the influence of <otherscientificterm_1> and the <method_7> and <otherscientificterm_6> on the <task_12> performance is investigated . the results show that to some extent the <task_12> performance is robust to <otherscientificterm_1> , depending on the <otherscientificterm_11> . furthermore , we demonstrate the crucial influence of several parameters on the <task_12> performance , especially when the <otherscientificterm_3> used for <task_12> have been corrupted by noise .	10 0 5 9 8 16 13 -1 4 13 -1 2 12 13 -1 1 7 6 17 18 13 -1 15 13 -1 11 14 13 -1
An Expert Lexicon Approach to Identifying English Phrasal Verbs .	natural language processing ; phrasal verb expert lexicon ; phrasal verb identification problem ; finite state approach ; phrasal verbs ; lexicon module ; shallow parsing ; nlp frameworks ; phrasal verbs ; english parser ; morpho-syntactic interaction ; english language ; deep parsing	<task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <material> <method>	12 0 10 ; 6 1 12 ; 7 0 5 ; 3 0 2 ; 8 6 11 ; 3 0 10	phrasal verbs are an important feature of the <material_11> . properly identifying <method_8> provides the basis for an <method_9> to decode the related structures . <otherscientificterm_4> have been a challenge to <task_0> because <otherscientificterm_4> sit at the borderline between lexicon and syntax . traditional <method_7> that separate the <otherscientificterm_5> from the <method_9> make it difficult to handle this problem properly . this paper presents a <method_3> that integrates a <otherscientificterm_1> between <method_6> and <method_12> to handle <otherscientificterm_10> . with precision/recall combined performance benchmarked consistently at 95.8 % -97.5 % , the <task_2> has basically been solved with the presented <method_3> .	11 18 13 -1 8 9 4 13 -1 0 13 -1 7 5 16 13 -1 3 1 6 12 10 14 15 19 13 -1 2 17 13 -1
Answering Definition Questions via Temporally-Anchored Text Snippets .	temporally-anchored text snippets ; lightweight extraction method ; test question sets ; text snippets ; lexical resources ; processing modules ; web	<material> <method> <material> <material> <material> <method> <material>	2 5 0 ; 1 0 3 ; 6 0 1 ; 6 0 3	a <method_1> derives <material_3> associated to dates from the <material_6> . the snippets are organized dynamically into answers to definition questions . experiments on standard <material_2> show that <material_0> allow for efficiently answering definition questions at accuracy levels comparable to the best systems , without any need for complex <material_4> , or specialized <method_5> dedicated to finding definitions .	1 3 6 9 10 11 7 -1 7 -1 2 0 4 5 8 7 -1
Detecting System-directed Utterances using Dialogue-level Features .	spoken dialogue system ; audio inputs ; utterance length ; classification accuracy ; dialogue status ; user utterances ; feature set ; user utterance ; utterance timing ; logistic regression ; features ; transcription ; classification	<method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <task> <task>	4 6 6 ; 2 6 6 ; 5 0 11 ; 2 0 9 ; 10 0 12 ; 6 0 9 ; 2 1 4 ; 8 6 6 ; 8 1 2	we have developed a method to determine whether a <material_7> is directed at the system or not . a <method_0> should not respond to <otherscientificterm_1> that are not directed at it -lrb- i.e. , a user 's mutter -rrb- , and it therefore needs to detect such inputs to avoid unsuitable responses . we classify the two cases by <method_9> based on a <otherscientificterm_6> including <otherscientificterm_8> , <otherscientificterm_2> , and <otherscientificterm_4> . we conducted experiments using 5395 <material_5> for both <task_11> and automatic speech recognition results . results showed that the <metric_3> improved by 11.0 and 4.1 points , respectively . we also discuss which <otherscientificterm_10> are effective in the <task_12> .	7 13 -1 0 1 13 -1 9 6 8 2 4 14 15 17 19 20 21 22 13 -1 5 11 16 13 -1 3 13 -1 18 13 -1
Multi-Image Focus of Attention for Rapid Site Model Construction .	multi-image focus of attention mechanism ; virtual , horizontal plane ; structured background clutter ; volume of space ; structural salience measure ; back-projected gradient orientations ; aerial image scenarios ; space-sweep stereo method ; scene locations ; structural salience ; structural edges ; raised objects ; features ; buildings ; edges	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 3	a <method_0> has been developed that can quickly distinguish <otherscientificterm_11> like <otherscientificterm_13> from <otherscientificterm_2> typical to many <task_6> . the underlying approach is the <method_7> , in which <otherscientificterm_12> from multiple images are backprojected onto a <otherscientificterm_1> that is methodically swept through the scene . <otherscientificterm_5> from multiple images are highly correlated when <otherscientificterm_5> come from <otherscientificterm_8> containing <otherscientificterm_10> that are roughly horizontal , like building roofs and terrain ; otherwise , <otherscientificterm_5> tend to be uniformly distributed . these observations are used to define a <metric_4> that can determine whether a given <otherscientificterm_3> contains a statistically significant number of <otherscientificterm_10> , without first performing precise reconstruction of those <otherscientificterm_14> . the utility of <otherscientificterm_9> for computing focus of attention regions is illustrated on sample data from ft.hood , texas .	0 11 13 2 6 15 -1 7 12 1 5 15 -1 8 10 15 -1 4 3 16 15 -1 14 15 -1
Responsive Information Architect : Enabling Context-Sensitive Information Seeking .	full-fledged , context-sensitive information system ; context-sensitive multimodal input interpretation ; intelligent user interaction technologies ; automated multimedia output generation ; context-sensitive interaction paradigm ; user data requests ; context-sensitive information	<task> <task> <method> <task> <method> <material> <otherscientificterm>	4 0 6 ; 2 3 0 ; 1 1 3	information seeking is an important but often difficult task especially when involving large and complex data sets . we hypothesize that a <method_4> can greatly assist users in their information seeking . such a <method_4> allows a system to both understand <material_5> and present the requested information in context . driven by this hypothesis , we have developed a suite of <method_2> and integrated <method_2> in a <task_0> . in this paper , we review two sets of key technologies : <task_1> and <task_3> . we also share our evaluation results , which indicate that our <method_4> are capable of supporting <otherscientificterm_6> seeking for practical applications .	7 -1 4 7 -1 5 7 -1 2 0 9 7 -1 1 3 10 7 -1 8 7 -1
Automatic Extraction of Social Networks from Literary Text : A Case Study on Alice in Wonderland .	un-weighted gold network ; support vector machines ; social network extraction ; social event detection ; al-ice in wonderland ; literary text ; news corpus ; social network ; tree kernels ; network measures ; un-weighted network ; f-measure	<method> <method> <task> <task> <material> <material> <material> <method> <otherscientificterm> <method> <method> <metric>	3 1 2 ; 11 0 3 ; 4 0 7 ; 5 0 2 ; 8 1 1	in this paper we present results for two tasks : <task_3> and <task_2> from a <material_5> , <material_4> . for the first task , our system trained on a <material_6> using <otherscientificterm_8> and <method_1> beats the baseline systems by a statistically significant margin . using this system we extract a <method_7> from <material_4> . we show that while we achieve an <metric_11> of about 61 % on <task_3> , our extracted <method_10> is not statistically dis-tinguishable from the <method_0> according to popularly used <method_9> .	3 2 5 4 13 16 12 -1 6 8 1 17 12 -1 7 15 12 -1 11 10 0 9 14 12 -1
Finding Glass .	consistent support regions ; glass edges ; transparent objects ; visual cues ; real images ; background texture ; glass surfaces ; edges ; classifiers	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 0 3 ; 8 1 4	this paper addresses the problem of finding glass objects in images . <otherscientificterm_3> obtained by combining the systematic distortions in <otherscientificterm_5> occurring at the boundaries of <otherscientificterm_2> with the strong highlights typical of <otherscientificterm_6> are used to train a hierarchy of <method_8> , identify <otherscientificterm_1> , and find <otherscientificterm_0> for these <otherscientificterm_7> . qualitative and quantitative experiments involving a number of different <method_8> and <material_4> are presented .	3 9 -1 5 2 6 8 1 0 7 10 9 -1 4 11 9 -1
PAC-Bayes Learning of Conjunctions and Classification of Gene-Expression Data .	soft greedy '' learning algorithm ; dna micro-array data sets ; single real-valued attributes ; pac-bayes risk bound ; classifiers ; rays	<method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	1 5 0	we propose a '' <method_0> for building small conjunctions of simple threshold functions , called <otherscientificterm_5> , defined on <otherscientificterm_2> . we also propose a <otherscientificterm_3> which is minimized for <method_4> achieving a non-trivial tradeoff between sparsity -lrb- the number of <otherscientificterm_5> used -rrb- and the magnitude of the separating margin of each ray . finally , we test the <method_0> on four <material_1> .	0 5 2 6 -1 3 4 6 -1 1 7 6 -1
Equivalence between frequency domain blind source separation and frequency domain adaptive null beamformers .	frequency domain blind source separation ; adaptive null beam-formers ; frequency domain adaptive microphone arrays ; mean square error sense ; bss update equation ; mean square error ; filter coefficients ; off-diagonal components ; unmixing matrix ; jammer	<task> <method> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <method> <method> <method>	6 3 0	frequency domain blind source separation -lrb- <task_0> -rrb- is shown to be equivalent to two sets of <otherscientificterm_2> , i.e. , <method_1> . the minimization of the <method_7> in the <otherscientificterm_4> can be viewed as the minimization of the <metric_5> in the <task_0> . the <method_8> of the <task_0> and the <otherscientificterm_6> of the <task_0> converge to the same solution in the <metric_3> if the two source signals are ideally independent . therefore , we can conclude that the performance of the <task_0> is upper bounded by that of the <task_0> . this understanding clearly explains the poor performance of the <task_0> in a real room with long reverberation . the fundamental difference exists in the adaptation period when they should adapt . that is , the <task_0> can adapt in the presence of a <method_9> but the absence of a target , whereas the <task_0> can adapt in the presence of a target and <method_9> , and also in the presence of only a target .	0 2 1 10 -1 7 4 5 10 -1 8 6 3 11 10 -1 10 -1 10 -1 10 -1 10 -1
Learning from labeled and unlabeled data on a directed graph .	real-world web classification problems ; directionality of the edges ; labeled and unlabeled data ; spectral clustering approach ; spectral clustering method ; numerical techniques ; directed graphs ; time complexity ; directed graph ; undirected graphs ; graph	<task> <otherscientificterm> <material> <method> <method> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 6 ; 3 0 9 ; 4 0 3	we propose a general framework for learning from <material_2> on a <otherscientificterm_8> in which the structure of the <otherscientificterm_10> including the <otherscientificterm_1> is considered . the <metric_7> of the algorithm derived from this framework is nearly linear due to recently developed <method_5> . in the absence of labeled instances , this framework can be utilized as a <method_4> for <material_6> , which generalizes the <method_3> for <otherscientificterm_9> . we have applied our framework to <task_0> and obtained encouraging results .	2 8 10 1 11 -1 7 5 11 -1 4 6 3 9 12 13 14 11 -1 0 11 -1
Stability and Incentive Compatibility in a Kernel-Based Combinatorial Auction .	statistical learning theory ; approximate truth-inducing payments ; universal competitive equilibrium ; auction 's properties ; kernel method ; price structure ; allocation computation ; incentive compatibility ; kernel function ; auction designs ; auction literature ; complexity	<method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <material> <metric>	2 3 10	we present the design and analysis of an approximately incentive-compatible combinatorial auction . in just a single run , the auction is able to extract enough value information from bidders to compute <otherscientificterm_1> . this stands in contrast to current <method_9> that need to repeat the <otherscientificterm_6> as many times as there are bidders to achieve <otherscientificterm_7> . the auction is formulated as a <method_4> , which allows for flexibility in choosing the <otherscientificterm_5> via a <method_8> . our main result characterizes the extent to which our auction is incentive-compatible in terms of the <metric_11> of the chosen <method_8> . our analysis of the <material_3> is based on novel insights connecting the notion of stability in <method_0> to that of <otherscientificterm_2> in the <material_10> .	12 -1 1 12 -1 9 6 7 12 -1 4 5 8 12 -1 11 12 -1 13 12 -1
SCALPEL : Segmentation Cascades with Localized Priors and Efficient Learning .	bottom-up segmentation models ; rich region-merging cues ; mid-and high-level information ; localized shape priors ; pascal voc2010 dataset ; object seg-mentation ; segmentation process ; flexible method ; stopping criterion ; object layout ; segmentation proposals ; scalpel ; re-ranking ; class	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	0 0 11 ; 7 0 5 ; 9 1 13	we propose <method_11> , a <method_7> for <task_5> that integrates <otherscientificterm_1> with <otherscientificterm_2> about <otherscientificterm_9> , <otherscientificterm_13> , and scale into the <task_6> . unlike competing approaches , <method_11> uses a cascade of <method_0> that is capable of learning to ignore boundaries early on , yet use them as a <otherscientificterm_8> once the object has been mostly segmented . furthermore , we show how such <method_11> can be learned efficiently . when paired with a novel method that generates better <otherscientificterm_3> than our competitors , our method leads to a concise , accurate set of <otherscientificterm_10> ; these proposals are more accurate on the <material_4> than state-of-the-art methods that use <method_12> to filter much larger bags of proposals . the code for our algorithm is available online .	11 7 5 1 2 9 13 6 16 17 14 -1 0 8 15 14 -1 14 -1 3 10 14 -1 4 12 14 -1
Learning Lexicalized Reordering Models from Reordering Graphs .	reordering relations of adjacent phrases ; nist chinese-english test sets ; structure named reordering graph ; lexicalized reordering models ; lex-icalized reordering models ; word-aligned bilingual corpus ; phrase-based translation systems ; reordering models ; phrase segmentations	<task> <material> <method> <method> <method> <material> <task> <method> <otherscientificterm>	0 0 5 ; 2 0 8 ; 3 0 6	lexicalized <method_7> play a crucial role in <task_6> . they are usually learned from the <material_5> by examining the <task_0> . instead of just checking whether there is one phrase adjacent to a given phrase , we argue that it is important to take the number of adjacent phrases into account for better estimations of <method_7> . we propose to use a <method_2> , which represents all <otherscientificterm_8> of a sentence pair , to learn <method_4> efficiently . experimental results on the <material_1> show that our approach significantly outperforms the baseline method .	7 6 12 9 -1 5 0 10 9 -1 9 -1 2 8 4 11 9 -1 1 3 9 -1
Comparison of Grapheme-to-Phoneme Methods on Large Pronunciation Dictionaries and LVCSR Tasks .	grapheme-to-phoneme conversion ; end user customization ; phoneme error rate ; open source software ; n-best pronunciation variants ; g2p task ; text data ; asr system ; g2p accuracy	<task> <otherscientificterm> <metric> <method> <otherscientificterm> <task> <material> <method> <metric>	0 5 0 ; 0 0 7	grapheme-to-phoneme conversion -lrb- g2p -rrb- is usually used within every state-of-the-art <method_7> to generalize beyond a fixed set of words . although the performance is typically already quite good -lrb- < 10 % <metric_2> -rrb- and pronunciations of important words are checked by a linguist , further improvements are still desirable , especially for <otherscientificterm_1> . in this work , we present and compare five methods/tools to tackle the <task_5> . although most of the methods have already been published and/or are available as <method_3> , the reported experiments are done on large state-of-the-art tasks and the used software is from the actual publications . besides an experimental comparison on <material_6> for a range of languages -lrb- i.e. measuring the <metric_8> only -rrb- , our focus in this paper is measuring the effect of improved <task_0> on lvcsr performance for a challenging <task_5> . additionally , the effect of using <otherscientificterm_4> instead of single best is investigated briefly .	7 11 9 -1 2 1 9 -1 5 9 -1 3 9 -1 10 9 -1 6 8 0 9 -1
Non-linear spectral contrast stretching for in-car speech recognition .	log mel-filterbanks ; adaptation of the auditory system ; non-linear contrast stretching ; cepstral post-processing techniques ; baseline mfcc system ; feature normalization method ; log mfb domain ; censrec-2 in-car database ; log-scaled spectral domain ; adverse conditions ; processing artifacts ; two-dimensional filter ; computation load ; noise robustness	<method> <task> <method> <method> <method> <method> <material> <material> <material> <otherscientificterm> <task> <method> <otherscientificterm> <metric>	7 5 4 ; 12 0 5 ; 2 0 1 ; 9 2 1 ; 7 5 5 ; 5 4 4 ; 5 0 13 ; 2 0 0 ; 11 0 10 ; 8 0 13 ; 0 0 1 ; 3 0 6	in this paper , we present a novel <method_5> in the <material_8> for improving the <metric_13> of speech recognition front-ends . in the proposed <method_5> , a <method_2> is added to the outputs of <method_0> to imitate the <task_1> under <otherscientificterm_9> . this is followed by a <method_11> to smooth out the <task_10> . the proposed <method_5> perform remarkably well on <material_7> with an average relative improvement of 29.3 % compared to <method_4> . it is also confirmed that the proposed processing in <material_6> can be integrated with conventional <method_3> to yield further improvements . the proposed <method_5> is simple and requires only a small extra <otherscientificterm_12> .	5 8 13 21 24 14 -1 2 0 1 9 17 18 22 25 14 -1 11 10 23 14 -1 7 4 15 19 20 14 -1 6 3 26 14 -1 16 14 -1
A new dialogue control method based on human listening process to construct an interface for ascertaining a user ² s inputs .	naturally controlled dialogue ; dialogue control method ; stress-free voice input ; human dialogue analysis ; recognition processes ; real-time responses ; pretense-type recognition	<material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method>	5 0 1 ; 4 0 1	this paper describes a new <method_1> that utilizes new <method_4> called '' presupposition-type recognition '' and '' <method_6> '' that we propose based on <method_3> . this <method_1> provides users with <otherscientificterm_2> through <otherscientificterm_5> , comprising a <material_0> to obtain information in order to winnow candidates comprehensively .	1 4 6 3 9 7 -1 2 5 0 8 7 -1
Adaptive Image Fusion Using Ica Bases .	independent component analysis ; adaptive fusion scheme ; ica fusion framework ; image fusion ; modality sensors ; composite image	<method> <method> <method> <task> <otherscientificterm> <material>	0 0 3 ; 2 0 1 ; 4 3 5	image fusion can be viewed as a process that incorporates essential information from different <otherscientificterm_4> into a <material_5> . the use of bases trained using <method_0> for <task_3> has been highlighted recently . common fusion rules can be used in the <method_2> with promising results . in this paper , the authors propose an <method_1> , based on the <method_2> , that maximises the sparsity of the fusion image in the transform domain .	4 5 9 6 -1 0 3 7 6 -1 2 6 -1 1 8 6 -1
Network tomography for internal delay estimation .	estimation and localization of internal delays ; sequential monte carlo procedure ; tracking non-stationary delay characteristics ; internal network performance ; end-to-end delay measurements ; internal delay distributions ; traffic transmission protocols ; dynamic routing algorithms ; internal behavior ; em algorithm ; observation period ; network traffic ; network dynamics	<task> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 1 6 ; 1 0 2	on-line , spatially localized information about <metric_3> can greatly assist <method_7> and <method_6> . however , it is impractical to measure <otherscientificterm_11> at all points in the network . a promising alternative is to measure only at the edge of the network and infer <otherscientificterm_8> from these measurements . in this paper we concentrate on the <task_0> based on <otherscientificterm_4> from sources to receivers . we develop an <method_9> for computing mles of the <otherscientificterm_5> in cases where the <otherscientificterm_12> are stationary over the <otherscientificterm_10> . for time-varying cases , we propose a <method_1> capable of <task_2> . simulations are included to demonstrate the promise of these techniques .	3 7 6 14 13 -1 11 13 -1 8 13 -1 0 4 13 -1 9 5 12 10 13 -1 1 2 15 13 -1 13 -1
Locally Assembled Binary -LRB- LAB -RRB- feature with feature-centric cascade for fast and accurate face detection .	locally assembled binary haar feature ; local binary pattern ; binary haar feature ; binary haar features ; accumulated intensities ; haar features ; haar feature ; ordinal relationship ; detection method ; feature-centric method ; computational cost ; face detection ; detection speed ; feature-centric cascade ; discriminating power	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <metric> <task> <metric> <otherscientificterm> <otherscientificterm>	6 1 1 ; 13 4 1 ; 1 0 11 ; 13 4 6 ; 0 0 11 ; 1 0 0 ; 5 0 7 ; 0 6 13 ; 6 0 0	in this paper , we describe a novel type of <otherscientificterm_13> for fast and accurate <task_11> . the <otherscientificterm_13> is called <method_0> . <method_0> is basically inspired by the success of <method_6> and <method_1> for <task_11> , but it is far beyond a simple combination . in our <method_0> , <otherscientificterm_5> are modified to keep only the <otherscientificterm_7> -lrb- named by <otherscientificterm_2> -rrb- rather than the difference between the <otherscientificterm_4> . several neighboring <otherscientificterm_3> are then assembled to capture their co-occurrence with similar idea to <method_1> . we show that the <otherscientificterm_13> is more efficient than <method_6> and <method_1> both in <otherscientificterm_14> and <metric_10> . furthermore , a novel efficient <method_8> called <otherscientificterm_13> is proposed to build an efficient detector , which is developed from the <method_9> . experimental results on the cmu+mit frontal face test set and cmu profile test set show that the proposed <method_0> can achieve very good results and amazing <metric_12> .	13 11 15 -1 0 23 15 -1 6 1 18 20 21 24 15 -1 5 7 2 4 22 15 -1 3 15 -1 16 17 19 15 -1 14 10 15 -1 8 9 15 -1
Simultaneous learning of a discriminative projection and prototypes for Nearest-Neighbor classification .	classification error probability ; linear projection base ; image recognition research ; dimensionality reduction techniques ; iterative algorithm ; nearest-neighbor classifier ; dimensionality reduction ; classifier	<metric> <otherscientificterm> <task> <method> <method> <method> <method> <method>	4 0 1	computer vision and <task_2> have a great interest in <method_3> . generally these techniques are independent of the <method_7> being used and the learning of the <method_7> is carried out after the <method_6> is performed , possibly discarding valuable information . in this paper we propose an <method_4> that simultaneously learns a <otherscientificterm_1> and a reduced set of prototypes optimized for the <method_5> . the <method_4> is derived by minimizing a suitable estimation of the <metric_0> . the proposed <method_4> is assessed through a series of experiments showing a good behavior and a real potential for practical applications .	2 3 8 -1 7 6 8 -1 4 1 5 9 8 -1 0 8 -1 8 -1
Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model .	local information ; valence-arousal space ; va ratings of texts ; regional cnn-lstm model ; continuous numerical values ; dimensional sentiment analysis ; fine-grained sentiment analysis ; categorical approach ; long-distance dependency ; prediction process ; dimensional approach ; sentiment classification ; va prediction ; nn-based methods ; binary classification ; affective information ; lstm ; cnn	<otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method> <task> <task> <method> <method> <otherscientificterm> <method> <method>	14 6 11 ; 7 0 11 ; 5 0 4 ; 16 0 12 ; 10 1 16 ; 3 4 13 ; 10 1 0 ; 10 1 8 ; 10 0 6 ; 16 0 15	dimensional sentiment analysis aims to recognize <otherscientificterm_4> in multiple dimensions such as the <otherscientificterm_1> . compared to the <method_7> that focuses on <task_11> such as <method_14> -lrb- i.e. , positive and negative -rrb- , the <method_10> can provide more <method_6> . this study proposes a <method_3> consisting of two parts : <method_10> and <method_16> to predict the <material_2> . unlike a conventional <method_17> which considers a whole text as input , the proposed <method_10> uses an individual sentence as a region , dividing an input text into several regions such that the useful <otherscientificterm_15> in each region can be extracted and weighted according to their contribution to the <task_12> . such <otherscientificterm_15> is sequentially integrated across regions using <method_16> for <task_12> . by combining the <method_10> and <method_16> , both <otherscientificterm_0> within sentences and <otherscientificterm_8> across sentences can be considered in the <method_9> . experimental results show that the proposed <method_3> outperforms lexicon-based , regression based , and <method_13> proposed in previous studies .	4 1 21 18 -1 7 11 14 10 6 19 20 27 18 -1 3 16 2 18 -1 17 15 18 -1 12 22 28 18 -1 23 25 26 18 -1 0 8 9 24 18 -1
Crowdsourcing Translation : Professional Quality from Non-Professionals .	-lrb- optionally -rrb- calibration ; country of residence ; non-professional translators ; translation quality ; mechanical turk ; edit rate ; lm perplexity ; redundant translations ; professional translation ; professional translators ; features ; translation	<method> <otherscientificterm> <method> <metric> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 1 5	naively collecting translations by crowd-sourcing the task to <method_2> yields disfluent , low-quality results if no quality control is exercised . we demonstrate a variety of mechanisms that increase the <metric_3> to near professional levels . specifically , we solicit <otherscientificterm_7> and edits to them , and automatically select the best output among them . we propose a set of <otherscientificterm_10> that model both the translations and the translators , such as <otherscientificterm_1> , <otherscientificterm_6> of the <otherscientificterm_11> , <metric_5> from the other translations , and <method_0> against <otherscientificterm_9> . using these <otherscientificterm_10> to score the collected translations , we are able to discriminate between acceptable and unacceptable translations . we recreate the nist 2009 urdu-to-english evaluation set with <material_4> , and quantitatively show that our models are able to select translations within the range of quality that we expect from <otherscientificterm_9> . the total cost is more than an order of magnitude lower than <otherscientificterm_8> .	2 12 -1 3 12 -1 7 12 -1 10 1 6 11 5 0 9 13 12 -1 12 -1 12 -1 4 12 -1
Effective separation of sparse and non-sparse image features for denoising .	compressible and incompress-ible regions ; posterior median-based denoising method ; principal components analysis ; canonical transformation ; approximate classifier ; natural images ; modeling strategy ; textured regions ; undecimated wa-velets ; edges ; image	<otherscientificterm> <method> <method> <otherscientificterm> <method> <material> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	1 0 1 ; 2 0 4	over-complete representations of images such as <material_8> have enjoyed immense popularity in recent years . though <material_8> are efficient for modeling singularities and <otherscientificterm_9> , <material_5> also consist of textures that are difficult to capture with any <otherscientificterm_3> . in this work , we develop a new <method_6> with a rigorous treatment of <otherscientificterm_7> . using <method_2> as an <method_4> for <otherscientificterm_9> and textures , we partition an <otherscientificterm_10> into <otherscientificterm_0> -- with corresponding <method_1> matching their behaviors . a <method_1> using these <method_1> is described with preliminary results that demonstrate the effectiveness of this <method_1> .	8 11 -1 9 5 3 11 -1 6 7 11 -1 2 4 10 0 1 13 11 -1 12 11 -1
Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors .	identification of sparse dynamic linear systems ; prediction error minimization ; bibo stability constraint ; stable spline kernel ; bayesian nonparametric approach ; group lar algorithm ; parametric identification techniques ; scale factors ; impulse responses ; armax models ; gaussian processes ; sparse solutions ; exponential hyperpriors	<task> <method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm>	5 1 6 ; 4 4 6 ; 12 0 11 ; 4 0 0 ; 1 0 6 ; 10 0 8 ; 4 4 5	we introduce a new <method_4> to <task_0> . the <otherscientificterm_8> are modeled as <method_10> whose autocovariances encode the <otherscientificterm_2> , as defined by the recently introduced '' <method_3> '' . <method_11> are obtained by placing <otherscientificterm_12> on the <otherscientificterm_7> of such kernels . numerical experiments regarding estimation of <method_9> show that this <method_4> provides a definite advantage over a <method_5> and state-of-the-art <method_6> based on <method_1> .	4 0 17 13 -1 8 10 2 3 11 19 13 -1 12 7 16 13 -1 9 5 6 1 14 15 18 20 13 -1
Simple , robust , scalable semi-supervised learning via expectation regularization .	<i> expectation regularization </i> ; conditional label-likelihood objective function ; exponential family parametric models ; semi-supervised learning method ; deployed applications ; non-independent features ; model predictions ; data sets ; semi-supervised learning ; semi-supervised methods ; label priors ; unlabeled data ; logistic regression ; tuning ; scales	<method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <task> <material> <method> <method> <otherscientificterm> <material> <method> <task> <otherscientificterm>	3 0 2 ; 3 0 1	although <method_8> has been an active area of research , its use in <task_4> is still relatively rare because the methods are often difficult to implement , fragile in <task_13> , or lacking in scalability . this paper presents <method_0> , a <method_3> for <method_2> that augments the traditional <otherscientificterm_1> with an additional term that encourages <task_6> on <material_11> to match certain expectations -- such as <otherscientificterm_10> . the <method_3> is extremely easy to implement , <otherscientificterm_14> as well as <method_12> , and can handle <otherscientificterm_5> . we present experiments on five different <material_7> , showing accuracy improvements over other <method_9> .	8 4 13 15 -1 0 3 2 1 6 11 10 16 17 15 -1 14 12 5 15 -1 7 15 -1
Memory-based Particle Filter for face pose tracking robust under complex dynamics .	memory-based particle filter ; visual tracking applications ; abrupt object movements ; particle filtering framework ; proper dynamics model ; face pose estimation ; pf formulation.our method ; nonlinear , time-variant ; pf frameworks ; random sampling ; markov assumption ; tracking failure ; long-term dynamics ; magnetic sensors ; particle filter ; modeling systems ; complex dynamics ; prior distribution ; prior prediction ; tracking loss ; accuracy ; occlusions	<method> <task> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <task> <task> <metric> <otherscientificterm>	13 0 5 ; 0 6 14 ; 0 0 15 ; 9 0 17 ; 3 0 10 ; 0 0 17	a novel <method_14> , the <method_0> , is proposed that can visually track moving objects that have <otherscientificterm_16> . we aim to realize robust-ness against <otherscientificterm_2> and quick recovery from <task_11> caused by factors such as <otherscientificterm_21> . to that end , we eliminate the <otherscientificterm_10> from the previous <method_3> and predict the <otherscientificterm_17> of the target state from the <otherscientificterm_12> . more concretely , <method_0> stores the past history of the estimated target states , and employs a <method_9> from the history to generate <otherscientificterm_17> ; <method_0> represents a novel <method_6> can handle <otherscientificterm_7> , and non-markov dynamics , which is not possible within existing <method_8> . accurate <task_18> based on <method_4> is especially effective for recovering lost tracks , because <method_0> can provide possible target states , which can drastically change since the track was lost . we target the face pose of seated humans in this paper . quantitative evaluations with <method_13> confirm improved <metric_20> in <task_5> and successful recovery from <task_19> . the proposed <method_0> suggests a new paradigm for <task_15> with <otherscientificterm_16> and so offers a various <task_1> .	14 0 16 24 22 -1 2 11 21 22 -1 10 3 17 12 27 22 -1 9 6 7 26 28 22 -1 8 22 -1 18 4 22 -1 23 22 -1 13 20 5 19 25 22 -1
Efficient Methods for Dealing with Missing Data in Supervised Learning .	missing inputs -lrb- incomplete feature vectors ; weighted averaged backpropagation step ; incomplete feature vectors ; arbitrary feedforward networks ; input data distribution ; closed form solutions ; parzen windows ; regression problem ; missing features ; backpropagation step ; complexity ; recall ; training ; classification	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <metric> <metric> <task> <method>	5 0 11 ; 9 0 2 ; 13 1 7 ; 1 0 2	we present efficient algorithms for dealing with the problem of <otherscientificterm_0> -rrb- during <task_12> and <metric_11> . our approach is based on the approximation of the <otherscientificterm_4> using <otherscientificterm_6> . for <metric_11> , we obtain <method_5> for <method_3> . for <task_12> , we show how the <otherscientificterm_9> for an <otherscientificterm_2> can be approximated by a <otherscientificterm_1> . the <metric_10> of the <method_5> for <task_12> and <metric_11> is independent of the number of <otherscientificterm_8> . we verify our theoretical results using one <method_13> and one <task_7> .	0 12 11 14 -1 4 6 14 -1 5 3 14 -1 9 2 1 16 18 14 -1 10 8 15 14 -1 13 7 17 14 -1
Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons .	extraction of statistically independent components ; blind source separation -rrb- ; high-dimensional multi-sensory input streams ; extraction of independent components ; abstract information optimization principles ; unsupervised learning principles ; independent component analysis ; information bottleneck method ; concrete learning rules ; information bottleneck optimization ; high-dimensional input streams ; processing strategy ; sensory processing ; information sources ; internal predictions ; internal representation ; proprioceptive feedback	<task> <method> <otherscientificterm> <task> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	14 6 13 ; 16 6 13 ; 2 0 12 ; 9 1 3 ; 14 1 16 ; 2 0 0 ; 4 0 8	the <task_0> from <otherscientificterm_2> is assumed to be an essential component of <task_12> in the brain . such <method_6> -lrb- or <method_1> could provide a less redundant representation of information about the external world . another powerful <method_11> is to extract preferentially those components from <otherscientificterm_10> that are related to other <otherscientificterm_13> , such as <otherscientificterm_14> or <otherscientificterm_16> . this <method_11> allows the optimization of <method_15> according to the <method_7> . however , <method_8> that implement these general <method_5> for spiking neurons are still missing . we show how both <method_9> and the <task_3> can in principle be implemented with stochastically spiking neurons with refractoriness . the new <method_8> that achieves this is derived from <method_4> .	0 2 12 20 23 17 -1 6 1 17 -1 11 10 13 14 16 18 19 22 17 -1 15 7 17 -1 8 5 17 -1 9 3 21 17 -1 24 17 -1
Subjective Natural Language Problems : Motivations , Applications , Characterizations , and Implications .	subjective natural language problems ; opinion mining ; computational linguistics ; problem-solving methods ; sentiment analysis ; holis-tic approach ; characterizations	<task> <method> <task> <method> <task> <method> <otherscientificterm>	3 1 2 ; 1 1 4 ; 5 0 0	this opinion paper discusses <task_0> in terms of their motivations , applications , <otherscientificterm_6> , and implications . it argues that such <task_0> deserve increased attention because of their potential to challenge the status of theoretical understanding , <method_3> , and evaluation techniques in <task_2> . the author supports a more <method_5> to such <task_0> ; a view that extends beyond <method_1> or <task_4> .	0 6 7 -1 3 2 8 7 -1 5 1 4 9 10 7 -1
Phase-Based Local Features .	global and local brightness variations ; phase-based local feature ; complex-valued steerable filters ; common image deformations ; common illumination changes ; common brightness changes ; scale changes ; feature vectors ; steerable filters ; 2-d rotation ; differential invariants ; image deformations ; phase data ; identity information ; rotation ; noise ; feature	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 0 14 ; 10 0 11 ; 14 6 11 ; 4 1 9 ; 6 1 15 ; 15 1 5 ; 2 0 1 ; 10 0 1 ; 8 0 16	we introduce a new type of <otherscientificterm_1> based on the phase and amplitude responses of <method_2> . the design of this <otherscientificterm_1> is motivated by a desire to obtain <otherscientificterm_7> which are semi-invariant under <otherscientificterm_3> , yet distinctive enough to provide useful <otherscientificterm_13> . a recent proposal for such <otherscientificterm_1> involves combining <otherscientificterm_10> to particular <otherscientificterm_11> , such as <otherscientificterm_14> . our approach differs in that we consider a wider class of <otherscientificterm_11> , including the addition of <otherscientificterm_15> , along with both <otherscientificterm_0> . we use <method_8> to make the <otherscientificterm_16> robust to <otherscientificterm_14> . and we exploit the fact that <material_12> is often locally stable with respect to <otherscientificterm_6> , <otherscientificterm_15> , and <otherscientificterm_5> . we provide empirical results comparing our <otherscientificterm_1> with one based on <otherscientificterm_10> . the results show that our <otherscientificterm_1> leads to better performance when dealing with <otherscientificterm_4> and <otherscientificterm_9> , while giving comparable effects in terms of <otherscientificterm_6> .	1 2 24 17 -1 7 3 13 17 -1 10 11 14 19 20 17 -1 15 0 17 -1 8 16 18 26 17 -1 22 23 17 -1 12 6 5 25 17 -1 21 17 -1
Robust Gram Embeddings .	robust gram ; word embedding models ; regularized embedding formulation ; vectorial word representations ; word similarity tasks ; nlp applications ; finite data ; human similarities ; small datasets ; generalization abilities ; context embeddings ; training data ; overfitting ; complexity	<method> <method> <method> <method> <task> <task> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <metric>	3 0 5 ; 1 0 5 ; 0 6 2 ; 8 0 0 ; 1 0 3	word embedding <method_1> learn <method_3> that can be used in a variety of <task_5> . when <material_11> is scarce , these <method_1> risk losing their <otherscientificterm_9> due to the <metric_13> of the <method_1> and the <otherscientificterm_12> to <material_6> . we propose a <method_2> , called <method_0> , which penalizes <otherscientificterm_12> by suppressing the disparity between target and <otherscientificterm_10> . our experimental analysis shows that the <method_0> trained on <material_8> generalizes better compared to alternatives , is more robust to variations in the training set , and correlates well to <otherscientificterm_7> in a set of <task_4> .	1 3 5 15 16 19 14 -1 11 9 13 12 6 14 -1 2 0 10 17 14 -1 8 7 4 18 14 -1
Scene-Adapted Structured Light .	structured light 3d acquisition methods ; sampling of foreshortened patterns ; local intensity ranges ; infamous specularity problems ; confidence measure ; over-and under-exposure ; scene geometry ; aliasing ; intensities ; colors ; accuracy ; scanning	<method> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task>	9 1 8	in order to overcome several limitations of <method_0> , the <otherscientificterm_9> , <otherscientificterm_8> , and shapes of the projected patterns are adapted to the scene . based on a crude estimate of the <otherscientificterm_6> and reflectance characteristics , the <otherscientificterm_2> in the projected patterns are adapted , in order to avoid <otherscientificterm_5> in the image . this avoids the <otherscientificterm_3> and generally increases <metric_10> . the estimated geometry also helps to limit the effect of <otherscientificterm_7> caused by the <task_1> . furthermore , the approach also acounts for the adverse effects that small motions during <task_11> would normally have . moreover , the approach yields a <metric_4> at every pixel of the range image . last but not least , the scanner consists of consumer products only , and therefore is cheap .	0 9 8 13 12 -1 6 2 5 12 -1 3 10 12 -1 7 1 12 -1 11 12 -1 12 -1 4 12 -1
A spectral conversion approach to feature denoising and speech enhancement .	average segmental output signal-to-noise ratio ; clean speech signal ; clean speech features ; noisy speech features ; iterative kalman filter ; speech enhancement problem ; feature denoising method ; spectral conversion ; kalman filter	<metric> <material> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task> <method>	7 0 1 ; 0 5 4 ; 7 0 5 ; 2 1 1 ; 7 0 8 ; 7 0 3 ; 6 0 5 ; 4 0 2 ; 7 0 2 ; 8 0 1	in this paper we demonstrate that <task_7> can be successfully applied to the <task_5> as a <method_6> . the enhanced <task_7> can be used in the context of the <method_8> for estimating the <material_1> . in essence , instead of estimating the <otherscientificterm_2> and the <material_1> using the <method_4> , we show that is more efficient to initially estimate the <otherscientificterm_2> from the <otherscientificterm_3> using <task_7> -lrb- using a training speech corpus -rrb- and then apply the standard <method_8> . our results show an average improvement compared to the <method_4> that can reach 6 db in the <metric_0> , in low input snr 's .	7 5 6 12 16 9 -1 8 1 10 14 19 9 -1 2 4 3 13 15 17 18 9 -1 0 11 9 -1
OFDM for underwater acoustic communications : Adaptive synchronization and sparse channel estimation .	non-uniform frequency offset compensation ; phase synchronization method ; channel impulse response ; low-complexity channel estimation ; time domain ; decision-directed operation ; adaptive synchronization	<method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method>	6 0 5	a <method_1> , which provides <method_0> needed for wideband ofdm -lsb- 1 -rsb- , is coupled with <task_3> in the <otherscientificterm_4> . sparsing of the <method_2> leads to an improved performance , while <method_6> supports <otherscientificterm_5> and yields low overhead . system performance is demonstrated using experimental data transmitted over a 1 km shallow water channel in the 19 khz-31 khz band .	1 0 3 4 7 -1 2 6 5 8 7 -1 7 -1
A three-stage solution for flexible vocabulary speech understanding .	column-bigram finite-state transducer ; natural language processor ; flexible vocabulary speech understanding system ; out-of-vocabulary words ; phonetic and or-thographic transcriptions ; angie sublexical models ; syllable-level lexical units ; tighter linguistic constraint ; instantaneous sound-to-letter capability ; grapheme information ; three-stage approach ; iterative procedure ; word network ; jupiter implementation ; unknown words ; unseen data ; recognition ; tina	<method> <method> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <material> <task> <method>	10 0 3 ; 11 0 6 ; 5 0 12 ; 10 0 12 ; 10 0 2 ; 9 0 5 ; 2 0 3 ; 5 0 10 ; 8 0 16 ; 13 5 10	this paper discusses our <method_10> to a <task_2> , which can detect <otherscientificterm_3> , and hypothesize their <material_4> . in the first stage , we introduce the <method_0> which , while embedding <method_5> , also supports previously <material_15> from <otherscientificterm_14> . secondly , the <method_5> utilize <otherscientificterm_9> , providing <otherscientificterm_7> as well as <otherscientificterm_8> during <task_16> . thirdly , the <otherscientificterm_6> of the first stage are automatically derived via an <method_11> to optimize performance . the <method_10> employs <method_5> to output a <method_12> which is parsed by <method_17> , our <method_1> , in stage three . experiments with a <method_13> of this <method_10> are described in -lsb- 1 -rsb- .	10 2 3 4 19 23 25 18 -1 0 5 15 14 18 -1 9 7 8 16 24 27 18 -1 6 11 20 18 -1 12 17 1 21 22 26 18 -1 13 28 18 -1
PETRELS : Subspace estimation and tracking from partial observations .	recursive least squares ; long-term behavior of the data stream ; state of the art batch algorithms ; sequential low-rank matrix completion problem ; parallel estimation and tracking ; low-dimensional linear subspace ; subspace matrix ; matrix completion ; data stream ; least-squares estimation ; online fashion ; numerical examples ; recursive procedure ; low-dimensional subspace ; direction-of-arrival estimation ; subspace	<method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <material> <material> <method> <otherscientificterm> <task> <otherscientificterm>	12 0 13 ; 3 0 8 ; 11 0 14	we consider the <material_8> of reconstructing a <material_8> from a small subset of its entries , where the <material_8> is assumed to lie in a <otherscientificterm_5> , possibly corrupted by noise . it is also important to track the change of underlying <otherscientificterm_15> for many applications . this <material_8> can be viewed as a <task_3> in which the <otherscientificterm_15> is learned in an <material_10> . the proposed algorithm , called <method_4> by <method_0> , identifies the underlying <otherscientificterm_13> via a <method_12> for each row of the <otherscientificterm_6> in parallel , and then reconstructs the missing entries via <otherscientificterm_9> if required . <method_0> outperforms previous approaches by discounting observations in order to capture <otherscientificterm_1> and be able to adapt to <method_0> . <material_11> are provided for <task_14> and <task_7> , comparing <method_0> with <method_2> .	8 5 16 -1 15 16 -1 3 10 18 16 -1 4 0 13 12 6 9 17 16 -1 16 -1 1 11 19 16 -1
Nonlocal PdES on graphs for active contours models with applications to image segmentation and data clustering .	partial difference equations ; binary partitioning of data ; continuous global active contours ; high dimensional data clustering ; nonlo-cal discrete perimeters ; nonlocal regular-ization functionals ; nonlocal regularization functionals ; nonlocal image segmentation ; nonlocal global minimiz-ers ; image segmentation ; co-area formula ; gradients ; sub-graph ; graphs	<method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 0 8 ; 9 0 1 ; 6 1 4 ; 2 0 9 ; 7 1 3 ; 5 0 10	we propose a transcription on <otherscientificterm_13> of recent <otherscientificterm_2> proposed for <task_9> to address the problem of <task_1> represented by <otherscientificterm_13> . to do so , using the framework of <method_0> , we propose a family of <otherscientificterm_5> that verify the <otherscientificterm_10> on <otherscientificterm_13> . the <otherscientificterm_11> of a <otherscientificterm_12> are introduced and their properties studied . relations , for the case of a <otherscientificterm_12> , between the introduced <otherscientificterm_6> and <otherscientificterm_4> are exhibited and the <otherscientificterm_10> on <otherscientificterm_13> is introduced . finally , <method_8> can be considered on <otherscientificterm_13> with the associated energies . experiments show the benefits of the approach for <task_7> and <task_3> .	13 2 9 1 16 18 14 -1 0 5 10 20 14 -1 11 12 14 -1 6 4 17 14 -1 8 15 14 -1 19 14 -1
Content-based recommender systems for spoken documents .	corpus of public domain internet audio ; music and text domains ; music recommender systems ; spoken document retrieval ; content-based recommender systems ; heterogeneous information sources ; hybrid fusion techniques ; non-linguistic aspects ; content-based recommendation ; preference ratings ; relevance judgement ; document relevance ; bag-of-words baseline ; multisource approach ; content-based features ; spoken documents ; gender ; feature ; bags-of-words ; features ; media ; speaker	<material> <material> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material>	9 1 19 ; 19 0 4 ; 8 0 15 ; 13 4 12 ; 9 0 4 ; 21 1 16 ; 0 0 8	content-based recommender systems use <otherscientificterm_9> and <otherscientificterm_19> that characterize <material_20> to model users ' interests or information needs for making future recommendations . while previously developed in the <material_1> , we present an initial exploration of <task_8> for <material_15> using a <material_0> . unlike familiar speech technologies of topic identification and <task_3> , our recommendation task requires a more comprehensive notion of <otherscientificterm_11> than <otherscientificterm_18> would supply . inspired by <method_2> , we automatically extract a wide variety of <otherscientificterm_14> to characterize <otherscientificterm_7> of the audio such as <material_21> , language , <otherscientificterm_16> , and environment . to combine these <otherscientificterm_5> into a single <otherscientificterm_10> , we evaluate <otherscientificterm_17> , score , and <method_6> . our study provides an essential first exploration of the task and clearly demonstrates the value of a <method_13> over a <otherscientificterm_12> .	9 19 20 23 24 27 22 -1 1 8 15 0 25 29 22 -1 3 11 18 22 -1 2 14 7 21 16 28 22 -1 22 -1 5 10 17 6 26 22 -1
Meeting acts : a labeling system for group interaction in meetings .	icsi meeting recorder corpus ; high-level group interaction tags ; dialog act information ; dialog act sequences ; labeling process ; meeting style ; annotation system	<material> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <method>	3 1 5	we describe a new system for labeling speech corpora with <otherscientificterm_1> , called '' meeting acts . '' the system was motivated by a need to assess work seeking to automatically detect <otherscientificterm_5> using <otherscientificterm_2> . we present information about the relationships seen between <material_3> and <otherscientificterm_5> to motivate the <task_4> . we provide a summary of the <method_6> and labeling procedure , as well as preliminary inter-annotator reliability statistics on the <material_0> .	1 7 -1 5 2 7 -1 3 4 8 7 -1 6 0 7 -1
Limited enquiry negotiation dialogues .	dialogue management strategy limited enquiry negotiation dialogues ; dialogue designer 's standard components toolbox ; menu-traversal and slot-filling ; dialogue behaviour ; man-machine dialogues	<method> <method> <otherscientificterm> <otherscientificterm> <method>	0 0 4	we define a new <method_0> designed for enabling simple <method_4> in which the parameters -lrb- for which the user will supply values -rrb- of a query to a database are negotiated . the choice of which query to make next is also not pre-ordained . the <method_0> is simple and intuitive but permits interestingly complex <otherscientificterm_3> . we propose <method_0> as an addition to a <method_1> along with other well-known ideas such as <otherscientificterm_2> . we illustrate the <method_0> by examining how <method_0> accounts for interesting but by no means rare data in a wizard of oz corpus of business trip planning dialogues . finally , we discuss some more theoretical issues arising from the <method_0> .	0 4 6 5 -1 5 -1 3 5 -1 1 2 5 -1 5 -1 5 -1
Lattice MLLR based m-vector system for speaker verification .	maximum likelihood linear regression super-vectors ; universal background model ; nist sre 2008 core condition ; transcription of speech segments ; asr transcription errors ; lattice word transcriptions ; 1-best -lrb- hypothesis ; m-vector approach ; uniform segmentation ; speaker verification ; phonetic content	<method> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <material>	7 4 7 ; 0 0 7 ; 0 0 9 ; 7 0 9 ; 5 0 0 ; 8 0 0 ; 6 0 0	the recently introduced <method_7> uses <method_0> for <task_9> , where <method_0> are estimated with respect to a <method_1> without any <otherscientificterm_3> and speaker m-vectors are obtained by <method_8> of their <method_0> . hence , this <method_7> does not exploit the <material_10> of the speech segments . in this paper , we propose the integration of an automatic speech recognition -lrb- asr -rrb- based multi-class mllr transformation into the <method_7> . we consider two variants , with <method_0> computed either on the <otherscientificterm_6> -rrb- or on the <otherscientificterm_5> . the former case is able to account for the risk of <otherscientificterm_4> . we show that the proposed <method_7> outperform the conventional <method_7> over various tasks of the <metric_2> .	7 0 9 1 3 8 13 14 15 17 11 -1 10 11 -1 11 -1 6 5 16 18 11 -1 4 11 -1 12 11 -1
Handling recordings acquired simultaneously over multiple channels with PLDA .	nist sre12 core condition ; nist sre dataset ; speaker recognition scenarios ; inter-session variability terms ; telephone speech ; minimum dcf ; phonetic content ; plda model ; channel variability ; plda	<otherscientificterm> <material> <task> <otherscientificterm> <material> <metric> <material> <method> <otherscientificterm> <method>	4 5 7 ; 5 5 7 ; 0 5 7	in some <task_2> we find conversations recorded simultaneously over multiple channels . that is the case of the interviews in the <material_1> . to take advantage of that , we propose a modification of the <method_7> that considers two different <otherscientificterm_3> . the first term is tied between all the recordings belonging to the same conversation whereas the second is not . thus , the former mainly intends to capture the variability due to the <material_6> of the conversation while the latter tries to capture the <otherscientificterm_8> . we test this <method_7> on the <otherscientificterm_0> using multiple channels per interview to enroll the speakers . the proposed <method_7> improves the <metric_5> by 26 -- 29 % on <material_4> and by 1 -- 8 % on interviews compared to the standard <method_9> -lrb- scored by the book -rrb- .	2 10 -1 1 10 -1 7 3 10 -1 10 -1 6 8 10 -1 0 13 10 -1 11 12 10 -1
Infinite Markov-Switching Maximum Entropy Discrimination Machines .	maximum entropy discrimination framework ; local nonlinearity of complex data ; nonparametric bayesian inference scheme ; large-margin kernel machines ; bayesian posterior inference ; complex temporal dynamics ; component large-margin classifiers ; sequential data classification ; component switching mechanism ; efficient model training ; bayesian nonparametrics ; large-margin classifiers ; large-margin principle ; stick-breaking priors ; real-world datasets ; model components ; markov-switching construction ; modeled datasets	<method> <material> <method> <method> <method> <otherscientificterm> <method> <task> <method> <method> <method> <method> <otherscientificterm> <method> <material> <method> <task> <material>	0 0 9 ; 4 1 12 ; 3 0 7 ; 17 0 5 ; 10 1 10	in this paper , we present a method that combines the merits of <method_10> , specifically <method_13> , and <method_3> in the context of <task_7> . the proposed model employs a set of -lrb- theoretically -rrb- infinite interdependent <method_11> as <method_15> , that robustly capture <material_1> . the employed <method_11> are connected in the context of a <task_16> that allows for capturing <otherscientificterm_5> in the <material_17> . appropriate <method_13> are imposed over the <method_8> of our model to allow for data-driven determination of the optimal number of <method_6> , under a standard <method_2> . <method_9> is performed under the <method_0> , which integrates the <otherscientificterm_12> with <method_4> . we evaluate our method using several <material_14> , and compare it to state-of-the-art alternatives .	10 13 3 7 21 23 18 -1 11 15 1 18 -1 16 5 17 22 18 -1 8 6 2 9 18 -1 0 19 20 18 -1 12 4 18 -1
Robust stability of time-variant difference equations with restricted parameter perturbations : regions in coefficient-space .	linear time-variant system ; dierence equation	<method> <otherscientificterm>	1 0 0	suppose rate of change of coecients of a <method_0> modeled via a <otherscientificterm_1> is restricted . the work presented herein is an attempt at developing an algorithm that determines regions in coe-cient-space where such a <method_0> is guaranteed to be globally asymptotically stable . such information can be extremely useful in many applications . some previously published related results are consolidated as well .	0 1 3 2 -1 2 -1 2 -1 2 -1
Using voice suppression algorithms to improve beat tracking in the presence of highly predominant vocals .	audio voice suppression techniques ; beat tracking estimations ; beat tracking estimation ; voice suppression methods ; low pass filter ; generic annotated collection ; highly predominant vocals ; pairwise combinations ; music signals ; voice suppression ; beat trackers ; song excerpts ; beat tracking	<method> <task> <task> <method> <method> <material> <material> <otherscientificterm> <material> <task> <method> <material> <method>	4 0 1 ; 12 1 3 ; 6 2 11 ; 8 0 2 ; 12 1 7	beat tracking estimation from <material_8> becomes difficult in the presence of <material_6> . we compare the performance of five state-of-the-art algorithms on two datasets , a <material_5> and a dataset comprised of <material_11> with <material_6> . then , we use seven state-of-the-art <method_0> and a simple <method_4> to improve <task_1> in the later case . finally , we evaluate all the <otherscientificterm_7> between <method_12> and <method_3> . we confirm our hypothesis that <task_9> improves the mean performance of <method_10> for the predominant vocal collection .	8 6 17 13 -1 5 11 16 13 -1 0 4 1 14 13 -1 7 12 3 15 18 13 -1 9 10 2 13 -1
Zero-Resource Audio-Only Spoken Term Detection Based on a Combination of Template Matching Techniques .	french and english phonetic posteri-orgrams ; known query words of interest ; train and test methods ; raw mfcc features ; dynamic time warping ; spoken term queries ; template matching module ; self-similarity matrix comparison ; spoken term detection ; information retrieval task ; gaussian posteriorgrams ; contentful information ; linguistic resources ; speech variability ; speech templates ; zero-resource approach ; acoustic level ; audio ; robustness	<material> <otherscientificterm> <method> <material> <otherscientificterm> <material> <method> <method> <task> <task> <method> <otherscientificterm> <material> <otherscientificterm> <material> <method> <otherscientificterm> <material> <metric>	3 6 14 ; 10 6 14 ; 14 5 15 ; 0 6 14 ; 3 1 10 ; 18 2 13 ; 15 0 8 ; 4 1 7 ; 15 4 2 ; 10 1 10	spoken term detection is a well-known <task_9> that seeks to extract <otherscientificterm_11> from <material_17> by locating occurrences of <otherscientificterm_1> . this paper describes a <method_15> to such <task_8> based on pattern matching of <material_5> at the <otherscientificterm_16> . the <method_6> comprises the cascade of a segmental variant of <otherscientificterm_4> and a <method_7> to further improve <metric_18> to <otherscientificterm_13> . this <method_15> notably differs from more traditional <method_2> that , while shown to be very accurate , rely upon the availability of large amounts of <material_12> . we evaluate our <method_15> on different param-eterizations of the <material_14> : <material_3> and <method_10> , <material_0> output by two different state of the art phoneme recog-nizers .	9 11 17 1 19 -1 15 8 5 16 26 19 -1 6 4 7 18 13 25 27 19 -1 2 12 28 19 -1 14 3 10 20 21 22 23 24 29 19 -1
Collective AI : context awareness via communication .	local communication mechanisms ; real microro-botic swarms ; communication hardware ; collective ai ; collective navigation ; information content ; microrobot ; swarm	<method> <otherscientificterm> <method> <task> <otherscientificterm> <material> <method> <otherscientificterm>	5 0 4 ; 0 0 4 ; 0 0 1	communication among participants -lrb- agents , robots -rrb- is central to an appearance of <task_3> . in this work we deal with the development of <method_0> for <otherscientificterm_1> . we demonstrate that despite of very limited capabilities of the <method_6> , the specific construction of <method_2> and software allows very extended collective capabilities of the whole <otherscientificterm_7> . we propose <method_0> providing <material_5> and context for <otherscientificterm_4> , coordination and spatial perception in a group of microrobots .	3 8 -1 0 1 11 8 -1 6 2 7 8 -1 5 4 9 10 8 -1
Robust Fisher Discriminant Analysis .	fisher linear discriminant analysis ; robust kernel fisher discriminant analysis ; high dimensional feature space ; product form uncertainty model ; convex uncertainty models ; robust fisher lda ; classification problem ; convex optimization ; sensitivity problem ; data uncertainty	<method> <task> <otherscientificterm> <method> <method> <method> <task> <method> <task> <otherscientificterm>	0 0 8	fisher linear discriminant analysis -lrb- lda -rrb- can be sensitive to the problem data . <method_5> can systematically alleviate the <task_8> by explicitly incorporating a model of <otherscientificterm_9> in a <task_6> and optimizing for the worst-case scenario under this model . the main contribution of this paper is show that with general <method_4> on the problem data , robust <method_0> can be carried out using <method_7> . for a certain type of <method_3> , robust <method_0> can be carried out at a cost comparable to standard <method_0> . the method is demonstrated with some numerical examples . finally , we show how to extend these results to <task_1> , i.e. , robust <method_0> in a <otherscientificterm_2> .	5 10 -1 8 9 6 11 10 -1 4 0 7 10 -1 3 10 -1 10 -1 10 -1
Spectrogram dimensionality reductionwith independence constraints .	regularized non-negative matrix factorization problem ; nonnegative ica algorithms ; observation streams ; non-square matrices ; regularization term ; low-dimensional decomposition ; nmf	<task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	2 4 1 ; 5 0 5	we present an algorithm to find a <method_5> of a spectrogram by formulating <method_5> as a <task_0> with a <otherscientificterm_4> chosen to encourage independence . this algorithm provides a better decomposition than standard <method_6> when the underlying sources are independent . it is directly applicable to <otherscientificterm_3> , and it makes better use of additional <otherscientificterm_2> than previous <method_1> .	5 0 4 9 7 -1 6 7 -1 3 2 1 8 7 -1
Speaker - and language-independent speech recognition in mobile communication systems .	embedded multilingual speech recognition systems ; sub-optimal on-line text-to-phoneme mapping ; acoustic model adaptation techniques ; language-and speaker-independent asr applications ; speaker-independent speech recognition technology ; sparse implementation resources ; mobile communication devices ; multilingual acoustic models ; automatic language identification ; multilingual acoustic modeling ; on-line pronunciation modeling ; recognition rates ; dynamic vocabularies ; speaker independence ; language-independent asr ; recognition accuracy ; logistic difficulties ; speaker-dependent	<task> <method> <method> <task> <method> <material> <task> <method> <task> <task> <task> <metric> <otherscientificterm> <otherscientificterm> <method> <metric> <task> <method>	8 1 10 ; 5 2 3 ; 9 1 10 ; 10 0 3 ; 11 5 7 ; 9 1 8 ; 12 1 5 ; 4 0 6 ; 8 0 3 ; 14 0 16 ; 1 1 8	in this paper , we investigate the technical challenges that are faced when making a transition from the <method_17> to <method_4> in <task_6> . due to globalization as well as the international nature of the markets and the future applications , <otherscientificterm_13> implies the development and use of <method_14> to avoid <task_16> . we propose here an architecture for <task_0> . <task_9> , <task_8> , and <task_10> are the key features which enable the creation of truly <task_3> with <otherscientificterm_12> and <material_5> . our experimental results confirm the viability of the proposed architecture . while the use of <method_7> degrades the <metric_11> only marginally , a <metric_15> decrease of approximately 4 % is observed due to <method_1> and <task_8> . this performance loss can nevertheless be compensated by applying <method_2> .	17 4 6 26 18 -1 13 14 16 28 18 -1 0 9 18 -1 8 10 3 12 5 19 20 21 22 24 25 27 18 -1 18 -1 7 23 29 18 -1 11 15 1 18 -1
The coupling of rotation and translation in motion estimation of planar surfaces .	estimated motion and structure p arameters ; assumption of gaussian noise ; eld of view ; instantaneous motion eld ; unknown motion parameter ; viewing direction ; translation magnitude ; measurement noise ; planar surface ; motion eld ; uncertainty bounds ; unbi-ased estimator ; perceived plane ; statistical theory ; error sensitivity ; motion-geometry connguration ; error co-variance ; slant ; translation ; 3d-motion ; rotation ; lower-bound-matrix	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	0 0 16 ; 2 1 15	this paper studies the <metric_14> in the estimation of the <otherscientificterm_19> and the normal of a <otherscientificterm_8> from an <otherscientificterm_3> . we use the <method_13> of the cramer-rao lower bound for the <otherscientificterm_16> in the <otherscientificterm_0> which enables the derivation of results valid for any <method_11> under the <otherscientificterm_1> in the <otherscientificterm_9> . the obtained <method_21> is studied analytically with respect to the <otherscientificterm_7> , size of the <otherscientificterm_2> and the <otherscientificterm_15> . the main result of this analysis is the coupling between <otherscientificterm_18> and <otherscientificterm_20> which is exacerbated if the <otherscientificterm_2> and the <otherscientificterm_17> of the plane become smaller and the deviation of the <otherscientificterm_18> from the <otherscientificterm_5> becomes larger . by-products of this study are the relationships o f the <otherscientificterm_10> for every <otherscientificterm_4> to the angle between <otherscientificterm_18> and the plane-normal , the size of the <otherscientificterm_2> , the distance f r om the <otherscientificterm_12> and the <otherscientificterm_6> .	14 19 8 3 22 -1 13 16 0 11 1 9 23 22 -1 21 7 2 15 24 22 -1 18 20 17 22 -1 5 22 -1
HARMONET : A Neural Net for Harmonizing Chorales in the Style of J. S. Bach .	backpropagation and symbolic algorithms ; musical real-world problem ; harmonet 's power ; musically relevant information ; music processing ; bach chorales ; coding scheme ; musical practice ; hierarchical system ; connectionist networks ; one-part melody ; error backpropagation ; four-part chorales ; harmonet	<method> <task> <method> <otherscientificterm> <task> <material> <method> <task> <method> <method> <otherscientificterm> <method> <material> <method>	13 0 4 ; 6 0 13 ; 6 0 2 ; 11 0 5 ; 3 0 2 ; 9 0 4 ; 9 0 13 ; 13 0 12	harmonet , a <method_13> employing <method_9> for <task_4> , is presented . after being trained on some dozen <material_5> using <method_11> , the <method_13> is capable of producing <material_12> in the style of j . s.bach , given a <otherscientificterm_10> . our <method_13> solves a <task_1> on a performance level appropriate for <task_7> . <method_2> is based on -lrb- a -rrb- a new <method_6> capturing <otherscientificterm_3> and -lrb- b -rrb- the integration of <method_0> in a <method_8> , combining the advantages of both .	13 9 4 15 20 21 14 -1 5 11 12 18 22 14 -1 10 14 -1 1 7 2 14 -1 6 3 0 8 16 17 19 14 -1
Harnessing Object and Scene Semantics for Large-Scale Video Understanding .	object-and scene-based semantic fusion network ; semantic relationships -lrb- correlations ; video class-object/video class-scene relationships ; large-scale cnn object-detector ; large-scale action recognition ; three-layer neural network ; zero-shot action/video classification ; video categorization ; cnn scene-detector ; computer vision ; fusion network ; video classes ; semantic representation ; large-scale datasets-activitynet ; supervised activity ; clustering	<method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task> <task> <method> <task> <method> <material> <method> <material> <task> <task>	7 5 0 ; 12 0 11 ; 5 0 0 ; 2 0 12 ; 14 1 7 ; 13 1 7 ; 4 1 7 ; 6 1 15 ; 6 0 12 ; 3 0 0	large-scale action recognition and <task_7> are important problems in <task_9> . to address these problems , we propose a novel <method_0> and representation . our <method_0> combines three streams of information using a <method_5> : -lrb- i -rrb- frame-based low-level cnn features , -lrb- ii -rrb- object features from a state-of-the-art <method_3> trained to recognize 20k classes , and -lrb- iii -rrb- scene features from a state-of-the-art <method_8> trained to recognize 205 scenes . the trained <method_0> achieves improvements in <task_14> and <task_7> in two complex <material_13> and fcvid , respectively . further , by examining and back propagating information through the <method_10> , <otherscientificterm_1> -rrb- between <material_11> and objects/scenes can be discovered . these <otherscientificterm_2> can in turn be used as <method_12> for the <material_11> themselves . we illustrate effectiveness of this <method_12> through experiments on <task_6> and <task_15> .	7 9 23 16 -1 0 16 -1 5 3 8 19 26 16 -1 14 13 17 21 22 16 -1 16 -1 10 1 11 18 20 16 -1 2 12 24 25 16 -1
Automatic Data-Driven Learning of Articulatory Primitives from Real-Time MRI Data Using Convolutive NMF with Sparseness Constraints .	real-time magnetic resonance imaging ; sparseness constraints ; gesture-based articulatory phonology framework ; inter-pretable dynamic articulatory primitives ; articulatory recognition task ; recently-acquired rt-mri corpus ; data-driven manner ; parameter values ; activation matrix ; image sequences	<method> <method> <method> <otherscientificterm> <task> <material> <method> <otherscientificterm> <method> <material>	9 0 6 ; 0 0 6	we present a procedure to automatically derive <otherscientificterm_3> in a <method_6> from <material_9> acquired through <method_0> . more specifically , we propose a convolutive nonnegative matrix factorization algorithm with <method_1> to decompose a given set of <material_9> into a set of basis <material_9> and an <method_8> . we use a <material_5> of read speech -lrb- 460 sentences from 4 speakers -rrb- as a test dataset for this procedure . we choose the free parameters of the algorithm empirically by analyzing algorithm performance for different <otherscientificterm_7> . we then validate the extracted basis sequences using an <task_4> and finally present an interpretation of the extracted basis set of <material_9> in a <method_2> .	3 6 9 0 11 12 10 -1 1 8 10 -1 5 10 -1 7 10 -1 4 10 -1
Multiple Instance Learning with Manifold Bags .	multiple instance learning ; high dimensional feature space ; machine learning applications ; low dimensional manifolds ; finite sized bags ; real-world data ; geometric structure ; mani-fold bags ; memory requirements ; supervised learning ; mil problems ; manifold bags ; image ; audio ; pac-learnability ; heuristic	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	15 0 8 ; 12 1 13 ; 13 6 0	in many <task_2> , labeling every instance of data is burdensome . <task_0> , in which training data is provided in the form of labeled bags rather than labeled instances , is one approach for a more relaxed form of <task_9> . though much progress has been made in analyzing <task_10> , existing work considers bags that have a finite number of instances . in this paper we argue that in many applications of <task_0> -lrb- e.g. <otherscientificterm_12> , <otherscientificterm_13> , etc. -rrb- the bags are better modeled as <otherscientificterm_3> in <otherscientificterm_1> . we show that the <otherscientificterm_6> of such <otherscientificterm_11> affects <otherscientificterm_14> . we discuss how a learning algorithm that is designed for <otherscientificterm_4> can be adapted to learn from <otherscientificterm_7> . furthermore , we propose a simple <method_15> that reduces the <otherscientificterm_8> of such algorithms . our experiments on <material_5> validate our analysis and show that our approach works well .	2 0 16 -1 9 16 -1 10 16 -1 12 13 3 1 18 19 16 -1 6 16 -1 11 14 16 -1 4 7 17 16 -1 15 8 16 -1
Correspondence driven adaptation for human profile recognition .	convolutional neural network based system ; gender and age estimation ; incremental stochastic training ; statistical learning models ; visual recognition models ; human profile recognition ; supervision of correspondences ; visual recognition systems ; estimation accuracy ; video datasets ; object correspondences ; real-world environment ; fg-net database ; weak supervision ; human gender ; successive frames ; face images	<method> <task> <method> <method> <method> <task> <otherscientificterm> <method> <metric> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <material>	4 0 5 ; 3 0 7 ; 10 0 4 ; 7 0 11	visual recognition systems for videos using <method_3> often show degraded performance when being deployed to a <otherscientificterm_11> , primarily due to the fact that training data can hardly cover sufficient variations in reality . to alleviate this issue , we propose to utilize the <otherscientificterm_10> in <otherscientificterm_15> as <otherscientificterm_13> to adapt <method_4> , which is particularly suitable for <task_5> . specifically , we substantialize this new strategy on an advanced <method_0> to estimate <material_14> , age , and race . we enforce the system to output consistent and stable results on <material_16> from the same trajectories in videos by using <method_2> . our baseline system already achieves competitive performance on <task_1> as compared to the state-of-the-art algorithms on the <material_12> . further , on two new <material_9> containing about 900 persons , the proposed <otherscientificterm_6> improves the <metric_8> by a large margin over the baseline .	3 11 19 21 17 -1 10 15 13 4 5 18 20 17 -1 0 14 17 -1 16 17 -1 2 17 -1 1 12 17 -1
Pre-initialized composition for large-vocabulary speech recognition .	large vocabulary speech recogntion ; google android platform ; large-vocabulary recognition tasks ; modified composition algorithm ; finite-state transducers ; recognition transducer ; language model ; fine-grained trade-off ; context-dependent phones ; context-dependent lexicon ; decoding	<task> <method> <task> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	9 6 4 ; 9 1 6 ; 1 0 2	this paper describes a <method_3> that is used for combining two <method_4> , representing the <otherscientificterm_9> and the <method_6> respectively , in <task_0> . this <method_3> is a hybrid between the static and dynamic expansion of the resultant transducer , which maps from <otherscientificterm_8> to words and is searched during <task_10> . the <method_3> is to pre-compute part of the <method_5> and leave the balance to be expanded during <task_10> . this <method_3> allows for a <otherscientificterm_7> between space and time in recognition . for example , the time overhead of purely dynamic expansion can be reduced by over six-fold with only a 20 % increase in memory in a collection of <task_2> available on the <method_1> .	3 4 9 6 0 12 13 11 -1 8 10 11 -1 5 11 -1 7 11 -1 14 11 -1
A vanishing point-based global descriptor for Manhattan scenes .	compact , global image descriptor ; aggregate image statistics ; viewpoint-invariant object matching ; global image descriptor ; zurich buildings database ; relative locations ; global descriptors ; image distortions ; edge shapes ; edge map ; scene geometry ; error rate ; discriminative ability ; edge strengths ; manhattan scenes ; local maxima ; scale-displacement plots ; translation ; rotation ; occlusion ; descriptor ; cropping ; illumination	<method> <material> <task> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <metric> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	17 1 22 ; 18 1 22 ; 17 1 21 ; 1 0 6 ; 21 1 19 ; 22 1 21 ; 7 0 2 ; 3 0 14 ; 18 1 17 ; 22 1 19	viewpoint-invariant object matching is challenging due to <otherscientificterm_7> caused by several factors such as <otherscientificterm_18> , <otherscientificterm_17> , <otherscientificterm_22> , <otherscientificterm_21> and <otherscientificterm_19> . we propose a <method_0> for <material_14> that captures <otherscientificterm_5> and strengths of edges along vanishing directions . to construct the <otherscientificterm_20> , an <otherscientificterm_9> is determined per vanishing point , capturing the <otherscientificterm_13> over a range of angles measured at the vanishing point . for matching , descriptors from two scenes are compared across multiple candidate scales and displacements . the matching performance is refined by comparing <otherscientificterm_8> at the <otherscientificterm_15> of the <method_16> . the proposed <method_3> achieves an equal <metric_11> of 7 % for the <material_4> , indicating significant gains in <metric_12> over other <otherscientificterm_6> that rely on <material_1> but do not exploit the underlying <method_10> .	7 18 17 22 21 19 24 25 26 28 29 30 32 33 23 -1 0 14 5 31 23 -1 20 9 13 23 -1 23 -1 8 15 16 23 -1 27 23 -1
Lorentzian based iterative hard thresholding for compressed sensing .	robust iterative hard thresolding algorithm ; lorentzian cost function ; reconstructing sparse signals ; sparse reconstruction techniques ; impulsive noise ; computational load ; impulsive environments ; reconstruction quality ; iht algorithm ; heavy-tailed models ; robustness ; iht	<method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <metric> <method>	0 0 2 ; 10 5 0 ; 0 4 3 ; 7 5 0	in this paper we propose a <method_0> for <task_2> in the presence of <otherscientificterm_4> . to address this problem , we use a <otherscientificterm_1> instead of the í µí ° ¿ 2 cost function employed by the traditional <method_8> . the derived <method_0> is comparable in <otherscientificterm_5> to the least squares based <method_11> . analysis of the proposed <method_0> demonstrates its <metric_10> under <method_9> . simulations show that the proposed <method_0> significantly outperform commonly employed <method_3> in <otherscientificterm_6> , while providing comparable <metric_7> in less demanding , light-tailed environments .	0 2 4 13 12 -1 1 8 12 -1 5 11 12 -1 10 9 14 12 -1 3 6 7 15 16 12 -1
Analysis of Bit Error Probability of Direct-Sequence CDMA Multiuser Demodulators .	direct-sequence binary phase-shift-keying cdma channel ; mpm -lrb- marginal posterior mode -rrb- demodulators ; additive gaussian noise ; information bit rate ; low noise level ; finite-temperature decoding problem ; analog-valued hopfield model ; multiuser demodulators ; replica analysis ; mean-field approximation ; map demodulator ; mean-field demodulator ; demodulator	<task> <method> <otherscientificterm> <metric> <otherscientificterm> <task> <method> <method> <method> <method> <method> <method> <method>	7 2 5 ; 7 0 0 ; 6 0 7 ; 8 0 1	we analyze the bit error probability of <method_7> for <task_0> with <otherscientificterm_2> . the problem of <method_7> is cast into the <task_5> , and <method_8> is applied to evaluate the performance of the resulting <method_1> , which include the optimal <method_12> and the <method_10> as special cases . an approximate implementation of <method_7> is proposed using <method_6> as a naive <method_9> to the <method_1> , and its performance is also evaluated by the <method_8> . results of the performance evaluation shows effectiveness of the optimal <method_12> and the <method_11> compared with the conventional one , especially in the cases of small <metric_3> and <otherscientificterm_4> .	7 0 2 15 13 -1 5 8 1 12 10 14 17 13 -1 6 9 16 13 -1 11 13 -1
Multiresolution Tangent Distance for Affine-invariant Classification .	face or character recognition ; local minima -rrb- ; multiresolution tangent distance ; robust estimation procedures ; image classification tasks ; invariant metric ; similarity metrics ; regular images ; image transformations ; multiresolution setting	<task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <metric> <material> <task> <otherscientificterm>	5 0 7 ; 6 0 8 ; 0 6 4 ; 6 0 4	the ability to rely on <metric_6> invariant to <task_8> is an important issue for <task_4> such as <task_0> . we analyze an <method_5> that has performed well for the latter-the tangent distance-and study its limitations when applied to <material_7> , showing that the most significant among these -lrb- convergence to <otherscientificterm_1> can be drastically reduced by computing the distance in a <otherscientificterm_9> . this leads to the <otherscientificterm_2> , which exhibits significantly higher invariance to <task_8> , and can be easily combined with <method_3> .	6 8 4 0 12 13 14 10 -1 5 7 1 9 11 10 -1 2 3 10 -1
Non-negative matrix factorization for visual coding .	mit-cbcl training faces data ; sparse non-negative matrix factorization ; close model-non-negative sparse coding ; generalized kullback-leibler divergence ; linear sparse coding ; non-negative matrix factorization ; mean square error ; sparseness constraints ; multiplicative updates ; sparser representation ; parts-based representation ; approximation error	<material> <method> <method> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	4 0 1 ; 6 0 3 ; 5 0 1 ; 4 1 5 ; 6 0 11	this paper combines <method_4> and <method_5> into <method_1> . in contrast to <method_5> , the new model can leam much <method_9> via imposing <otherscientificterm_7> explicitly ; in contrast to a <method_2> , the new model can learn <method_10> via fully <otherscientificterm_8> because of adapting a <otherscientificterm_3> instead of the conventional <metric_6> for <otherscientificterm_11> . experiments on <material_0> demonstrate the effectiveness of the proposed method .	4 5 1 13 15 16 12 -1 9 7 2 10 8 3 6 11 14 17 12 -1 0 12 -1
An analysis of the Map Seeking Circuit and Monte Carlo extensions .	map seeking circuit ; ordering property of superpositions ; resolution of parameter estimates ; superpositions of the circuit ; resource constrained implementations ; high dimensional problem ; natural tasks ; biological vision ; parallel search ; monte-carlo approaches ; transformation discovery ; inverse kinematics ; transformation space ; signal processing ; vision ; collusions	<method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm>	11 1 6 ; 13 1 14 ; 14 1 11 ; 0 0 10 ; 2 0 4 ; 9 0 0 ; 8 0 5	the <method_0> has been suggested to address the inverse problem of <task_10> as found in <task_13> , <task_14> , <otherscientificterm_11> and many other <task_6> . according to this idea , a <method_8> in the <otherscientificterm_12> of a <otherscientificterm_5> can be decomposed into parts efficiently using the <method_1> . deterministic formulations of the circuit have been suggested . here , we provide a proba-bilistic interpretation of the architecture whereby the <otherscientificterm_3> are seen as a series of marginalisations over parameters of the transform . based on this , we interpret the weights of the <method_0> as importance weights . the latter suggests the incorporation of <method_9> in the <method_0> , providing improved <task_2> within <method_4> . as a final contribution , we model mixed serial/parallel search strategies of <otherscientificterm_7> to reduce the problem of <otherscientificterm_15> , a common problem in the standard <method_0> .	0 10 13 14 11 6 17 18 19 20 16 -1 8 12 5 1 23 16 -1 16 -1 3 16 -1 16 -1 21 22 16 -1 9 2 4 16 -1
Design of a high order binaural microphone array for hearing aids using a rigid spherical model .	speech-intelligibility weighted directivity index ; bilateral and binaural arrays ; artificial head + torso ; binaural hearing aids ; spherical head model ; free-field model ; free-field/spherical model ; free-field/spherical models ; bilateral arrays ; wireless technology ; hearing aids ; artificial head ; binaural arrays ; microphone arrays ; sii-di ; di	<metric> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	4 4 5 ; 4 0 15 ; 13 0 3 ; 7 0 1 ; 11 1 4 ; 4 0 13 ; 5 0 13 ; 11 1 2 ; 15 4 5 ; 9 0 13 ; 4 0 10	wireless technology has allowed for a much wider variety in the design of <otherscientificterm_13> for <task_3> . to facilitate the design of these <otherscientificterm_13> , this paper investigates the use of a <method_4> in the design of bilateral and binaural <otherscientificterm_13> for <task_10> . the <otherscientificterm_13> have been designed using a <method_5> , a <method_4> , measurements on an <otherscientificterm_11> , and measurements on an <otherscientificterm_2> . the results show that the <method_7> overestimate the <metric_0> of the <otherscientificterm_1> by respectively 0.9 / 0.4 and 0.8 / 0.5 db . furthermore the weights designed with the <method_6> yield an <method_14> that is 0.7 / 0.6 db lower for <otherscientificterm_8> and 0.9 / 0.9 db lower for <otherscientificterm_12> than the optimal <method_14> . although the results show that the <method_4> is better in predicting the <method_15> than the <method_5> , the <method_4> does not design better weights .	13 3 19 26 16 -1 4 10 27 16 -1 5 11 2 21 22 23 24 16 -1 7 0 1 20 16 -1 6 14 16 -1 8 12 17 18 25 16 -1
Multi-Conditional Learning : Generative/Discriminative Training for Clustering and Classification .	multi-conditional learning ; generative topic models ; latent dirichlet allocation ; exponential family harmonium ; conditional random fields ; text data sets ; discriminative classifiers ; classification error ; latent variables ; mcl regularization ; training criterion ; latent structure ; logistic regression ; precision ; recall ; accuracy ; regularizer ; robustness	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <metric> <metric> <metric> <method> <metric>	2 1 3 ; 12 1 4 ; 2 1 12 ; 2 6 6 ; 4 6 6 ; 13 1 14 ; 3 6 1 ; 2 6 1 ; 2 1 4 ; 12 6 6	this paper presents <method_0> , a <otherscientificterm_10> based on a product of multiple conditional likelihoods . when combining the traditional conditional probability of '' label given input '' with a generative probability of '' input given label '' the later acts as a surprisingly effective <method_16> . when applied to models with <otherscientificterm_8> , <method_0> combines the structure-discovery capabilities of <method_1> , such as <otherscientificterm_2> and the <otherscientificterm_3> , with the <metric_15> and <metric_17> of <method_6> , such as <method_12> and <otherscientificterm_4> . we present results on several standard <material_5> showing significant reductions in <otherscientificterm_7> due to <task_9> , and substantial gains in <metric_13> and <metric_14> due to the <otherscientificterm_11> discovered under <method_0> .	0 10 18 -1 16 18 -1 8 1 2 3 15 17 6 12 4 19 20 21 22 23 25 26 27 28 18 -1 5 7 9 24 18 -1
Multilinear generalization of Common Spatial Pattern .	common spatial patterns algorithm ; brain computer interface ; simultaneous optimization of projection matrices ; multi-class motor imagery eeg ; tensor analysis theory ; high-order tensor data ; classification accuracy ; optimization criteria ; multilinear formulation ; eeg classification	<method> <task> <task> <task> <method> <material> <metric> <method> <method> <task>	0 0 9 ; 6 5 8 ; 8 0 2 ; 4 0 2 ; 8 0 3 ; 8 0 0 ; 9 1 1 ; 0 0 1 ; 6 5 3	the <method_0> has been widely used in <task_9> and <task_1> . in this paper , we propose a <method_8> of the <method_0> , termed as tensorcsp or common tensor discriminant analysis -lrb- ctda -rrb- for <material_5> . as a natural extension of <method_0> , the proposed <method_8> uses the analogous <method_7> in <method_0> and a new framework for <task_2> on each mode based on <method_4> is developed . experimental results demonstrate that our proposed <method_8> is able to improve <metric_6> of <task_3> .	0 9 1 11 17 18 10 -1 8 5 16 10 -1 7 2 4 13 14 10 -1 6 3 12 15 19 10 -1
Active Task Selection for Lifelong Machine Learning .	batch multi-task learning methods ; lifelong learning algorithms ; curriculum selection methods ; lifelong learning setting ; active task selection ; lifelong learning framework ; knowledge acquisition ; learning tasks ; learning time ; transfer learning ; lifelong learning	<method> <method> <method> <task> <method> <method> <task> <task> <metric> <method> <task>	1 0 0 ; 9 0 3 ; 2 0 10 ; 9 0 6	in a <method_5> , an <method_5> acquires knowledge incrementally over consecutive <task_7> , continually building upon its experience . recent <method_1> have achieved nearly identical performance to <method_0> while reducing <metric_8> by three orders of magnitude . in this paper , we further improve the scalability of <task_10> by developing <method_2> that enable an <method_5> to actively select the next task to learn in order to maximize performance on future <task_7> . we demonstrate that <method_4> is highly reliable and effective , allowing an <method_5> to learn high performance models using up to 50 % fewer tasks than when the <method_5> has no control over the task order . we also explore a variant of <method_9> in the <task_3> in which the <method_5> can focus <task_6> toward a particular target task .	5 7 11 -1 1 0 8 12 11 -1 10 2 14 11 -1 4 11 -1 13 15 11 -1
Soccer Video Retrival Using Adaptive Time-Frequency Methods .	automatic annotation of events ; retrieval of soccer highlights ; adaptive time-frequency representation ; adaptive time-frequency decomposition ; feature extraction procedure ; matching pursuit concept ; feature extraction stage ; real soccer video ; multimedia database management ; soccer video ; video indexing ; classification stage ; soccer games ; audio soundtrack	<otherscientificterm> <task> <method> <method> <method> <method> <otherscientificterm> <material> <method> <material> <task> <otherscientificterm> <material> <material>	7 0 2 ; 1 0 10 ; 6 0 2	the <task_1> is a suitable technique for <task_10> , required by the <method_8> or for the development of television on demand . for these purposes , it should be interesting to have an <otherscientificterm_0> happened in <material_12> . one solution consists in analyzing the <material_13> associated to the <material_9> and to detect the interesting frames . in this paper we use the <method_3> of the soundtrack as a <method_4> . this decomposition is based on the <method_5> and a dictionary composed of gabor functions . the parameters provided by these transformations constitute the input of the <otherscientificterm_11> . the results provided for <material_7> will prove the efficiency of the <method_2> as a <otherscientificterm_6> .	1 10 8 16 14 -1 0 12 14 -1 13 9 14 -1 3 4 14 -1 5 14 -1 11 14 -1 15 17 14 -1
Evaluation of objective measures for quality assessment of reverberant speech .	reverberant and dereverberated speech ; objective quality measures ; subjective rating scales ; subjective quality ratings ; overall speech quality ; reverberation tail effect ; speech coloration ; reverberant speech ; dereverberation algorithms ; pesq-based measures	<material> <metric> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <material> <method> <method>	6 1 5 ; 5 1 4	in this paper , we evaluate the performance of existing and new objective measures in terms of predicting the quality of <material_7> and speech enhanced by <method_8> . we use <method_3> designed to evaluate the quality of speech along three dimensions : <otherscientificterm_6> , <otherscientificterm_5> and <metric_4> . experimental results assess the correlations between the proposed <metric_1> and the three <otherscientificterm_2> and suggest that <method_9> can very reliably predict the quality of <material_0> .	7 8 10 -1 3 6 5 4 11 12 10 -1 1 2 9 0 10 -1
Nonlinear filtering by kriging , with application to system inversion .	parametric behavioural models ; nonlinear system inversion ; parametric models ; prediction methods ; model structure ; prediction	<method> <task> <method> <method> <otherscientificterm> <task>	4 0 5 ; 2 0 3	prediction by kriging does not rely on any specific <otherscientificterm_4> , and is thus much more flexible than approaches based on <method_0> . since accurate predictions are obtained for extremely short training sequences , it generally performs better than <method_3> using <method_2> . application to <task_1> is considered	4 0 7 6 -1 3 2 8 6 -1 1 5 6 -1
Energy Minimization via Graph Cuts : Settling What is Possible .	pair-wise and triplewise pixel interactions ; graph cut based algorithms ; graph cut methods ; k-wise pixel interactions ; graph cuts ; energy functions ; algebraic approach ; computer vision ; approximate algorithms ; functions	<otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm>	4 0 5 ; 2 0 7	the recent explosion of interest in <method_2> in <task_7> naturally spawns the question : what <otherscientificterm_5> can be minimized via <method_4> ? this question was first attacked by two papers of kolmogorov and zabih -lsb- 23 , 24 -rsb- , in which they dealt with <otherscientificterm_9> with <otherscientificterm_0> . in this work , we extend their results in two directions . first , we examine the case of <otherscientificterm_3> ; the results are derived from a purely <method_6> . second , we discuss the applicability of provably <method_8> . both of these developments should help researchers best understand what can and can not be achieved when designing <method_1> .	2 7 5 4 9 0 11 12 10 -1 10 -1 3 6 10 -1 8 10 -1 10 -1 1 10 -1
Investigating sampling and quantization using a digital storage oscilloscope .	a/d converter ; laboratory exercise ; display capabilities ; aliasing ; quantization ; sampling	<otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task>	5 1 3 ; 1 0 5 ; 2 0 1 ; 1 0 3 ; 3 1 4	the objective of this paper is to remforce students understanding of <task_5> through experimentation . the scope of this paper is very narrow , focusing on a single <method_1> for learning about <task_5> , which is a critically important topic for students to comprehend . the <method_1> makes an ideal platform for studying <task_5> , <task_3> , and <otherscientificterm_4> , because not only does the <method_1> have a built in <otherscientificterm_0> and all the supporting electronics , but <method_1> has the <otherscientificterm_2> in both the time and frequency domains . additionally , students obtain a better understanding of test and measurement equipment such as the <method_1> .	5 6 -1 1 6 -1 3 4 0 2 7 8 9 10 11 6 -1 6 -1
Sparse variable PCA using a steepest descent on a Grassman manifold .	vector l1 penalized pca criterion ; svpca algorithm ; grassman manifold ; pca or-thogonality ; geodesic	<method> <method> <otherscientificterm> <method> <otherscientificterm>	1 4 0 ; 0 4 1 ; 4 0 0	recently there has developed considerable interest in using sparse-ness with <method_3> . almost all previous methods concentrate on zeroing out some loadings . here we develop a new approach which zeros out whole variables automatically . we formulate a <method_0> and optimize <method_0> by steepest descent along <otherscientificterm_4> on a <otherscientificterm_2> . this ensures that each step obeys <method_3> as well as an invariance property of the criterion . we show in simulations that <method_0> outperforms a previous <method_1> and apply <method_0> to a real high dimensional functional magnetic resonance imaging -lrb- fmri -rrb- data .	3 5 -1 5 -1 5 -1 0 4 2 8 5 -1 5 -1 1 6 7 5 -1
Application of Meddis ' inner hair-cell model to the prediction of subjective speech quality .	mean opinion scores mos ; instrumental speech-quality measure ; auditory-nerve ring-patterns	<metric> <method> <method>	2 0 1	this paper demonstrates how an <method_1> based on the comparison of <method_2> can be constructed . four available subjective tests prove that the <metric_0> estimated by the objective measure are in good agreement with the subjectively obtained results .	1 2 4 3 -1 0 3 -1
An Experimentally Efficient Method for -LRB- MSS , CoMSS -RRB- Partitioning .	mss -lrb- maximal satisfiable subset -rrb- ; minimal correction subset -rrb- ; boolean cnf formula ; a.i. approaches ; comss	<method> <method> <method> <method> <method>	0 1 1 ; 1 1 4	the concepts of <method_0> and <method_4> -lrb- also called <method_1> play a key role in many <method_3> and techniques . in this paper , a novel algorithm for partitioning a <method_2> into one <method_1> and the corresponding <method_4> is introduced . extensive empirical evaluation shows that it is more robust and more efficient on most instances than currently available techniques .	0 4 1 3 6 5 -1 2 7 5 -1 5 -1
Unsupervised language model adaptation for automatic speech recognition of broadcast news using web 2.0 .	un-supervised text collection and decoding strategy ; french broadcast news shows ; tf-idf-based topic words extraction ; time-and topic-relevant text data ; rapid language adaptation toolkit ; automatic speech recognition ; word error rates ; language model interpolation ; broadcast news ; web 2.0 ; quaero project ; rss feeds ; text normalization ; language modeling ; language model ; 2-pass decoding ; twitter	<method> <material> <task> <material> <method> <task> <metric> <task> <material> <material> <material> <material> <task> <task> <method> <method> <material>	4 0 7 ; 0 0 12 ; 3 0 13 ; 14 1 0	we improve the <task_5> of <material_8> using paradigms from <material_9> to obtain <material_3> for <task_13> . we elaborate an <method_0> that includes crawling appropriate texts from <material_11> , complementing <method_0> with texts from <material_16> , <method_14> and vocabulary adaptation , as well as a <method_15> . the <metric_6> of the tested <material_1> from europe 1 are reduced by almost 32 % relative with an underlying <method_14> from the globalphone project -lsb- 1 -rsb- and by almost 4 % with an underlying <method_14> from the <material_10> . the <method_0> that we use for the <task_12> , the collection of <material_11> together with the text on the related websites , a <task_2> , as well as the opportunity for <task_7> are available in our <method_4> -lsb- 2 -rsb- -lsb- 3 -rsb- .	5 8 9 3 13 20 17 -1 0 11 16 14 15 21 17 -1 6 1 10 17 -1 12 18 19 17 -1
Building Deep Dependency Structures using a Wide-Coverage CCG Parser .	combinatory categorial grammar ; treebank of ccg normal-form derivations ; local predicate-argument dependencies ; wide-coverage tree-bank parsers ; wide-coverage statistical parser ; long-range dependencies ; unlabelled dependencies ; dependency structures ; penn treebank ; labelled dependencies ; coordination ; extraction ; control	<method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	7 0 4 ; 10 1 11 ; 11 1 12 ; 0 0 4 ; 4 0 7 ; 1 0 4 ; 9 4 6 ; 4 4 3	this paper describes a <method_4> that uses <method_0> to derive <otherscientificterm_7> . the <method_4> differs from most existing <method_3> in capturing the <otherscientificterm_5> inherent in constructions such as <otherscientificterm_10> , <task_11> , raising and <otherscientificterm_12> , as well as the standard <otherscientificterm_2> . a set of <otherscientificterm_7> used for training and testing the <method_4> is obtained from a <material_1> , which have been derived -lrb- semi - -rrb- automatically from the <material_8> . the <method_4> correctly recovers over 80 % of <otherscientificterm_9> , and around 90 % of <otherscientificterm_6> .	4 0 7 17 18 13 -1 3 5 10 11 12 2 15 16 21 13 -1 1 8 14 19 13 -1 9 6 20 13 -1
Objective quality estimation of wide-band speech using a narrow-band prior .	estimation of speech signal quality ; non-intrusive wide-band quality assessment algorithm ; baseline wide-band system ; quality assessment models ; narrow-band quality estimate ; subjectively labelled databases ; quality prior ; narrow-band prior ; objective models ; databases	<task> <method> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <method> <material>	8 0 0 ; 4 0 1 ; 6 3 1 ; 1 4 2	a fundamental challenge in the design of <method_8> for <task_0> lies in the shortage of <material_5> . this problem is particularly relevant when developing <method_3> for wide-band -lrb- 16 khz sampling rate -rrb- signals where <material_9> are scarce . we explore the possibility for seamlessly integrating a <otherscientificterm_6> in the form of a <method_4> into the framework of a <method_1> . experimental results confirm that the proposed <method_1> can be used to improve performance over a <method_2> without a <otherscientificterm_7> .	8 0 5 11 10 -1 3 9 10 -1 6 4 1 12 13 10 -1 2 7 14 10 -1
Classifying clear and conversational speech based on acoustic features .	spectral and prosodic features ; hyper-articulated -rrb- speaking style ; decision tree classifiers ; conversational speaking style ; speaking styles ; multi-layer perceptrons ; predictive power ; spectral cues ; prosodic features ; features ; classification ; accuracies	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric>	2 1 5 ; 2 0 0 ; 8 0 10 ; 3 1 1 ; 7 4 8	this paper reports an investigation of <otherscientificterm_9> relevant for classifying two <otherscientificterm_4> , namely , <otherscientificterm_3> and clear -lrb- e.g. <otherscientificterm_1> . <otherscientificterm_0> were automatically extracted from speech and classified using <method_2> and <otherscientificterm_5> to achieve <metric_11> of about 71 % and 77 % respectively . more interestingly , we found that out of the 56 <otherscientificterm_9> only about 9 <otherscientificterm_9> are needed to capture the most <otherscientificterm_6> . while perceptual studies have shown that <otherscientificterm_7> are more useful than <otherscientificterm_8> for intel-ligibility -lsb- 1 -rsb- , here we find <otherscientificterm_8> are more important for <task_10> .	9 4 3 1 0 16 12 -1 2 5 11 13 14 12 -1 6 12 -1 7 8 10 15 17 12 -1
Efficient Task Sub-Delegation for Crowdsourcing .	reputation aware task sub-delegation approach ; resource constrained trustee agents ; reputation-based decision-making models ; multi-agent trust networks ; worker 's reputation ; epinions trust network ; high workload conditions ; intelligent agent ; reputation-based approaches ; sub-delegation decisions ; crowdsourcing system ; workload	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	0 0 9 ; 1 3 10 ; 8 0 10 ; 6 2 0 ; 1 3 3	reputation-based approaches allow a <method_10> to identify reliable workers to whom tasks can be delegated . in <method_10> that can be modeled as <method_3> consist of <method_1> -lrb- i.e. , workers -rrb- , workers may need to further sub-delegate tasks to others if they determine that they can not complete all pending tasks before the stipulated deadlines . existing <method_2> can not help workers decide when and to whom to sub-delegate tasks . in this paper , we proposed a <method_0> to bridge this gap . by jointly considering a <otherscientificterm_4> , <otherscientificterm_11> , the price of its effort and its trust relationships with others , <method_0> can be implemented as an <method_7> to help workers make <otherscientificterm_9> in a distributed manner . the resulting task allocation maximizes social welfare through efficient utilization of the collective capacity of a crowd , and provides provable performance guarantees . experimental comparisons with state-of-the-art approaches based on the <method_5> demonstrate significant advantages of <method_0> under <otherscientificterm_6> .	10 15 12 -1 3 1 14 17 12 -1 2 12 -1 0 12 -1 4 11 13 12 -1 7 9 12 -1 16 12 -1
Improving speech recognition performance of small microphone arrays using missing data techniques .	microphone array speech recognition systems ; missing data speech recognition ; baseline missing data system ; microphone array enhancement ; small microphone arrays ; frequency band reliability ; noisy input ; signal enhancement ; decoded sequence ; reliability mask ; speech recognition ; recognition	<method> <task> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <task> <material> <otherscientificterm> <task> <task>	3 1 2 ; 9 0 1 ; 0 0 10	traditional <method_0> simply recognise the enhanced output of the array . as the level of <task_7> depends on the number of microphones , such <method_0> do not achieve acceptable <task_10> performance for arrays having only a few microphones . for <otherscientificterm_4> , we instead propose using the enhanced output to estimate a <otherscientificterm_9> , which is then used in <task_1> . in <task_1> , the <material_8> depends on the <otherscientificterm_9> of each input feature . this <otherscientificterm_9> is usually based on the signal to noise ratio in each frequency band . in this paper , we use the energy difference between the <otherscientificterm_6> and the enhanced output of a small microphone array to determine the <metric_5> . <task_11> experiments with a small array demonstrate the effectiveness of the technique , compared to both traditional <method_3> and a <method_2> .	0 12 -1 7 10 15 12 -1 4 9 1 14 12 -1 8 12 -1 12 -1 12 -1 6 5 11 13 12 -1
Dimension Recognition and Geometry Reconstruction in Vectorization of Engineering Drawings .	rectifying deviations of entity dimensions ; detection of dimension sets ; low quality drawings ; recognized dimension annotations ; coordinate grid structure ; two-dimensional spatial constraints ; symbol recognition ; drawing entities ; dimension frames ; reconstruction algorithm ; dimension symbols ; engineering drawings ; vectorization ; scanning	<task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task>	4 0 5 ; 13 1 12 ; 3 0 9 ; 9 0 7	this paper presents a novel approach for recognizing and interpreting dimensions in <task_11> . it starts by detecting potential <otherscientificterm_8> , each comprising only the line and text components of a dimension , then verifies them by detecting the <otherscientificterm_10> . by removing the prerequisite of <task_6> from <task_1> , our method is capable of handling <otherscientificterm_2> . we also propose a <method_9> for rebuilding the <otherscientificterm_7> based on the <otherscientificterm_3> . a <otherscientificterm_4> is introduced to represent and analyze <otherscientificterm_5> between entities ; this simplifies and unifies the process of <task_0> induced during <task_13> and <otherscientificterm_12> .	11 14 -1 8 10 14 -1 6 1 2 14 -1 9 7 3 17 18 14 -1 4 5 0 13 12 15 16 14 -1
Hidden semi-Markov model based speech synthesis .	explicit state duration probability distributions ; speech parameter vector sequence ; hmm-based speech synthesis system ; state duration probability distributions ; single gaussian distributions ; rhythm and tempo ; synthesized speech ; hsmm training ; sentence hmm ; state durations ; hmm ; hmms	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <method> <method>	4 0 3 ; 7 0 6 ; 10 0 2	in the present paper , a hidden-semi markov model -lrb- <method_7> -rrb- based speech synthesis system is proposed . in a hidden markov model -lrb- <method_10> -rrb- based speech synthesis system which we have proposed , <otherscientificterm_5> are controlled by <otherscientificterm_3> modeled by <otherscientificterm_4> . to synthesis speech , it constructs a <otherscientificterm_8> corresponding to an arbitralily given text and determine <otherscientificterm_9> maximizing their probabilities , then a <otherscientificterm_1> is generated for the given state sequence . however , there is an inconsistency : although the speech is synthesized from <method_11> with <otherscientificterm_0> , <method_11> are trained without them . in the present paper , we introduce an <method_7> , which is an <method_10> with <otherscientificterm_0> , into the <method_2> . experimental results show that the use of <method_7> improves the naturalness of the <material_6> .	7 12 -1 10 5 3 4 13 12 -1 8 9 1 12 -1 11 0 12 -1 15 12 -1 2 14 12 -1
Improved Bayesian learning of hidden Markov models for speaker adaptation .	continuous-density hidden markov model parameters ; posteriori learning algorithm ; transfer vector interpolation scheme ; speaker-independent hmm parameters ; adaptation methods ; unseen units ; map adaptation ; speaker adaptation ; adaptation approaches ; hmm parameters ; transformation functions ; adaptation data	<otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <material>	10 0 3 ; 0 0 7 ; 2 0 11 ; 6 0 9	we propose an improved maximum a <method_1> of <otherscientificterm_0> for <task_7> . the algorithm is developed by sequentially combining three <method_8> . first , the clusters of <otherscientificterm_3> are locally transformed through a group of <otherscientificterm_10> . then , the transformed <otherscientificterm_9> are globally smoothed via the <method_6> . within the <method_6> , the parameters of <otherscientificterm_5> in <material_11> are further adapted by employing the <method_2> . experiments show that the combined algorithm converges rapidly and outperforms those other <method_4> .	1 0 7 14 12 -1 8 12 -1 3 10 13 12 -1 9 6 16 12 -1 5 11 2 15 12 -1 4 12 -1
Learning the Compositional Nature of Visual Objects .	category level object recognition system ; compositional nature of visual objects ; hierarchy of relevant compositions ; large standard benchmark datasets ; global shape of objects ; compo-sitional structure of objects ; structured object models ; graphical model ; representation complexity ; compositional representation ; mod-eling strategy ; feature sharing ; probability distributions ; statistical model ; inference ; supervision ; compositions	<method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm>	7 0 4 ; 13 0 0 ; 13 0 14 ; 12 2 16 ; 14 0 0 ; 7 0 5	the <otherscientificterm_1> significantly limits their <metric_8> and renders learning of <method_6> tractable . adopting this <method_10> we both -lrb- i -rrb- automatically decompose objects into a <otherscientificterm_2> and we -lrb- ii -rrb- learn such a <method_9> for each category without <otherscientificterm_15> . the <method_9> supports <otherscientificterm_11> already on the lowest level of small image patches . <otherscientificterm_16> are represented as <otherscientificterm_12> over their constituent parts and the relations between them . the <otherscientificterm_4> is captured by a <method_7> which combines all compositions . <task_14> based on the underlying <method_13> is then employed to obtain a <method_0> . experiments on <material_3> underline the competitive recognition performance of this <method_7> and <method_7> provide insights into the learned <otherscientificterm_5> .	1 8 6 17 -1 10 2 9 15 17 -1 11 16 17 -1 12 21 17 -1 4 7 14 18 17 -1 13 0 19 20 22 17 -1 3 23 17 -1
Sympathy for the Details : Dense Trajectories and Hybrid Classification Architectures for Action Recognition .	unsupervised representations of hand-crafted spatio-temporal features ; action recognition in videos ; hybrid video classification architec-tures ; action recognition methods ; supervised deep networks ; manually labelled images ; hybrid model ; deep learning ; spatio-temporal patterns ; video data ; deep models ; hand-crafted features ; image classification ; action recognition ; videos	<method> <task> <method> <method> <method> <material> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <task> <task> <material>	11 0 3 ; 5 1 14 ; 4 0 0 ; 0 0 2 ; 5 0 10 ; 7 0 12	action recognition in <material_14> is a challenging task due to the complexity of the <otherscientificterm_8> to model and the difficulty to acquire and learn on large quantities of <material_9> . <method_7> , although a breakthrough for <task_12> and showing promise for <material_14> , has still not clearly superseded <method_3> using <otherscientificterm_11> , even when training on massive datasets . in this paper , we introduce <method_2> based on carefully designed <method_0> classified by <method_4> . as we show in our experiments on five popular benchmarks for <task_13> , our <method_6> combines the best of both worlds : it is data efficient -lrb- trained on 150 to 10000 short clips -rrb- and yet improves significantly on the state of the art , including recent <method_10> trained on millions of <material_5> and <material_14> .	14 8 9 7 15 -1 12 3 11 16 21 15 -1 2 0 4 18 19 15 -1 13 6 17 20 15 -1
Multi-scale-audio indexing for translingual spoken document retrieval .	voice of america mandarin news broadcasts ; mei -lrb- mandarin-english information -rrb- ; chinese word tokenization ambiguity ; word and subword scales ; chinese homophone ambiguity ; overlapping subword n-grams ; multi-scale audio indexing ; mei syllable recognizer ; information retrieval technologies ; lattice structures ; chinese words ; out-of-vocabulary words ; speech recognition ; audio indexing ; multi-scale paradigm ; machine translation ; word unit ; spoken documents ; subword units ; cl-sdr ; retrieval	<material> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <material> <otherscientificterm> <task> <task> <method> <task> <method> <material> <method> <method> <task>	18 0 2 ; 3 5 12 ; 4 1 11 ; 15 1 8 ; 18 0 16 ; 2 1 4 ; 5 1 9 ; 12 0 0 ; 11 3 13 ; 12 1 15	mei -lrb- mandarin-english information -rrb- is an english-chinese crosslingual spoken document <task_20> -lrb- <method_19> -rrb- system developed during the johns hopkins university summer workshop 2000 . we integrate <task_12> , <task_15> , and <method_8> to perform <method_19> . <method_1> advocates a <method_14> , where both <material_10> and subwords -lrb- characters and syllables -rrb- are used in <task_20> . the use of <method_18> can complement the <method_16> in handling the problems of <task_2> , <otherscientificterm_4> , and <otherscientificterm_11> in <task_13> . this paper focuses on <task_6> in <method_1> . experiments are based on the topic detection and tracking corpora -lrb- tdt-2 and tdt-3 -rrb- , where we indexed <material_0> by <task_12> on both the <otherscientificterm_3> . in this paper , we discuss the development of the <method_7> , the representations of <material_17> using <otherscientificterm_5> and <otherscientificterm_9> . results show that augmenting words with subwords is beneficial to <method_19> performance .	20 19 21 -1 12 15 8 1 25 31 21 -1 14 10 21 -1 18 16 2 4 11 13 22 24 26 27 30 21 -1 6 21 -1 23 29 21 -1 0 3 28 21 -1 7 17 5 9 21 -1
A robust speech understanding system using conceptual relational grammar .	robust speech understanding system ; conceptual relational grammar ; data retrieval system ; database query tasks ; spoken language processing ; natural language parser ; database retrieval ; nlu system ; atis database ; speech recognizer ; hmm	<method> <method> <method> <task> <task> <method> <task> <method> <material> <method> <method>	2 3 0 ; 9 3 0 ; 1 0 5 ; 5 3 0 ; 0 0 4 ; 9 0 6 ; 8 0 5 ; 0 0 3 ; 9 1 5 ; 4 0 6 ; 8 0 2 ; 9 0 0 ; 10 6 5 ; 1 0 9 ; 10 0 9 ; 9 1 2 ; 0 0 6	we describe a <method_0> based on our newly developed approach to <task_4> . we show that a robust <method_7> can be rapidly developed using a relatively simple <method_9> to provide sufficient information for <task_6> by <task_4> . our experimental <method_0> consists of three components : a <method_9> based on <method_10> , a <method_5> based on <method_1> and a <method_2> based on the <material_8> . with the use of the <method_0> , <task_3> can be successfully performed .	0 4 16 11 -1 7 9 6 17 21 23 28 11 -1 10 5 1 2 8 12 13 14 15 18 20 22 24 25 26 27 11 -1 3 19 11 -1
A direct equalization method .	symmetrical twisted pair transmission channels ; digital adaptive channel equalizer ; digital adaptive signal processing ; local distribution networks ; unshielded twisted pair ; analog equalization approach ; reduced system complexity ; direct equalization method ; inter-symbol interference ; transmission media ; transmitter ; analog ; receiver ; equalizer	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm>	4 0 3 ; 7 0 5 ; 9 0 3 ; 5 0 6 ; 4 0 9	the <otherscientificterm_4> can be used as a <method_9> for <method_3> . to maintain a high transmission throughput , an <method_11> or a <otherscientificterm_1> is usually required in the <method_12> to minimize the effect of <otherscientificterm_8> . under the observation that the high sampling rate high precision a/d and subsequent <task_2> is an expensive approach , a <method_7> , where the <otherscientificterm_13> is implemented in the <otherscientificterm_10> , is proposed for <otherscientificterm_0> . this <method_7> can also be applied to the <method_5> for <metric_6> .	4 9 3 15 17 19 14 -1 11 1 12 8 14 -1 2 7 13 10 0 14 -1 5 6 16 18 14 -1
Mind the Eigen-Gap , or How to Accelerate Semi-Supervised Spectral Learning Algorithms .	clustering coherence measure ; continuous semi-supervised solution ; data laplacian matrix ; data mining practitioners ; semi-supervised learning algorithms ; spectral methods ; semi-supervised clustering ; text clustering ; semi-supervised learning ; semi-supervised methods ; partial supervision ; eigenvec-tor computations ; context quality ; theoretical intuitions ; background knowledge	<metric> <method> <otherscientificterm> <method> <method> <method> <method> <task> <method> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	14 0 4 ; 5 0 6 ; 14 0 3 ; 10 0 2	semi-supervised learning algorithms commonly incorporate the available <otherscientificterm_14> such that an expression of the derived model 's quality is improved . depending on the specific <metric_12> can take several forms and can be related to the generalization performance or to a simple <metric_0> . recently , a novel perspective of <method_8> has been put forward , that associates <method_6> with the efficiency of <method_5> . more precisely , it has been demonstrated that the appropriate use of <method_10> can bias the <otherscientificterm_2> such that the necessary <otherscientificterm_11> are provably accelerated . this result allows <method_3> to use <otherscientificterm_14> not only for improving the quality of clustering results , but also for accelerating the required <otherscientificterm_11> . in this paper we initially provide a high level overview of the relevant efficiency maximizing <method_9> such that their <otherscientificterm_13> are comprehensively outlined . consecutively , we demonstrate how these methods can be extended to handle multiple clusters and also discuss possible issues that may arise in the <method_1> . finally , we illustrate the proposed extensions empirically in the context of <task_7> .	14 16 15 -1 12 0 15 -1 8 6 5 17 15 -1 10 2 11 19 15 -1 3 18 15 -1 15 -1 9 13 15 -1 1 15 -1
Sparse Space-Time Deconvolution for Calcium Image Analysis .	real and synthetic data ; heuristic pre-or postprocessing ; calcium image sequences ; impulse responses ; unified formulation ; spike timings ; activity estimates ; optimization problem ; cell segmentations ; cell locations ; cell shapes	<material> <method> <material> <otherscientificterm> <method> <otherscientificterm> <task> <task> <task> <otherscientificterm> <otherscientificterm>	5 1 3 ; 9 1 10 ; 10 1 3 ; 9 1 5 ; 10 1 5 ; 4 0 2 ; 8 1 6	we describe a <method_4> and algorithm to find an extremely sparse representation for <material_2> in terms of <otherscientificterm_9> , <otherscientificterm_10> , <otherscientificterm_5> and <otherscientificterm_3> . solution of a single <task_7> yields <task_8> and <task_6> that are on par with the state of the art , without the need for <method_1> . experiments on <material_0> demonstrate the viability of the proposed method .	4 2 9 10 5 3 12 13 14 15 16 17 11 -1 7 8 6 1 18 11 -1 0 11 -1
Aggregated cross-validation and its efficient application to Gaussian mixture optimization .	agcv likelihood based gaussian mixture optimization algorithm ; aggregated cross-validation ; cv and mdl based methods ; gaussian mixture optimization algorithm ; gaussian mixture hmm ; word error rates ; model selection ability ; score estimation ; cv likelihood ; large models ; oral presentations ; cv framework ; model structure ; speech recognition ; held-out subset ; bagging-like approach ; cv	<method> <method> <method> <method> <method> <metric> <otherscientificterm> <task> <otherscientificterm> <method> <material> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method>	16 0 14 ; 16 0 3 ; 13 5 0 ; 1 0 15 ; 4 6 9 ; 15 3 11 ; 1 0 3 ; 15 0 6 ; 0 4 2	we have previously proposed a cross-validation -lrb- <method_16> -rrb- based gaussian mixture optimization method that efficiently optimizes the <otherscientificterm_12> based on <otherscientificterm_8> . in this study , we propose <method_1> that introduces a <method_15> in the <method_11> to reinforce the <otherscientificterm_6> . while a single model is used in <method_16> to evaluate a <otherscientificterm_14> , <method_1> uses multiple models to reduce the variance in the <task_7> . by integrating <method_1> instead of <method_16> in the <method_3> , an <method_0> is obtained . the <method_0> works efficiently by using sufficient statistics and can be applied to <method_9> such as <method_4> . the proposed <method_0> is evaluated by <task_13> experiments on <material_10> and it is shown that lower <metric_5> are obtained by the <method_0> when compared to <method_2> .	16 12 8 17 -1 1 15 11 6 21 23 25 17 -1 14 7 18 17 -1 3 0 19 24 17 -1 9 4 22 17 -1 20 26 17 -1
Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs .	mrf term encoding spatial coherency ; object driven image retrieval ; trust region graph cuts ; interactive image editing ; global constraint ; video tracking ; appearance histograms ; generative model ; image pair ; rigid/non-rigid object ; term cosegmentation ; optimization scheme ; inference ; optimization ; cosegmentation ; np-hard	<otherscientificterm> <task> <method> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <task> <method>	5 1 3 ; 2 6 11 ; 12 0 7 ; 1 1 5 ; 11 0 10 ; 7 0 14	we introduce the <method_10> which denotes the task of segmenting simultaneously the common parts of an <otherscientificterm_8> . a <method_7> for <task_14> is presented . <task_12> in the <method_7> leads to minimizing an energy with an <otherscientificterm_0> and a <otherscientificterm_4> which attempts to match the <otherscientificterm_6> of the common parts . this energy has not been proposed previously and its <method_13> is challenging and <method_15> . for this <method_10> a novel <method_11> which we call <method_2> is presented . we demonstrate that this <method_11> has the potential to improve a wide range of research : <task_1> , <task_5> and segmentation , and <task_3> . the power of the <method_11> lies in its generality , the common part can be a <otherscientificterm_9> -lrb- or scene -rrb- , observed from different viewpoints or even similar objects of the same class .	10 8 16 -1 7 14 12 22 16 -1 0 4 6 19 16 -1 13 15 16 -1 11 2 18 21 16 -1 1 5 17 20 16 -1 3 16 -1
Building Joint Spaces for Relation Extraction .	dbpedia and medical relations ; relation specific term embeddings ; textual features ; labeled data ; relation extraction ; joint space ; term pairs ; closed-form solution	<material> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <method>	5 0 1	in this paper , we present a novel approach for <task_4> using only <otherscientificterm_6> as the input without <otherscientificterm_2> . we aim to build a single <otherscientificterm_5> for each relation which is then used to produce <otherscientificterm_1> . the proposed method fits particularly well for domains in which similar arguments are often associated with similar relations . it can also handle the situation when the <material_3> is limited . the proposed method is evaluated both theoretically with a proof for the <method_7> and experimentally with promising results on both <material_0> .	4 6 2 8 -1 5 1 9 8 -1 8 -1 3 8 -1 7 0 8 -1
Enhancement of harmonic content of speech based on a dynamic programming pitch tracking algorithm .	dynamic programming algorithms ; voiced or voiceless pitch estimates ; separations of target ; multi-channel autocorrelation-based estimator ; interfering speech ; harmonic content ; pitch candidates ; pitch tracking ; pitch information ; noisy speech	<method> <material> <otherscientificterm> <method> <material> <material> <material> <task> <otherscientificterm> <material>	8 0 5 ; 3 0 6	for <task_7> of a single speaker , a common requirement is to find the optimal path through a set of <material_1> over a sequence of time frames . <method_0> have been applied before to this problem . here , the <material_6> are provided by a <method_3> , and <method_0> is extended to <task_7> of multiple concurrent speakers . we use the resulting <otherscientificterm_8> to enhance <material_5> in <material_9> and to obtain <otherscientificterm_2> from <material_4> .	7 1 0 10 -1 10 -1 6 3 12 10 -1 8 5 9 2 4 11 10 -1
Accelerated Generative Models for 3D Point Cloud Data .	parallel hierarchical expectation maximization algorithm ; 3d point cloud data ; compact generative representations of pcd ; dynamic creation of voxel grids ; deterministic spatial subdivision methods ; octree and ndt-based methods ; local mixture modeling ; spatial perception applications ; maximum likelihood segmentation ; run-time occupancy calculations ; gener-ative models ; probabilistic subdivisions ; voxel grids ; model size ; expectation sparsification ; deterministic structures ; model fidelity ; stochastic sampling ; octrees ; subdivisions ; para-metric ; sparsity	<method> <method> <method> <task> <method> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	16 1 13 ; 12 6 15 ; 12 1 18 ; 10 0 1 ; 0 0 1 ; 18 6 15	finding meaningful , structured representations of <method_1> has become a core task for <task_7> . in this paper we introduce a method for constructing <method_2> at multiple levels of detail . as opposed to <otherscientificterm_15> such as <otherscientificterm_12> or <otherscientificterm_18> , we propose <otherscientificterm_11> of the data through <method_6> , and show how these <otherscientificterm_19> can provide a <method_8> of the data . the final representation is hierarchical , compact , <otherscientificterm_20> , and statistically derived , facilitating <otherscientificterm_9> through <method_17> . unlike traditional <method_4> , our technique enables <task_3> according the application 's best needs . in contrast to other <method_10> for <method_1> , we explicitly enforce <otherscientificterm_21> among points and mixtures , a technique which we call <method_14> . this leads to a highly <method_0> well-suited for the <method_1> and real-time execution . we explore the trade-offs between <otherscientificterm_16> and <otherscientificterm_13> at various levels of detail , our tests showing favorable performance when compared to <method_5> .	1 7 22 -1 2 22 -1 15 12 18 11 6 19 8 24 25 28 22 -1 20 9 17 22 -1 4 3 22 -1 26 22 -1 10 21 14 27 22 -1 0 23 22 -1
Aspects of modern multi-modal/multi-media corpora exploitation environments .	synchronized media and text streams ; multimodal/multimedia language resources ; metadata descriptions ; collaborative annotation ; distributed environments ; multi-media corpora	<material> <material> <material> <task> <material> <material>	2 0 1 ; 3 6 1 ; 2 0 3	this paper wants to discuss several aspects of <material_1> such as the use of <material_2> for easy location purposes , their <task_3> and exploitation via internet , the generation of <material_0> in <material_4> , and general annotation formats . these aspects that although they may be discussed independently have to fit together seamlessly to offer users an adequate exploitation environment that is up to the huge amount of data that is available in modern <material_5> and is able to exploit fully the current technology advancements .	1 2 3 0 4 7 8 9 6 -1 5 6 -1
Channel estimation for DS-CDMA with aperiodic spreading codes .	multiuser parameter estimation problem ; blind channel estimation problem ; maximum likelihood ml estimator ; medium snr values ; multiuser digital signals ; aperiodic spreading codes ; computer simulation ; iterative algorithm ; channel parameters ; multiuser detectors ; global maxima ; alternating optimization ; multiuser detection ; cdma communications ; ds-cdma systems ; channel estimation	<task> <task> <method> <otherscientificterm> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <task> <method> <task>	7 0 10 ; 5 0 14 ; 7 0 8 ; 9 0 4 ; 6 0 10 ; 12 0 13 ; 2 0 15	for high performance <task_13> , <task_12> is often required to suppress the multiple access interference mai . most <method_9> rely on accurate channel information to recover the <material_4> . this paper studies the <task_1> for <method_14> using <otherscientificterm_5> . the <method_2> is formulated for <task_15> . we rst convert the <task_0> into a set of single user optimization problems via <method_11> , and then determine the <otherscientificterm_8> for each user using an <method_7> derived . it is shown by <method_6> that this <method_7> can reach <otherscientificterm_10> almost always under <otherscientificterm_3> .	13 12 22 16 -1 9 4 20 16 -1 1 14 5 18 16 -1 2 15 23 16 -1 0 11 8 7 19 16 -1 6 10 3 17 21 16 -1
Estimating dependency and significance for high-dimensional data .	signal processing applications ; high-dimensional measurements ; dependency structure ; nonparametric tests ; high-dimensional observations ; data association	<task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	2 0 0	understanding the <otherscientificterm_2> of a set of variables is a key component in various <task_0> which involve <task_5> . the simple task of detecting whether any dependency exists is particularly difficult when models of the data are unknown or difficult to characterize because of <otherscientificterm_1> . we review the use of <method_3> for characterizing dependency and how to carry out these tests with <otherscientificterm_4> . in addition we present a method to assess the significance of the tests .	2 0 5 7 6 -1 1 6 -1 3 4 6 -1 6 -1
A new binary mask based on noise constraints for improved speech intelligibility .	time-frequency units ; noise overestimated t-f units ; noise distortion constraints ; binary mask approach ; binary mask ; noise-corrupted speech ; speech intelligibility ; t-f units ; interfering noise	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm>	4 0 1 ; 4 0 5 ; 4 0 6 ; 2 0 4 ; 3 0 6	it has been shown that large gains in <task_6> can be obtained by using the <method_3> which retains the <otherscientificterm_0> of the mixture signal that are stronger than the <otherscientificterm_8> -lrb- masker -rrb- -lrb- i.e. , snr > 0 db -rrb- , and removes the <otherscientificterm_7> where the <otherscientificterm_8> dominates . in this paper , we introduce a new <method_4> for improving <task_6> based on <otherscientificterm_2> . a <method_4> is designed to retain <otherscientificterm_1> while discarding noise underestimated <otherscientificterm_7> . listening tests were conducted to evaluate the new <method_4> in terms of intelligibility . results from the listening tests indicated that large gains in intelligibility can be achieved by the application of the proposed <method_4> to <material_5> even at extremely low snr levels -lrb- -10 db -rrb- .	6 3 0 8 7 14 9 -1 4 2 12 13 9 -1 1 10 9 -1 9 -1 11 9 -1
Perceptually-Inspired and Edge-Directed Color Image Super-Resolution .	edge-directed , reconstruction-based and learning-based methods ; high-resolution color image reconstruction ; multi-scale tensor voting framework ; perceptual grouping and segmentation ; edge-preserving smoothness prior ; color image super-resolution ; dense voting field ; low-resolution color image ; time-consuming learning procedure ; multi-scale edge representation ; image super-resolution techniques ; multi-scale tensor voting ; back projection constraint ; computational framework ; high-resolution curves ; color channels ; edge-directed technique	<method> <task> <method> <task> <otherscientificterm> <task> <otherscientificterm> <material> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	16 0 5 ; 0 0 16 ; 13 0 3 ; 15 0 9 ; 9 0 1 ; 7 0 16 ; 2 0 9 ; 11 0 14 ; 6 0 11 ; 2 0 1 ; 13 0 16	inspired by <method_11> , a <method_13> for <task_3> , we propose an <method_16> for <task_5> given a single <material_7> . our <method_16> combines the advantages of <method_0> , and is unique in two ways . first , we consider simultaneously all the three <otherscientificterm_15> in our <method_2> to produce a <method_9> to guide the process of <task_1> , which is subject to the <otherscientificterm_12> . fine details are inferred without noticeable blurry or ringing artifacts . second , the inference of <otherscientificterm_14> is achieved by <method_11> , using the <otherscientificterm_6> as an <otherscientificterm_4> which is derived geometrically without any <method_8> . qualitative and quantitative results indicate that our <method_16> produces convincing results in complex test cases typically used by state-of-the-art <method_10> .	11 13 3 16 5 7 18 20 23 28 17 -1 0 19 17 -1 15 2 9 1 12 21 22 24 27 17 -1 17 -1 14 6 4 8 25 26 17 -1 17 -1
Frequency analysis using non-uniform sampling with application to active queue management .	real life problems ; fourier transform approximation ; continuous time signal ; vibra-tional analysis ; fourier transform ; embedded systems ; sample values ; non-uniform sampling ; frequency windows ; non-uniform data ; frequency analysis ; real-time applications ; frequency domain ; analytical expressions	<task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <material> <task> <task> <otherscientificterm> <otherscientificterm>	9 0 5 ; 13 0 7 ; 9 0 10 ; 6 6 11	in many <task_11> , <otherscientificterm_6> and time stamps are delivered in pairs , where sampling times are non-uniform . <task_10> using <material_9> occurs in various <task_0> and <method_5> , such as <method_3> in cars and control of packet network queue lengths . our contribution is to first overview different ways to approximate the <otherscientificterm_4> , and secondly to give <otherscientificterm_13> for how <task_7> affects these approximations . the results are expressed in terms of <otherscientificterm_8> describing how a single frequency in the <otherscientificterm_2> is smeared out in the <otherscientificterm_12> , or , more precisely , in the expected value of the <otherscientificterm_1> .	11 6 10 18 14 -1 9 0 5 3 15 17 14 -1 4 13 7 16 14 -1 8 2 12 14 -1
Generalization of Linear Discriminant Analysis used in Segmental Unit Input HMM for Speech Recognition .	power linear discriminant analysis ; heteroscedastic discriminant analysis ; linear discriminant analysis ; segmental unit input hmm ; dimensionality reduction method ; data sets ; dimension-ality reduction ; speech recognition ; discriminative information ; features ; pca	<method> <method> <method> <method> <method> <material> <task> <task> <otherscientificterm> <otherscientificterm> <method>	4 0 3 ; 1 0 5 ; 10 1 2 ; 2 1 1 ; 0 4 1 ; 0 4 10 ; 0 4 2	to precisely model the time dependency of <otherscientificterm_9> is one of the important issues for <task_7> . <method_3> with a <method_4> is widely used to address this issue . <method_2> and <method_1> are classical and popular approaches to reduce dimensionality . however , it is difficult to find one particular criterion suitable for any kind of data set in carrying out <task_6> while preserving <otherscientificterm_8> . in this paper , we propose a new framework which we call <method_0> . <method_0> can describe various criteria including <method_2> and <method_1> with one parameter . experimental results show that the <method_0> is more effective than <method_10> , <method_2> , and <method_1> for various <material_5> .	9 7 3 11 -1 4 2 12 11 -1 1 11 -1 6 8 11 -1 0 11 -1 11 -1 13 14 15 16 17 18 11 -1
Significance-aware Hammerstein group models for nonlinear acoustic echo cancellation .	linear kernels of the hammerstein submodels ; nonlinear acoustic echo cancellation ; linear echo canceller ; parallel hammerstein models ; speech recordings ; non-linear preprocessor ; echo cancellation ; echo path ; hammerstein model ; computational complexity ; smartphone ; preprocessor	<otherscientificterm> <task> <method> <method> <material> <method> <metric> <otherscientificterm> <method> <metric> <material> <method>	5 0 7 ; 11 5 8 ; 8 0 7	in this work , a novel approach for <task_1> is proposed . the main innovative idea of the proposed method is to model only the small region of the <otherscientificterm_7> around the direct path by a group of <method_3> , to estimate a <method_5> by correlations between the <otherscientificterm_0> , and to describe the remaining <otherscientificterm_7> by a simple <method_8> with the <method_11> determined in the aforementioned way . while the <metric_9> of such a system increases only slightly in comparison to a <method_2> , experiments with <material_4> from a <material_10> in different environments confirm a significantly increased <metric_6> performance .	1 12 -1 7 3 5 0 8 11 13 14 15 12 -1 9 2 4 10 6 12 -1
A Probabilistic Contour Discriminant for Object Localisation .	feature detection process ; initialising contour trackers ; sampling methods ; probabilistic model ; contour discriminant ; observation densities ; localising objects ; likelihood ratio ; clutter features ; image	<method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <material>	2 0 1 ; 3 0 0	a method of <task_6> in images is proposed . possible conngurations are evaluated using the <otherscientificterm_4> , a <metric_7> which is derived from a <method_3> of the <method_0> . we treat each step in this process probabilistically , including the occurrence of <otherscientificterm_8> , and derive the <otherscientificterm_5> for both correct \ target '' con-gurations and incorrect \ clutter '' conngurations . the <otherscientificterm_4> distinguishes target objects from the background even in heavy clutter , making only the most general assumptions about the form that clutter might take . the method generates samples stochasti-cally to avoid the cost of processing an entire <material_9> , and promises to be particularly suited to the task of <task_1> based on <method_2> .	6 10 -1 4 7 3 0 12 10 -1 8 5 10 -1 10 -1 11 10 -1
Two-dimensional frequency estimation using autocorrelation phase fitting .	two-dimensional frequency estimation ; noise ratio -lrb- accuracy ; least square plane fitting ; white gaussian additive noise ; 2-d phase unwrapping step ; 2-d frequency esti-mator ; cramer rao bounds ; local frequency estimation ; monte carlo simulations ; frequency estimator ; autocorrelation estimation ; robustness	<task> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <task> <metric>	11 5 5 ; 2 0 9 ; 8 0 5	in this paper , the problem of <task_0> of a complex sinusoid embedded in a <otherscientificterm_3> is addressed . a new <method_9> based on a <method_2> of the estimated autocorrelation phase of the signal is derived . this algorithm requires a <otherscientificterm_4> which can be easily done . this algorithm is shown to be unbiased and attains the <otherscientificterm_6> for high signal to <metric_1> and <metric_11> of this new <method_5> are statistically assessed by <method_8> . the results obtained show that a good <method_7> can be achieved with a very simple algorithm , and a very small amount of points used for the <task_10> .	0 3 12 -1 9 2 14 12 -1 4 12 -1 6 1 11 5 8 13 15 12 -1 7 12 -1
Propagation Redundancy for Permutation Channels .	goal driven learning ; airspace task orders domain ; base reasoner ; meta-reasoning capabilities ; learning paradigms ; meta-reasoning module ; ai systems ; learning goals ; learning strategies ; meta-reasoner	<method> <material> <method> <method> <method> <method> <method> <method> <method> <method>	0 0 0 ; 0 3 9 ; 3 0 2 ; 2 0 0 ; 3 0 0	goal driven learning -lrb- gdl -rrb- focuses on systems that determine by themselves what has to be learnt and how to learn <method_0> . typically <method_0> use <method_3> over a <method_2> , identifying <method_7> and devising strategies . in this paper we present a novel <method_0> to deal with complex <method_6> where the <method_5> has to analyze the reasoning trace of multiple components with potentially different <method_4> . our <method_0> works by distributing the generation of <method_8> among the different modules instead of centralizing <method_0> in the <method_9> . we implemented our <method_0> in the <method_0> , that works in the <material_1> , showing an increase in performance .	0 10 -1 3 2 7 13 14 15 10 -1 6 5 4 10 -1 8 9 12 10 -1 11 10 -1
Use of metadata to improve recognition of spontaneous speech and named entities .	malach corpus of holocaust testimonials ; lexicon and language model ; named-entity recognition errors ; word error rate ; lvcsr tasks ; spontaneous speech ; textual information ; side information ; named entities ; recognition accuracies ; speech recognition ; pre-interview questionaire ; speaker-by-speaker basis ; recognition	<material> <method> <otherscientificterm> <metric> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <method> <otherscientificterm> <task>	6 0 10 ; 11 0 0 ; 9 0 4 ; 7 1 0	with improved <metric_9> for <task_4> , it has become possible to search large collections of <material_5> for a variety of information . the <material_0> is one such collection , in which we are interested in automatically transcribing and retrieving portions that are relevant to <otherscientificterm_8> such as people , places , and organizations . since the testimonials were gathered from thousands of people in countries throughout europe , an extremely large number of potential <otherscientificterm_8> are possible , and this causes a well-known dilemma : increasing the size of the vocabulary allows for more of these words to be recognized , but also increases confusability , and can harm <task_13> performance . however , the <material_0> , like many other collections , includes <otherscientificterm_7> or <material_0> that can be exploited to provide prior information on exactly which <otherscientificterm_8> are likely to appear . this paper proposes a method that capitalizes on this prior information to reduce <otherscientificterm_2> by over 50 % relative , and simultaneously decrease the overall <metric_3> by 7 % relative . the <material_0> we use derives from a <method_11> that includes the names of friends , relatives , places visited , membership of organizations , synonyms of place names , and similar information . by augmenting the <method_1> with this information on a <otherscientificterm_12> , we are able to exploit the <otherscientificterm_6> that is already available in the corpus to facilitate much improved <task_10> .	9 4 5 17 14 -1 0 8 14 -1 14 -1 13 18 14 -1 7 14 -1 2 3 16 14 -1 11 15 14 -1
Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic .	real-world customer behavior prediction problems ; roc curve ; mean squared error ; wireless service provider ; cable service provider ; real-world classification problems ; gradient-based methods ; cost functions ; classification rate ; wilcoxon-mann-whitney statistic ; objective function ; cross entropy ; roc curve ; classifier	<task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <metric> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	13 0 1 ; 12 6 5 ; 10 0 0 ; 10 0 3 ; 6 0 13 ; 11 1 2	when the goal is to achieve the best correct <metric_8> , <otherscientificterm_11> and <otherscientificterm_2> are typical <otherscientificterm_7> used to optimize <method_13> performance . however , for many <task_5> , the <otherscientificterm_12> is a more meaningful performance measure . we demonstrate that minimizing <otherscientificterm_11> or <otherscientificterm_2> does not necessarily maximize the area under the <otherscientificterm_1> . we then consider alternative objective functions for training a <method_13> to maximize the <otherscientificterm_1> directly . we propose an <otherscientificterm_10> that is an approximation to the <material_9> , which is equivalent to the <otherscientificterm_1> . the proposed <otherscientificterm_10> is differentiable , so <method_6> can be used to train the <method_13> . we apply the new <otherscientificterm_10> to <task_0> for a <method_3> and a <method_4> , and achieve reliable improvements in the <otherscientificterm_12> .	8 11 2 7 13 14 -1 5 12 16 14 -1 1 20 14 -1 15 14 -1 10 9 14 -1 6 19 14 -1 17 18 14 -1
New ℌ ∞ bounds for the recursive least squares algorithm exploiting input structure .	recursive least squares algorithm ; structured input data ; human speech ; noise process ; additive analysis ; convergence guarantees ; noise	<method> <material> <material> <method> <method> <otherscientificterm> <otherscientificterm>	2 0 4	the <method_0> is well known and has been widely used for many years . most analyses of <method_0> have assumed statistical properties of the data or the <method_3> , but recent robust h ∞ analyses have been used to bound the ratio of the performance of the algorithm to the total <otherscientificterm_6> . in this paper , we provide an <method_4> bounding the difference between performance and <otherscientificterm_6> . our <method_4> provides additional <otherscientificterm_5> in general , and particular benefits for <material_1> . we illustrate the <method_4> using <material_2> and white <otherscientificterm_6> .	0 7 -1 3 6 7 -1 4 7 -1 5 1 7 -1 2 8 7 -1
Tractable Bayesian Network Structure Learning with Bounded Vertex Cover Number .	bounded vertex cover number bayesian networks ; integer linear programming ; bounded tree-width bayesian networks ; learning and inference tasks ; bounded tree-width networks ; polynomial time ; bayesian networks ; learning problem	<method> <method> <method> <task> <method> <otherscientificterm> <method> <task>	6 0 3 ; 0 4 4	both <task_3> on <method_6> are np-hard in general . <method_2> have recently received a lot of attention as a way to circumvent this complexity issue ; however , while inference on <method_4> is tractable , the <task_7> remains np-hard even for tree-width 2 . in this paper , we propose <method_0> as an alternative to <method_4> . in particular , we show that both inference and learning can be done in <otherscientificterm_5> for any fixed vertex cover number bound k , in contrast to the general and bounded tree-width cases ; on the other hand , we also show that <task_7> is w -lsb- 1 -rsb- - hard in parameter k. furthermore , we give an alternative way to learn <method_0> using <method_1> , and show this is feasible in practice .	3 6 2 9 8 -1 4 7 8 -1 0 10 8 -1 5 8 -1
Competition and Arbors in Ocular Dominance .	hebbian and competitive hebbian algorithms ; competitive and interactive cortical influences ; modeling pattern formation ; cortical development ; common footing	<method> <otherscientificterm> <task> <task> <otherscientificterm>	3 2 2	hebbian and competitive hebbian algorithms are almost ubiquitous in <task_2> in <task_3> . we analyse in theoretical detail a particular model -lrb- adapted from piepenbrock & ober-mayer , 1999 -rrb- for the development of id stripe-like patterns , which places <otherscientificterm_1> , and free and restricted initial arborisation onto a <otherscientificterm_4> .	2 3 6 5 -1 1 4 0 5 -1
Universal Approximnation and Learning of Trajectories Using Oscillators .	natural and artificial neural circuits ; fast and slow oscillations ; universal approximation properties ; state space trajectories ; amorphous networks ; complex trajectories ; bounded frequencies ; oscil-lators ; trajectories	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	0 0 3	natural and artificial neural circuits must be capable of traversing specific <otherscientificterm_3> . a natural approach to this <otherscientificterm_0> is to learn the relevant <otherscientificterm_8> from examples . unfortunately , gradient descent learning of <otherscientificterm_5> in <method_4> is unsuccessful . we suggest a possible approach where <otherscientificterm_8> are realized by combining simple <method_7> , in various modular ways . we contrast two regimes of <otherscientificterm_1> . in all cases , we show that banks of oscillators with <otherscientificterm_6> have <otherscientificterm_2> . open questions are also discussed briefly .	3 10 9 -1 0 8 9 -1 5 4 9 -1 7 9 -1 1 9 -1 6 2 9 -1 9 -1
What makes some POMDP problems easy to approximate ? .	high dimensional belief spaces ; fully observed state variables ; circulant state-transition matrices ; reachable belief space ; optimal reachable space ; pomdp planning ; optimal policy ; pomdp problems ; time polynomial ; polynomial time ; belief-space properties ; belief space ; sparse support ; smooth beliefs ; pomdp solution ; approximate solution ; point-based algorithms ; point-based algorithms ; beliefs	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm>	8 2 3 ; 9 2 15 ; 13 1 2 ; 12 2 18 ; 12 1 13 ; 13 1 18	point-based algorithms have been surprisingly successful in computing approximately optimal solutions for partially observable markov decision processes -lrb- pomdps -rrb- in <otherscientificterm_0> . in this work , we seek to understand the <otherscientificterm_10> that allow some <otherscientificterm_7> to be approximated efficiently and thus help to explain the <method_17> ' success often observed in the experiments . we show that an approximately optimal <method_14> can be computed in <otherscientificterm_8> in the covering number of a <otherscientificterm_3> , which is the subset of the <otherscientificterm_11> reachable from a given belief point . we also show that under the weaker condition of having a small covering number for an <otherscientificterm_4> , which is the subset of the <otherscientificterm_11> reachable under an <otherscientificterm_6> , computing an approximately optimal solution is np-hard . however , given a suitable set of points that '' cover '' an optimal reach-able space well , an <method_15> can be computed in <otherscientificterm_9> . the covering number highlights several interesting properties that reduce the complexity of <task_5> in practice , e.g. , <otherscientificterm_1> , <otherscientificterm_18> with <otherscientificterm_12> , <otherscientificterm_13> , and <otherscientificterm_2> .	0 19 -1 10 7 17 19 -1 14 8 3 11 20 19 -1 19 -1 4 6 21 19 -1 15 9 22 23 24 25 19 -1
Probabilistic Abstraction Hierarchies .	global optimization algorithms ; real data ; clustering data ; probabilistic framework ; prob-abilistic model ; theoretical analysis ; synthetic data ; abstraction hierarchy ; local maxima ; local steps ; noise ; clusters ; taxonomy ; sensitivity	<method> <material> <task> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	3 0 2 ; 0 0 3	many domains are naturally organized in an <otherscientificterm_7> or <otherscientificterm_12> , where the instances in '' nearby '' classes in the <otherscientificterm_12> are similar . in this paper , we provide a general <method_3> for <task_2> into a set of classes organized as a <otherscientificterm_12> , where each class is associated with a <method_4> from which the data was generated . the <method_3> simultaneously optimizes three things : the assignment of data instances to <otherscientificterm_11> , the models associated with the <otherscientificterm_11> , and the structure of the <otherscientificterm_7> . a unique feature of our <method_3> is that <method_3> utilizes <method_0> for both of the last two steps , reducing the <metric_13> to <otherscientificterm_10> and the propensity to <otherscientificterm_8> that are characteristic of algorithms that only take <otherscientificterm_9> . we provide a <method_5> for our <method_3> , showing that <method_3> converges to a local maximum of the probability of model and data . we present experimental results on <material_6> , and on <material_1> in the domains of gene expression and text .	7 12 14 -1 3 2 4 15 14 -1 11 14 -1 16 14 -1 0 13 10 8 9 14 -1 5 14 -1
Stereo from uncalibrated cameras .	projective invariants of 3-d geometric configurations ; uncalibrated perspective views ; camera calibration ; model restrictions ; iterative methods ; image correspondences ; perspective views ; camera parameters	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm>	4 1 5 ; 4 1 3	this paper considers the problem of computing placement of points in 3 dimensional space given two <otherscientificterm_1> . the main theorem shows that the placement of the points is determined only up to an arbitrary projective transformation of 3-space . given additional ground control points , however , the location of the points and the <otherscientificterm_7> may be determined . the method is linear and non-iterative whereas previously known methods for solving the <task_2> and placement to take proper account of both ground-control points and <material_5> are unsatisfactory in requiring either <method_4> or <otherscientificterm_3> . as a result of the main theorem , it is possible to determine <otherscientificterm_0> from two <otherscientificterm_6> .	1 8 -1 8 -1 7 8 -1 2 5 4 3 9 10 8 -1 8 -1
Speaker clustering for speech recognition using the parameters characterizing vocal-tract dimensions .	speaker-clustered tied-state hmms ; baseline gender dependent model ; vocal-tract-size related articulatory parameters ; gross vocal-tract dimensions ; speaker clustering methods ; japanese phoneme recognition ; recognition error reduction ; vocal-tract parameters ; speaker clusters ; clustering method ; acoustic criteria ; cluster	<method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	7 0 9 ; 9 0 6 ; 0 0 11 ; 2 0 4 ; 10 0 8 ; 0 0 5	we propose <method_4> based on the <otherscientificterm_2> associated with individual speakers . two parameters characterizing <otherscientificterm_3> are rst derived from formants of speaker-specic japanese vowels , and are then used to <otherscientificterm_11> a total of 148 male japanese speakers . the resultant <otherscientificterm_8> are found to be signicantly dierent from the <otherscientificterm_8> obtained by conventional <otherscientificterm_10> . <task_5> experiments are carried out using <method_0> trained for each <otherscientificterm_11> . compared with the <method_1> , 5.7 % of <task_6> has been achieved based on the <method_9> using <otherscientificterm_7> .	4 2 16 12 -1 3 11 12 -1 8 10 5 17 12 -1 0 15 18 12 -1 1 6 9 7 13 14 12 -1
Unsupervised Learning from Narrated Instruction Videos .	video and natural language narration ; narrated instruction videos ; joint modeling video ; internet instruction videos ; annotated dataset ; unsupervised manner ; car tire ; joint model ; single-modality baselines	<task> <material> <material> <material> <material> <method> <otherscientificterm> <method> <otherscientificterm>	4 0 3 ; 7 0 0 ; 1 0 6 ; 5 0 7 ; 7 4 8	we address the problem of automatically learning the main steps to complete a certain task , such as changing a <otherscientificterm_6> , from a set of <material_1> . the contributions of this paper are threefold . first , we develop a <method_7> for <task_0> that takes advantage of the complementary nature of the two signals . second , we collect an <material_4> of 57 <material_3> containing more than 350,000 frames for two tasks -lrb- changing <otherscientificterm_6> and cardiopulmonary resuscitation -rrb- . third , we experimentally demonstrate that the proposed <method_7> automatically discovers , in an <method_5> , the main steps to achieve each task and locate them within the input videos . the results further show that the proposed <method_7> outperforms <otherscientificterm_8> , demonstrating the benefits of <material_2> and text .	6 1 12 9 -1 9 -1 7 0 11 9 -1 4 3 10 9 -1 5 13 9 -1 14 9 -1
A computationally efficient refinement of the fundamental frequency estimate for the Adaptive Harmonic Model .	full-band adaptive harmonic model ; adaptive iterative refinement algorithm ; adaptive discrete fourier transform ; least squares solution ; peak picking approach ; ls solution approach ; f 0 curve ; average time reduction ; speech recording ; frequency basis ; ahm-air ; quality	<method> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <method> <metric>	0 0 4 ; 1 0 8 ; 4 0 3 ; 7 5 5	the <method_0> can be used by the <method_1> to accurately model the perceived characteristics of a <task_8> . however , the <method_3> used in the current <method_10> makes the f 0 refinement in air time consuming , limiting the use of this algorithm for large databases . in this paper , a <method_4> is suggested as a substitution to the <method_3> . in order to integrate the adaptivity scheme of <method_0> in the <method_4> , an <method_2> is also suggested in this paper , whose <otherscientificterm_9> can fully follow the frequency variations of the <otherscientificterm_6> . evaluations have shown an <metric_7> of 5.5 times compared to the <method_5> , while the <metric_11> of the re-synthesis is preserved compared to the original <method_10> .	0 1 8 14 12 -1 3 10 12 -1 4 15 12 -1 2 9 6 13 12 -1 16 12 -1
An Adaptive Descriptor Design for Object Recognition in the Wild .	domain adaptation data set ; robust object recognition system ; pixel mapping function g ; oxford flower data set ; flower data set ; g-incorporated kernel descriptor ; post processing functions ; photography effect filters ; gradient-based image descriptors ; ` picture styles ; picture styles ; image de-scriptors ; digital images ; color tone ; scene radiance ; adaptive approach ; image styles ; object recognition ; kernel learning ; photography effects ; contrast ; vignetting ; recognition ; descriptors ; complexity ; post-processing	<material> <method> <otherscientificterm> <material> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <metric> <method>	10 0 17 ; 20 1 21 ; 5 0 15 ; 7 6 6 ; 11 0 10 ; 11 0 17 ; 11 1 2 ; 22 5 15 ; 2 0 10 ; 13 1 20	digital images nowadays show large appearance vari-abilities on <material_10> , in terms of <otherscientificterm_13> , <otherscientificterm_20> , <otherscientificterm_21> , and etc. . these <otherscientificterm_9> ' are directly related to the <otherscientificterm_14> , image pipeline of the camera , and <otherscientificterm_6> -lrb- e.g. , <otherscientificterm_7> -rrb- . due to the <metric_24> and nonlinearity of these factors , popular <otherscientificterm_8> generally are not invariant to different <material_10> , which could degrade the performance for <task_17> . given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various <otherscientificterm_6> , to find a <method_1> is useful and challenging . in this paper , we investigate the influence of <material_10> on <task_17> by making a connection between <otherscientificterm_11> and a <otherscientificterm_2> , and accordingly propose an <method_15> based on a <method_5> and multiple <method_18> , without estimating or specifying the <otherscientificterm_16> used in training and testing . we conduct experiments on the <material_0> , the <material_3> , and several variants of the <material_4> by introducing popular <otherscientificterm_19> through <method_25> . the results demonstrate that the proposed <method_15> consistently yields <task_22> improvements over standard <method_23> in all studied cases .	10 13 20 21 28 36 26 -1 9 14 6 7 30 26 -1 24 8 17 26 -1 26 -1 1 27 29 31 32 33 35 26 -1 11 2 15 5 18 16 26 -1 0 3 4 19 25 34 26 -1
Analysis of subspace within-class covariance normalization for SVM-based speaker verification .	linear discriminant analysis ; within-class covariance normalization ; nuisance attribute projection ; svm based speaker verification systems ; low dimensional feature space ; nist sre tasks ; intersession variability compensation ; discriminative training ; nuisance subspace ; feature space ; session variability ; subspace	<method> <method> <method> <task> <otherscientificterm> <material> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 7 ; 2 1 1 ; 6 0 3 ; 1 0 6 ; 1 0 1 ; 1 4 1	nuisance attribute projection -lrb- nap -rrb- and <method_1> are two effective techniques for <task_6> in <task_3> . however , by normalizing or removing the <otherscientificterm_8> containing the <otherscientificterm_10> can not guarantee to enlarge the distance between speakers . in this paper , we investigated the probability of using <method_0> for <task_7> . to cope with the small sample size problem which prevents us from using <method_0> directly , we adapted the <method_1> , which first projects the whole <otherscientificterm_9> into a relatively low dimensional <otherscientificterm_11> by <method_0> , and then performs <method_0> in the <otherscientificterm_11> . by some modification , the <method_1> can be degenerated into a kind of <method_1> , which we called <method_1> . experiments on <material_5> showed that , the <method_1> outperformed the conventional <method_1> , especially in <otherscientificterm_4> .	1 6 3 14 15 16 12 -1 8 10 12 -1 0 7 13 12 -1 9 11 12 -1 17 12 -1 18 12 -1
Classification of depression state based on articulatory precision .	support vector machine classifiers ; gaussian mixture model ; clinical measures of depression severity ; vocal tract formant frequencies ; automatically classifying depression state ; formant frequency tracks ; major depression disorder ; articulatory features ; formant-based characterization ; neurophysiological changes ; formant frequencies ; articulatory precision ; depression state ; speech production ; conversational speech ; dynamic features ; sustained vowels ; vocal source ; velocity ; sensitivity/specificity/area ; gmms ; audio	<method> <method> <metric> <material> <task> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <material> <otherscientificterm> <material> <material> <otherscientificterm> <method> <otherscientificterm> <material>	1 0 20 ; 3 1 15 ; 20 1 0 ; 17 1 8 ; 11 2 13 ; 16 1 15 ; 16 1 14 ; 1 1 0 ; 1 0 0 ; 5 0 7	neurophysiological changes in the brain associated with <otherscientificterm_6> can disrupt <metric_11> in <task_13> . motivated by this observation , we address the hypothesis that <otherscientificterm_7> , as manifested through <material_5> , can help in <task_4> . specifically , we investigate the relative importance of <material_3> and their <otherscientificterm_15> from <material_16> and <material_14> . using a database consisting of <material_21> from 35 subjects with <metric_2> , we explore the performance of <method_1> and <method_0> . with only <otherscientificterm_10> and their dynamics given by <otherscientificterm_18> and acceleration , we show that <otherscientificterm_12> can be classified with an optimal <method_19> under the <method_1> for <otherscientificterm_20> and <method_0> , respectively . future work will involve merging our <method_8> with <material_17> and prosodic features .	6 11 13 27 22 -1 7 5 4 32 22 -1 3 15 16 14 24 28 29 22 -1 21 2 1 0 30 22 -1 10 18 12 19 23 25 31 22 -1 20 26 22 -1
Word Sense Disambiguation by Relative Selection .	co-occurrence frequency matrix ; word sense disam-biguation ; raw corpora ; english datum ; hypernyms ; meronyms ; synonyms	<otherscientificterm> <method> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 1 4 ; 4 1 5	this paper describes a novel method for a <method_1> that utilizes relatives -lrb- i.e. <otherscientificterm_6> , <otherscientificterm_4> , <otherscientificterm_5> , etc in wordnet -rrb- of a target word and <material_2> . the method disam-biguates senses of a target word by selecting a relative that most probably occurs in a new sentence including the target word . only one <otherscientificterm_0> is utilized to efficiently disambiguate senses of many target words . experiments on several <material_3> present that our proposed method achieves a good performance .	1 6 4 5 2 8 9 7 -1 7 -1 0 7 -1 3 7 -1
Scalable distributed Kalman filtering through consensus .	data driven average consensus framework ; communication resource allocation policy ; scal-able wireless communication architecture ; component-wise state estimation error ; distributed kalman filtering ; distributed filtering computations ; wireless sensor networks ; distributed application ; kalman filtering ; classical problem ; filtering	<method> <method> <method> <otherscientificterm> <method> <method> <task> <task> <method> <task> <task>	0 0 2 ; 7 0 6	kalman <task_10> is a <task_9> of significant interest in the context of a <task_7> for <task_6> . in this paper we consider a specific algorithm for <method_4> proposed recently by olfati-saber -lsb- 1 -rsb- and present a <method_2> suited for implementation in <task_6> . the proposed <method_2> uses a <method_0> . this allows us to explicitly characterize the delay vs. estimate accuracy tradeoff in <task_10> . by exploiting the structure of the <method_5> , we derive an optimal <method_1> for minimizing the <otherscientificterm_3> . furthermore , our <method_2> is scalable in terms of the network size n . we provide simulation results demonstrating the performance of our <method_2> .	10 9 7 6 13 11 -1 4 2 11 -1 0 12 11 -1 11 -1 5 1 3 11 -1 11 -1 11 -1
Shape priors in variational image segmentation : Convexity , Lipschitz continuity and globally optimal solutions .	global versus local optimality ; implicit representation of shape ; probabilis-tic representation of shape ; mild regularity assumptions ; space of shapes ; level set method ; statistical shape priors ; implicit shape representations ; variational image segmentation ; shape priors ; shape deformations ; pixel ; tracking ; segmentation	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	13 1 12 ; 4 6 7 ; 9 0 8	in this work , we introduce a novel <method_1> which is based on assigning to each <otherscientificterm_11> a probability that this <otherscientificterm_11> is inside the shape . this <otherscientificterm_2> resolves two important drawbacks of alternative <method_7> such as the <method_5> : firstly , the <otherscientificterm_4> is convex in the sense that arbitrary convex combinations of a set of shapes again correspond to a valid shape . secondly , we prove that the introduction of <otherscientificterm_9> into <task_8> leads to functionals which are convex with respect to <otherscientificterm_10> . for a large class of commonly considered -lrb- spatially continuous -rrb- functionals , we prove that -- under <otherscientificterm_3> -- <otherscientificterm_13> and <task_12> with <otherscientificterm_6> can be performed in a globally optimal manner . in experiments on <task_12> a walking person through a cluttered scene we demonstrate the advantage of <otherscientificterm_0> .	1 11 14 -1 2 7 5 4 16 14 -1 9 8 10 17 14 -1 15 14 -1 3 13 12 6 14 -1
Approximate signal processing using incremental refinement and deadline-based algorithms .	multi-stage incremen-tal reenement algorithms ; approximate signal processing ; design criteria ; computational cost ; solution quality ; tradeoo	<method> <task> <metric> <metric> <metric> <otherscientificterm>	4 1 3	a framework for <task_1> is introduced which can be used to design novel classes of algorithms for performing dft and stft calculations . in particular , we focus on the derivation of <method_0> that meet a variety of <metric_2> on the <otherscientificterm_5> achieved at each stage between <metric_4> and <metric_3> .	1 6 -1 0 2 5 4 3 7 6 -1
Improved Speaker Model Migration Via Stochastic Synthesis .	stochastic synthesis of feature sequences ; baseline mean-only migration technique ; nist 2003 cellular task ; speaker recognition technology ; statistical migration technique ; gaussian mixture models ; user voice accounts ; waveform storage ; migrated models ; configuration changes ; mean-only method ; speaker recognition ; covariance information ; speech waveforms ; legacy problems ; parametrically-obsolete models ; gaussian means ; model migration ; migrated accounts ; mismatch ; accuracy ; priors ; migration	<material> <method> <material> <method> <method> <method> <material> <task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <material> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	2 5 4 ; 16 1 21 ; 8 4 10 ; 5 0 4 ; 0 0 4 ; 17 0 11 ; 4 0 17 ; 3 0 17 ; 3 0 14 ; 0 0 17	model <otherscientificterm_22> in <task_11> is a task of converting <method_15> to new structures and configurations without the requirement to store the original <otherscientificterm_13> or feature vector sequences along with the <task_17> . the need for <task_17> arises in large-scale deployments of <method_3> in which the potential for <task_14> increases as the evolving technology may require <otherscientificterm_9> thus invalidating already existing <material_6> . a <otherscientificterm_22> may represent the only alternative to otherwise costly user re-enrollment or <task_7> and , as a new research problem , presents the challenge of developing algorithms to minimize the loss in <metric_20> in the <material_18> . this paper reports on further enhancements of a <method_4> based on <method_5> , introduced previously . the present <method_4> is based on a <material_0> from obsolete <task_17> that are subsequently used to create the new <task_17> . here , in addition to <method_16> and <otherscientificterm_21> , as utilized in the previous contribution , also the covariances are included resulting in significant performance gains in the <method_8> , compared to the <method_10> . overall , measured on the <material_2> , the described <method_4> achieves a <task_17> incurring a loss in performance of 8-20 % relative to a full re-enrollment from waveforms , dependent on the type of <otherscientificterm_19> between the obsolete and the new configuration . the inclusion of the <otherscientificterm_12> is shown to reduce the loss of performance by a factor of 3-4 as compared to the <method_1> .	22 11 15 13 17 29 23 -1 3 14 9 6 31 32 23 -1 7 20 18 23 -1 27 23 -1 4 5 28 33 23 -1 0 25 26 23 -1 16 21 8 10 24 30 23 -1 2 23 -1
Interactive visualization of human-machine dialogs .	directed-dialog and natural-language applications ; empirical dialog trajectory analysis ; automated spoken dialog systems ; stochastic finite state machines ; automatic tokenization procedure ; feed of call-logs ; dialog system developers ; diagnosing problems ; fine-grained analysis ; call data ; business intelligence ; systematic procedures ; system evaluation ; interactive tool ; complexity ; web ; dialog	<task> <method> <method> <otherscientificterm> <method> <method> <method> <task> <method> <material> <task> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm>	12 1 10 ; 8 0 12 ; 3 6 1 ; 4 0 14 ; 11 0 2 ; 8 0 10	automated spoken dialog <method_2> require <method_11> for evaluating performance and <task_7> . we present an <method_13> that provides graphical views of how callers navigate through such <method_2> , enabling <method_8> for <task_12> and <task_10> . the input is a <method_5> . the output is an <method_1> represented as <otherscientificterm_3> , accessible via the <material_15> . <otherscientificterm_14> is managed by an <method_4> that hides fine details until needed . users can generate selective views of parts of the <otherscientificterm_16> at high resolution -lrb- with access to <material_9> -rrb- , or zoom out to a summary . the <method_13> provides <method_6> with all the information they need from a single source , and is in use with <task_0> .	2 11 7 22 17 -1 13 8 12 10 18 19 23 17 -1 5 17 -1 1 3 15 14 20 17 -1 4 21 17 -1 16 9 17 -1 6 17 -1
Active contours : an overview with applications to motion artifact cancellation in MRI .	actit -rrb- e contours ; motio ~ l parameters ; motion model parameters ; noise-free mr ima ; motion artifacts ; motion parameters ; patient motion ; subband images ; relative motion ; ying time ; edges ; motion ; mri ; k-space ; subbands	<method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm>	12 0 4	motion can be estimated by detectirtg the <otherscientificterm_10> of a mof -rrb- iny object using <method_0> , and registering them to , yether to obtain the <otherscientificterm_2> . this idea can be applied to <task_6> during the acquisition of an <method_12> to eliminate <otherscientificterm_4> in the image . the data obtained durin , y the <method_12> acquzs-tio ~ ~ , the <otherscientificterm_13> , can be dil -rsb- ided into several . <otherscientificterm_14> such that each subband is acquired in a small fraction of the full ima , <otherscientificterm_9> . these sub bands create in -lsb- -rsb- -lrb- ~ riant tissue feature maps called <material_7> . usin , q acti ~ le contours , the <otherscientificterm_8> is analyzed acros ~ th -lrb- ' diferent sub bor -rrb- , d image ~ to determine the <otherscientificterm_1> . usin , y these <otherscientificterm_5> at ispossible to correct the <otherscientificterm_14> , thus correctin , y the k ; - sp -lrb- ~ ce . this has the potential to yield clear , <material_3> , ye.s .	10 0 2 15 -1 6 12 4 16 15 -1 13 14 15 -1 9 15 -1 15 -1 7 15 -1 8 1 15 -1 5 15 -1
Learning a World Model and Planning with a Self-Organizing , Dynamic Neural System .	local and adaptation ; growing self-organizing layer ; hebbian ideas ; motor layer ; connectionist architecture ; state transitions ; state representations ; planning process ; lateral connectivity ; motor signals ; behavior planning ; dynamic field ; perceptions ; layer ; perception	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 7 ; 14 1 3	we present a <method_4> that can learn a model of the relations between <otherscientificterm_12> and actions and use this model for <task_10> . <method_6> are learned with a <otherscientificterm_1> which is directly coupled to a <otherscientificterm_14> and a <otherscientificterm_3> . knowledge about possible <otherscientificterm_5> is encoded in the <otherscientificterm_8> . <material_9> modulate this <otherscientificterm_8> and a <otherscientificterm_11> on the <otherscientificterm_13> organizes a <task_7> . all mechanisms are <otherscientificterm_0> is based on <otherscientificterm_2> . the model is continuous in the action , <otherscientificterm_14> , and time domain .	4 12 10 6 15 -1 1 14 3 17 15 -1 5 8 9 15 -1 11 13 7 16 15 -1 0 2 15 -1 15 -1
Semantic Kernels for Semantic Parsing .	concept seg-mentation and labeling ; semantic tree kernels ; semantic parsing ; semantic information ; semantic similarity ; semantic kernels ; similarity measures ; restaurant domain ; csl parser ; tree structures ; brown clusters ; processing structures ; classifier	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <method> <method>	4 0 1 ; 3 0 0 ; 11 3 12 ; 10 6 1 ; 6 0 5 ; 4 0 12	we present an empirical study on the use of <otherscientificterm_3> for <task_0> , which is an important step for <task_2> . we represent the alternative analyses output by a state-of-the-art <method_8> with <otherscientificterm_9> , which we rerank with a <method_12> trained on two types of <otherscientificterm_1> : one <method_11> built with words , concepts and <otherscientificterm_10> , and another one using <otherscientificterm_4> among the words composing the structure . the results on a corpus from the <material_7> show that our <method_5> exploiting <method_6> out-perform state-of-the-art rerankers .	3 0 2 15 13 -1 8 9 12 1 11 10 4 14 16 17 19 13 -1 7 5 6 18 13 -1
Outlier-aware robust clustering .	machine learning applications ; scarcity of outliers ; judiciously defined domain ; well-separated subsets ; input vectors ; fuzzy k-means ; outlier-aware algorithms ; clustering schemes ; outlier-agnostic counterparts ; hard k-means ; model-incompatible inputs ; probabilistic clustering ; computational complexity ; closed form ; cluster centers ; outliers ; sparsity ; clustering	<task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	5 6 7 ; 11 6 7 ; 9 1 5 ; 15 6 10 ; 5 1 11 ; 12 4 8	clustering is a basic task in a variety of <task_0> . partitioning a set of <otherscientificterm_4> into compact , <otherscientificterm_3> can be severely affected by the presence of <otherscientificterm_10> called <otherscientificterm_15> . the present paper develops robust clustering algorithms for jointly partitioning the data and identifying the <otherscientificterm_15> . the novel approach relies on translating <otherscientificterm_1> to <otherscientificterm_16> in a <material_2> , to ro-bustify three widely used <method_7> : <method_9> , <otherscientificterm_5> , and <method_11> . <method_14> and assignments are iteratively updated in <otherscientificterm_13> . the developed <method_6> are guaranteed to converge , while their <metric_12> is of the same order as their <otherscientificterm_8> . preliminary simulations validate the analytical claims .	0 18 -1 4 3 10 15 22 18 -1 18 -1 1 16 2 7 9 5 11 14 19 20 21 23 18 -1 13 18 -1 6 12 24 18 -1 8 18 -1
Description of the NCU Chinese Word Segmentation and Part-of-Speech Tagging for SIGHAN Bakeoff 2007 .	support vector machine based chunking model ; conditional random fields ; part-of-speech tagging ; pos tagging task ; sequential tagging models ; language processing ; predefined dictionaries ; ws task ; word segmentation ; syntactic labels ; segmented word ; pos tag ; word boundaries ; rank ; chinese	<method> <otherscientificterm> <method> <task> <method> <task> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	11 3 3 ; 0 0 11 ; 6 0 12 ; 8 1 2 ; 8 0 5	in <material_14> , most of the <task_5> starts from <task_8> and <method_2> . these two steps tokenize the word from a sequence of characters and predict the <otherscientificterm_9> for each <otherscientificterm_10> . in this paper , we present two distinct <method_4> for the above two tasks . the first <method_4> was basically similar to previous work which made use of <otherscientificterm_1> and set of <otherscientificterm_6> to recognize <otherscientificterm_12> . second , we revise and modify <method_0> to label the <otherscientificterm_11> in the <task_3> . our <method_0> in the <task_7> achieves moderately <otherscientificterm_13> among all participants , while in the <task_3> , it reaches very competitive results .	14 5 8 2 19 20 15 -1 9 10 15 -1 4 15 -1 1 6 12 18 15 -1 0 11 3 16 17 15 -1 7 13 15 -1
Instantaneous frequency estimation based on the robust spectrogram .	rspec based instantaneous frequency estimator ; rare high magnitude noise values ; analysis of nonstationary signals ; rspec based if estimation ; analysis of signals ; time-varying window length ; heavy-tailed distribution noise ; adaptive algorithm ; bias-variance trade-off ; robust m-periodogram ; window length ; accuracy	<method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric>	0 0 2 ; 6 2 4 ; 5 0 0	robust m-periodogram is defined for the <task_4> with <otherscientificterm_6> . in the form of a robust spectrogram -lrb- rspec -rrb- <method_0> can be used for the <task_2> . in this paper a <method_0> , with a <otherscientificterm_5> , is presented . the optimal choice of the <otherscientificterm_10> can resolve the <otherscientificterm_8> in the <method_3> . however , <method_0> depends on the unknown nonlinearity of the <method_0> . the <method_0> used in this paper is able to provide the <metric_11> close to the one that could be achieved if the <method_0> , to be estimated , were known in advance . simulations show good <metric_11> ability of the <method_7> and good robustness property with respect to <otherscientificterm_1> .	4 6 14 12 -1 0 2 13 12 -1 5 15 12 -1 10 8 3 12 -1 12 -1 11 12 -1 12 -1
Evaluation of random-projection-based feature combination on speech recognition .	vote-based random-projection combination ; speech feature extraction ; speech recognition accuracy ; computationally simple method ; random matrices ; random projection ; dimension-ality reduction ; word recognition ; euclidean distance ; random-projection-based features ; random projection ; random matrix ; sub-space ; projection	<method> <task> <metric> <method> <otherscientificterm> <task> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 9 ; 10 0 1 ; 3 0 8	random <otherscientificterm_13> has been suggested as a means of <task_6> , where the original data are projected onto a <otherscientificterm_12> using a <otherscientificterm_11> . it represents a <method_3> that approximately preserves the <otherscientificterm_8> of any two points through the <otherscientificterm_13> . moreover , as we are able to produce various <otherscientificterm_4> , there may be some possibility of finding a <otherscientificterm_11> that gives a better <metric_2> among these <otherscientificterm_4> . in this paper , we investigate the feasibility of <task_10> for <task_1> . to obtain an optimal result from among many -lrb- infinite -rrb- <otherscientificterm_4> , a <method_0> is introduced in this paper , where <method_0> is applied to <otherscientificterm_9> . its effectiveness is confirmed by <task_7> experiments .	13 6 12 11 14 -1 3 8 17 14 -1 4 2 14 -1 10 1 16 14 -1 0 15 14 -1 9 14 -1
Towards Internet-scale multi-view stereo .	multi-view stereo methods ; overlapping clustering problem ; unstructured photo collections ; global visibility constraints ; low-quality reconstructions ; merging algorithm ; 3d reconstruction ; constrained optimization ; filtering steps ; flickr.com	<method> <task> <material> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <material>	7 0 1	this paper introduces an approach for enabling existing <method_0> to operate on extremely large <material_2> . the main idea is to decompose the collection into a set of overlapping sets of photos that can be processed in parallel , and to merge the resulting reconstructions . this <task_1> is formulated as a <method_7> and solved iteratively . the <method_5> , designed to be parallel and out-of-core , incorporates robust <method_8> to eliminate <otherscientificterm_4> and enforce <otherscientificterm_3> . the approach has been tested on several large datasets downloaded from <material_9> , including one with over ten thousand images , yielding a <task_6> with nearly thirty million points .	0 2 10 -1 10 -1 1 7 11 10 -1 5 8 4 3 10 -1 9 10 -1
Reshaping Visual Datasets for Domain Adaptation .	image or video datasets ; training and test data ; human activity recognition tasks ; visual recognition problems ; data distribution mismatches ; adaptation algorithms ; image data ; nonparametric formulation ; domain adaptation ; maximum extent ; latent domains ; discrete domains ; optimization procedure ; object recognition ; maximum learnability ; maximum distinctiveness ; discriminative model ; pose ; resolution ; background	<material> <material> <task> <task> <otherscientificterm> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 3 0 ; 5 0 11 ; 19 1 18 ; 17 1 18 ; 13 1 2 ; 6 0 11 ; 15 1 14 ; 7 0 12 ; 17 1 19	in <task_3> , the common <otherscientificterm_4> between training and testing make <task_8> essential . however , <material_6> is difficult to manually divide into the <otherscientificterm_11> required by <method_5> , and the standard practice of equating datasets with domains is a weak proxy for all the real conditions that alter the statistics in complex ways -lrb- lighting , <otherscientificterm_17> , <otherscientificterm_19> , <otherscientificterm_18> , etc. -rrb- we propose an approach to automatically discover <otherscientificterm_10> in <material_0> . our formulation imposes two key properties on domains : <otherscientificterm_15> and <otherscientificterm_14> . by <otherscientificterm_15> , we require the underlying distributions of the identified domains to be different from each other to the <otherscientificterm_9> ; by <otherscientificterm_14> , we ensure that a strong <method_16> can be learned from the domain . we devise a <method_7> and efficient <method_12> that can successfully discover domains among both <material_1> . we extensively evaluate our approach on <task_13> and <task_2> .	3 4 8 20 -1 6 11 5 17 19 18 10 0 21 22 23 24 26 29 20 -1 15 14 27 20 -1 20 -1 9 16 28 20 -1 7 12 1 25 20 -1
Smart decoder : A new paradigm for video coding .	high efficiency video coding ; video coding standard ; average bitrate saving ; signal coding modes ; coding efficiency ; coding scheme ; video sequences ; coding modes ; causal references ; signaling bitrate ; spatio-temporal redundancies ; encoder ; en-coder ; hevc ; decoder	<method> <method> <metric> <otherscientificterm> <metric> <method> <material> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method>	2 5 13 ; 8 0 5 ; 14 0 11	the <metric_4> of the new <method_1> , <method_0> , is strongly associated with better use of <method_10> thanks to an increased number of competing <method_7> . however , this competition involves a massive increase in <otherscientificterm_9> which becomes a possible limit for the next generation of <otherscientificterm_12> . this paper proposes a new <method_5> that breaks with conventional approaches . <method_5> exploits a more complex <method_14> able to reproduce the choice of the <otherscientificterm_11> based on <otherscientificterm_8> , eliminating thus the need to <otherscientificterm_3> and associated parameters . the general outline of this new <method_5> and a proposed implementation are described in this paper . experimental results under common test conditions report an <metric_2> of 1.7 % at the same quality compared to <method_13> for a wide range of <material_6> .	4 1 0 10 7 15 -1 9 12 15 -1 5 15 -1 14 11 8 3 17 18 15 -1 15 -1 16 15 -1
Predicting the Performance of IDA * with Conditional Distributions .	static distribution of heuristic values ; conditional distribution of heuristic values ; single start states ; inconsistent heuristics ; random sample ; start states ; static distribution ; heuristic ; accuracy	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <metric>	6 0 1	-lrb- korf , reid , and edelkamp 2001 -rrb- introduced a formula to predict the number of nodes ida * will expand given the <otherscientificterm_0> . their formula proved to be very accurate but it is only accurate under the following limitations : -lrb- 1 -rrb- the <method_7> must be consistent ; -lrb- 2 -rrb- the prediction is for a large <material_4> of <otherscientificterm_5> -lrb- or for large thresholds -rrb- . in this paper we generalize the <otherscientificterm_6> to a <otherscientificterm_1> . we then propose a new formula for predicting the performance of ida * that works well for <method_3> -lrb- zahavi et al. 2007 -rrb- and for any set of <otherscientificterm_5> , not just a <material_4> . we also show how the formula can be enhanced to work well for <otherscientificterm_2> . experimental results demonstrate the <metric_8> of our method in all these situations .	0 9 -1 7 4 5 9 -1 6 1 10 9 -1 3 9 -1 9 -1 2 9 -1
Particle swarm optimization based channel identification in cross-ambiguity domain .	generalized expectation maximization technique ; particle swarm optimization ; array signal processing technique ; pso based technique ; multipath channel parameters ; channel parameters ; optimization problem ; transmitted signal ; snr values	<method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm>	1 0 2 ; 1 4 3 ; 2 0 4 ; 1 4 0 ; 3 0 8	in this paper , a new <method_2> by using <method_1> is proposed to identify <otherscientificterm_4> . the proposed <method_2> provides estimates to the <otherscientificterm_5> by finding a global minimum of an <task_6> . since the <task_6> is formulated in the cross-ambiguity function -lrb- caf -rrb- domain of the <material_7> and the received array outputs , the proposed <method_2> is called as <method_1> . the performance of the <method_1> is compared with the space alternating <method_0> and with another recently proposed <method_3> for various <otherscientificterm_8> . simulation results indicate the superior performance of the <method_3> over mentioned techniques for all <otherscientificterm_8> .	2 1 4 10 12 9 -1 5 6 9 -1 7 9 -1 0 3 8 11 13 14 9 -1 9 -1
